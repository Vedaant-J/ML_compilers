class GraphModule(torch.nn.Module):
    def forward(self, primals_1: "f32[2, 3, 100, 100]", primals_2: "f32[8, 3, 3, 3]", primals_3: "f32[8]"):
         # File: /opt/pytorch/lib/python3.12/site-packages/torch/nn/functional.py:5209 in pad, code: return torch._C._nn.pad(input, pad, mode, value)
        constant_pad_nd: "f32[2, 3, 102, 102]" = torch.ops.aten.constant_pad_nd.default(primals_1, [1, 1, 1, 1], 0.0);  primals_1 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:43 in im2col_manual, code: starting_rows = torch.arange(0, self.H+2*P-KH+1, step=S)
        iota: "i64[100]" = torch.ops.prims.iota.default(100, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:45 in im2col_manual, code: grid_rows, grid_cols = torch.meshgrid(starting_rows, starting_cols, indexing='ij')
        view: "i64[100, 1]" = torch.ops.aten.reshape.default(iota, [-1, 1])
        expand: "i64[100, 100]" = torch.ops.aten.expand.default(view, [100, 100]);  view = None
        view_1: "i64[1, 100]" = torch.ops.aten.reshape.default(iota, [1, -1]);  iota = None
        expand_1: "i64[100, 100]" = torch.ops.aten.expand.default(view_1, [100, 100]);  view_1 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:46 in im2col_manual, code: row_patches = grid_rows.flatten()
        clone: "i64[100, 100]" = torch.ops.aten.clone.default(expand, memory_format = torch.contiguous_format);  expand = None
        view_2: "i64[10000]" = torch.ops.aten.reshape.default(clone, [10000]);  clone = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:47 in im2col_manual, code: row_patches = row_patches.view(-1, 1) + torch.arange(KH).view(1, -1) # (out_h*out_w, KH)
        view_3: "i64[10000, 1]" = torch.ops.aten.reshape.default(view_2, [-1, 1]);  view_2 = None
        iota_2: "i64[3]" = torch.ops.prims.iota.default(3, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
        view_4: "i64[1, 3]" = torch.ops.aten.reshape.default(iota_2, [1, -1]);  iota_2 = None
        add: "i64[10000, 3]" = torch.ops.aten.add.Tensor(view_3, view_4);  view_3 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:48 in im2col_manual, code: col_patches = grid_cols.flatten()
        clone_1: "i64[100, 100]" = torch.ops.aten.clone.default(expand_1, memory_format = torch.contiguous_format);  expand_1 = None
        view_5: "i64[10000]" = torch.ops.aten.reshape.default(clone_1, [10000]);  clone_1 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:49 in im2col_manual, code: col_patches = col_patches.view(-1, 1) + torch.arange(KW).view(1, -1) # (out_h*out_w, KW)
        view_6: "i64[10000, 1]" = torch.ops.aten.reshape.default(view_5, [-1, 1]);  view_5 = None
        add_1: "i64[10000, 3]" = torch.ops.aten.add.Tensor(view_6, view_4);  view_6 = view_4 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:52 in im2col_manual, code: row_patches = row_patches.unsqueeze(-1)
        unsqueeze: "i64[10000, 3, 1]" = torch.ops.aten.unsqueeze.default(add, -1);  add = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:53 in im2col_manual, code: col_patches = col_patches.unsqueeze(1)
        unsqueeze_1: "i64[10000, 1, 3]" = torch.ops.aten.unsqueeze.default(add_1, 1);  add_1 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:55 in im2col_manual, code: patches = x_pad[:, :, row_patches, col_patches].permute(0, 2, 1, 3, 4)
        index: "f32[2, 3, 10000, 3, 3]" = torch.ops.aten.index.Tensor(constant_pad_nd, [None, None, unsqueeze, unsqueeze_1]);  constant_pad_nd = unsqueeze = unsqueeze_1 = None
        permute: "f32[2, 10000, 3, 3, 3]" = torch.ops.aten.permute.default(index, [0, 2, 1, 3, 4]);  index = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:56 in im2col_manual, code: patches = patches.reshape(N, int(out_h*out_w), C*KH*KW)
        clone_2: "f32[2, 10000, 3, 3, 3]" = torch.ops.aten.clone.default(permute, memory_format = torch.contiguous_format);  permute = None
        view_8: "f32[2, 10000, 27]" = torch.ops.aten.reshape.default(clone_2, [2, 10000, 27]);  clone_2 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:69 in conv2d_manual, code: weight_flat = self.weight.view(C_out, -1)
        view_9: "f32[8, 27]" = torch.ops.aten.reshape.default(primals_2, [8, -1]);  primals_2 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:70 in conv2d_manual, code: weight_flat = weight_flat.contiguous().t()  # (C*KH*KW, C_out)
        permute_1: "f32[27, 8]" = torch.ops.aten.permute.default(view_9, [1, 0]);  view_9 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:73 in conv2d_manual, code: out = torch.zeros((N, int(self.out_h*self.out_w), C_out), device=x.device)
        full: "f32[2, 10000, 8]" = torch.ops.aten.full.default([2, 10000, 8], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 0, 16)
        slice_5: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:78 in conv2d_manual, code: weight_tile = weight_flat[k:k+TILE_SIZE, j:j+TILE_SIZE] # (TILE_SIZE, TILE_SIZE)
        slice_6: "f32[16, 8]" = torch.ops.aten.slice.Tensor(permute_1, 0, 0, 16)
        slice_7: "f32[16, 8]" = torch.ops.aten.slice.Tensor(slice_6, 1, 0, 16);  slice_6 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(full, 1, 0, 16)
        slice_10: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9, 2, 0, 16);  slice_9 = None
        clone_3: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5, memory_format = torch.contiguous_format);  slice_5 = None
        view_10: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_3, [32, 16]);  clone_3 = None
        mm: "f32[32, 8]" = torch.ops.aten.mm.default(view_10, slice_7)
        view_11: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm, [2, 16, 8]);  mm = None
        add_2: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10, view_11);  slice_10 = view_11 = None
        
        # No stacktrace found for following nodes
        slice_tensor: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(full, 1, 0, 16)
        slice_scatter_default: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor, add_2, 2, 0, 16);  slice_tensor = add_2 = None
        slice_scatter_default_1: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(full, slice_scatter_default, 1, 0, 16);  slice_scatter_default = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1, 1, 0, 16)
        slice_15: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14, 2, 0, 16);  slice_14 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1, 1, 0, 16)
        slice_scatter_default_2: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1, slice_15, 2, 0, 16);  slice_tensor_1 = slice_15 = None
        slice_scatter_default_3: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1, slice_scatter_default_2, 1, 0, 16);  slice_scatter_default_1 = slice_scatter_default_2 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4, 2, 16, 32);  slice_4 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:78 in conv2d_manual, code: weight_tile = weight_flat[k:k+TILE_SIZE, j:j+TILE_SIZE] # (TILE_SIZE, TILE_SIZE)
        slice_36: "f32[11, 8]" = torch.ops.aten.slice.Tensor(permute_1, 0, 16, 32);  permute_1 = None
        slice_37: "f32[11, 8]" = torch.ops.aten.slice.Tensor(slice_36, 1, 0, 16);  slice_36 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_4: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35, memory_format = torch.contiguous_format);  slice_35 = None
        view_12: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_4, [32, 11]);  clone_4 = None
        mm_1: "f32[32, 8]" = torch.ops.aten.mm.default(view_12, slice_37)
        view_13: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1, [2, 16, 8]);  mm_1 = None
        slice_42: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3, 1, 0, 16)
        slice_43: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_42, 2, 0, 16);  slice_42 = None
        add_3: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_43, view_13);  slice_43 = view_13 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3, 1, 0, 16)
        slice_scatter_default_4: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2, add_3, 2, 0, 16);  slice_tensor_2 = add_3 = None
        slice_scatter_default_5: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3, slice_scatter_default_4, 1, 0, 16);  slice_scatter_default_3 = slice_scatter_default_4 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_47: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_5, 1, 0, 16)
        slice_48: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_47, 2, 0, 16);  slice_47 = None
        
        # No stacktrace found for following nodes
        slice_tensor_3: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_5, 1, 0, 16)
        slice_scatter_default_6: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_3, slice_48, 2, 0, 16);  slice_tensor_3 = slice_48 = None
        slice_scatter_default_7: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_5, slice_scatter_default_6, 1, 0, 16);  slice_scatter_default_5 = slice_scatter_default_6 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_67: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 16, 32)
        slice_68: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_67, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_5: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_68, memory_format = torch.contiguous_format);  slice_68 = None
        view_14: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_5, [32, 16]);  clone_5 = None
        mm_2: "f32[32, 8]" = torch.ops.aten.mm.default(view_14, slice_7)
        view_15: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_2, [2, 16, 8]);  mm_2 = None
        slice_75: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_7, 1, 16, 32)
        slice_76: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_75, 2, 0, 16);  slice_75 = None
        add_4: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_76, view_15);  slice_76 = view_15 = None
        
        # No stacktrace found for following nodes
        slice_tensor_4: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_7, 1, 16, 32)
        slice_scatter_default_8: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_4, add_4, 2, 0, 16);  slice_tensor_4 = add_4 = None
        slice_scatter_default_9: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_7, slice_scatter_default_8, 1, 16, 32);  slice_scatter_default_7 = slice_scatter_default_8 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_80: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_9, 1, 16, 32)
        slice_81: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_80, 2, 0, 16);  slice_80 = None
        
        # No stacktrace found for following nodes
        slice_tensor_5: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_9, 1, 16, 32)
        slice_scatter_default_10: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_5, slice_81, 2, 0, 16);  slice_tensor_5 = slice_81 = None
        slice_scatter_default_11: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_9, slice_scatter_default_10, 1, 16, 32);  slice_scatter_default_9 = slice_scatter_default_10 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_101: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_67, 2, 16, 32);  slice_67 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_6: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_101, memory_format = torch.contiguous_format);  slice_101 = None
        view_16: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_6, [32, 11]);  clone_6 = None
        mm_3: "f32[32, 8]" = torch.ops.aten.mm.default(view_16, slice_37)
        view_17: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_3, [2, 16, 8]);  mm_3 = None
        slice_108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_11, 1, 16, 32)
        slice_109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_108, 2, 0, 16);  slice_108 = None
        add_5: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_109, view_17);  slice_109 = view_17 = None
        
        # No stacktrace found for following nodes
        slice_tensor_6: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_11, 1, 16, 32)
        slice_scatter_default_12: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_6, add_5, 2, 0, 16);  slice_tensor_6 = add_5 = None
        slice_scatter_default_13: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_11, slice_scatter_default_12, 1, 16, 32);  slice_scatter_default_11 = slice_scatter_default_12 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_13, 1, 16, 32)
        slice_114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_113, 2, 0, 16);  slice_113 = None
        
        # No stacktrace found for following nodes
        slice_tensor_7: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_13, 1, 16, 32)
        slice_scatter_default_14: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_7, slice_114, 2, 0, 16);  slice_tensor_7 = slice_114 = None
        slice_scatter_default_15: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_13, slice_scatter_default_14, 1, 16, 32);  slice_scatter_default_13 = slice_scatter_default_14 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_133: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 32, 48)
        slice_134: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_133, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_7: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_134, memory_format = torch.contiguous_format);  slice_134 = None
        view_18: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_7, [32, 16]);  clone_7 = None
        mm_4: "f32[32, 8]" = torch.ops.aten.mm.default(view_18, slice_7)
        view_19: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_4, [2, 16, 8]);  mm_4 = None
        slice_141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_15, 1, 32, 48)
        slice_142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_141, 2, 0, 16);  slice_141 = None
        add_6: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_142, view_19);  slice_142 = view_19 = None
        
        # No stacktrace found for following nodes
        slice_tensor_8: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_15, 1, 32, 48)
        slice_scatter_default_16: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_8, add_6, 2, 0, 16);  slice_tensor_8 = add_6 = None
        slice_scatter_default_17: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_15, slice_scatter_default_16, 1, 32, 48);  slice_scatter_default_15 = slice_scatter_default_16 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_17, 1, 32, 48)
        slice_147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_146, 2, 0, 16);  slice_146 = None
        
        # No stacktrace found for following nodes
        slice_tensor_9: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_17, 1, 32, 48)
        slice_scatter_default_18: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_9, slice_147, 2, 0, 16);  slice_tensor_9 = slice_147 = None
        slice_scatter_default_19: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_17, slice_scatter_default_18, 1, 32, 48);  slice_scatter_default_17 = slice_scatter_default_18 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_167: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_133, 2, 16, 32);  slice_133 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_8: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_167, memory_format = torch.contiguous_format);  slice_167 = None
        view_20: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_8, [32, 11]);  clone_8 = None
        mm_5: "f32[32, 8]" = torch.ops.aten.mm.default(view_20, slice_37)
        view_21: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_5, [2, 16, 8]);  mm_5 = None
        slice_174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_19, 1, 32, 48)
        slice_175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_174, 2, 0, 16);  slice_174 = None
        add_7: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_175, view_21);  slice_175 = view_21 = None
        
        # No stacktrace found for following nodes
        slice_tensor_10: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_19, 1, 32, 48)
        slice_scatter_default_20: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_10, add_7, 2, 0, 16);  slice_tensor_10 = add_7 = None
        slice_scatter_default_21: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_19, slice_scatter_default_20, 1, 32, 48);  slice_scatter_default_19 = slice_scatter_default_20 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_21, 1, 32, 48)
        slice_180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_179, 2, 0, 16);  slice_179 = None
        
        # No stacktrace found for following nodes
        slice_tensor_11: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_21, 1, 32, 48)
        slice_scatter_default_22: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_11, slice_180, 2, 0, 16);  slice_tensor_11 = slice_180 = None
        slice_scatter_default_23: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_21, slice_scatter_default_22, 1, 32, 48);  slice_scatter_default_21 = slice_scatter_default_22 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_199: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 48, 64)
        slice_200: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_199, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_9: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_200, memory_format = torch.contiguous_format);  slice_200 = None
        view_22: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_9, [32, 16]);  clone_9 = None
        mm_6: "f32[32, 8]" = torch.ops.aten.mm.default(view_22, slice_7)
        view_23: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_6, [2, 16, 8]);  mm_6 = None
        slice_207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_23, 1, 48, 64)
        slice_208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_207, 2, 0, 16);  slice_207 = None
        add_8: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_208, view_23);  slice_208 = view_23 = None
        
        # No stacktrace found for following nodes
        slice_tensor_12: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_23, 1, 48, 64)
        slice_scatter_default_24: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_12, add_8, 2, 0, 16);  slice_tensor_12 = add_8 = None
        slice_scatter_default_25: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_23, slice_scatter_default_24, 1, 48, 64);  slice_scatter_default_23 = slice_scatter_default_24 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_25, 1, 48, 64)
        slice_213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_212, 2, 0, 16);  slice_212 = None
        
        # No stacktrace found for following nodes
        slice_tensor_13: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_25, 1, 48, 64)
        slice_scatter_default_26: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_13, slice_213, 2, 0, 16);  slice_tensor_13 = slice_213 = None
        slice_scatter_default_27: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_25, slice_scatter_default_26, 1, 48, 64);  slice_scatter_default_25 = slice_scatter_default_26 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_233: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_199, 2, 16, 32);  slice_199 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_10: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_233, memory_format = torch.contiguous_format);  slice_233 = None
        view_24: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_10, [32, 11]);  clone_10 = None
        mm_7: "f32[32, 8]" = torch.ops.aten.mm.default(view_24, slice_37)
        view_25: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_7, [2, 16, 8]);  mm_7 = None
        slice_240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_27, 1, 48, 64)
        slice_241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_240, 2, 0, 16);  slice_240 = None
        add_9: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_241, view_25);  slice_241 = view_25 = None
        
        # No stacktrace found for following nodes
        slice_tensor_14: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_27, 1, 48, 64)
        slice_scatter_default_28: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_14, add_9, 2, 0, 16);  slice_tensor_14 = add_9 = None
        slice_scatter_default_29: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_27, slice_scatter_default_28, 1, 48, 64);  slice_scatter_default_27 = slice_scatter_default_28 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_29, 1, 48, 64)
        slice_246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_245, 2, 0, 16);  slice_245 = None
        
        # No stacktrace found for following nodes
        slice_tensor_15: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_29, 1, 48, 64)
        slice_scatter_default_30: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_15, slice_246, 2, 0, 16);  slice_tensor_15 = slice_246 = None
        slice_scatter_default_31: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_29, slice_scatter_default_30, 1, 48, 64);  slice_scatter_default_29 = slice_scatter_default_30 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_265: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 64, 80)
        slice_266: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_265, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_11: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_266, memory_format = torch.contiguous_format);  slice_266 = None
        view_26: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_11, [32, 16]);  clone_11 = None
        mm_8: "f32[32, 8]" = torch.ops.aten.mm.default(view_26, slice_7)
        view_27: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_8, [2, 16, 8]);  mm_8 = None
        slice_273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_31, 1, 64, 80)
        slice_274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_273, 2, 0, 16);  slice_273 = None
        add_10: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_274, view_27);  slice_274 = view_27 = None
        
        # No stacktrace found for following nodes
        slice_tensor_16: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_31, 1, 64, 80)
        slice_scatter_default_32: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_16, add_10, 2, 0, 16);  slice_tensor_16 = add_10 = None
        slice_scatter_default_33: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_31, slice_scatter_default_32, 1, 64, 80);  slice_scatter_default_31 = slice_scatter_default_32 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_33, 1, 64, 80)
        slice_279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_278, 2, 0, 16);  slice_278 = None
        
        # No stacktrace found for following nodes
        slice_tensor_17: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_33, 1, 64, 80)
        slice_scatter_default_34: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_17, slice_279, 2, 0, 16);  slice_tensor_17 = slice_279 = None
        slice_scatter_default_35: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_33, slice_scatter_default_34, 1, 64, 80);  slice_scatter_default_33 = slice_scatter_default_34 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_299: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_265, 2, 16, 32);  slice_265 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_12: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_299, memory_format = torch.contiguous_format);  slice_299 = None
        view_28: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_12, [32, 11]);  clone_12 = None
        mm_9: "f32[32, 8]" = torch.ops.aten.mm.default(view_28, slice_37)
        view_29: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_9, [2, 16, 8]);  mm_9 = None
        slice_306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_35, 1, 64, 80)
        slice_307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_306, 2, 0, 16);  slice_306 = None
        add_11: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_307, view_29);  slice_307 = view_29 = None
        
        # No stacktrace found for following nodes
        slice_tensor_18: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_35, 1, 64, 80)
        slice_scatter_default_36: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_18, add_11, 2, 0, 16);  slice_tensor_18 = add_11 = None
        slice_scatter_default_37: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_35, slice_scatter_default_36, 1, 64, 80);  slice_scatter_default_35 = slice_scatter_default_36 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_37, 1, 64, 80)
        slice_312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_311, 2, 0, 16);  slice_311 = None
        
        # No stacktrace found for following nodes
        slice_tensor_19: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_37, 1, 64, 80)
        slice_scatter_default_38: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_19, slice_312, 2, 0, 16);  slice_tensor_19 = slice_312 = None
        slice_scatter_default_39: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_37, slice_scatter_default_38, 1, 64, 80);  slice_scatter_default_37 = slice_scatter_default_38 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_331: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 80, 96)
        slice_332: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_331, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_13: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_332, memory_format = torch.contiguous_format);  slice_332 = None
        view_30: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_13, [32, 16]);  clone_13 = None
        mm_10: "f32[32, 8]" = torch.ops.aten.mm.default(view_30, slice_7)
        view_31: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_10, [2, 16, 8]);  mm_10 = None
        slice_339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_39, 1, 80, 96)
        slice_340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_339, 2, 0, 16);  slice_339 = None
        add_12: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_340, view_31);  slice_340 = view_31 = None
        
        # No stacktrace found for following nodes
        slice_tensor_20: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_39, 1, 80, 96)
        slice_scatter_default_40: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_20, add_12, 2, 0, 16);  slice_tensor_20 = add_12 = None
        slice_scatter_default_41: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_39, slice_scatter_default_40, 1, 80, 96);  slice_scatter_default_39 = slice_scatter_default_40 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_41, 1, 80, 96)
        slice_345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_344, 2, 0, 16);  slice_344 = None
        
        # No stacktrace found for following nodes
        slice_tensor_21: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_41, 1, 80, 96)
        slice_scatter_default_42: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_21, slice_345, 2, 0, 16);  slice_tensor_21 = slice_345 = None
        slice_scatter_default_43: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_41, slice_scatter_default_42, 1, 80, 96);  slice_scatter_default_41 = slice_scatter_default_42 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_365: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_331, 2, 16, 32);  slice_331 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_14: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_365, memory_format = torch.contiguous_format);  slice_365 = None
        view_32: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_14, [32, 11]);  clone_14 = None
        mm_11: "f32[32, 8]" = torch.ops.aten.mm.default(view_32, slice_37)
        view_33: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_11, [2, 16, 8]);  mm_11 = None
        slice_372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_43, 1, 80, 96)
        slice_373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_372, 2, 0, 16);  slice_372 = None
        add_13: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_373, view_33);  slice_373 = view_33 = None
        
        # No stacktrace found for following nodes
        slice_tensor_22: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_43, 1, 80, 96)
        slice_scatter_default_44: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_22, add_13, 2, 0, 16);  slice_tensor_22 = add_13 = None
        slice_scatter_default_45: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_43, slice_scatter_default_44, 1, 80, 96);  slice_scatter_default_43 = slice_scatter_default_44 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_45, 1, 80, 96)
        slice_378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_377, 2, 0, 16);  slice_377 = None
        
        # No stacktrace found for following nodes
        slice_tensor_23: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_45, 1, 80, 96)
        slice_scatter_default_46: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_23, slice_378, 2, 0, 16);  slice_tensor_23 = slice_378 = None
        slice_scatter_default_47: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_45, slice_scatter_default_46, 1, 80, 96);  slice_scatter_default_45 = slice_scatter_default_46 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_397: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 96, 112)
        slice_398: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_397, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_15: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_398, memory_format = torch.contiguous_format);  slice_398 = None
        view_34: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_15, [32, 16]);  clone_15 = None
        mm_12: "f32[32, 8]" = torch.ops.aten.mm.default(view_34, slice_7)
        view_35: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_12, [2, 16, 8]);  mm_12 = None
        slice_405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_47, 1, 96, 112)
        slice_406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_405, 2, 0, 16);  slice_405 = None
        add_14: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_406, view_35);  slice_406 = view_35 = None
        
        # No stacktrace found for following nodes
        slice_tensor_24: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_47, 1, 96, 112)
        slice_scatter_default_48: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_24, add_14, 2, 0, 16);  slice_tensor_24 = add_14 = None
        slice_scatter_default_49: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_47, slice_scatter_default_48, 1, 96, 112);  slice_scatter_default_47 = slice_scatter_default_48 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_49, 1, 96, 112)
        slice_411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_410, 2, 0, 16);  slice_410 = None
        
        # No stacktrace found for following nodes
        slice_tensor_25: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_49, 1, 96, 112)
        slice_scatter_default_50: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_25, slice_411, 2, 0, 16);  slice_tensor_25 = slice_411 = None
        slice_scatter_default_51: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_49, slice_scatter_default_50, 1, 96, 112);  slice_scatter_default_49 = slice_scatter_default_50 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_431: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_397, 2, 16, 32);  slice_397 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_16: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_431, memory_format = torch.contiguous_format);  slice_431 = None
        view_36: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_16, [32, 11]);  clone_16 = None
        mm_13: "f32[32, 8]" = torch.ops.aten.mm.default(view_36, slice_37)
        view_37: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_13, [2, 16, 8]);  mm_13 = None
        slice_438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_51, 1, 96, 112)
        slice_439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_438, 2, 0, 16);  slice_438 = None
        add_15: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_439, view_37);  slice_439 = view_37 = None
        
        # No stacktrace found for following nodes
        slice_tensor_26: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_51, 1, 96, 112)
        slice_scatter_default_52: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_26, add_15, 2, 0, 16);  slice_tensor_26 = add_15 = None
        slice_scatter_default_53: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_51, slice_scatter_default_52, 1, 96, 112);  slice_scatter_default_51 = slice_scatter_default_52 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_53, 1, 96, 112)
        slice_444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_443, 2, 0, 16);  slice_443 = None
        
        # No stacktrace found for following nodes
        slice_tensor_27: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_53, 1, 96, 112)
        slice_scatter_default_54: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_27, slice_444, 2, 0, 16);  slice_tensor_27 = slice_444 = None
        slice_scatter_default_55: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_53, slice_scatter_default_54, 1, 96, 112);  slice_scatter_default_53 = slice_scatter_default_54 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_463: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 112, 128)
        slice_464: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_463, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_17: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_464, memory_format = torch.contiguous_format);  slice_464 = None
        view_38: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_17, [32, 16]);  clone_17 = None
        mm_14: "f32[32, 8]" = torch.ops.aten.mm.default(view_38, slice_7)
        view_39: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_14, [2, 16, 8]);  mm_14 = None
        slice_471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_55, 1, 112, 128)
        slice_472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_471, 2, 0, 16);  slice_471 = None
        add_16: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_472, view_39);  slice_472 = view_39 = None
        
        # No stacktrace found for following nodes
        slice_tensor_28: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_55, 1, 112, 128)
        slice_scatter_default_56: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_28, add_16, 2, 0, 16);  slice_tensor_28 = add_16 = None
        slice_scatter_default_57: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_55, slice_scatter_default_56, 1, 112, 128);  slice_scatter_default_55 = slice_scatter_default_56 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_57, 1, 112, 128)
        slice_477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_476, 2, 0, 16);  slice_476 = None
        
        # No stacktrace found for following nodes
        slice_tensor_29: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_57, 1, 112, 128)
        slice_scatter_default_58: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_29, slice_477, 2, 0, 16);  slice_tensor_29 = slice_477 = None
        slice_scatter_default_59: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_57, slice_scatter_default_58, 1, 112, 128);  slice_scatter_default_57 = slice_scatter_default_58 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_497: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_463, 2, 16, 32);  slice_463 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_18: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_497, memory_format = torch.contiguous_format);  slice_497 = None
        view_40: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_18, [32, 11]);  clone_18 = None
        mm_15: "f32[32, 8]" = torch.ops.aten.mm.default(view_40, slice_37)
        view_41: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_15, [2, 16, 8]);  mm_15 = None
        slice_504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_59, 1, 112, 128)
        slice_505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_504, 2, 0, 16);  slice_504 = None
        add_17: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_505, view_41);  slice_505 = view_41 = None
        
        # No stacktrace found for following nodes
        slice_tensor_30: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_59, 1, 112, 128)
        slice_scatter_default_60: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_30, add_17, 2, 0, 16);  slice_tensor_30 = add_17 = None
        slice_scatter_default_61: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_59, slice_scatter_default_60, 1, 112, 128);  slice_scatter_default_59 = slice_scatter_default_60 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_61, 1, 112, 128)
        slice_510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_509, 2, 0, 16);  slice_509 = None
        
        # No stacktrace found for following nodes
        slice_tensor_31: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_61, 1, 112, 128)
        slice_scatter_default_62: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_31, slice_510, 2, 0, 16);  slice_tensor_31 = slice_510 = None
        slice_scatter_default_63: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_61, slice_scatter_default_62, 1, 112, 128);  slice_scatter_default_61 = slice_scatter_default_62 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_529: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 128, 144)
        slice_530: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_529, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_19: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_530, memory_format = torch.contiguous_format);  slice_530 = None
        view_42: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_19, [32, 16]);  clone_19 = None
        mm_16: "f32[32, 8]" = torch.ops.aten.mm.default(view_42, slice_7)
        view_43: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_16, [2, 16, 8]);  mm_16 = None
        slice_537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_63, 1, 128, 144)
        slice_538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_537, 2, 0, 16);  slice_537 = None
        add_18: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_538, view_43);  slice_538 = view_43 = None
        
        # No stacktrace found for following nodes
        slice_tensor_32: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_63, 1, 128, 144)
        slice_scatter_default_64: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_32, add_18, 2, 0, 16);  slice_tensor_32 = add_18 = None
        slice_scatter_default_65: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_63, slice_scatter_default_64, 1, 128, 144);  slice_scatter_default_63 = slice_scatter_default_64 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_65, 1, 128, 144)
        slice_543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_542, 2, 0, 16);  slice_542 = None
        
        # No stacktrace found for following nodes
        slice_tensor_33: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_65, 1, 128, 144)
        slice_scatter_default_66: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_33, slice_543, 2, 0, 16);  slice_tensor_33 = slice_543 = None
        slice_scatter_default_67: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_65, slice_scatter_default_66, 1, 128, 144);  slice_scatter_default_65 = slice_scatter_default_66 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_563: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_529, 2, 16, 32);  slice_529 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_20: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_563, memory_format = torch.contiguous_format);  slice_563 = None
        view_44: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_20, [32, 11]);  clone_20 = None
        mm_17: "f32[32, 8]" = torch.ops.aten.mm.default(view_44, slice_37)
        view_45: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_17, [2, 16, 8]);  mm_17 = None
        slice_570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_67, 1, 128, 144)
        slice_571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_570, 2, 0, 16);  slice_570 = None
        add_19: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_571, view_45);  slice_571 = view_45 = None
        
        # No stacktrace found for following nodes
        slice_tensor_34: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_67, 1, 128, 144)
        slice_scatter_default_68: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_34, add_19, 2, 0, 16);  slice_tensor_34 = add_19 = None
        slice_scatter_default_69: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_67, slice_scatter_default_68, 1, 128, 144);  slice_scatter_default_67 = slice_scatter_default_68 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_69, 1, 128, 144)
        slice_576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_575, 2, 0, 16);  slice_575 = None
        
        # No stacktrace found for following nodes
        slice_tensor_35: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_69, 1, 128, 144)
        slice_scatter_default_70: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_35, slice_576, 2, 0, 16);  slice_tensor_35 = slice_576 = None
        slice_scatter_default_71: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_69, slice_scatter_default_70, 1, 128, 144);  slice_scatter_default_69 = slice_scatter_default_70 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_595: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 144, 160)
        slice_596: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_595, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_21: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_596, memory_format = torch.contiguous_format);  slice_596 = None
        view_46: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_21, [32, 16]);  clone_21 = None
        mm_18: "f32[32, 8]" = torch.ops.aten.mm.default(view_46, slice_7)
        view_47: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_18, [2, 16, 8]);  mm_18 = None
        slice_603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_71, 1, 144, 160)
        slice_604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_603, 2, 0, 16);  slice_603 = None
        add_20: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_604, view_47);  slice_604 = view_47 = None
        
        # No stacktrace found for following nodes
        slice_tensor_36: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_71, 1, 144, 160)
        slice_scatter_default_72: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_36, add_20, 2, 0, 16);  slice_tensor_36 = add_20 = None
        slice_scatter_default_73: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_71, slice_scatter_default_72, 1, 144, 160);  slice_scatter_default_71 = slice_scatter_default_72 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_73, 1, 144, 160)
        slice_609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_608, 2, 0, 16);  slice_608 = None
        
        # No stacktrace found for following nodes
        slice_tensor_37: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_73, 1, 144, 160)
        slice_scatter_default_74: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_37, slice_609, 2, 0, 16);  slice_tensor_37 = slice_609 = None
        slice_scatter_default_75: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_73, slice_scatter_default_74, 1, 144, 160);  slice_scatter_default_73 = slice_scatter_default_74 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_629: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_595, 2, 16, 32);  slice_595 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_22: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_629, memory_format = torch.contiguous_format);  slice_629 = None
        view_48: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_22, [32, 11]);  clone_22 = None
        mm_19: "f32[32, 8]" = torch.ops.aten.mm.default(view_48, slice_37)
        view_49: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_19, [2, 16, 8]);  mm_19 = None
        slice_636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_75, 1, 144, 160)
        slice_637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_636, 2, 0, 16);  slice_636 = None
        add_21: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_637, view_49);  slice_637 = view_49 = None
        
        # No stacktrace found for following nodes
        slice_tensor_38: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_75, 1, 144, 160)
        slice_scatter_default_76: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_38, add_21, 2, 0, 16);  slice_tensor_38 = add_21 = None
        slice_scatter_default_77: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_75, slice_scatter_default_76, 1, 144, 160);  slice_scatter_default_75 = slice_scatter_default_76 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_77, 1, 144, 160)
        slice_642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_641, 2, 0, 16);  slice_641 = None
        
        # No stacktrace found for following nodes
        slice_tensor_39: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_77, 1, 144, 160)
        slice_scatter_default_78: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_39, slice_642, 2, 0, 16);  slice_tensor_39 = slice_642 = None
        slice_scatter_default_79: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_77, slice_scatter_default_78, 1, 144, 160);  slice_scatter_default_77 = slice_scatter_default_78 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_661: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 160, 176)
        slice_662: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_661, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_23: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_662, memory_format = torch.contiguous_format);  slice_662 = None
        view_50: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_23, [32, 16]);  clone_23 = None
        mm_20: "f32[32, 8]" = torch.ops.aten.mm.default(view_50, slice_7)
        view_51: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_20, [2, 16, 8]);  mm_20 = None
        slice_669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_79, 1, 160, 176)
        slice_670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_669, 2, 0, 16);  slice_669 = None
        add_22: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_670, view_51);  slice_670 = view_51 = None
        
        # No stacktrace found for following nodes
        slice_tensor_40: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_79, 1, 160, 176)
        slice_scatter_default_80: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_40, add_22, 2, 0, 16);  slice_tensor_40 = add_22 = None
        slice_scatter_default_81: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_79, slice_scatter_default_80, 1, 160, 176);  slice_scatter_default_79 = slice_scatter_default_80 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_81, 1, 160, 176)
        slice_675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_674, 2, 0, 16);  slice_674 = None
        
        # No stacktrace found for following nodes
        slice_tensor_41: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_81, 1, 160, 176)
        slice_scatter_default_82: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_41, slice_675, 2, 0, 16);  slice_tensor_41 = slice_675 = None
        slice_scatter_default_83: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_81, slice_scatter_default_82, 1, 160, 176);  slice_scatter_default_81 = slice_scatter_default_82 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_695: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_661, 2, 16, 32);  slice_661 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_24: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_695, memory_format = torch.contiguous_format);  slice_695 = None
        view_52: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_24, [32, 11]);  clone_24 = None
        mm_21: "f32[32, 8]" = torch.ops.aten.mm.default(view_52, slice_37)
        view_53: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_21, [2, 16, 8]);  mm_21 = None
        slice_702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_83, 1, 160, 176)
        slice_703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_702, 2, 0, 16);  slice_702 = None
        add_23: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_703, view_53);  slice_703 = view_53 = None
        
        # No stacktrace found for following nodes
        slice_tensor_42: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_83, 1, 160, 176)
        slice_scatter_default_84: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_42, add_23, 2, 0, 16);  slice_tensor_42 = add_23 = None
        slice_scatter_default_85: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_83, slice_scatter_default_84, 1, 160, 176);  slice_scatter_default_83 = slice_scatter_default_84 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_85, 1, 160, 176)
        slice_708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_707, 2, 0, 16);  slice_707 = None
        
        # No stacktrace found for following nodes
        slice_tensor_43: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_85, 1, 160, 176)
        slice_scatter_default_86: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_43, slice_708, 2, 0, 16);  slice_tensor_43 = slice_708 = None
        slice_scatter_default_87: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_85, slice_scatter_default_86, 1, 160, 176);  slice_scatter_default_85 = slice_scatter_default_86 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_727: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 176, 192)
        slice_728: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_727, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_25: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_728, memory_format = torch.contiguous_format);  slice_728 = None
        view_54: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_25, [32, 16]);  clone_25 = None
        mm_22: "f32[32, 8]" = torch.ops.aten.mm.default(view_54, slice_7)
        view_55: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_22, [2, 16, 8]);  mm_22 = None
        slice_735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_87, 1, 176, 192)
        slice_736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_735, 2, 0, 16);  slice_735 = None
        add_24: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_736, view_55);  slice_736 = view_55 = None
        
        # No stacktrace found for following nodes
        slice_tensor_44: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_87, 1, 176, 192)
        slice_scatter_default_88: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_44, add_24, 2, 0, 16);  slice_tensor_44 = add_24 = None
        slice_scatter_default_89: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_87, slice_scatter_default_88, 1, 176, 192);  slice_scatter_default_87 = slice_scatter_default_88 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_89, 1, 176, 192)
        slice_741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_740, 2, 0, 16);  slice_740 = None
        
        # No stacktrace found for following nodes
        slice_tensor_45: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_89, 1, 176, 192)
        slice_scatter_default_90: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_45, slice_741, 2, 0, 16);  slice_tensor_45 = slice_741 = None
        slice_scatter_default_91: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_89, slice_scatter_default_90, 1, 176, 192);  slice_scatter_default_89 = slice_scatter_default_90 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_761: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_727, 2, 16, 32);  slice_727 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_26: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_761, memory_format = torch.contiguous_format);  slice_761 = None
        view_56: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_26, [32, 11]);  clone_26 = None
        mm_23: "f32[32, 8]" = torch.ops.aten.mm.default(view_56, slice_37)
        view_57: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_23, [2, 16, 8]);  mm_23 = None
        slice_768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_91, 1, 176, 192)
        slice_769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_768, 2, 0, 16);  slice_768 = None
        add_25: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_769, view_57);  slice_769 = view_57 = None
        
        # No stacktrace found for following nodes
        slice_tensor_46: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_91, 1, 176, 192)
        slice_scatter_default_92: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_46, add_25, 2, 0, 16);  slice_tensor_46 = add_25 = None
        slice_scatter_default_93: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_91, slice_scatter_default_92, 1, 176, 192);  slice_scatter_default_91 = slice_scatter_default_92 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_93, 1, 176, 192)
        slice_774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_773, 2, 0, 16);  slice_773 = None
        
        # No stacktrace found for following nodes
        slice_tensor_47: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_93, 1, 176, 192)
        slice_scatter_default_94: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_47, slice_774, 2, 0, 16);  slice_tensor_47 = slice_774 = None
        slice_scatter_default_95: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_93, slice_scatter_default_94, 1, 176, 192);  slice_scatter_default_93 = slice_scatter_default_94 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_793: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 192, 208)
        slice_794: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_793, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_27: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_794, memory_format = torch.contiguous_format);  slice_794 = None
        view_58: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_27, [32, 16]);  clone_27 = None
        mm_24: "f32[32, 8]" = torch.ops.aten.mm.default(view_58, slice_7)
        view_59: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_24, [2, 16, 8]);  mm_24 = None
        slice_801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_95, 1, 192, 208)
        slice_802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_801, 2, 0, 16);  slice_801 = None
        add_26: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_802, view_59);  slice_802 = view_59 = None
        
        # No stacktrace found for following nodes
        slice_tensor_48: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_95, 1, 192, 208)
        slice_scatter_default_96: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_48, add_26, 2, 0, 16);  slice_tensor_48 = add_26 = None
        slice_scatter_default_97: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_95, slice_scatter_default_96, 1, 192, 208);  slice_scatter_default_95 = slice_scatter_default_96 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_97, 1, 192, 208)
        slice_807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_806, 2, 0, 16);  slice_806 = None
        
        # No stacktrace found for following nodes
        slice_tensor_49: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_97, 1, 192, 208)
        slice_scatter_default_98: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_49, slice_807, 2, 0, 16);  slice_tensor_49 = slice_807 = None
        slice_scatter_default_99: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_97, slice_scatter_default_98, 1, 192, 208);  slice_scatter_default_97 = slice_scatter_default_98 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_827: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_793, 2, 16, 32);  slice_793 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_28: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_827, memory_format = torch.contiguous_format);  slice_827 = None
        view_60: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_28, [32, 11]);  clone_28 = None
        mm_25: "f32[32, 8]" = torch.ops.aten.mm.default(view_60, slice_37)
        view_61: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_25, [2, 16, 8]);  mm_25 = None
        slice_834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_99, 1, 192, 208)
        slice_835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_834, 2, 0, 16);  slice_834 = None
        add_27: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_835, view_61);  slice_835 = view_61 = None
        
        # No stacktrace found for following nodes
        slice_tensor_50: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_99, 1, 192, 208)
        slice_scatter_default_100: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_50, add_27, 2, 0, 16);  slice_tensor_50 = add_27 = None
        slice_scatter_default_101: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_99, slice_scatter_default_100, 1, 192, 208);  slice_scatter_default_99 = slice_scatter_default_100 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_101, 1, 192, 208)
        slice_840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_839, 2, 0, 16);  slice_839 = None
        
        # No stacktrace found for following nodes
        slice_tensor_51: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_101, 1, 192, 208)
        slice_scatter_default_102: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_51, slice_840, 2, 0, 16);  slice_tensor_51 = slice_840 = None
        slice_scatter_default_103: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_101, slice_scatter_default_102, 1, 192, 208);  slice_scatter_default_101 = slice_scatter_default_102 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_859: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 208, 224)
        slice_860: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_859, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_29: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_860, memory_format = torch.contiguous_format);  slice_860 = None
        view_62: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_29, [32, 16]);  clone_29 = None
        mm_26: "f32[32, 8]" = torch.ops.aten.mm.default(view_62, slice_7)
        view_63: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_26, [2, 16, 8]);  mm_26 = None
        slice_867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_103, 1, 208, 224)
        slice_868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_867, 2, 0, 16);  slice_867 = None
        add_28: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_868, view_63);  slice_868 = view_63 = None
        
        # No stacktrace found for following nodes
        slice_tensor_52: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_103, 1, 208, 224)
        slice_scatter_default_104: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_52, add_28, 2, 0, 16);  slice_tensor_52 = add_28 = None
        slice_scatter_default_105: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_103, slice_scatter_default_104, 1, 208, 224);  slice_scatter_default_103 = slice_scatter_default_104 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_105, 1, 208, 224)
        slice_873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_872, 2, 0, 16);  slice_872 = None
        
        # No stacktrace found for following nodes
        slice_tensor_53: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_105, 1, 208, 224)
        slice_scatter_default_106: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_53, slice_873, 2, 0, 16);  slice_tensor_53 = slice_873 = None
        slice_scatter_default_107: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_105, slice_scatter_default_106, 1, 208, 224);  slice_scatter_default_105 = slice_scatter_default_106 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_893: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_859, 2, 16, 32);  slice_859 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_30: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_893, memory_format = torch.contiguous_format);  slice_893 = None
        view_64: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_30, [32, 11]);  clone_30 = None
        mm_27: "f32[32, 8]" = torch.ops.aten.mm.default(view_64, slice_37)
        view_65: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_27, [2, 16, 8]);  mm_27 = None
        slice_900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_107, 1, 208, 224)
        slice_901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_900, 2, 0, 16);  slice_900 = None
        add_29: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_901, view_65);  slice_901 = view_65 = None
        
        # No stacktrace found for following nodes
        slice_tensor_54: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_107, 1, 208, 224)
        slice_scatter_default_108: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_54, add_29, 2, 0, 16);  slice_tensor_54 = add_29 = None
        slice_scatter_default_109: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_107, slice_scatter_default_108, 1, 208, 224);  slice_scatter_default_107 = slice_scatter_default_108 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_109, 1, 208, 224)
        slice_906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_905, 2, 0, 16);  slice_905 = None
        
        # No stacktrace found for following nodes
        slice_tensor_55: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_109, 1, 208, 224)
        slice_scatter_default_110: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_55, slice_906, 2, 0, 16);  slice_tensor_55 = slice_906 = None
        slice_scatter_default_111: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_109, slice_scatter_default_110, 1, 208, 224);  slice_scatter_default_109 = slice_scatter_default_110 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_925: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 224, 240)
        slice_926: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_925, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_31: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_926, memory_format = torch.contiguous_format);  slice_926 = None
        view_66: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_31, [32, 16]);  clone_31 = None
        mm_28: "f32[32, 8]" = torch.ops.aten.mm.default(view_66, slice_7)
        view_67: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_28, [2, 16, 8]);  mm_28 = None
        slice_933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_111, 1, 224, 240)
        slice_934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_933, 2, 0, 16);  slice_933 = None
        add_30: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_934, view_67);  slice_934 = view_67 = None
        
        # No stacktrace found for following nodes
        slice_tensor_56: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_111, 1, 224, 240)
        slice_scatter_default_112: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_56, add_30, 2, 0, 16);  slice_tensor_56 = add_30 = None
        slice_scatter_default_113: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_111, slice_scatter_default_112, 1, 224, 240);  slice_scatter_default_111 = slice_scatter_default_112 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_113, 1, 224, 240)
        slice_939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_938, 2, 0, 16);  slice_938 = None
        
        # No stacktrace found for following nodes
        slice_tensor_57: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_113, 1, 224, 240)
        slice_scatter_default_114: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_57, slice_939, 2, 0, 16);  slice_tensor_57 = slice_939 = None
        slice_scatter_default_115: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_113, slice_scatter_default_114, 1, 224, 240);  slice_scatter_default_113 = slice_scatter_default_114 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_959: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_925, 2, 16, 32);  slice_925 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_32: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_959, memory_format = torch.contiguous_format);  slice_959 = None
        view_68: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_32, [32, 11]);  clone_32 = None
        mm_29: "f32[32, 8]" = torch.ops.aten.mm.default(view_68, slice_37)
        view_69: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_29, [2, 16, 8]);  mm_29 = None
        slice_966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_115, 1, 224, 240)
        slice_967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_966, 2, 0, 16);  slice_966 = None
        add_31: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_967, view_69);  slice_967 = view_69 = None
        
        # No stacktrace found for following nodes
        slice_tensor_58: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_115, 1, 224, 240)
        slice_scatter_default_116: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_58, add_31, 2, 0, 16);  slice_tensor_58 = add_31 = None
        slice_scatter_default_117: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_115, slice_scatter_default_116, 1, 224, 240);  slice_scatter_default_115 = slice_scatter_default_116 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_117, 1, 224, 240)
        slice_972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_971, 2, 0, 16);  slice_971 = None
        
        # No stacktrace found for following nodes
        slice_tensor_59: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_117, 1, 224, 240)
        slice_scatter_default_118: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_59, slice_972, 2, 0, 16);  slice_tensor_59 = slice_972 = None
        slice_scatter_default_119: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_117, slice_scatter_default_118, 1, 224, 240);  slice_scatter_default_117 = slice_scatter_default_118 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_991: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 240, 256)
        slice_992: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_991, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_33: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_992, memory_format = torch.contiguous_format);  slice_992 = None
        view_70: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_33, [32, 16]);  clone_33 = None
        mm_30: "f32[32, 8]" = torch.ops.aten.mm.default(view_70, slice_7)
        view_71: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_30, [2, 16, 8]);  mm_30 = None
        slice_999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_119, 1, 240, 256)
        slice_1000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_999, 2, 0, 16);  slice_999 = None
        add_32: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1000, view_71);  slice_1000 = view_71 = None
        
        # No stacktrace found for following nodes
        slice_tensor_60: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_119, 1, 240, 256)
        slice_scatter_default_120: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_60, add_32, 2, 0, 16);  slice_tensor_60 = add_32 = None
        slice_scatter_default_121: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_119, slice_scatter_default_120, 1, 240, 256);  slice_scatter_default_119 = slice_scatter_default_120 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_121, 1, 240, 256)
        slice_1005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1004, 2, 0, 16);  slice_1004 = None
        
        # No stacktrace found for following nodes
        slice_tensor_61: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_121, 1, 240, 256)
        slice_scatter_default_122: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_61, slice_1005, 2, 0, 16);  slice_tensor_61 = slice_1005 = None
        slice_scatter_default_123: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_121, slice_scatter_default_122, 1, 240, 256);  slice_scatter_default_121 = slice_scatter_default_122 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1025: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_991, 2, 16, 32);  slice_991 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_34: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1025, memory_format = torch.contiguous_format);  slice_1025 = None
        view_72: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_34, [32, 11]);  clone_34 = None
        mm_31: "f32[32, 8]" = torch.ops.aten.mm.default(view_72, slice_37)
        view_73: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_31, [2, 16, 8]);  mm_31 = None
        slice_1032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_123, 1, 240, 256)
        slice_1033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1032, 2, 0, 16);  slice_1032 = None
        add_33: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1033, view_73);  slice_1033 = view_73 = None
        
        # No stacktrace found for following nodes
        slice_tensor_62: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_123, 1, 240, 256)
        slice_scatter_default_124: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_62, add_33, 2, 0, 16);  slice_tensor_62 = add_33 = None
        slice_scatter_default_125: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_123, slice_scatter_default_124, 1, 240, 256);  slice_scatter_default_123 = slice_scatter_default_124 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_125, 1, 240, 256)
        slice_1038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1037, 2, 0, 16);  slice_1037 = None
        
        # No stacktrace found for following nodes
        slice_tensor_63: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_125, 1, 240, 256)
        slice_scatter_default_126: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_63, slice_1038, 2, 0, 16);  slice_tensor_63 = slice_1038 = None
        slice_scatter_default_127: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_125, slice_scatter_default_126, 1, 240, 256);  slice_scatter_default_125 = slice_scatter_default_126 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1057: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 256, 272)
        slice_1058: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1057, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_35: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1058, memory_format = torch.contiguous_format);  slice_1058 = None
        view_74: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_35, [32, 16]);  clone_35 = None
        mm_32: "f32[32, 8]" = torch.ops.aten.mm.default(view_74, slice_7)
        view_75: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_32, [2, 16, 8]);  mm_32 = None
        slice_1065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_127, 1, 256, 272)
        slice_1066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1065, 2, 0, 16);  slice_1065 = None
        add_34: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1066, view_75);  slice_1066 = view_75 = None
        
        # No stacktrace found for following nodes
        slice_tensor_64: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_127, 1, 256, 272)
        slice_scatter_default_128: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_64, add_34, 2, 0, 16);  slice_tensor_64 = add_34 = None
        slice_scatter_default_129: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_127, slice_scatter_default_128, 1, 256, 272);  slice_scatter_default_127 = slice_scatter_default_128 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_129, 1, 256, 272)
        slice_1071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1070, 2, 0, 16);  slice_1070 = None
        
        # No stacktrace found for following nodes
        slice_tensor_65: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_129, 1, 256, 272)
        slice_scatter_default_130: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_65, slice_1071, 2, 0, 16);  slice_tensor_65 = slice_1071 = None
        slice_scatter_default_131: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_129, slice_scatter_default_130, 1, 256, 272);  slice_scatter_default_129 = slice_scatter_default_130 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1091: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1057, 2, 16, 32);  slice_1057 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_36: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1091, memory_format = torch.contiguous_format);  slice_1091 = None
        view_76: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_36, [32, 11]);  clone_36 = None
        mm_33: "f32[32, 8]" = torch.ops.aten.mm.default(view_76, slice_37)
        view_77: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_33, [2, 16, 8]);  mm_33 = None
        slice_1098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_131, 1, 256, 272)
        slice_1099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1098, 2, 0, 16);  slice_1098 = None
        add_35: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1099, view_77);  slice_1099 = view_77 = None
        
        # No stacktrace found for following nodes
        slice_tensor_66: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_131, 1, 256, 272)
        slice_scatter_default_132: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_66, add_35, 2, 0, 16);  slice_tensor_66 = add_35 = None
        slice_scatter_default_133: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_131, slice_scatter_default_132, 1, 256, 272);  slice_scatter_default_131 = slice_scatter_default_132 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_133, 1, 256, 272)
        slice_1104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1103, 2, 0, 16);  slice_1103 = None
        
        # No stacktrace found for following nodes
        slice_tensor_67: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_133, 1, 256, 272)
        slice_scatter_default_134: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_67, slice_1104, 2, 0, 16);  slice_tensor_67 = slice_1104 = None
        slice_scatter_default_135: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_133, slice_scatter_default_134, 1, 256, 272);  slice_scatter_default_133 = slice_scatter_default_134 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1123: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 272, 288)
        slice_1124: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1123, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_37: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1124, memory_format = torch.contiguous_format);  slice_1124 = None
        view_78: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_37, [32, 16]);  clone_37 = None
        mm_34: "f32[32, 8]" = torch.ops.aten.mm.default(view_78, slice_7)
        view_79: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_34, [2, 16, 8]);  mm_34 = None
        slice_1131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_135, 1, 272, 288)
        slice_1132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1131, 2, 0, 16);  slice_1131 = None
        add_36: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1132, view_79);  slice_1132 = view_79 = None
        
        # No stacktrace found for following nodes
        slice_tensor_68: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_135, 1, 272, 288)
        slice_scatter_default_136: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_68, add_36, 2, 0, 16);  slice_tensor_68 = add_36 = None
        slice_scatter_default_137: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_135, slice_scatter_default_136, 1, 272, 288);  slice_scatter_default_135 = slice_scatter_default_136 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_137, 1, 272, 288)
        slice_1137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1136, 2, 0, 16);  slice_1136 = None
        
        # No stacktrace found for following nodes
        slice_tensor_69: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_137, 1, 272, 288)
        slice_scatter_default_138: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_69, slice_1137, 2, 0, 16);  slice_tensor_69 = slice_1137 = None
        slice_scatter_default_139: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_137, slice_scatter_default_138, 1, 272, 288);  slice_scatter_default_137 = slice_scatter_default_138 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1157: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1123, 2, 16, 32);  slice_1123 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_38: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1157, memory_format = torch.contiguous_format);  slice_1157 = None
        view_80: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_38, [32, 11]);  clone_38 = None
        mm_35: "f32[32, 8]" = torch.ops.aten.mm.default(view_80, slice_37)
        view_81: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_35, [2, 16, 8]);  mm_35 = None
        slice_1164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_139, 1, 272, 288)
        slice_1165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1164, 2, 0, 16);  slice_1164 = None
        add_37: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1165, view_81);  slice_1165 = view_81 = None
        
        # No stacktrace found for following nodes
        slice_tensor_70: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_139, 1, 272, 288)
        slice_scatter_default_140: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_70, add_37, 2, 0, 16);  slice_tensor_70 = add_37 = None
        slice_scatter_default_141: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_139, slice_scatter_default_140, 1, 272, 288);  slice_scatter_default_139 = slice_scatter_default_140 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_141, 1, 272, 288)
        slice_1170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1169, 2, 0, 16);  slice_1169 = None
        
        # No stacktrace found for following nodes
        slice_tensor_71: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_141, 1, 272, 288)
        slice_scatter_default_142: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_71, slice_1170, 2, 0, 16);  slice_tensor_71 = slice_1170 = None
        slice_scatter_default_143: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_141, slice_scatter_default_142, 1, 272, 288);  slice_scatter_default_141 = slice_scatter_default_142 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1189: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 288, 304)
        slice_1190: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1189, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_39: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1190, memory_format = torch.contiguous_format);  slice_1190 = None
        view_82: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_39, [32, 16]);  clone_39 = None
        mm_36: "f32[32, 8]" = torch.ops.aten.mm.default(view_82, slice_7)
        view_83: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_36, [2, 16, 8]);  mm_36 = None
        slice_1197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_143, 1, 288, 304)
        slice_1198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1197, 2, 0, 16);  slice_1197 = None
        add_38: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1198, view_83);  slice_1198 = view_83 = None
        
        # No stacktrace found for following nodes
        slice_tensor_72: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_143, 1, 288, 304)
        slice_scatter_default_144: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_72, add_38, 2, 0, 16);  slice_tensor_72 = add_38 = None
        slice_scatter_default_145: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_143, slice_scatter_default_144, 1, 288, 304);  slice_scatter_default_143 = slice_scatter_default_144 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_145, 1, 288, 304)
        slice_1203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1202, 2, 0, 16);  slice_1202 = None
        
        # No stacktrace found for following nodes
        slice_tensor_73: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_145, 1, 288, 304)
        slice_scatter_default_146: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_73, slice_1203, 2, 0, 16);  slice_tensor_73 = slice_1203 = None
        slice_scatter_default_147: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_145, slice_scatter_default_146, 1, 288, 304);  slice_scatter_default_145 = slice_scatter_default_146 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1223: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1189, 2, 16, 32);  slice_1189 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_40: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1223, memory_format = torch.contiguous_format);  slice_1223 = None
        view_84: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_40, [32, 11]);  clone_40 = None
        mm_37: "f32[32, 8]" = torch.ops.aten.mm.default(view_84, slice_37)
        view_85: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_37, [2, 16, 8]);  mm_37 = None
        slice_1230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_147, 1, 288, 304)
        slice_1231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1230, 2, 0, 16);  slice_1230 = None
        add_39: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1231, view_85);  slice_1231 = view_85 = None
        
        # No stacktrace found for following nodes
        slice_tensor_74: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_147, 1, 288, 304)
        slice_scatter_default_148: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_74, add_39, 2, 0, 16);  slice_tensor_74 = add_39 = None
        slice_scatter_default_149: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_147, slice_scatter_default_148, 1, 288, 304);  slice_scatter_default_147 = slice_scatter_default_148 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_149, 1, 288, 304)
        slice_1236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1235, 2, 0, 16);  slice_1235 = None
        
        # No stacktrace found for following nodes
        slice_tensor_75: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_149, 1, 288, 304)
        slice_scatter_default_150: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_75, slice_1236, 2, 0, 16);  slice_tensor_75 = slice_1236 = None
        slice_scatter_default_151: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_149, slice_scatter_default_150, 1, 288, 304);  slice_scatter_default_149 = slice_scatter_default_150 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1255: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 304, 320)
        slice_1256: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1255, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_41: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1256, memory_format = torch.contiguous_format);  slice_1256 = None
        view_86: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_41, [32, 16]);  clone_41 = None
        mm_38: "f32[32, 8]" = torch.ops.aten.mm.default(view_86, slice_7)
        view_87: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_38, [2, 16, 8]);  mm_38 = None
        slice_1263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_151, 1, 304, 320)
        slice_1264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1263, 2, 0, 16);  slice_1263 = None
        add_40: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1264, view_87);  slice_1264 = view_87 = None
        
        # No stacktrace found for following nodes
        slice_tensor_76: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_151, 1, 304, 320)
        slice_scatter_default_152: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_76, add_40, 2, 0, 16);  slice_tensor_76 = add_40 = None
        slice_scatter_default_153: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_151, slice_scatter_default_152, 1, 304, 320);  slice_scatter_default_151 = slice_scatter_default_152 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_153, 1, 304, 320)
        slice_1269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1268, 2, 0, 16);  slice_1268 = None
        
        # No stacktrace found for following nodes
        slice_tensor_77: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_153, 1, 304, 320)
        slice_scatter_default_154: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_77, slice_1269, 2, 0, 16);  slice_tensor_77 = slice_1269 = None
        slice_scatter_default_155: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_153, slice_scatter_default_154, 1, 304, 320);  slice_scatter_default_153 = slice_scatter_default_154 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1289: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1255, 2, 16, 32);  slice_1255 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_42: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1289, memory_format = torch.contiguous_format);  slice_1289 = None
        view_88: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_42, [32, 11]);  clone_42 = None
        mm_39: "f32[32, 8]" = torch.ops.aten.mm.default(view_88, slice_37)
        view_89: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_39, [2, 16, 8]);  mm_39 = None
        slice_1296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_155, 1, 304, 320)
        slice_1297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1296, 2, 0, 16);  slice_1296 = None
        add_41: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1297, view_89);  slice_1297 = view_89 = None
        
        # No stacktrace found for following nodes
        slice_tensor_78: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_155, 1, 304, 320)
        slice_scatter_default_156: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_78, add_41, 2, 0, 16);  slice_tensor_78 = add_41 = None
        slice_scatter_default_157: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_155, slice_scatter_default_156, 1, 304, 320);  slice_scatter_default_155 = slice_scatter_default_156 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_157, 1, 304, 320)
        slice_1302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1301, 2, 0, 16);  slice_1301 = None
        
        # No stacktrace found for following nodes
        slice_tensor_79: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_157, 1, 304, 320)
        slice_scatter_default_158: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_79, slice_1302, 2, 0, 16);  slice_tensor_79 = slice_1302 = None
        slice_scatter_default_159: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_157, slice_scatter_default_158, 1, 304, 320);  slice_scatter_default_157 = slice_scatter_default_158 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1321: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 320, 336)
        slice_1322: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1321, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_43: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1322, memory_format = torch.contiguous_format);  slice_1322 = None
        view_90: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_43, [32, 16]);  clone_43 = None
        mm_40: "f32[32, 8]" = torch.ops.aten.mm.default(view_90, slice_7)
        view_91: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_40, [2, 16, 8]);  mm_40 = None
        slice_1329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_159, 1, 320, 336)
        slice_1330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1329, 2, 0, 16);  slice_1329 = None
        add_42: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1330, view_91);  slice_1330 = view_91 = None
        
        # No stacktrace found for following nodes
        slice_tensor_80: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_159, 1, 320, 336)
        slice_scatter_default_160: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_80, add_42, 2, 0, 16);  slice_tensor_80 = add_42 = None
        slice_scatter_default_161: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_159, slice_scatter_default_160, 1, 320, 336);  slice_scatter_default_159 = slice_scatter_default_160 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_161, 1, 320, 336)
        slice_1335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1334, 2, 0, 16);  slice_1334 = None
        
        # No stacktrace found for following nodes
        slice_tensor_81: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_161, 1, 320, 336)
        slice_scatter_default_162: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_81, slice_1335, 2, 0, 16);  slice_tensor_81 = slice_1335 = None
        slice_scatter_default_163: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_161, slice_scatter_default_162, 1, 320, 336);  slice_scatter_default_161 = slice_scatter_default_162 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1355: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1321, 2, 16, 32);  slice_1321 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_44: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1355, memory_format = torch.contiguous_format);  slice_1355 = None
        view_92: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_44, [32, 11]);  clone_44 = None
        mm_41: "f32[32, 8]" = torch.ops.aten.mm.default(view_92, slice_37)
        view_93: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_41, [2, 16, 8]);  mm_41 = None
        slice_1362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_163, 1, 320, 336)
        slice_1363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1362, 2, 0, 16);  slice_1362 = None
        add_43: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1363, view_93);  slice_1363 = view_93 = None
        
        # No stacktrace found for following nodes
        slice_tensor_82: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_163, 1, 320, 336)
        slice_scatter_default_164: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_82, add_43, 2, 0, 16);  slice_tensor_82 = add_43 = None
        slice_scatter_default_165: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_163, slice_scatter_default_164, 1, 320, 336);  slice_scatter_default_163 = slice_scatter_default_164 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_165, 1, 320, 336)
        slice_1368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1367, 2, 0, 16);  slice_1367 = None
        
        # No stacktrace found for following nodes
        slice_tensor_83: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_165, 1, 320, 336)
        slice_scatter_default_166: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_83, slice_1368, 2, 0, 16);  slice_tensor_83 = slice_1368 = None
        slice_scatter_default_167: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_165, slice_scatter_default_166, 1, 320, 336);  slice_scatter_default_165 = slice_scatter_default_166 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1387: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 336, 352)
        slice_1388: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1387, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_45: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1388, memory_format = torch.contiguous_format);  slice_1388 = None
        view_94: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_45, [32, 16]);  clone_45 = None
        mm_42: "f32[32, 8]" = torch.ops.aten.mm.default(view_94, slice_7)
        view_95: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_42, [2, 16, 8]);  mm_42 = None
        slice_1395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_167, 1, 336, 352)
        slice_1396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1395, 2, 0, 16);  slice_1395 = None
        add_44: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1396, view_95);  slice_1396 = view_95 = None
        
        # No stacktrace found for following nodes
        slice_tensor_84: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_167, 1, 336, 352)
        slice_scatter_default_168: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_84, add_44, 2, 0, 16);  slice_tensor_84 = add_44 = None
        slice_scatter_default_169: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_167, slice_scatter_default_168, 1, 336, 352);  slice_scatter_default_167 = slice_scatter_default_168 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_169, 1, 336, 352)
        slice_1401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1400, 2, 0, 16);  slice_1400 = None
        
        # No stacktrace found for following nodes
        slice_tensor_85: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_169, 1, 336, 352)
        slice_scatter_default_170: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_85, slice_1401, 2, 0, 16);  slice_tensor_85 = slice_1401 = None
        slice_scatter_default_171: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_169, slice_scatter_default_170, 1, 336, 352);  slice_scatter_default_169 = slice_scatter_default_170 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1421: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1387, 2, 16, 32);  slice_1387 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_46: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1421, memory_format = torch.contiguous_format);  slice_1421 = None
        view_96: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_46, [32, 11]);  clone_46 = None
        mm_43: "f32[32, 8]" = torch.ops.aten.mm.default(view_96, slice_37)
        view_97: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_43, [2, 16, 8]);  mm_43 = None
        slice_1428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_171, 1, 336, 352)
        slice_1429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1428, 2, 0, 16);  slice_1428 = None
        add_45: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1429, view_97);  slice_1429 = view_97 = None
        
        # No stacktrace found for following nodes
        slice_tensor_86: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_171, 1, 336, 352)
        slice_scatter_default_172: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_86, add_45, 2, 0, 16);  slice_tensor_86 = add_45 = None
        slice_scatter_default_173: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_171, slice_scatter_default_172, 1, 336, 352);  slice_scatter_default_171 = slice_scatter_default_172 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_173, 1, 336, 352)
        slice_1434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1433, 2, 0, 16);  slice_1433 = None
        
        # No stacktrace found for following nodes
        slice_tensor_87: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_173, 1, 336, 352)
        slice_scatter_default_174: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_87, slice_1434, 2, 0, 16);  slice_tensor_87 = slice_1434 = None
        slice_scatter_default_175: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_173, slice_scatter_default_174, 1, 336, 352);  slice_scatter_default_173 = slice_scatter_default_174 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1453: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 352, 368)
        slice_1454: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1453, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_47: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1454, memory_format = torch.contiguous_format);  slice_1454 = None
        view_98: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_47, [32, 16]);  clone_47 = None
        mm_44: "f32[32, 8]" = torch.ops.aten.mm.default(view_98, slice_7)
        view_99: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_44, [2, 16, 8]);  mm_44 = None
        slice_1461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_175, 1, 352, 368)
        slice_1462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1461, 2, 0, 16);  slice_1461 = None
        add_46: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1462, view_99);  slice_1462 = view_99 = None
        
        # No stacktrace found for following nodes
        slice_tensor_88: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_175, 1, 352, 368)
        slice_scatter_default_176: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_88, add_46, 2, 0, 16);  slice_tensor_88 = add_46 = None
        slice_scatter_default_177: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_175, slice_scatter_default_176, 1, 352, 368);  slice_scatter_default_175 = slice_scatter_default_176 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_177, 1, 352, 368)
        slice_1467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1466, 2, 0, 16);  slice_1466 = None
        
        # No stacktrace found for following nodes
        slice_tensor_89: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_177, 1, 352, 368)
        slice_scatter_default_178: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_89, slice_1467, 2, 0, 16);  slice_tensor_89 = slice_1467 = None
        slice_scatter_default_179: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_177, slice_scatter_default_178, 1, 352, 368);  slice_scatter_default_177 = slice_scatter_default_178 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1487: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1453, 2, 16, 32);  slice_1453 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_48: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1487, memory_format = torch.contiguous_format);  slice_1487 = None
        view_100: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_48, [32, 11]);  clone_48 = None
        mm_45: "f32[32, 8]" = torch.ops.aten.mm.default(view_100, slice_37)
        view_101: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_45, [2, 16, 8]);  mm_45 = None
        slice_1494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_179, 1, 352, 368)
        slice_1495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1494, 2, 0, 16);  slice_1494 = None
        add_47: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1495, view_101);  slice_1495 = view_101 = None
        
        # No stacktrace found for following nodes
        slice_tensor_90: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_179, 1, 352, 368)
        slice_scatter_default_180: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_90, add_47, 2, 0, 16);  slice_tensor_90 = add_47 = None
        slice_scatter_default_181: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_179, slice_scatter_default_180, 1, 352, 368);  slice_scatter_default_179 = slice_scatter_default_180 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_181, 1, 352, 368)
        slice_1500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1499, 2, 0, 16);  slice_1499 = None
        
        # No stacktrace found for following nodes
        slice_tensor_91: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_181, 1, 352, 368)
        slice_scatter_default_182: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_91, slice_1500, 2, 0, 16);  slice_tensor_91 = slice_1500 = None
        slice_scatter_default_183: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_181, slice_scatter_default_182, 1, 352, 368);  slice_scatter_default_181 = slice_scatter_default_182 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1519: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 368, 384)
        slice_1520: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1519, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_49: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1520, memory_format = torch.contiguous_format);  slice_1520 = None
        view_102: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_49, [32, 16]);  clone_49 = None
        mm_46: "f32[32, 8]" = torch.ops.aten.mm.default(view_102, slice_7)
        view_103: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_46, [2, 16, 8]);  mm_46 = None
        slice_1527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_183, 1, 368, 384)
        slice_1528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1527, 2, 0, 16);  slice_1527 = None
        add_48: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1528, view_103);  slice_1528 = view_103 = None
        
        # No stacktrace found for following nodes
        slice_tensor_92: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_183, 1, 368, 384)
        slice_scatter_default_184: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_92, add_48, 2, 0, 16);  slice_tensor_92 = add_48 = None
        slice_scatter_default_185: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_183, slice_scatter_default_184, 1, 368, 384);  slice_scatter_default_183 = slice_scatter_default_184 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_185, 1, 368, 384)
        slice_1533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1532, 2, 0, 16);  slice_1532 = None
        
        # No stacktrace found for following nodes
        slice_tensor_93: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_185, 1, 368, 384)
        slice_scatter_default_186: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_93, slice_1533, 2, 0, 16);  slice_tensor_93 = slice_1533 = None
        slice_scatter_default_187: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_185, slice_scatter_default_186, 1, 368, 384);  slice_scatter_default_185 = slice_scatter_default_186 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1553: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1519, 2, 16, 32);  slice_1519 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_50: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1553, memory_format = torch.contiguous_format);  slice_1553 = None
        view_104: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_50, [32, 11]);  clone_50 = None
        mm_47: "f32[32, 8]" = torch.ops.aten.mm.default(view_104, slice_37)
        view_105: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_47, [2, 16, 8]);  mm_47 = None
        slice_1560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_187, 1, 368, 384)
        slice_1561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1560, 2, 0, 16);  slice_1560 = None
        add_49: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1561, view_105);  slice_1561 = view_105 = None
        
        # No stacktrace found for following nodes
        slice_tensor_94: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_187, 1, 368, 384)
        slice_scatter_default_188: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_94, add_49, 2, 0, 16);  slice_tensor_94 = add_49 = None
        slice_scatter_default_189: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_187, slice_scatter_default_188, 1, 368, 384);  slice_scatter_default_187 = slice_scatter_default_188 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_189, 1, 368, 384)
        slice_1566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1565, 2, 0, 16);  slice_1565 = None
        
        # No stacktrace found for following nodes
        slice_tensor_95: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_189, 1, 368, 384)
        slice_scatter_default_190: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_95, slice_1566, 2, 0, 16);  slice_tensor_95 = slice_1566 = None
        slice_scatter_default_191: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_189, slice_scatter_default_190, 1, 368, 384);  slice_scatter_default_189 = slice_scatter_default_190 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1585: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 384, 400)
        slice_1586: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1585, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_51: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1586, memory_format = torch.contiguous_format);  slice_1586 = None
        view_106: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_51, [32, 16]);  clone_51 = None
        mm_48: "f32[32, 8]" = torch.ops.aten.mm.default(view_106, slice_7)
        view_107: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_48, [2, 16, 8]);  mm_48 = None
        slice_1593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_191, 1, 384, 400)
        slice_1594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1593, 2, 0, 16);  slice_1593 = None
        add_50: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1594, view_107);  slice_1594 = view_107 = None
        
        # No stacktrace found for following nodes
        slice_tensor_96: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_191, 1, 384, 400)
        slice_scatter_default_192: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_96, add_50, 2, 0, 16);  slice_tensor_96 = add_50 = None
        slice_scatter_default_193: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_191, slice_scatter_default_192, 1, 384, 400);  slice_scatter_default_191 = slice_scatter_default_192 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_193, 1, 384, 400)
        slice_1599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1598, 2, 0, 16);  slice_1598 = None
        
        # No stacktrace found for following nodes
        slice_tensor_97: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_193, 1, 384, 400)
        slice_scatter_default_194: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_97, slice_1599, 2, 0, 16);  slice_tensor_97 = slice_1599 = None
        slice_scatter_default_195: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_193, slice_scatter_default_194, 1, 384, 400);  slice_scatter_default_193 = slice_scatter_default_194 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1619: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1585, 2, 16, 32);  slice_1585 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_52: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1619, memory_format = torch.contiguous_format);  slice_1619 = None
        view_108: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_52, [32, 11]);  clone_52 = None
        mm_49: "f32[32, 8]" = torch.ops.aten.mm.default(view_108, slice_37)
        view_109: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_49, [2, 16, 8]);  mm_49 = None
        slice_1626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_195, 1, 384, 400)
        slice_1627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1626, 2, 0, 16);  slice_1626 = None
        add_51: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1627, view_109);  slice_1627 = view_109 = None
        
        # No stacktrace found for following nodes
        slice_tensor_98: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_195, 1, 384, 400)
        slice_scatter_default_196: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_98, add_51, 2, 0, 16);  slice_tensor_98 = add_51 = None
        slice_scatter_default_197: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_195, slice_scatter_default_196, 1, 384, 400);  slice_scatter_default_195 = slice_scatter_default_196 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_197, 1, 384, 400)
        slice_1632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1631, 2, 0, 16);  slice_1631 = None
        
        # No stacktrace found for following nodes
        slice_tensor_99: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_197, 1, 384, 400)
        slice_scatter_default_198: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_99, slice_1632, 2, 0, 16);  slice_tensor_99 = slice_1632 = None
        slice_scatter_default_199: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_197, slice_scatter_default_198, 1, 384, 400);  slice_scatter_default_197 = slice_scatter_default_198 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1651: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 400, 416)
        slice_1652: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1651, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_53: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1652, memory_format = torch.contiguous_format);  slice_1652 = None
        view_110: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_53, [32, 16]);  clone_53 = None
        mm_50: "f32[32, 8]" = torch.ops.aten.mm.default(view_110, slice_7)
        view_111: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_50, [2, 16, 8]);  mm_50 = None
        slice_1659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_199, 1, 400, 416)
        slice_1660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1659, 2, 0, 16);  slice_1659 = None
        add_52: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1660, view_111);  slice_1660 = view_111 = None
        
        # No stacktrace found for following nodes
        slice_tensor_100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_199, 1, 400, 416)
        slice_scatter_default_200: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_100, add_52, 2, 0, 16);  slice_tensor_100 = add_52 = None
        slice_scatter_default_201: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_199, slice_scatter_default_200, 1, 400, 416);  slice_scatter_default_199 = slice_scatter_default_200 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_201, 1, 400, 416)
        slice_1665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1664, 2, 0, 16);  slice_1664 = None
        
        # No stacktrace found for following nodes
        slice_tensor_101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_201, 1, 400, 416)
        slice_scatter_default_202: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_101, slice_1665, 2, 0, 16);  slice_tensor_101 = slice_1665 = None
        slice_scatter_default_203: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_201, slice_scatter_default_202, 1, 400, 416);  slice_scatter_default_201 = slice_scatter_default_202 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1685: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1651, 2, 16, 32);  slice_1651 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_54: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1685, memory_format = torch.contiguous_format);  slice_1685 = None
        view_112: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_54, [32, 11]);  clone_54 = None
        mm_51: "f32[32, 8]" = torch.ops.aten.mm.default(view_112, slice_37)
        view_113: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_51, [2, 16, 8]);  mm_51 = None
        slice_1692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_203, 1, 400, 416)
        slice_1693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1692, 2, 0, 16);  slice_1692 = None
        add_53: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1693, view_113);  slice_1693 = view_113 = None
        
        # No stacktrace found for following nodes
        slice_tensor_102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_203, 1, 400, 416)
        slice_scatter_default_204: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_102, add_53, 2, 0, 16);  slice_tensor_102 = add_53 = None
        slice_scatter_default_205: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_203, slice_scatter_default_204, 1, 400, 416);  slice_scatter_default_203 = slice_scatter_default_204 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_205, 1, 400, 416)
        slice_1698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1697, 2, 0, 16);  slice_1697 = None
        
        # No stacktrace found for following nodes
        slice_tensor_103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_205, 1, 400, 416)
        slice_scatter_default_206: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_103, slice_1698, 2, 0, 16);  slice_tensor_103 = slice_1698 = None
        slice_scatter_default_207: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_205, slice_scatter_default_206, 1, 400, 416);  slice_scatter_default_205 = slice_scatter_default_206 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1717: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 416, 432)
        slice_1718: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1717, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_55: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1718, memory_format = torch.contiguous_format);  slice_1718 = None
        view_114: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_55, [32, 16]);  clone_55 = None
        mm_52: "f32[32, 8]" = torch.ops.aten.mm.default(view_114, slice_7)
        view_115: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_52, [2, 16, 8]);  mm_52 = None
        slice_1725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_207, 1, 416, 432)
        slice_1726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1725, 2, 0, 16);  slice_1725 = None
        add_54: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1726, view_115);  slice_1726 = view_115 = None
        
        # No stacktrace found for following nodes
        slice_tensor_104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_207, 1, 416, 432)
        slice_scatter_default_208: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_104, add_54, 2, 0, 16);  slice_tensor_104 = add_54 = None
        slice_scatter_default_209: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_207, slice_scatter_default_208, 1, 416, 432);  slice_scatter_default_207 = slice_scatter_default_208 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_209, 1, 416, 432)
        slice_1731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1730, 2, 0, 16);  slice_1730 = None
        
        # No stacktrace found for following nodes
        slice_tensor_105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_209, 1, 416, 432)
        slice_scatter_default_210: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_105, slice_1731, 2, 0, 16);  slice_tensor_105 = slice_1731 = None
        slice_scatter_default_211: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_209, slice_scatter_default_210, 1, 416, 432);  slice_scatter_default_209 = slice_scatter_default_210 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1751: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1717, 2, 16, 32);  slice_1717 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_56: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1751, memory_format = torch.contiguous_format);  slice_1751 = None
        view_116: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_56, [32, 11]);  clone_56 = None
        mm_53: "f32[32, 8]" = torch.ops.aten.mm.default(view_116, slice_37)
        view_117: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_53, [2, 16, 8]);  mm_53 = None
        slice_1758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_211, 1, 416, 432)
        slice_1759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1758, 2, 0, 16);  slice_1758 = None
        add_55: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1759, view_117);  slice_1759 = view_117 = None
        
        # No stacktrace found for following nodes
        slice_tensor_106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_211, 1, 416, 432)
        slice_scatter_default_212: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_106, add_55, 2, 0, 16);  slice_tensor_106 = add_55 = None
        slice_scatter_default_213: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_211, slice_scatter_default_212, 1, 416, 432);  slice_scatter_default_211 = slice_scatter_default_212 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_213, 1, 416, 432)
        slice_1764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1763, 2, 0, 16);  slice_1763 = None
        
        # No stacktrace found for following nodes
        slice_tensor_107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_213, 1, 416, 432)
        slice_scatter_default_214: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_107, slice_1764, 2, 0, 16);  slice_tensor_107 = slice_1764 = None
        slice_scatter_default_215: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_213, slice_scatter_default_214, 1, 416, 432);  slice_scatter_default_213 = slice_scatter_default_214 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1783: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 432, 448)
        slice_1784: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1783, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_57: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1784, memory_format = torch.contiguous_format);  slice_1784 = None
        view_118: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_57, [32, 16]);  clone_57 = None
        mm_54: "f32[32, 8]" = torch.ops.aten.mm.default(view_118, slice_7)
        view_119: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_54, [2, 16, 8]);  mm_54 = None
        slice_1791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_215, 1, 432, 448)
        slice_1792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1791, 2, 0, 16);  slice_1791 = None
        add_56: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1792, view_119);  slice_1792 = view_119 = None
        
        # No stacktrace found for following nodes
        slice_tensor_108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_215, 1, 432, 448)
        slice_scatter_default_216: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_108, add_56, 2, 0, 16);  slice_tensor_108 = add_56 = None
        slice_scatter_default_217: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_215, slice_scatter_default_216, 1, 432, 448);  slice_scatter_default_215 = slice_scatter_default_216 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_217, 1, 432, 448)
        slice_1797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1796, 2, 0, 16);  slice_1796 = None
        
        # No stacktrace found for following nodes
        slice_tensor_109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_217, 1, 432, 448)
        slice_scatter_default_218: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_109, slice_1797, 2, 0, 16);  slice_tensor_109 = slice_1797 = None
        slice_scatter_default_219: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_217, slice_scatter_default_218, 1, 432, 448);  slice_scatter_default_217 = slice_scatter_default_218 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1817: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1783, 2, 16, 32);  slice_1783 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_58: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1817, memory_format = torch.contiguous_format);  slice_1817 = None
        view_120: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_58, [32, 11]);  clone_58 = None
        mm_55: "f32[32, 8]" = torch.ops.aten.mm.default(view_120, slice_37)
        view_121: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_55, [2, 16, 8]);  mm_55 = None
        slice_1824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_219, 1, 432, 448)
        slice_1825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1824, 2, 0, 16);  slice_1824 = None
        add_57: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1825, view_121);  slice_1825 = view_121 = None
        
        # No stacktrace found for following nodes
        slice_tensor_110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_219, 1, 432, 448)
        slice_scatter_default_220: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_110, add_57, 2, 0, 16);  slice_tensor_110 = add_57 = None
        slice_scatter_default_221: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_219, slice_scatter_default_220, 1, 432, 448);  slice_scatter_default_219 = slice_scatter_default_220 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_221, 1, 432, 448)
        slice_1830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1829, 2, 0, 16);  slice_1829 = None
        
        # No stacktrace found for following nodes
        slice_tensor_111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_221, 1, 432, 448)
        slice_scatter_default_222: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_111, slice_1830, 2, 0, 16);  slice_tensor_111 = slice_1830 = None
        slice_scatter_default_223: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_221, slice_scatter_default_222, 1, 432, 448);  slice_scatter_default_221 = slice_scatter_default_222 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1849: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 448, 464)
        slice_1850: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1849, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_59: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1850, memory_format = torch.contiguous_format);  slice_1850 = None
        view_122: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_59, [32, 16]);  clone_59 = None
        mm_56: "f32[32, 8]" = torch.ops.aten.mm.default(view_122, slice_7)
        view_123: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_56, [2, 16, 8]);  mm_56 = None
        slice_1857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_223, 1, 448, 464)
        slice_1858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1857, 2, 0, 16);  slice_1857 = None
        add_58: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1858, view_123);  slice_1858 = view_123 = None
        
        # No stacktrace found for following nodes
        slice_tensor_112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_223, 1, 448, 464)
        slice_scatter_default_224: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_112, add_58, 2, 0, 16);  slice_tensor_112 = add_58 = None
        slice_scatter_default_225: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_223, slice_scatter_default_224, 1, 448, 464);  slice_scatter_default_223 = slice_scatter_default_224 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_225, 1, 448, 464)
        slice_1863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1862, 2, 0, 16);  slice_1862 = None
        
        # No stacktrace found for following nodes
        slice_tensor_113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_225, 1, 448, 464)
        slice_scatter_default_226: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_113, slice_1863, 2, 0, 16);  slice_tensor_113 = slice_1863 = None
        slice_scatter_default_227: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_225, slice_scatter_default_226, 1, 448, 464);  slice_scatter_default_225 = slice_scatter_default_226 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1883: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1849, 2, 16, 32);  slice_1849 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_60: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1883, memory_format = torch.contiguous_format);  slice_1883 = None
        view_124: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_60, [32, 11]);  clone_60 = None
        mm_57: "f32[32, 8]" = torch.ops.aten.mm.default(view_124, slice_37)
        view_125: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_57, [2, 16, 8]);  mm_57 = None
        slice_1890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_227, 1, 448, 464)
        slice_1891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1890, 2, 0, 16);  slice_1890 = None
        add_59: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1891, view_125);  slice_1891 = view_125 = None
        
        # No stacktrace found for following nodes
        slice_tensor_114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_227, 1, 448, 464)
        slice_scatter_default_228: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_114, add_59, 2, 0, 16);  slice_tensor_114 = add_59 = None
        slice_scatter_default_229: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_227, slice_scatter_default_228, 1, 448, 464);  slice_scatter_default_227 = slice_scatter_default_228 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_229, 1, 448, 464)
        slice_1896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1895, 2, 0, 16);  slice_1895 = None
        
        # No stacktrace found for following nodes
        slice_tensor_115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_229, 1, 448, 464)
        slice_scatter_default_230: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_115, slice_1896, 2, 0, 16);  slice_tensor_115 = slice_1896 = None
        slice_scatter_default_231: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_229, slice_scatter_default_230, 1, 448, 464);  slice_scatter_default_229 = slice_scatter_default_230 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1915: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 464, 480)
        slice_1916: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1915, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_61: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1916, memory_format = torch.contiguous_format);  slice_1916 = None
        view_126: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_61, [32, 16]);  clone_61 = None
        mm_58: "f32[32, 8]" = torch.ops.aten.mm.default(view_126, slice_7)
        view_127: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_58, [2, 16, 8]);  mm_58 = None
        slice_1923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_231, 1, 464, 480)
        slice_1924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1923, 2, 0, 16);  slice_1923 = None
        add_60: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1924, view_127);  slice_1924 = view_127 = None
        
        # No stacktrace found for following nodes
        slice_tensor_116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_231, 1, 464, 480)
        slice_scatter_default_232: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_116, add_60, 2, 0, 16);  slice_tensor_116 = add_60 = None
        slice_scatter_default_233: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_231, slice_scatter_default_232, 1, 464, 480);  slice_scatter_default_231 = slice_scatter_default_232 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_233, 1, 464, 480)
        slice_1929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1928, 2, 0, 16);  slice_1928 = None
        
        # No stacktrace found for following nodes
        slice_tensor_117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_233, 1, 464, 480)
        slice_scatter_default_234: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_117, slice_1929, 2, 0, 16);  slice_tensor_117 = slice_1929 = None
        slice_scatter_default_235: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_233, slice_scatter_default_234, 1, 464, 480);  slice_scatter_default_233 = slice_scatter_default_234 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1949: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1915, 2, 16, 32);  slice_1915 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_62: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_1949, memory_format = torch.contiguous_format);  slice_1949 = None
        view_128: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_62, [32, 11]);  clone_62 = None
        mm_59: "f32[32, 8]" = torch.ops.aten.mm.default(view_128, slice_37)
        view_129: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_59, [2, 16, 8]);  mm_59 = None
        slice_1956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_235, 1, 464, 480)
        slice_1957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1956, 2, 0, 16);  slice_1956 = None
        add_61: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1957, view_129);  slice_1957 = view_129 = None
        
        # No stacktrace found for following nodes
        slice_tensor_118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_235, 1, 464, 480)
        slice_scatter_default_236: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_118, add_61, 2, 0, 16);  slice_tensor_118 = add_61 = None
        slice_scatter_default_237: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_235, slice_scatter_default_236, 1, 464, 480);  slice_scatter_default_235 = slice_scatter_default_236 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_237, 1, 464, 480)
        slice_1962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1961, 2, 0, 16);  slice_1961 = None
        
        # No stacktrace found for following nodes
        slice_tensor_119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_237, 1, 464, 480)
        slice_scatter_default_238: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_119, slice_1962, 2, 0, 16);  slice_tensor_119 = slice_1962 = None
        slice_scatter_default_239: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_237, slice_scatter_default_238, 1, 464, 480);  slice_scatter_default_237 = slice_scatter_default_238 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_1981: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 480, 496)
        slice_1982: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_1981, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_63: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_1982, memory_format = torch.contiguous_format);  slice_1982 = None
        view_130: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_63, [32, 16]);  clone_63 = None
        mm_60: "f32[32, 8]" = torch.ops.aten.mm.default(view_130, slice_7)
        view_131: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_60, [2, 16, 8]);  mm_60 = None
        slice_1989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_239, 1, 480, 496)
        slice_1990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1989, 2, 0, 16);  slice_1989 = None
        add_62: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_1990, view_131);  slice_1990 = view_131 = None
        
        # No stacktrace found for following nodes
        slice_tensor_120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_239, 1, 480, 496)
        slice_scatter_default_240: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_120, add_62, 2, 0, 16);  slice_tensor_120 = add_62 = None
        slice_scatter_default_241: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_239, slice_scatter_default_240, 1, 480, 496);  slice_scatter_default_239 = slice_scatter_default_240 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_1994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_241, 1, 480, 496)
        slice_1995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_1994, 2, 0, 16);  slice_1994 = None
        
        # No stacktrace found for following nodes
        slice_tensor_121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_241, 1, 480, 496)
        slice_scatter_default_242: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_121, slice_1995, 2, 0, 16);  slice_tensor_121 = slice_1995 = None
        slice_scatter_default_243: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_241, slice_scatter_default_242, 1, 480, 496);  slice_scatter_default_241 = slice_scatter_default_242 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2015: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_1981, 2, 16, 32);  slice_1981 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_64: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2015, memory_format = torch.contiguous_format);  slice_2015 = None
        view_132: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_64, [32, 11]);  clone_64 = None
        mm_61: "f32[32, 8]" = torch.ops.aten.mm.default(view_132, slice_37)
        view_133: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_61, [2, 16, 8]);  mm_61 = None
        slice_2022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_243, 1, 480, 496)
        slice_2023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2022, 2, 0, 16);  slice_2022 = None
        add_63: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2023, view_133);  slice_2023 = view_133 = None
        
        # No stacktrace found for following nodes
        slice_tensor_122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_243, 1, 480, 496)
        slice_scatter_default_244: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_122, add_63, 2, 0, 16);  slice_tensor_122 = add_63 = None
        slice_scatter_default_245: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_243, slice_scatter_default_244, 1, 480, 496);  slice_scatter_default_243 = slice_scatter_default_244 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_245, 1, 480, 496)
        slice_2028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2027, 2, 0, 16);  slice_2027 = None
        
        # No stacktrace found for following nodes
        slice_tensor_123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_245, 1, 480, 496)
        slice_scatter_default_246: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_123, slice_2028, 2, 0, 16);  slice_tensor_123 = slice_2028 = None
        slice_scatter_default_247: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_245, slice_scatter_default_246, 1, 480, 496);  slice_scatter_default_245 = slice_scatter_default_246 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2047: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 496, 512)
        slice_2048: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2047, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_65: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2048, memory_format = torch.contiguous_format);  slice_2048 = None
        view_134: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_65, [32, 16]);  clone_65 = None
        mm_62: "f32[32, 8]" = torch.ops.aten.mm.default(view_134, slice_7)
        view_135: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_62, [2, 16, 8]);  mm_62 = None
        slice_2055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_247, 1, 496, 512)
        slice_2056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2055, 2, 0, 16);  slice_2055 = None
        add_64: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2056, view_135);  slice_2056 = view_135 = None
        
        # No stacktrace found for following nodes
        slice_tensor_124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_247, 1, 496, 512)
        slice_scatter_default_248: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_124, add_64, 2, 0, 16);  slice_tensor_124 = add_64 = None
        slice_scatter_default_249: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_247, slice_scatter_default_248, 1, 496, 512);  slice_scatter_default_247 = slice_scatter_default_248 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_249, 1, 496, 512)
        slice_2061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2060, 2, 0, 16);  slice_2060 = None
        
        # No stacktrace found for following nodes
        slice_tensor_125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_249, 1, 496, 512)
        slice_scatter_default_250: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_125, slice_2061, 2, 0, 16);  slice_tensor_125 = slice_2061 = None
        slice_scatter_default_251: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_249, slice_scatter_default_250, 1, 496, 512);  slice_scatter_default_249 = slice_scatter_default_250 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2081: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2047, 2, 16, 32);  slice_2047 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_66: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2081, memory_format = torch.contiguous_format);  slice_2081 = None
        view_136: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_66, [32, 11]);  clone_66 = None
        mm_63: "f32[32, 8]" = torch.ops.aten.mm.default(view_136, slice_37)
        view_137: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_63, [2, 16, 8]);  mm_63 = None
        slice_2088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_251, 1, 496, 512)
        slice_2089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2088, 2, 0, 16);  slice_2088 = None
        add_65: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2089, view_137);  slice_2089 = view_137 = None
        
        # No stacktrace found for following nodes
        slice_tensor_126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_251, 1, 496, 512)
        slice_scatter_default_252: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_126, add_65, 2, 0, 16);  slice_tensor_126 = add_65 = None
        slice_scatter_default_253: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_251, slice_scatter_default_252, 1, 496, 512);  slice_scatter_default_251 = slice_scatter_default_252 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_253, 1, 496, 512)
        slice_2094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2093, 2, 0, 16);  slice_2093 = None
        
        # No stacktrace found for following nodes
        slice_tensor_127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_253, 1, 496, 512)
        slice_scatter_default_254: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_127, slice_2094, 2, 0, 16);  slice_tensor_127 = slice_2094 = None
        slice_scatter_default_255: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_253, slice_scatter_default_254, 1, 496, 512);  slice_scatter_default_253 = slice_scatter_default_254 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2113: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 512, 528)
        slice_2114: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2113, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_67: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2114, memory_format = torch.contiguous_format);  slice_2114 = None
        view_138: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_67, [32, 16]);  clone_67 = None
        mm_64: "f32[32, 8]" = torch.ops.aten.mm.default(view_138, slice_7)
        view_139: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_64, [2, 16, 8]);  mm_64 = None
        slice_2121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_255, 1, 512, 528)
        slice_2122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2121, 2, 0, 16);  slice_2121 = None
        add_66: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2122, view_139);  slice_2122 = view_139 = None
        
        # No stacktrace found for following nodes
        slice_tensor_128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_255, 1, 512, 528)
        slice_scatter_default_256: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_128, add_66, 2, 0, 16);  slice_tensor_128 = add_66 = None
        slice_scatter_default_257: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_255, slice_scatter_default_256, 1, 512, 528);  slice_scatter_default_255 = slice_scatter_default_256 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_257, 1, 512, 528)
        slice_2127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2126, 2, 0, 16);  slice_2126 = None
        
        # No stacktrace found for following nodes
        slice_tensor_129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_257, 1, 512, 528)
        slice_scatter_default_258: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_129, slice_2127, 2, 0, 16);  slice_tensor_129 = slice_2127 = None
        slice_scatter_default_259: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_257, slice_scatter_default_258, 1, 512, 528);  slice_scatter_default_257 = slice_scatter_default_258 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2147: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2113, 2, 16, 32);  slice_2113 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_68: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2147, memory_format = torch.contiguous_format);  slice_2147 = None
        view_140: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_68, [32, 11]);  clone_68 = None
        mm_65: "f32[32, 8]" = torch.ops.aten.mm.default(view_140, slice_37)
        view_141: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_65, [2, 16, 8]);  mm_65 = None
        slice_2154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_259, 1, 512, 528)
        slice_2155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2154, 2, 0, 16);  slice_2154 = None
        add_67: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2155, view_141);  slice_2155 = view_141 = None
        
        # No stacktrace found for following nodes
        slice_tensor_130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_259, 1, 512, 528)
        slice_scatter_default_260: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_130, add_67, 2, 0, 16);  slice_tensor_130 = add_67 = None
        slice_scatter_default_261: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_259, slice_scatter_default_260, 1, 512, 528);  slice_scatter_default_259 = slice_scatter_default_260 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_261, 1, 512, 528)
        slice_2160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2159, 2, 0, 16);  slice_2159 = None
        
        # No stacktrace found for following nodes
        slice_tensor_131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_261, 1, 512, 528)
        slice_scatter_default_262: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_131, slice_2160, 2, 0, 16);  slice_tensor_131 = slice_2160 = None
        slice_scatter_default_263: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_261, slice_scatter_default_262, 1, 512, 528);  slice_scatter_default_261 = slice_scatter_default_262 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2179: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 528, 544)
        slice_2180: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2179, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_69: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2180, memory_format = torch.contiguous_format);  slice_2180 = None
        view_142: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_69, [32, 16]);  clone_69 = None
        mm_66: "f32[32, 8]" = torch.ops.aten.mm.default(view_142, slice_7)
        view_143: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_66, [2, 16, 8]);  mm_66 = None
        slice_2187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_263, 1, 528, 544)
        slice_2188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2187, 2, 0, 16);  slice_2187 = None
        add_68: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2188, view_143);  slice_2188 = view_143 = None
        
        # No stacktrace found for following nodes
        slice_tensor_132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_263, 1, 528, 544)
        slice_scatter_default_264: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_132, add_68, 2, 0, 16);  slice_tensor_132 = add_68 = None
        slice_scatter_default_265: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_263, slice_scatter_default_264, 1, 528, 544);  slice_scatter_default_263 = slice_scatter_default_264 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_265, 1, 528, 544)
        slice_2193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2192, 2, 0, 16);  slice_2192 = None
        
        # No stacktrace found for following nodes
        slice_tensor_133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_265, 1, 528, 544)
        slice_scatter_default_266: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_133, slice_2193, 2, 0, 16);  slice_tensor_133 = slice_2193 = None
        slice_scatter_default_267: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_265, slice_scatter_default_266, 1, 528, 544);  slice_scatter_default_265 = slice_scatter_default_266 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2213: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2179, 2, 16, 32);  slice_2179 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_70: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2213, memory_format = torch.contiguous_format);  slice_2213 = None
        view_144: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_70, [32, 11]);  clone_70 = None
        mm_67: "f32[32, 8]" = torch.ops.aten.mm.default(view_144, slice_37)
        view_145: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_67, [2, 16, 8]);  mm_67 = None
        slice_2220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_267, 1, 528, 544)
        slice_2221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2220, 2, 0, 16);  slice_2220 = None
        add_69: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2221, view_145);  slice_2221 = view_145 = None
        
        # No stacktrace found for following nodes
        slice_tensor_134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_267, 1, 528, 544)
        slice_scatter_default_268: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_134, add_69, 2, 0, 16);  slice_tensor_134 = add_69 = None
        slice_scatter_default_269: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_267, slice_scatter_default_268, 1, 528, 544);  slice_scatter_default_267 = slice_scatter_default_268 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_269, 1, 528, 544)
        slice_2226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2225, 2, 0, 16);  slice_2225 = None
        
        # No stacktrace found for following nodes
        slice_tensor_135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_269, 1, 528, 544)
        slice_scatter_default_270: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_135, slice_2226, 2, 0, 16);  slice_tensor_135 = slice_2226 = None
        slice_scatter_default_271: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_269, slice_scatter_default_270, 1, 528, 544);  slice_scatter_default_269 = slice_scatter_default_270 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2245: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 544, 560)
        slice_2246: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2245, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_71: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2246, memory_format = torch.contiguous_format);  slice_2246 = None
        view_146: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_71, [32, 16]);  clone_71 = None
        mm_68: "f32[32, 8]" = torch.ops.aten.mm.default(view_146, slice_7)
        view_147: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_68, [2, 16, 8]);  mm_68 = None
        slice_2253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_271, 1, 544, 560)
        slice_2254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2253, 2, 0, 16);  slice_2253 = None
        add_70: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2254, view_147);  slice_2254 = view_147 = None
        
        # No stacktrace found for following nodes
        slice_tensor_136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_271, 1, 544, 560)
        slice_scatter_default_272: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_136, add_70, 2, 0, 16);  slice_tensor_136 = add_70 = None
        slice_scatter_default_273: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_271, slice_scatter_default_272, 1, 544, 560);  slice_scatter_default_271 = slice_scatter_default_272 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_273, 1, 544, 560)
        slice_2259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2258, 2, 0, 16);  slice_2258 = None
        
        # No stacktrace found for following nodes
        slice_tensor_137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_273, 1, 544, 560)
        slice_scatter_default_274: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_137, slice_2259, 2, 0, 16);  slice_tensor_137 = slice_2259 = None
        slice_scatter_default_275: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_273, slice_scatter_default_274, 1, 544, 560);  slice_scatter_default_273 = slice_scatter_default_274 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2279: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2245, 2, 16, 32);  slice_2245 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_72: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2279, memory_format = torch.contiguous_format);  slice_2279 = None
        view_148: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_72, [32, 11]);  clone_72 = None
        mm_69: "f32[32, 8]" = torch.ops.aten.mm.default(view_148, slice_37)
        view_149: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_69, [2, 16, 8]);  mm_69 = None
        slice_2286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_275, 1, 544, 560)
        slice_2287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2286, 2, 0, 16);  slice_2286 = None
        add_71: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2287, view_149);  slice_2287 = view_149 = None
        
        # No stacktrace found for following nodes
        slice_tensor_138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_275, 1, 544, 560)
        slice_scatter_default_276: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_138, add_71, 2, 0, 16);  slice_tensor_138 = add_71 = None
        slice_scatter_default_277: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_275, slice_scatter_default_276, 1, 544, 560);  slice_scatter_default_275 = slice_scatter_default_276 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_277, 1, 544, 560)
        slice_2292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2291, 2, 0, 16);  slice_2291 = None
        
        # No stacktrace found for following nodes
        slice_tensor_139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_277, 1, 544, 560)
        slice_scatter_default_278: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_139, slice_2292, 2, 0, 16);  slice_tensor_139 = slice_2292 = None
        slice_scatter_default_279: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_277, slice_scatter_default_278, 1, 544, 560);  slice_scatter_default_277 = slice_scatter_default_278 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2311: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 560, 576)
        slice_2312: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2311, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_73: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2312, memory_format = torch.contiguous_format);  slice_2312 = None
        view_150: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_73, [32, 16]);  clone_73 = None
        mm_70: "f32[32, 8]" = torch.ops.aten.mm.default(view_150, slice_7)
        view_151: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_70, [2, 16, 8]);  mm_70 = None
        slice_2319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_279, 1, 560, 576)
        slice_2320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2319, 2, 0, 16);  slice_2319 = None
        add_72: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2320, view_151);  slice_2320 = view_151 = None
        
        # No stacktrace found for following nodes
        slice_tensor_140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_279, 1, 560, 576)
        slice_scatter_default_280: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_140, add_72, 2, 0, 16);  slice_tensor_140 = add_72 = None
        slice_scatter_default_281: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_279, slice_scatter_default_280, 1, 560, 576);  slice_scatter_default_279 = slice_scatter_default_280 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_281, 1, 560, 576)
        slice_2325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2324, 2, 0, 16);  slice_2324 = None
        
        # No stacktrace found for following nodes
        slice_tensor_141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_281, 1, 560, 576)
        slice_scatter_default_282: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_141, slice_2325, 2, 0, 16);  slice_tensor_141 = slice_2325 = None
        slice_scatter_default_283: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_281, slice_scatter_default_282, 1, 560, 576);  slice_scatter_default_281 = slice_scatter_default_282 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2345: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2311, 2, 16, 32);  slice_2311 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_74: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2345, memory_format = torch.contiguous_format);  slice_2345 = None
        view_152: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_74, [32, 11]);  clone_74 = None
        mm_71: "f32[32, 8]" = torch.ops.aten.mm.default(view_152, slice_37)
        view_153: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_71, [2, 16, 8]);  mm_71 = None
        slice_2352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_283, 1, 560, 576)
        slice_2353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2352, 2, 0, 16);  slice_2352 = None
        add_73: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2353, view_153);  slice_2353 = view_153 = None
        
        # No stacktrace found for following nodes
        slice_tensor_142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_283, 1, 560, 576)
        slice_scatter_default_284: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_142, add_73, 2, 0, 16);  slice_tensor_142 = add_73 = None
        slice_scatter_default_285: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_283, slice_scatter_default_284, 1, 560, 576);  slice_scatter_default_283 = slice_scatter_default_284 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_285, 1, 560, 576)
        slice_2358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2357, 2, 0, 16);  slice_2357 = None
        
        # No stacktrace found for following nodes
        slice_tensor_143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_285, 1, 560, 576)
        slice_scatter_default_286: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_143, slice_2358, 2, 0, 16);  slice_tensor_143 = slice_2358 = None
        slice_scatter_default_287: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_285, slice_scatter_default_286, 1, 560, 576);  slice_scatter_default_285 = slice_scatter_default_286 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2377: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 576, 592)
        slice_2378: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2377, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_75: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2378, memory_format = torch.contiguous_format);  slice_2378 = None
        view_154: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_75, [32, 16]);  clone_75 = None
        mm_72: "f32[32, 8]" = torch.ops.aten.mm.default(view_154, slice_7)
        view_155: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_72, [2, 16, 8]);  mm_72 = None
        slice_2385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_287, 1, 576, 592)
        slice_2386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2385, 2, 0, 16);  slice_2385 = None
        add_74: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2386, view_155);  slice_2386 = view_155 = None
        
        # No stacktrace found for following nodes
        slice_tensor_144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_287, 1, 576, 592)
        slice_scatter_default_288: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_144, add_74, 2, 0, 16);  slice_tensor_144 = add_74 = None
        slice_scatter_default_289: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_287, slice_scatter_default_288, 1, 576, 592);  slice_scatter_default_287 = slice_scatter_default_288 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_289, 1, 576, 592)
        slice_2391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2390, 2, 0, 16);  slice_2390 = None
        
        # No stacktrace found for following nodes
        slice_tensor_145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_289, 1, 576, 592)
        slice_scatter_default_290: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_145, slice_2391, 2, 0, 16);  slice_tensor_145 = slice_2391 = None
        slice_scatter_default_291: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_289, slice_scatter_default_290, 1, 576, 592);  slice_scatter_default_289 = slice_scatter_default_290 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2411: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2377, 2, 16, 32);  slice_2377 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_76: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2411, memory_format = torch.contiguous_format);  slice_2411 = None
        view_156: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_76, [32, 11]);  clone_76 = None
        mm_73: "f32[32, 8]" = torch.ops.aten.mm.default(view_156, slice_37)
        view_157: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_73, [2, 16, 8]);  mm_73 = None
        slice_2418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_291, 1, 576, 592)
        slice_2419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2418, 2, 0, 16);  slice_2418 = None
        add_75: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2419, view_157);  slice_2419 = view_157 = None
        
        # No stacktrace found for following nodes
        slice_tensor_146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_291, 1, 576, 592)
        slice_scatter_default_292: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_146, add_75, 2, 0, 16);  slice_tensor_146 = add_75 = None
        slice_scatter_default_293: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_291, slice_scatter_default_292, 1, 576, 592);  slice_scatter_default_291 = slice_scatter_default_292 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_293, 1, 576, 592)
        slice_2424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2423, 2, 0, 16);  slice_2423 = None
        
        # No stacktrace found for following nodes
        slice_tensor_147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_293, 1, 576, 592)
        slice_scatter_default_294: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_147, slice_2424, 2, 0, 16);  slice_tensor_147 = slice_2424 = None
        slice_scatter_default_295: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_293, slice_scatter_default_294, 1, 576, 592);  slice_scatter_default_293 = slice_scatter_default_294 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2443: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 592, 608)
        slice_2444: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2443, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_77: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2444, memory_format = torch.contiguous_format);  slice_2444 = None
        view_158: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_77, [32, 16]);  clone_77 = None
        mm_74: "f32[32, 8]" = torch.ops.aten.mm.default(view_158, slice_7)
        view_159: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_74, [2, 16, 8]);  mm_74 = None
        slice_2451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_295, 1, 592, 608)
        slice_2452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2451, 2, 0, 16);  slice_2451 = None
        add_76: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2452, view_159);  slice_2452 = view_159 = None
        
        # No stacktrace found for following nodes
        slice_tensor_148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_295, 1, 592, 608)
        slice_scatter_default_296: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_148, add_76, 2, 0, 16);  slice_tensor_148 = add_76 = None
        slice_scatter_default_297: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_295, slice_scatter_default_296, 1, 592, 608);  slice_scatter_default_295 = slice_scatter_default_296 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_297, 1, 592, 608)
        slice_2457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2456, 2, 0, 16);  slice_2456 = None
        
        # No stacktrace found for following nodes
        slice_tensor_149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_297, 1, 592, 608)
        slice_scatter_default_298: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_149, slice_2457, 2, 0, 16);  slice_tensor_149 = slice_2457 = None
        slice_scatter_default_299: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_297, slice_scatter_default_298, 1, 592, 608);  slice_scatter_default_297 = slice_scatter_default_298 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2477: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2443, 2, 16, 32);  slice_2443 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_78: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2477, memory_format = torch.contiguous_format);  slice_2477 = None
        view_160: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_78, [32, 11]);  clone_78 = None
        mm_75: "f32[32, 8]" = torch.ops.aten.mm.default(view_160, slice_37)
        view_161: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_75, [2, 16, 8]);  mm_75 = None
        slice_2484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_299, 1, 592, 608)
        slice_2485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2484, 2, 0, 16);  slice_2484 = None
        add_77: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2485, view_161);  slice_2485 = view_161 = None
        
        # No stacktrace found for following nodes
        slice_tensor_150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_299, 1, 592, 608)
        slice_scatter_default_300: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_150, add_77, 2, 0, 16);  slice_tensor_150 = add_77 = None
        slice_scatter_default_301: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_299, slice_scatter_default_300, 1, 592, 608);  slice_scatter_default_299 = slice_scatter_default_300 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_301, 1, 592, 608)
        slice_2490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2489, 2, 0, 16);  slice_2489 = None
        
        # No stacktrace found for following nodes
        slice_tensor_151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_301, 1, 592, 608)
        slice_scatter_default_302: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_151, slice_2490, 2, 0, 16);  slice_tensor_151 = slice_2490 = None
        slice_scatter_default_303: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_301, slice_scatter_default_302, 1, 592, 608);  slice_scatter_default_301 = slice_scatter_default_302 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2509: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 608, 624)
        slice_2510: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2509, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_79: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2510, memory_format = torch.contiguous_format);  slice_2510 = None
        view_162: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_79, [32, 16]);  clone_79 = None
        mm_76: "f32[32, 8]" = torch.ops.aten.mm.default(view_162, slice_7)
        view_163: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_76, [2, 16, 8]);  mm_76 = None
        slice_2517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_303, 1, 608, 624)
        slice_2518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2517, 2, 0, 16);  slice_2517 = None
        add_78: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2518, view_163);  slice_2518 = view_163 = None
        
        # No stacktrace found for following nodes
        slice_tensor_152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_303, 1, 608, 624)
        slice_scatter_default_304: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_152, add_78, 2, 0, 16);  slice_tensor_152 = add_78 = None
        slice_scatter_default_305: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_303, slice_scatter_default_304, 1, 608, 624);  slice_scatter_default_303 = slice_scatter_default_304 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_305, 1, 608, 624)
        slice_2523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2522, 2, 0, 16);  slice_2522 = None
        
        # No stacktrace found for following nodes
        slice_tensor_153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_305, 1, 608, 624)
        slice_scatter_default_306: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_153, slice_2523, 2, 0, 16);  slice_tensor_153 = slice_2523 = None
        slice_scatter_default_307: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_305, slice_scatter_default_306, 1, 608, 624);  slice_scatter_default_305 = slice_scatter_default_306 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2543: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2509, 2, 16, 32);  slice_2509 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_80: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2543, memory_format = torch.contiguous_format);  slice_2543 = None
        view_164: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_80, [32, 11]);  clone_80 = None
        mm_77: "f32[32, 8]" = torch.ops.aten.mm.default(view_164, slice_37)
        view_165: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_77, [2, 16, 8]);  mm_77 = None
        slice_2550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_307, 1, 608, 624)
        slice_2551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2550, 2, 0, 16);  slice_2550 = None
        add_79: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2551, view_165);  slice_2551 = view_165 = None
        
        # No stacktrace found for following nodes
        slice_tensor_154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_307, 1, 608, 624)
        slice_scatter_default_308: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_154, add_79, 2, 0, 16);  slice_tensor_154 = add_79 = None
        slice_scatter_default_309: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_307, slice_scatter_default_308, 1, 608, 624);  slice_scatter_default_307 = slice_scatter_default_308 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_309, 1, 608, 624)
        slice_2556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2555, 2, 0, 16);  slice_2555 = None
        
        # No stacktrace found for following nodes
        slice_tensor_155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_309, 1, 608, 624)
        slice_scatter_default_310: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_155, slice_2556, 2, 0, 16);  slice_tensor_155 = slice_2556 = None
        slice_scatter_default_311: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_309, slice_scatter_default_310, 1, 608, 624);  slice_scatter_default_309 = slice_scatter_default_310 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2575: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 624, 640)
        slice_2576: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2575, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_81: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2576, memory_format = torch.contiguous_format);  slice_2576 = None
        view_166: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_81, [32, 16]);  clone_81 = None
        mm_78: "f32[32, 8]" = torch.ops.aten.mm.default(view_166, slice_7)
        view_167: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_78, [2, 16, 8]);  mm_78 = None
        slice_2583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_311, 1, 624, 640)
        slice_2584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2583, 2, 0, 16);  slice_2583 = None
        add_80: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2584, view_167);  slice_2584 = view_167 = None
        
        # No stacktrace found for following nodes
        slice_tensor_156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_311, 1, 624, 640)
        slice_scatter_default_312: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_156, add_80, 2, 0, 16);  slice_tensor_156 = add_80 = None
        slice_scatter_default_313: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_311, slice_scatter_default_312, 1, 624, 640);  slice_scatter_default_311 = slice_scatter_default_312 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_313, 1, 624, 640)
        slice_2589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2588, 2, 0, 16);  slice_2588 = None
        
        # No stacktrace found for following nodes
        slice_tensor_157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_313, 1, 624, 640)
        slice_scatter_default_314: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_157, slice_2589, 2, 0, 16);  slice_tensor_157 = slice_2589 = None
        slice_scatter_default_315: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_313, slice_scatter_default_314, 1, 624, 640);  slice_scatter_default_313 = slice_scatter_default_314 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2609: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2575, 2, 16, 32);  slice_2575 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_82: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2609, memory_format = torch.contiguous_format);  slice_2609 = None
        view_168: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_82, [32, 11]);  clone_82 = None
        mm_79: "f32[32, 8]" = torch.ops.aten.mm.default(view_168, slice_37)
        view_169: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_79, [2, 16, 8]);  mm_79 = None
        slice_2616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_315, 1, 624, 640)
        slice_2617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2616, 2, 0, 16);  slice_2616 = None
        add_81: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2617, view_169);  slice_2617 = view_169 = None
        
        # No stacktrace found for following nodes
        slice_tensor_158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_315, 1, 624, 640)
        slice_scatter_default_316: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_158, add_81, 2, 0, 16);  slice_tensor_158 = add_81 = None
        slice_scatter_default_317: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_315, slice_scatter_default_316, 1, 624, 640);  slice_scatter_default_315 = slice_scatter_default_316 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_317, 1, 624, 640)
        slice_2622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2621, 2, 0, 16);  slice_2621 = None
        
        # No stacktrace found for following nodes
        slice_tensor_159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_317, 1, 624, 640)
        slice_scatter_default_318: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_159, slice_2622, 2, 0, 16);  slice_tensor_159 = slice_2622 = None
        slice_scatter_default_319: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_317, slice_scatter_default_318, 1, 624, 640);  slice_scatter_default_317 = slice_scatter_default_318 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2641: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 640, 656)
        slice_2642: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2641, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_83: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2642, memory_format = torch.contiguous_format);  slice_2642 = None
        view_170: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_83, [32, 16]);  clone_83 = None
        mm_80: "f32[32, 8]" = torch.ops.aten.mm.default(view_170, slice_7)
        view_171: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_80, [2, 16, 8]);  mm_80 = None
        slice_2649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_319, 1, 640, 656)
        slice_2650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2649, 2, 0, 16);  slice_2649 = None
        add_82: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2650, view_171);  slice_2650 = view_171 = None
        
        # No stacktrace found for following nodes
        slice_tensor_160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_319, 1, 640, 656)
        slice_scatter_default_320: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_160, add_82, 2, 0, 16);  slice_tensor_160 = add_82 = None
        slice_scatter_default_321: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_319, slice_scatter_default_320, 1, 640, 656);  slice_scatter_default_319 = slice_scatter_default_320 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_321, 1, 640, 656)
        slice_2655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2654, 2, 0, 16);  slice_2654 = None
        
        # No stacktrace found for following nodes
        slice_tensor_161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_321, 1, 640, 656)
        slice_scatter_default_322: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_161, slice_2655, 2, 0, 16);  slice_tensor_161 = slice_2655 = None
        slice_scatter_default_323: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_321, slice_scatter_default_322, 1, 640, 656);  slice_scatter_default_321 = slice_scatter_default_322 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2675: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2641, 2, 16, 32);  slice_2641 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_84: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2675, memory_format = torch.contiguous_format);  slice_2675 = None
        view_172: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_84, [32, 11]);  clone_84 = None
        mm_81: "f32[32, 8]" = torch.ops.aten.mm.default(view_172, slice_37)
        view_173: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_81, [2, 16, 8]);  mm_81 = None
        slice_2682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_323, 1, 640, 656)
        slice_2683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2682, 2, 0, 16);  slice_2682 = None
        add_83: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2683, view_173);  slice_2683 = view_173 = None
        
        # No stacktrace found for following nodes
        slice_tensor_162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_323, 1, 640, 656)
        slice_scatter_default_324: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_162, add_83, 2, 0, 16);  slice_tensor_162 = add_83 = None
        slice_scatter_default_325: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_323, slice_scatter_default_324, 1, 640, 656);  slice_scatter_default_323 = slice_scatter_default_324 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_325, 1, 640, 656)
        slice_2688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2687, 2, 0, 16);  slice_2687 = None
        
        # No stacktrace found for following nodes
        slice_tensor_163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_325, 1, 640, 656)
        slice_scatter_default_326: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_163, slice_2688, 2, 0, 16);  slice_tensor_163 = slice_2688 = None
        slice_scatter_default_327: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_325, slice_scatter_default_326, 1, 640, 656);  slice_scatter_default_325 = slice_scatter_default_326 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2707: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 656, 672)
        slice_2708: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2707, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_85: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2708, memory_format = torch.contiguous_format);  slice_2708 = None
        view_174: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_85, [32, 16]);  clone_85 = None
        mm_82: "f32[32, 8]" = torch.ops.aten.mm.default(view_174, slice_7)
        view_175: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_82, [2, 16, 8]);  mm_82 = None
        slice_2715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_327, 1, 656, 672)
        slice_2716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2715, 2, 0, 16);  slice_2715 = None
        add_84: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2716, view_175);  slice_2716 = view_175 = None
        
        # No stacktrace found for following nodes
        slice_tensor_164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_327, 1, 656, 672)
        slice_scatter_default_328: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_164, add_84, 2, 0, 16);  slice_tensor_164 = add_84 = None
        slice_scatter_default_329: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_327, slice_scatter_default_328, 1, 656, 672);  slice_scatter_default_327 = slice_scatter_default_328 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_329, 1, 656, 672)
        slice_2721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2720, 2, 0, 16);  slice_2720 = None
        
        # No stacktrace found for following nodes
        slice_tensor_165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_329, 1, 656, 672)
        slice_scatter_default_330: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_165, slice_2721, 2, 0, 16);  slice_tensor_165 = slice_2721 = None
        slice_scatter_default_331: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_329, slice_scatter_default_330, 1, 656, 672);  slice_scatter_default_329 = slice_scatter_default_330 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2741: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2707, 2, 16, 32);  slice_2707 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_86: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2741, memory_format = torch.contiguous_format);  slice_2741 = None
        view_176: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_86, [32, 11]);  clone_86 = None
        mm_83: "f32[32, 8]" = torch.ops.aten.mm.default(view_176, slice_37)
        view_177: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_83, [2, 16, 8]);  mm_83 = None
        slice_2748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_331, 1, 656, 672)
        slice_2749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2748, 2, 0, 16);  slice_2748 = None
        add_85: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2749, view_177);  slice_2749 = view_177 = None
        
        # No stacktrace found for following nodes
        slice_tensor_166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_331, 1, 656, 672)
        slice_scatter_default_332: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_166, add_85, 2, 0, 16);  slice_tensor_166 = add_85 = None
        slice_scatter_default_333: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_331, slice_scatter_default_332, 1, 656, 672);  slice_scatter_default_331 = slice_scatter_default_332 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_333, 1, 656, 672)
        slice_2754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2753, 2, 0, 16);  slice_2753 = None
        
        # No stacktrace found for following nodes
        slice_tensor_167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_333, 1, 656, 672)
        slice_scatter_default_334: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_167, slice_2754, 2, 0, 16);  slice_tensor_167 = slice_2754 = None
        slice_scatter_default_335: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_333, slice_scatter_default_334, 1, 656, 672);  slice_scatter_default_333 = slice_scatter_default_334 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2773: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 672, 688)
        slice_2774: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2773, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_87: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2774, memory_format = torch.contiguous_format);  slice_2774 = None
        view_178: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_87, [32, 16]);  clone_87 = None
        mm_84: "f32[32, 8]" = torch.ops.aten.mm.default(view_178, slice_7)
        view_179: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_84, [2, 16, 8]);  mm_84 = None
        slice_2781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_335, 1, 672, 688)
        slice_2782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2781, 2, 0, 16);  slice_2781 = None
        add_86: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2782, view_179);  slice_2782 = view_179 = None
        
        # No stacktrace found for following nodes
        slice_tensor_168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_335, 1, 672, 688)
        slice_scatter_default_336: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_168, add_86, 2, 0, 16);  slice_tensor_168 = add_86 = None
        slice_scatter_default_337: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_335, slice_scatter_default_336, 1, 672, 688);  slice_scatter_default_335 = slice_scatter_default_336 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_337, 1, 672, 688)
        slice_2787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2786, 2, 0, 16);  slice_2786 = None
        
        # No stacktrace found for following nodes
        slice_tensor_169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_337, 1, 672, 688)
        slice_scatter_default_338: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_169, slice_2787, 2, 0, 16);  slice_tensor_169 = slice_2787 = None
        slice_scatter_default_339: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_337, slice_scatter_default_338, 1, 672, 688);  slice_scatter_default_337 = slice_scatter_default_338 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2807: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2773, 2, 16, 32);  slice_2773 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_88: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2807, memory_format = torch.contiguous_format);  slice_2807 = None
        view_180: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_88, [32, 11]);  clone_88 = None
        mm_85: "f32[32, 8]" = torch.ops.aten.mm.default(view_180, slice_37)
        view_181: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_85, [2, 16, 8]);  mm_85 = None
        slice_2814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_339, 1, 672, 688)
        slice_2815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2814, 2, 0, 16);  slice_2814 = None
        add_87: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2815, view_181);  slice_2815 = view_181 = None
        
        # No stacktrace found for following nodes
        slice_tensor_170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_339, 1, 672, 688)
        slice_scatter_default_340: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_170, add_87, 2, 0, 16);  slice_tensor_170 = add_87 = None
        slice_scatter_default_341: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_339, slice_scatter_default_340, 1, 672, 688);  slice_scatter_default_339 = slice_scatter_default_340 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_341, 1, 672, 688)
        slice_2820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2819, 2, 0, 16);  slice_2819 = None
        
        # No stacktrace found for following nodes
        slice_tensor_171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_341, 1, 672, 688)
        slice_scatter_default_342: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_171, slice_2820, 2, 0, 16);  slice_tensor_171 = slice_2820 = None
        slice_scatter_default_343: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_341, slice_scatter_default_342, 1, 672, 688);  slice_scatter_default_341 = slice_scatter_default_342 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2839: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 688, 704)
        slice_2840: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2839, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_89: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2840, memory_format = torch.contiguous_format);  slice_2840 = None
        view_182: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_89, [32, 16]);  clone_89 = None
        mm_86: "f32[32, 8]" = torch.ops.aten.mm.default(view_182, slice_7)
        view_183: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_86, [2, 16, 8]);  mm_86 = None
        slice_2847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_343, 1, 688, 704)
        slice_2848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2847, 2, 0, 16);  slice_2847 = None
        add_88: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2848, view_183);  slice_2848 = view_183 = None
        
        # No stacktrace found for following nodes
        slice_tensor_172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_343, 1, 688, 704)
        slice_scatter_default_344: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_172, add_88, 2, 0, 16);  slice_tensor_172 = add_88 = None
        slice_scatter_default_345: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_343, slice_scatter_default_344, 1, 688, 704);  slice_scatter_default_343 = slice_scatter_default_344 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_345, 1, 688, 704)
        slice_2853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2852, 2, 0, 16);  slice_2852 = None
        
        # No stacktrace found for following nodes
        slice_tensor_173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_345, 1, 688, 704)
        slice_scatter_default_346: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_173, slice_2853, 2, 0, 16);  slice_tensor_173 = slice_2853 = None
        slice_scatter_default_347: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_345, slice_scatter_default_346, 1, 688, 704);  slice_scatter_default_345 = slice_scatter_default_346 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2873: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2839, 2, 16, 32);  slice_2839 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_90: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2873, memory_format = torch.contiguous_format);  slice_2873 = None
        view_184: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_90, [32, 11]);  clone_90 = None
        mm_87: "f32[32, 8]" = torch.ops.aten.mm.default(view_184, slice_37)
        view_185: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_87, [2, 16, 8]);  mm_87 = None
        slice_2880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_347, 1, 688, 704)
        slice_2881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2880, 2, 0, 16);  slice_2880 = None
        add_89: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2881, view_185);  slice_2881 = view_185 = None
        
        # No stacktrace found for following nodes
        slice_tensor_174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_347, 1, 688, 704)
        slice_scatter_default_348: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_174, add_89, 2, 0, 16);  slice_tensor_174 = add_89 = None
        slice_scatter_default_349: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_347, slice_scatter_default_348, 1, 688, 704);  slice_scatter_default_347 = slice_scatter_default_348 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_349, 1, 688, 704)
        slice_2886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2885, 2, 0, 16);  slice_2885 = None
        
        # No stacktrace found for following nodes
        slice_tensor_175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_349, 1, 688, 704)
        slice_scatter_default_350: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_175, slice_2886, 2, 0, 16);  slice_tensor_175 = slice_2886 = None
        slice_scatter_default_351: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_349, slice_scatter_default_350, 1, 688, 704);  slice_scatter_default_349 = slice_scatter_default_350 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2905: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 704, 720)
        slice_2906: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2905, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_91: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2906, memory_format = torch.contiguous_format);  slice_2906 = None
        view_186: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_91, [32, 16]);  clone_91 = None
        mm_88: "f32[32, 8]" = torch.ops.aten.mm.default(view_186, slice_7)
        view_187: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_88, [2, 16, 8]);  mm_88 = None
        slice_2913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_351, 1, 704, 720)
        slice_2914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2913, 2, 0, 16);  slice_2913 = None
        add_90: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2914, view_187);  slice_2914 = view_187 = None
        
        # No stacktrace found for following nodes
        slice_tensor_176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_351, 1, 704, 720)
        slice_scatter_default_352: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_176, add_90, 2, 0, 16);  slice_tensor_176 = add_90 = None
        slice_scatter_default_353: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_351, slice_scatter_default_352, 1, 704, 720);  slice_scatter_default_351 = slice_scatter_default_352 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_353, 1, 704, 720)
        slice_2919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2918, 2, 0, 16);  slice_2918 = None
        
        # No stacktrace found for following nodes
        slice_tensor_177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_353, 1, 704, 720)
        slice_scatter_default_354: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_177, slice_2919, 2, 0, 16);  slice_tensor_177 = slice_2919 = None
        slice_scatter_default_355: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_353, slice_scatter_default_354, 1, 704, 720);  slice_scatter_default_353 = slice_scatter_default_354 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2939: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2905, 2, 16, 32);  slice_2905 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_92: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_2939, memory_format = torch.contiguous_format);  slice_2939 = None
        view_188: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_92, [32, 11]);  clone_92 = None
        mm_89: "f32[32, 8]" = torch.ops.aten.mm.default(view_188, slice_37)
        view_189: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_89, [2, 16, 8]);  mm_89 = None
        slice_2946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_355, 1, 704, 720)
        slice_2947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2946, 2, 0, 16);  slice_2946 = None
        add_91: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2947, view_189);  slice_2947 = view_189 = None
        
        # No stacktrace found for following nodes
        slice_tensor_178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_355, 1, 704, 720)
        slice_scatter_default_356: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_178, add_91, 2, 0, 16);  slice_tensor_178 = add_91 = None
        slice_scatter_default_357: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_355, slice_scatter_default_356, 1, 704, 720);  slice_scatter_default_355 = slice_scatter_default_356 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_357, 1, 704, 720)
        slice_2952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2951, 2, 0, 16);  slice_2951 = None
        
        # No stacktrace found for following nodes
        slice_tensor_179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_357, 1, 704, 720)
        slice_scatter_default_358: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_179, slice_2952, 2, 0, 16);  slice_tensor_179 = slice_2952 = None
        slice_scatter_default_359: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_357, slice_scatter_default_358, 1, 704, 720);  slice_scatter_default_357 = slice_scatter_default_358 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_2971: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 720, 736)
        slice_2972: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_2971, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_93: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_2972, memory_format = torch.contiguous_format);  slice_2972 = None
        view_190: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_93, [32, 16]);  clone_93 = None
        mm_90: "f32[32, 8]" = torch.ops.aten.mm.default(view_190, slice_7)
        view_191: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_90, [2, 16, 8]);  mm_90 = None
        slice_2979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_359, 1, 720, 736)
        slice_2980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2979, 2, 0, 16);  slice_2979 = None
        add_92: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_2980, view_191);  slice_2980 = view_191 = None
        
        # No stacktrace found for following nodes
        slice_tensor_180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_359, 1, 720, 736)
        slice_scatter_default_360: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_180, add_92, 2, 0, 16);  slice_tensor_180 = add_92 = None
        slice_scatter_default_361: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_359, slice_scatter_default_360, 1, 720, 736);  slice_scatter_default_359 = slice_scatter_default_360 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_2984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_361, 1, 720, 736)
        slice_2985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_2984, 2, 0, 16);  slice_2984 = None
        
        # No stacktrace found for following nodes
        slice_tensor_181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_361, 1, 720, 736)
        slice_scatter_default_362: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_181, slice_2985, 2, 0, 16);  slice_tensor_181 = slice_2985 = None
        slice_scatter_default_363: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_361, slice_scatter_default_362, 1, 720, 736);  slice_scatter_default_361 = slice_scatter_default_362 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3005: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_2971, 2, 16, 32);  slice_2971 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_94: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3005, memory_format = torch.contiguous_format);  slice_3005 = None
        view_192: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_94, [32, 11]);  clone_94 = None
        mm_91: "f32[32, 8]" = torch.ops.aten.mm.default(view_192, slice_37)
        view_193: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_91, [2, 16, 8]);  mm_91 = None
        slice_3012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_363, 1, 720, 736)
        slice_3013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3012, 2, 0, 16);  slice_3012 = None
        add_93: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3013, view_193);  slice_3013 = view_193 = None
        
        # No stacktrace found for following nodes
        slice_tensor_182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_363, 1, 720, 736)
        slice_scatter_default_364: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_182, add_93, 2, 0, 16);  slice_tensor_182 = add_93 = None
        slice_scatter_default_365: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_363, slice_scatter_default_364, 1, 720, 736);  slice_scatter_default_363 = slice_scatter_default_364 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_365, 1, 720, 736)
        slice_3018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3017, 2, 0, 16);  slice_3017 = None
        
        # No stacktrace found for following nodes
        slice_tensor_183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_365, 1, 720, 736)
        slice_scatter_default_366: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_183, slice_3018, 2, 0, 16);  slice_tensor_183 = slice_3018 = None
        slice_scatter_default_367: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_365, slice_scatter_default_366, 1, 720, 736);  slice_scatter_default_365 = slice_scatter_default_366 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3037: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 736, 752)
        slice_3038: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3037, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_95: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3038, memory_format = torch.contiguous_format);  slice_3038 = None
        view_194: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_95, [32, 16]);  clone_95 = None
        mm_92: "f32[32, 8]" = torch.ops.aten.mm.default(view_194, slice_7)
        view_195: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_92, [2, 16, 8]);  mm_92 = None
        slice_3045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_367, 1, 736, 752)
        slice_3046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3045, 2, 0, 16);  slice_3045 = None
        add_94: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3046, view_195);  slice_3046 = view_195 = None
        
        # No stacktrace found for following nodes
        slice_tensor_184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_367, 1, 736, 752)
        slice_scatter_default_368: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_184, add_94, 2, 0, 16);  slice_tensor_184 = add_94 = None
        slice_scatter_default_369: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_367, slice_scatter_default_368, 1, 736, 752);  slice_scatter_default_367 = slice_scatter_default_368 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_369, 1, 736, 752)
        slice_3051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3050, 2, 0, 16);  slice_3050 = None
        
        # No stacktrace found for following nodes
        slice_tensor_185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_369, 1, 736, 752)
        slice_scatter_default_370: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_185, slice_3051, 2, 0, 16);  slice_tensor_185 = slice_3051 = None
        slice_scatter_default_371: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_369, slice_scatter_default_370, 1, 736, 752);  slice_scatter_default_369 = slice_scatter_default_370 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3071: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3037, 2, 16, 32);  slice_3037 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_96: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3071, memory_format = torch.contiguous_format);  slice_3071 = None
        view_196: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_96, [32, 11]);  clone_96 = None
        mm_93: "f32[32, 8]" = torch.ops.aten.mm.default(view_196, slice_37)
        view_197: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_93, [2, 16, 8]);  mm_93 = None
        slice_3078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_371, 1, 736, 752)
        slice_3079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3078, 2, 0, 16);  slice_3078 = None
        add_95: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3079, view_197);  slice_3079 = view_197 = None
        
        # No stacktrace found for following nodes
        slice_tensor_186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_371, 1, 736, 752)
        slice_scatter_default_372: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_186, add_95, 2, 0, 16);  slice_tensor_186 = add_95 = None
        slice_scatter_default_373: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_371, slice_scatter_default_372, 1, 736, 752);  slice_scatter_default_371 = slice_scatter_default_372 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_373, 1, 736, 752)
        slice_3084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3083, 2, 0, 16);  slice_3083 = None
        
        # No stacktrace found for following nodes
        slice_tensor_187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_373, 1, 736, 752)
        slice_scatter_default_374: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_187, slice_3084, 2, 0, 16);  slice_tensor_187 = slice_3084 = None
        slice_scatter_default_375: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_373, slice_scatter_default_374, 1, 736, 752);  slice_scatter_default_373 = slice_scatter_default_374 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3103: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 752, 768)
        slice_3104: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3103, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_97: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3104, memory_format = torch.contiguous_format);  slice_3104 = None
        view_198: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_97, [32, 16]);  clone_97 = None
        mm_94: "f32[32, 8]" = torch.ops.aten.mm.default(view_198, slice_7)
        view_199: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_94, [2, 16, 8]);  mm_94 = None
        slice_3111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_375, 1, 752, 768)
        slice_3112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3111, 2, 0, 16);  slice_3111 = None
        add_96: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3112, view_199);  slice_3112 = view_199 = None
        
        # No stacktrace found for following nodes
        slice_tensor_188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_375, 1, 752, 768)
        slice_scatter_default_376: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_188, add_96, 2, 0, 16);  slice_tensor_188 = add_96 = None
        slice_scatter_default_377: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_375, slice_scatter_default_376, 1, 752, 768);  slice_scatter_default_375 = slice_scatter_default_376 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_377, 1, 752, 768)
        slice_3117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3116, 2, 0, 16);  slice_3116 = None
        
        # No stacktrace found for following nodes
        slice_tensor_189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_377, 1, 752, 768)
        slice_scatter_default_378: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_189, slice_3117, 2, 0, 16);  slice_tensor_189 = slice_3117 = None
        slice_scatter_default_379: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_377, slice_scatter_default_378, 1, 752, 768);  slice_scatter_default_377 = slice_scatter_default_378 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3137: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3103, 2, 16, 32);  slice_3103 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_98: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3137, memory_format = torch.contiguous_format);  slice_3137 = None
        view_200: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_98, [32, 11]);  clone_98 = None
        mm_95: "f32[32, 8]" = torch.ops.aten.mm.default(view_200, slice_37)
        view_201: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_95, [2, 16, 8]);  mm_95 = None
        slice_3144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_379, 1, 752, 768)
        slice_3145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3144, 2, 0, 16);  slice_3144 = None
        add_97: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3145, view_201);  slice_3145 = view_201 = None
        
        # No stacktrace found for following nodes
        slice_tensor_190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_379, 1, 752, 768)
        slice_scatter_default_380: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_190, add_97, 2, 0, 16);  slice_tensor_190 = add_97 = None
        slice_scatter_default_381: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_379, slice_scatter_default_380, 1, 752, 768);  slice_scatter_default_379 = slice_scatter_default_380 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_381, 1, 752, 768)
        slice_3150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3149, 2, 0, 16);  slice_3149 = None
        
        # No stacktrace found for following nodes
        slice_tensor_191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_381, 1, 752, 768)
        slice_scatter_default_382: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_191, slice_3150, 2, 0, 16);  slice_tensor_191 = slice_3150 = None
        slice_scatter_default_383: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_381, slice_scatter_default_382, 1, 752, 768);  slice_scatter_default_381 = slice_scatter_default_382 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3169: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 768, 784)
        slice_3170: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3169, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_99: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3170, memory_format = torch.contiguous_format);  slice_3170 = None
        view_202: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_99, [32, 16]);  clone_99 = None
        mm_96: "f32[32, 8]" = torch.ops.aten.mm.default(view_202, slice_7)
        view_203: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_96, [2, 16, 8]);  mm_96 = None
        slice_3177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_383, 1, 768, 784)
        slice_3178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3177, 2, 0, 16);  slice_3177 = None
        add_98: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3178, view_203);  slice_3178 = view_203 = None
        
        # No stacktrace found for following nodes
        slice_tensor_192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_383, 1, 768, 784)
        slice_scatter_default_384: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_192, add_98, 2, 0, 16);  slice_tensor_192 = add_98 = None
        slice_scatter_default_385: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_383, slice_scatter_default_384, 1, 768, 784);  slice_scatter_default_383 = slice_scatter_default_384 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_385, 1, 768, 784)
        slice_3183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3182, 2, 0, 16);  slice_3182 = None
        
        # No stacktrace found for following nodes
        slice_tensor_193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_385, 1, 768, 784)
        slice_scatter_default_386: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_193, slice_3183, 2, 0, 16);  slice_tensor_193 = slice_3183 = None
        slice_scatter_default_387: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_385, slice_scatter_default_386, 1, 768, 784);  slice_scatter_default_385 = slice_scatter_default_386 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3203: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3169, 2, 16, 32);  slice_3169 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_100: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3203, memory_format = torch.contiguous_format);  slice_3203 = None
        view_204: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_100, [32, 11]);  clone_100 = None
        mm_97: "f32[32, 8]" = torch.ops.aten.mm.default(view_204, slice_37)
        view_205: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_97, [2, 16, 8]);  mm_97 = None
        slice_3210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_387, 1, 768, 784)
        slice_3211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3210, 2, 0, 16);  slice_3210 = None
        add_99: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3211, view_205);  slice_3211 = view_205 = None
        
        # No stacktrace found for following nodes
        slice_tensor_194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_387, 1, 768, 784)
        slice_scatter_default_388: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_194, add_99, 2, 0, 16);  slice_tensor_194 = add_99 = None
        slice_scatter_default_389: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_387, slice_scatter_default_388, 1, 768, 784);  slice_scatter_default_387 = slice_scatter_default_388 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_389, 1, 768, 784)
        slice_3216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3215, 2, 0, 16);  slice_3215 = None
        
        # No stacktrace found for following nodes
        slice_tensor_195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_389, 1, 768, 784)
        slice_scatter_default_390: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_195, slice_3216, 2, 0, 16);  slice_tensor_195 = slice_3216 = None
        slice_scatter_default_391: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_389, slice_scatter_default_390, 1, 768, 784);  slice_scatter_default_389 = slice_scatter_default_390 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3235: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 784, 800)
        slice_3236: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3235, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_101: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3236, memory_format = torch.contiguous_format);  slice_3236 = None
        view_206: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_101, [32, 16]);  clone_101 = None
        mm_98: "f32[32, 8]" = torch.ops.aten.mm.default(view_206, slice_7)
        view_207: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_98, [2, 16, 8]);  mm_98 = None
        slice_3243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_391, 1, 784, 800)
        slice_3244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3243, 2, 0, 16);  slice_3243 = None
        add_100: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3244, view_207);  slice_3244 = view_207 = None
        
        # No stacktrace found for following nodes
        slice_tensor_196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_391, 1, 784, 800)
        slice_scatter_default_392: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_196, add_100, 2, 0, 16);  slice_tensor_196 = add_100 = None
        slice_scatter_default_393: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_391, slice_scatter_default_392, 1, 784, 800);  slice_scatter_default_391 = slice_scatter_default_392 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_393, 1, 784, 800)
        slice_3249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3248, 2, 0, 16);  slice_3248 = None
        
        # No stacktrace found for following nodes
        slice_tensor_197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_393, 1, 784, 800)
        slice_scatter_default_394: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_197, slice_3249, 2, 0, 16);  slice_tensor_197 = slice_3249 = None
        slice_scatter_default_395: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_393, slice_scatter_default_394, 1, 784, 800);  slice_scatter_default_393 = slice_scatter_default_394 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3269: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3235, 2, 16, 32);  slice_3235 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_102: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3269, memory_format = torch.contiguous_format);  slice_3269 = None
        view_208: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_102, [32, 11]);  clone_102 = None
        mm_99: "f32[32, 8]" = torch.ops.aten.mm.default(view_208, slice_37)
        view_209: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_99, [2, 16, 8]);  mm_99 = None
        slice_3276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_395, 1, 784, 800)
        slice_3277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3276, 2, 0, 16);  slice_3276 = None
        add_101: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3277, view_209);  slice_3277 = view_209 = None
        
        # No stacktrace found for following nodes
        slice_tensor_198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_395, 1, 784, 800)
        slice_scatter_default_396: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_198, add_101, 2, 0, 16);  slice_tensor_198 = add_101 = None
        slice_scatter_default_397: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_395, slice_scatter_default_396, 1, 784, 800);  slice_scatter_default_395 = slice_scatter_default_396 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_397, 1, 784, 800)
        slice_3282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3281, 2, 0, 16);  slice_3281 = None
        
        # No stacktrace found for following nodes
        slice_tensor_199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_397, 1, 784, 800)
        slice_scatter_default_398: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_199, slice_3282, 2, 0, 16);  slice_tensor_199 = slice_3282 = None
        slice_scatter_default_399: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_397, slice_scatter_default_398, 1, 784, 800);  slice_scatter_default_397 = slice_scatter_default_398 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3301: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 800, 816)
        slice_3302: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3301, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_103: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3302, memory_format = torch.contiguous_format);  slice_3302 = None
        view_210: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_103, [32, 16]);  clone_103 = None
        mm_100: "f32[32, 8]" = torch.ops.aten.mm.default(view_210, slice_7)
        view_211: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_100, [2, 16, 8]);  mm_100 = None
        slice_3309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_399, 1, 800, 816)
        slice_3310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3309, 2, 0, 16);  slice_3309 = None
        add_102: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3310, view_211);  slice_3310 = view_211 = None
        
        # No stacktrace found for following nodes
        slice_tensor_200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_399, 1, 800, 816)
        slice_scatter_default_400: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_200, add_102, 2, 0, 16);  slice_tensor_200 = add_102 = None
        slice_scatter_default_401: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_399, slice_scatter_default_400, 1, 800, 816);  slice_scatter_default_399 = slice_scatter_default_400 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_401, 1, 800, 816)
        slice_3315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3314, 2, 0, 16);  slice_3314 = None
        
        # No stacktrace found for following nodes
        slice_tensor_201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_401, 1, 800, 816)
        slice_scatter_default_402: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_201, slice_3315, 2, 0, 16);  slice_tensor_201 = slice_3315 = None
        slice_scatter_default_403: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_401, slice_scatter_default_402, 1, 800, 816);  slice_scatter_default_401 = slice_scatter_default_402 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3335: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3301, 2, 16, 32);  slice_3301 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_104: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3335, memory_format = torch.contiguous_format);  slice_3335 = None
        view_212: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_104, [32, 11]);  clone_104 = None
        mm_101: "f32[32, 8]" = torch.ops.aten.mm.default(view_212, slice_37)
        view_213: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_101, [2, 16, 8]);  mm_101 = None
        slice_3342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_403, 1, 800, 816)
        slice_3343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3342, 2, 0, 16);  slice_3342 = None
        add_103: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3343, view_213);  slice_3343 = view_213 = None
        
        # No stacktrace found for following nodes
        slice_tensor_202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_403, 1, 800, 816)
        slice_scatter_default_404: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_202, add_103, 2, 0, 16);  slice_tensor_202 = add_103 = None
        slice_scatter_default_405: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_403, slice_scatter_default_404, 1, 800, 816);  slice_scatter_default_403 = slice_scatter_default_404 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_405, 1, 800, 816)
        slice_3348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3347, 2, 0, 16);  slice_3347 = None
        
        # No stacktrace found for following nodes
        slice_tensor_203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_405, 1, 800, 816)
        slice_scatter_default_406: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_203, slice_3348, 2, 0, 16);  slice_tensor_203 = slice_3348 = None
        slice_scatter_default_407: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_405, slice_scatter_default_406, 1, 800, 816);  slice_scatter_default_405 = slice_scatter_default_406 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3367: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 816, 832)
        slice_3368: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3367, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_105: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3368, memory_format = torch.contiguous_format);  slice_3368 = None
        view_214: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_105, [32, 16]);  clone_105 = None
        mm_102: "f32[32, 8]" = torch.ops.aten.mm.default(view_214, slice_7)
        view_215: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_102, [2, 16, 8]);  mm_102 = None
        slice_3375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_407, 1, 816, 832)
        slice_3376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3375, 2, 0, 16);  slice_3375 = None
        add_104: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3376, view_215);  slice_3376 = view_215 = None
        
        # No stacktrace found for following nodes
        slice_tensor_204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_407, 1, 816, 832)
        slice_scatter_default_408: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_204, add_104, 2, 0, 16);  slice_tensor_204 = add_104 = None
        slice_scatter_default_409: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_407, slice_scatter_default_408, 1, 816, 832);  slice_scatter_default_407 = slice_scatter_default_408 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_409, 1, 816, 832)
        slice_3381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3380, 2, 0, 16);  slice_3380 = None
        
        # No stacktrace found for following nodes
        slice_tensor_205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_409, 1, 816, 832)
        slice_scatter_default_410: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_205, slice_3381, 2, 0, 16);  slice_tensor_205 = slice_3381 = None
        slice_scatter_default_411: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_409, slice_scatter_default_410, 1, 816, 832);  slice_scatter_default_409 = slice_scatter_default_410 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3401: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3367, 2, 16, 32);  slice_3367 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_106: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3401, memory_format = torch.contiguous_format);  slice_3401 = None
        view_216: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_106, [32, 11]);  clone_106 = None
        mm_103: "f32[32, 8]" = torch.ops.aten.mm.default(view_216, slice_37)
        view_217: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_103, [2, 16, 8]);  mm_103 = None
        slice_3408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_411, 1, 816, 832)
        slice_3409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3408, 2, 0, 16);  slice_3408 = None
        add_105: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3409, view_217);  slice_3409 = view_217 = None
        
        # No stacktrace found for following nodes
        slice_tensor_206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_411, 1, 816, 832)
        slice_scatter_default_412: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_206, add_105, 2, 0, 16);  slice_tensor_206 = add_105 = None
        slice_scatter_default_413: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_411, slice_scatter_default_412, 1, 816, 832);  slice_scatter_default_411 = slice_scatter_default_412 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_413, 1, 816, 832)
        slice_3414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3413, 2, 0, 16);  slice_3413 = None
        
        # No stacktrace found for following nodes
        slice_tensor_207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_413, 1, 816, 832)
        slice_scatter_default_414: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_207, slice_3414, 2, 0, 16);  slice_tensor_207 = slice_3414 = None
        slice_scatter_default_415: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_413, slice_scatter_default_414, 1, 816, 832);  slice_scatter_default_413 = slice_scatter_default_414 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3433: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 832, 848)
        slice_3434: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3433, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_107: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3434, memory_format = torch.contiguous_format);  slice_3434 = None
        view_218: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_107, [32, 16]);  clone_107 = None
        mm_104: "f32[32, 8]" = torch.ops.aten.mm.default(view_218, slice_7)
        view_219: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_104, [2, 16, 8]);  mm_104 = None
        slice_3441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_415, 1, 832, 848)
        slice_3442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3441, 2, 0, 16);  slice_3441 = None
        add_106: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3442, view_219);  slice_3442 = view_219 = None
        
        # No stacktrace found for following nodes
        slice_tensor_208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_415, 1, 832, 848)
        slice_scatter_default_416: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_208, add_106, 2, 0, 16);  slice_tensor_208 = add_106 = None
        slice_scatter_default_417: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_415, slice_scatter_default_416, 1, 832, 848);  slice_scatter_default_415 = slice_scatter_default_416 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_417, 1, 832, 848)
        slice_3447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3446, 2, 0, 16);  slice_3446 = None
        
        # No stacktrace found for following nodes
        slice_tensor_209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_417, 1, 832, 848)
        slice_scatter_default_418: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_209, slice_3447, 2, 0, 16);  slice_tensor_209 = slice_3447 = None
        slice_scatter_default_419: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_417, slice_scatter_default_418, 1, 832, 848);  slice_scatter_default_417 = slice_scatter_default_418 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3467: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3433, 2, 16, 32);  slice_3433 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_108: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3467, memory_format = torch.contiguous_format);  slice_3467 = None
        view_220: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_108, [32, 11]);  clone_108 = None
        mm_105: "f32[32, 8]" = torch.ops.aten.mm.default(view_220, slice_37)
        view_221: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_105, [2, 16, 8]);  mm_105 = None
        slice_3474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_419, 1, 832, 848)
        slice_3475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3474, 2, 0, 16);  slice_3474 = None
        add_107: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3475, view_221);  slice_3475 = view_221 = None
        
        # No stacktrace found for following nodes
        slice_tensor_210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_419, 1, 832, 848)
        slice_scatter_default_420: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_210, add_107, 2, 0, 16);  slice_tensor_210 = add_107 = None
        slice_scatter_default_421: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_419, slice_scatter_default_420, 1, 832, 848);  slice_scatter_default_419 = slice_scatter_default_420 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_421, 1, 832, 848)
        slice_3480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3479, 2, 0, 16);  slice_3479 = None
        
        # No stacktrace found for following nodes
        slice_tensor_211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_421, 1, 832, 848)
        slice_scatter_default_422: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_211, slice_3480, 2, 0, 16);  slice_tensor_211 = slice_3480 = None
        slice_scatter_default_423: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_421, slice_scatter_default_422, 1, 832, 848);  slice_scatter_default_421 = slice_scatter_default_422 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3499: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 848, 864)
        slice_3500: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3499, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_109: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3500, memory_format = torch.contiguous_format);  slice_3500 = None
        view_222: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_109, [32, 16]);  clone_109 = None
        mm_106: "f32[32, 8]" = torch.ops.aten.mm.default(view_222, slice_7)
        view_223: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_106, [2, 16, 8]);  mm_106 = None
        slice_3507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_423, 1, 848, 864)
        slice_3508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3507, 2, 0, 16);  slice_3507 = None
        add_108: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3508, view_223);  slice_3508 = view_223 = None
        
        # No stacktrace found for following nodes
        slice_tensor_212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_423, 1, 848, 864)
        slice_scatter_default_424: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_212, add_108, 2, 0, 16);  slice_tensor_212 = add_108 = None
        slice_scatter_default_425: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_423, slice_scatter_default_424, 1, 848, 864);  slice_scatter_default_423 = slice_scatter_default_424 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_425, 1, 848, 864)
        slice_3513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3512, 2, 0, 16);  slice_3512 = None
        
        # No stacktrace found for following nodes
        slice_tensor_213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_425, 1, 848, 864)
        slice_scatter_default_426: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_213, slice_3513, 2, 0, 16);  slice_tensor_213 = slice_3513 = None
        slice_scatter_default_427: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_425, slice_scatter_default_426, 1, 848, 864);  slice_scatter_default_425 = slice_scatter_default_426 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3533: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3499, 2, 16, 32);  slice_3499 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_110: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3533, memory_format = torch.contiguous_format);  slice_3533 = None
        view_224: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_110, [32, 11]);  clone_110 = None
        mm_107: "f32[32, 8]" = torch.ops.aten.mm.default(view_224, slice_37)
        view_225: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_107, [2, 16, 8]);  mm_107 = None
        slice_3540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_427, 1, 848, 864)
        slice_3541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3540, 2, 0, 16);  slice_3540 = None
        add_109: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3541, view_225);  slice_3541 = view_225 = None
        
        # No stacktrace found for following nodes
        slice_tensor_214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_427, 1, 848, 864)
        slice_scatter_default_428: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_214, add_109, 2, 0, 16);  slice_tensor_214 = add_109 = None
        slice_scatter_default_429: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_427, slice_scatter_default_428, 1, 848, 864);  slice_scatter_default_427 = slice_scatter_default_428 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_429, 1, 848, 864)
        slice_3546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3545, 2, 0, 16);  slice_3545 = None
        
        # No stacktrace found for following nodes
        slice_tensor_215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_429, 1, 848, 864)
        slice_scatter_default_430: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_215, slice_3546, 2, 0, 16);  slice_tensor_215 = slice_3546 = None
        slice_scatter_default_431: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_429, slice_scatter_default_430, 1, 848, 864);  slice_scatter_default_429 = slice_scatter_default_430 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3565: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 864, 880)
        slice_3566: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3565, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_111: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3566, memory_format = torch.contiguous_format);  slice_3566 = None
        view_226: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_111, [32, 16]);  clone_111 = None
        mm_108: "f32[32, 8]" = torch.ops.aten.mm.default(view_226, slice_7)
        view_227: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_108, [2, 16, 8]);  mm_108 = None
        slice_3573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_431, 1, 864, 880)
        slice_3574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3573, 2, 0, 16);  slice_3573 = None
        add_110: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3574, view_227);  slice_3574 = view_227 = None
        
        # No stacktrace found for following nodes
        slice_tensor_216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_431, 1, 864, 880)
        slice_scatter_default_432: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_216, add_110, 2, 0, 16);  slice_tensor_216 = add_110 = None
        slice_scatter_default_433: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_431, slice_scatter_default_432, 1, 864, 880);  slice_scatter_default_431 = slice_scatter_default_432 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_433, 1, 864, 880)
        slice_3579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3578, 2, 0, 16);  slice_3578 = None
        
        # No stacktrace found for following nodes
        slice_tensor_217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_433, 1, 864, 880)
        slice_scatter_default_434: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_217, slice_3579, 2, 0, 16);  slice_tensor_217 = slice_3579 = None
        slice_scatter_default_435: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_433, slice_scatter_default_434, 1, 864, 880);  slice_scatter_default_433 = slice_scatter_default_434 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3599: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3565, 2, 16, 32);  slice_3565 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_112: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3599, memory_format = torch.contiguous_format);  slice_3599 = None
        view_228: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_112, [32, 11]);  clone_112 = None
        mm_109: "f32[32, 8]" = torch.ops.aten.mm.default(view_228, slice_37)
        view_229: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_109, [2, 16, 8]);  mm_109 = None
        slice_3606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_435, 1, 864, 880)
        slice_3607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3606, 2, 0, 16);  slice_3606 = None
        add_111: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3607, view_229);  slice_3607 = view_229 = None
        
        # No stacktrace found for following nodes
        slice_tensor_218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_435, 1, 864, 880)
        slice_scatter_default_436: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_218, add_111, 2, 0, 16);  slice_tensor_218 = add_111 = None
        slice_scatter_default_437: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_435, slice_scatter_default_436, 1, 864, 880);  slice_scatter_default_435 = slice_scatter_default_436 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_437, 1, 864, 880)
        slice_3612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3611, 2, 0, 16);  slice_3611 = None
        
        # No stacktrace found for following nodes
        slice_tensor_219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_437, 1, 864, 880)
        slice_scatter_default_438: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_219, slice_3612, 2, 0, 16);  slice_tensor_219 = slice_3612 = None
        slice_scatter_default_439: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_437, slice_scatter_default_438, 1, 864, 880);  slice_scatter_default_437 = slice_scatter_default_438 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3631: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 880, 896)
        slice_3632: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3631, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_113: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3632, memory_format = torch.contiguous_format);  slice_3632 = None
        view_230: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_113, [32, 16]);  clone_113 = None
        mm_110: "f32[32, 8]" = torch.ops.aten.mm.default(view_230, slice_7)
        view_231: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_110, [2, 16, 8]);  mm_110 = None
        slice_3639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_439, 1, 880, 896)
        slice_3640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3639, 2, 0, 16);  slice_3639 = None
        add_112: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3640, view_231);  slice_3640 = view_231 = None
        
        # No stacktrace found for following nodes
        slice_tensor_220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_439, 1, 880, 896)
        slice_scatter_default_440: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_220, add_112, 2, 0, 16);  slice_tensor_220 = add_112 = None
        slice_scatter_default_441: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_439, slice_scatter_default_440, 1, 880, 896);  slice_scatter_default_439 = slice_scatter_default_440 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_441, 1, 880, 896)
        slice_3645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3644, 2, 0, 16);  slice_3644 = None
        
        # No stacktrace found for following nodes
        slice_tensor_221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_441, 1, 880, 896)
        slice_scatter_default_442: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_221, slice_3645, 2, 0, 16);  slice_tensor_221 = slice_3645 = None
        slice_scatter_default_443: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_441, slice_scatter_default_442, 1, 880, 896);  slice_scatter_default_441 = slice_scatter_default_442 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3665: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3631, 2, 16, 32);  slice_3631 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_114: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3665, memory_format = torch.contiguous_format);  slice_3665 = None
        view_232: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_114, [32, 11]);  clone_114 = None
        mm_111: "f32[32, 8]" = torch.ops.aten.mm.default(view_232, slice_37)
        view_233: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_111, [2, 16, 8]);  mm_111 = None
        slice_3672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_443, 1, 880, 896)
        slice_3673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3672, 2, 0, 16);  slice_3672 = None
        add_113: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3673, view_233);  slice_3673 = view_233 = None
        
        # No stacktrace found for following nodes
        slice_tensor_222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_443, 1, 880, 896)
        slice_scatter_default_444: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_222, add_113, 2, 0, 16);  slice_tensor_222 = add_113 = None
        slice_scatter_default_445: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_443, slice_scatter_default_444, 1, 880, 896);  slice_scatter_default_443 = slice_scatter_default_444 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_445, 1, 880, 896)
        slice_3678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3677, 2, 0, 16);  slice_3677 = None
        
        # No stacktrace found for following nodes
        slice_tensor_223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_445, 1, 880, 896)
        slice_scatter_default_446: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_223, slice_3678, 2, 0, 16);  slice_tensor_223 = slice_3678 = None
        slice_scatter_default_447: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_445, slice_scatter_default_446, 1, 880, 896);  slice_scatter_default_445 = slice_scatter_default_446 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3697: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 896, 912)
        slice_3698: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3697, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_115: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3698, memory_format = torch.contiguous_format);  slice_3698 = None
        view_234: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_115, [32, 16]);  clone_115 = None
        mm_112: "f32[32, 8]" = torch.ops.aten.mm.default(view_234, slice_7)
        view_235: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_112, [2, 16, 8]);  mm_112 = None
        slice_3705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_447, 1, 896, 912)
        slice_3706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3705, 2, 0, 16);  slice_3705 = None
        add_114: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3706, view_235);  slice_3706 = view_235 = None
        
        # No stacktrace found for following nodes
        slice_tensor_224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_447, 1, 896, 912)
        slice_scatter_default_448: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_224, add_114, 2, 0, 16);  slice_tensor_224 = add_114 = None
        slice_scatter_default_449: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_447, slice_scatter_default_448, 1, 896, 912);  slice_scatter_default_447 = slice_scatter_default_448 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_449, 1, 896, 912)
        slice_3711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3710, 2, 0, 16);  slice_3710 = None
        
        # No stacktrace found for following nodes
        slice_tensor_225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_449, 1, 896, 912)
        slice_scatter_default_450: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_225, slice_3711, 2, 0, 16);  slice_tensor_225 = slice_3711 = None
        slice_scatter_default_451: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_449, slice_scatter_default_450, 1, 896, 912);  slice_scatter_default_449 = slice_scatter_default_450 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3731: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3697, 2, 16, 32);  slice_3697 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_116: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3731, memory_format = torch.contiguous_format);  slice_3731 = None
        view_236: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_116, [32, 11]);  clone_116 = None
        mm_113: "f32[32, 8]" = torch.ops.aten.mm.default(view_236, slice_37)
        view_237: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_113, [2, 16, 8]);  mm_113 = None
        slice_3738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_451, 1, 896, 912)
        slice_3739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3738, 2, 0, 16);  slice_3738 = None
        add_115: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3739, view_237);  slice_3739 = view_237 = None
        
        # No stacktrace found for following nodes
        slice_tensor_226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_451, 1, 896, 912)
        slice_scatter_default_452: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_226, add_115, 2, 0, 16);  slice_tensor_226 = add_115 = None
        slice_scatter_default_453: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_451, slice_scatter_default_452, 1, 896, 912);  slice_scatter_default_451 = slice_scatter_default_452 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_453, 1, 896, 912)
        slice_3744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3743, 2, 0, 16);  slice_3743 = None
        
        # No stacktrace found for following nodes
        slice_tensor_227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_453, 1, 896, 912)
        slice_scatter_default_454: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_227, slice_3744, 2, 0, 16);  slice_tensor_227 = slice_3744 = None
        slice_scatter_default_455: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_453, slice_scatter_default_454, 1, 896, 912);  slice_scatter_default_453 = slice_scatter_default_454 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3763: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 912, 928)
        slice_3764: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3763, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_117: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3764, memory_format = torch.contiguous_format);  slice_3764 = None
        view_238: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_117, [32, 16]);  clone_117 = None
        mm_114: "f32[32, 8]" = torch.ops.aten.mm.default(view_238, slice_7)
        view_239: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_114, [2, 16, 8]);  mm_114 = None
        slice_3771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_455, 1, 912, 928)
        slice_3772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3771, 2, 0, 16);  slice_3771 = None
        add_116: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3772, view_239);  slice_3772 = view_239 = None
        
        # No stacktrace found for following nodes
        slice_tensor_228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_455, 1, 912, 928)
        slice_scatter_default_456: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_228, add_116, 2, 0, 16);  slice_tensor_228 = add_116 = None
        slice_scatter_default_457: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_455, slice_scatter_default_456, 1, 912, 928);  slice_scatter_default_455 = slice_scatter_default_456 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_457, 1, 912, 928)
        slice_3777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3776, 2, 0, 16);  slice_3776 = None
        
        # No stacktrace found for following nodes
        slice_tensor_229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_457, 1, 912, 928)
        slice_scatter_default_458: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_229, slice_3777, 2, 0, 16);  slice_tensor_229 = slice_3777 = None
        slice_scatter_default_459: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_457, slice_scatter_default_458, 1, 912, 928);  slice_scatter_default_457 = slice_scatter_default_458 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3797: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3763, 2, 16, 32);  slice_3763 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_118: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3797, memory_format = torch.contiguous_format);  slice_3797 = None
        view_240: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_118, [32, 11]);  clone_118 = None
        mm_115: "f32[32, 8]" = torch.ops.aten.mm.default(view_240, slice_37)
        view_241: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_115, [2, 16, 8]);  mm_115 = None
        slice_3804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_459, 1, 912, 928)
        slice_3805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3804, 2, 0, 16);  slice_3804 = None
        add_117: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3805, view_241);  slice_3805 = view_241 = None
        
        # No stacktrace found for following nodes
        slice_tensor_230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_459, 1, 912, 928)
        slice_scatter_default_460: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_230, add_117, 2, 0, 16);  slice_tensor_230 = add_117 = None
        slice_scatter_default_461: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_459, slice_scatter_default_460, 1, 912, 928);  slice_scatter_default_459 = slice_scatter_default_460 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_461, 1, 912, 928)
        slice_3810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3809, 2, 0, 16);  slice_3809 = None
        
        # No stacktrace found for following nodes
        slice_tensor_231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_461, 1, 912, 928)
        slice_scatter_default_462: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_231, slice_3810, 2, 0, 16);  slice_tensor_231 = slice_3810 = None
        slice_scatter_default_463: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_461, slice_scatter_default_462, 1, 912, 928);  slice_scatter_default_461 = slice_scatter_default_462 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3829: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 928, 944)
        slice_3830: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3829, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_119: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3830, memory_format = torch.contiguous_format);  slice_3830 = None
        view_242: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_119, [32, 16]);  clone_119 = None
        mm_116: "f32[32, 8]" = torch.ops.aten.mm.default(view_242, slice_7)
        view_243: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_116, [2, 16, 8]);  mm_116 = None
        slice_3837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_463, 1, 928, 944)
        slice_3838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3837, 2, 0, 16);  slice_3837 = None
        add_118: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3838, view_243);  slice_3838 = view_243 = None
        
        # No stacktrace found for following nodes
        slice_tensor_232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_463, 1, 928, 944)
        slice_scatter_default_464: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_232, add_118, 2, 0, 16);  slice_tensor_232 = add_118 = None
        slice_scatter_default_465: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_463, slice_scatter_default_464, 1, 928, 944);  slice_scatter_default_463 = slice_scatter_default_464 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_465, 1, 928, 944)
        slice_3843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3842, 2, 0, 16);  slice_3842 = None
        
        # No stacktrace found for following nodes
        slice_tensor_233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_465, 1, 928, 944)
        slice_scatter_default_466: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_233, slice_3843, 2, 0, 16);  slice_tensor_233 = slice_3843 = None
        slice_scatter_default_467: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_465, slice_scatter_default_466, 1, 928, 944);  slice_scatter_default_465 = slice_scatter_default_466 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3863: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3829, 2, 16, 32);  slice_3829 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_120: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3863, memory_format = torch.contiguous_format);  slice_3863 = None
        view_244: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_120, [32, 11]);  clone_120 = None
        mm_117: "f32[32, 8]" = torch.ops.aten.mm.default(view_244, slice_37)
        view_245: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_117, [2, 16, 8]);  mm_117 = None
        slice_3870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_467, 1, 928, 944)
        slice_3871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3870, 2, 0, 16);  slice_3870 = None
        add_119: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3871, view_245);  slice_3871 = view_245 = None
        
        # No stacktrace found for following nodes
        slice_tensor_234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_467, 1, 928, 944)
        slice_scatter_default_468: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_234, add_119, 2, 0, 16);  slice_tensor_234 = add_119 = None
        slice_scatter_default_469: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_467, slice_scatter_default_468, 1, 928, 944);  slice_scatter_default_467 = slice_scatter_default_468 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_469, 1, 928, 944)
        slice_3876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3875, 2, 0, 16);  slice_3875 = None
        
        # No stacktrace found for following nodes
        slice_tensor_235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_469, 1, 928, 944)
        slice_scatter_default_470: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_235, slice_3876, 2, 0, 16);  slice_tensor_235 = slice_3876 = None
        slice_scatter_default_471: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_469, slice_scatter_default_470, 1, 928, 944);  slice_scatter_default_469 = slice_scatter_default_470 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3895: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 944, 960)
        slice_3896: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3895, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_121: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3896, memory_format = torch.contiguous_format);  slice_3896 = None
        view_246: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_121, [32, 16]);  clone_121 = None
        mm_118: "f32[32, 8]" = torch.ops.aten.mm.default(view_246, slice_7)
        view_247: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_118, [2, 16, 8]);  mm_118 = None
        slice_3903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_471, 1, 944, 960)
        slice_3904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3903, 2, 0, 16);  slice_3903 = None
        add_120: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3904, view_247);  slice_3904 = view_247 = None
        
        # No stacktrace found for following nodes
        slice_tensor_236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_471, 1, 944, 960)
        slice_scatter_default_472: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_236, add_120, 2, 0, 16);  slice_tensor_236 = add_120 = None
        slice_scatter_default_473: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_471, slice_scatter_default_472, 1, 944, 960);  slice_scatter_default_471 = slice_scatter_default_472 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_473, 1, 944, 960)
        slice_3909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3908, 2, 0, 16);  slice_3908 = None
        
        # No stacktrace found for following nodes
        slice_tensor_237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_473, 1, 944, 960)
        slice_scatter_default_474: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_237, slice_3909, 2, 0, 16);  slice_tensor_237 = slice_3909 = None
        slice_scatter_default_475: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_473, slice_scatter_default_474, 1, 944, 960);  slice_scatter_default_473 = slice_scatter_default_474 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3929: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3895, 2, 16, 32);  slice_3895 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_122: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3929, memory_format = torch.contiguous_format);  slice_3929 = None
        view_248: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_122, [32, 11]);  clone_122 = None
        mm_119: "f32[32, 8]" = torch.ops.aten.mm.default(view_248, slice_37)
        view_249: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_119, [2, 16, 8]);  mm_119 = None
        slice_3936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_475, 1, 944, 960)
        slice_3937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3936, 2, 0, 16);  slice_3936 = None
        add_121: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3937, view_249);  slice_3937 = view_249 = None
        
        # No stacktrace found for following nodes
        slice_tensor_238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_475, 1, 944, 960)
        slice_scatter_default_476: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_238, add_121, 2, 0, 16);  slice_tensor_238 = add_121 = None
        slice_scatter_default_477: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_475, slice_scatter_default_476, 1, 944, 960);  slice_scatter_default_475 = slice_scatter_default_476 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_477, 1, 944, 960)
        slice_3942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3941, 2, 0, 16);  slice_3941 = None
        
        # No stacktrace found for following nodes
        slice_tensor_239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_477, 1, 944, 960)
        slice_scatter_default_478: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_239, slice_3942, 2, 0, 16);  slice_tensor_239 = slice_3942 = None
        slice_scatter_default_479: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_477, slice_scatter_default_478, 1, 944, 960);  slice_scatter_default_477 = slice_scatter_default_478 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3961: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 960, 976)
        slice_3962: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_3961, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_123: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_3962, memory_format = torch.contiguous_format);  slice_3962 = None
        view_250: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_123, [32, 16]);  clone_123 = None
        mm_120: "f32[32, 8]" = torch.ops.aten.mm.default(view_250, slice_7)
        view_251: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_120, [2, 16, 8]);  mm_120 = None
        slice_3969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_479, 1, 960, 976)
        slice_3970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3969, 2, 0, 16);  slice_3969 = None
        add_122: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_3970, view_251);  slice_3970 = view_251 = None
        
        # No stacktrace found for following nodes
        slice_tensor_240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_479, 1, 960, 976)
        slice_scatter_default_480: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_240, add_122, 2, 0, 16);  slice_tensor_240 = add_122 = None
        slice_scatter_default_481: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_479, slice_scatter_default_480, 1, 960, 976);  slice_scatter_default_479 = slice_scatter_default_480 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_3974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_481, 1, 960, 976)
        slice_3975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_3974, 2, 0, 16);  slice_3974 = None
        
        # No stacktrace found for following nodes
        slice_tensor_241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_481, 1, 960, 976)
        slice_scatter_default_482: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_241, slice_3975, 2, 0, 16);  slice_tensor_241 = slice_3975 = None
        slice_scatter_default_483: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_481, slice_scatter_default_482, 1, 960, 976);  slice_scatter_default_481 = slice_scatter_default_482 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_3995: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_3961, 2, 16, 32);  slice_3961 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_124: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_3995, memory_format = torch.contiguous_format);  slice_3995 = None
        view_252: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_124, [32, 11]);  clone_124 = None
        mm_121: "f32[32, 8]" = torch.ops.aten.mm.default(view_252, slice_37)
        view_253: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_121, [2, 16, 8]);  mm_121 = None
        slice_4002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_483, 1, 960, 976)
        slice_4003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4002, 2, 0, 16);  slice_4002 = None
        add_123: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4003, view_253);  slice_4003 = view_253 = None
        
        # No stacktrace found for following nodes
        slice_tensor_242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_483, 1, 960, 976)
        slice_scatter_default_484: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_242, add_123, 2, 0, 16);  slice_tensor_242 = add_123 = None
        slice_scatter_default_485: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_483, slice_scatter_default_484, 1, 960, 976);  slice_scatter_default_483 = slice_scatter_default_484 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_485, 1, 960, 976)
        slice_4008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4007, 2, 0, 16);  slice_4007 = None
        
        # No stacktrace found for following nodes
        slice_tensor_243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_485, 1, 960, 976)
        slice_scatter_default_486: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_243, slice_4008, 2, 0, 16);  slice_tensor_243 = slice_4008 = None
        slice_scatter_default_487: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_485, slice_scatter_default_486, 1, 960, 976);  slice_scatter_default_485 = slice_scatter_default_486 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4027: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 976, 992)
        slice_4028: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4027, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_125: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4028, memory_format = torch.contiguous_format);  slice_4028 = None
        view_254: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_125, [32, 16]);  clone_125 = None
        mm_122: "f32[32, 8]" = torch.ops.aten.mm.default(view_254, slice_7)
        view_255: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_122, [2, 16, 8]);  mm_122 = None
        slice_4035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_487, 1, 976, 992)
        slice_4036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4035, 2, 0, 16);  slice_4035 = None
        add_124: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4036, view_255);  slice_4036 = view_255 = None
        
        # No stacktrace found for following nodes
        slice_tensor_244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_487, 1, 976, 992)
        slice_scatter_default_488: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_244, add_124, 2, 0, 16);  slice_tensor_244 = add_124 = None
        slice_scatter_default_489: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_487, slice_scatter_default_488, 1, 976, 992);  slice_scatter_default_487 = slice_scatter_default_488 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_489, 1, 976, 992)
        slice_4041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4040, 2, 0, 16);  slice_4040 = None
        
        # No stacktrace found for following nodes
        slice_tensor_245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_489, 1, 976, 992)
        slice_scatter_default_490: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_245, slice_4041, 2, 0, 16);  slice_tensor_245 = slice_4041 = None
        slice_scatter_default_491: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_489, slice_scatter_default_490, 1, 976, 992);  slice_scatter_default_489 = slice_scatter_default_490 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4061: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4027, 2, 16, 32);  slice_4027 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_126: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4061, memory_format = torch.contiguous_format);  slice_4061 = None
        view_256: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_126, [32, 11]);  clone_126 = None
        mm_123: "f32[32, 8]" = torch.ops.aten.mm.default(view_256, slice_37)
        view_257: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_123, [2, 16, 8]);  mm_123 = None
        slice_4068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_491, 1, 976, 992)
        slice_4069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4068, 2, 0, 16);  slice_4068 = None
        add_125: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4069, view_257);  slice_4069 = view_257 = None
        
        # No stacktrace found for following nodes
        slice_tensor_246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_491, 1, 976, 992)
        slice_scatter_default_492: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_246, add_125, 2, 0, 16);  slice_tensor_246 = add_125 = None
        slice_scatter_default_493: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_491, slice_scatter_default_492, 1, 976, 992);  slice_scatter_default_491 = slice_scatter_default_492 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_493, 1, 976, 992)
        slice_4074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4073, 2, 0, 16);  slice_4073 = None
        
        # No stacktrace found for following nodes
        slice_tensor_247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_493, 1, 976, 992)
        slice_scatter_default_494: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_247, slice_4074, 2, 0, 16);  slice_tensor_247 = slice_4074 = None
        slice_scatter_default_495: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_493, slice_scatter_default_494, 1, 976, 992);  slice_scatter_default_493 = slice_scatter_default_494 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4093: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 992, 1008)
        slice_4094: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4093, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_127: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4094, memory_format = torch.contiguous_format);  slice_4094 = None
        view_258: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_127, [32, 16]);  clone_127 = None
        mm_124: "f32[32, 8]" = torch.ops.aten.mm.default(view_258, slice_7)
        view_259: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_124, [2, 16, 8]);  mm_124 = None
        slice_4101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_495, 1, 992, 1008)
        slice_4102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4101, 2, 0, 16);  slice_4101 = None
        add_126: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4102, view_259);  slice_4102 = view_259 = None
        
        # No stacktrace found for following nodes
        slice_tensor_248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_495, 1, 992, 1008)
        slice_scatter_default_496: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_248, add_126, 2, 0, 16);  slice_tensor_248 = add_126 = None
        slice_scatter_default_497: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_495, slice_scatter_default_496, 1, 992, 1008);  slice_scatter_default_495 = slice_scatter_default_496 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_497, 1, 992, 1008)
        slice_4107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4106, 2, 0, 16);  slice_4106 = None
        
        # No stacktrace found for following nodes
        slice_tensor_249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_497, 1, 992, 1008)
        slice_scatter_default_498: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_249, slice_4107, 2, 0, 16);  slice_tensor_249 = slice_4107 = None
        slice_scatter_default_499: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_497, slice_scatter_default_498, 1, 992, 1008);  slice_scatter_default_497 = slice_scatter_default_498 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4127: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4093, 2, 16, 32);  slice_4093 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_128: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4127, memory_format = torch.contiguous_format);  slice_4127 = None
        view_260: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_128, [32, 11]);  clone_128 = None
        mm_125: "f32[32, 8]" = torch.ops.aten.mm.default(view_260, slice_37)
        view_261: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_125, [2, 16, 8]);  mm_125 = None
        slice_4134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_499, 1, 992, 1008)
        slice_4135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4134, 2, 0, 16);  slice_4134 = None
        add_127: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4135, view_261);  slice_4135 = view_261 = None
        
        # No stacktrace found for following nodes
        slice_tensor_250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_499, 1, 992, 1008)
        slice_scatter_default_500: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_250, add_127, 2, 0, 16);  slice_tensor_250 = add_127 = None
        slice_scatter_default_501: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_499, slice_scatter_default_500, 1, 992, 1008);  slice_scatter_default_499 = slice_scatter_default_500 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_501, 1, 992, 1008)
        slice_4140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4139, 2, 0, 16);  slice_4139 = None
        
        # No stacktrace found for following nodes
        slice_tensor_251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_501, 1, 992, 1008)
        slice_scatter_default_502: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_251, slice_4140, 2, 0, 16);  slice_tensor_251 = slice_4140 = None
        slice_scatter_default_503: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_501, slice_scatter_default_502, 1, 992, 1008);  slice_scatter_default_501 = slice_scatter_default_502 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4159: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1008, 1024)
        slice_4160: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4159, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_129: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4160, memory_format = torch.contiguous_format);  slice_4160 = None
        view_262: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_129, [32, 16]);  clone_129 = None
        mm_126: "f32[32, 8]" = torch.ops.aten.mm.default(view_262, slice_7)
        view_263: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_126, [2, 16, 8]);  mm_126 = None
        slice_4167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_503, 1, 1008, 1024)
        slice_4168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4167, 2, 0, 16);  slice_4167 = None
        add_128: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4168, view_263);  slice_4168 = view_263 = None
        
        # No stacktrace found for following nodes
        slice_tensor_252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_503, 1, 1008, 1024)
        slice_scatter_default_504: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_252, add_128, 2, 0, 16);  slice_tensor_252 = add_128 = None
        slice_scatter_default_505: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_503, slice_scatter_default_504, 1, 1008, 1024);  slice_scatter_default_503 = slice_scatter_default_504 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_505, 1, 1008, 1024)
        slice_4173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4172, 2, 0, 16);  slice_4172 = None
        
        # No stacktrace found for following nodes
        slice_tensor_253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_505, 1, 1008, 1024)
        slice_scatter_default_506: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_253, slice_4173, 2, 0, 16);  slice_tensor_253 = slice_4173 = None
        slice_scatter_default_507: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_505, slice_scatter_default_506, 1, 1008, 1024);  slice_scatter_default_505 = slice_scatter_default_506 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4193: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4159, 2, 16, 32);  slice_4159 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_130: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4193, memory_format = torch.contiguous_format);  slice_4193 = None
        view_264: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_130, [32, 11]);  clone_130 = None
        mm_127: "f32[32, 8]" = torch.ops.aten.mm.default(view_264, slice_37)
        view_265: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_127, [2, 16, 8]);  mm_127 = None
        slice_4200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_507, 1, 1008, 1024)
        slice_4201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4200, 2, 0, 16);  slice_4200 = None
        add_129: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4201, view_265);  slice_4201 = view_265 = None
        
        # No stacktrace found for following nodes
        slice_tensor_254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_507, 1, 1008, 1024)
        slice_scatter_default_508: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_254, add_129, 2, 0, 16);  slice_tensor_254 = add_129 = None
        slice_scatter_default_509: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_507, slice_scatter_default_508, 1, 1008, 1024);  slice_scatter_default_507 = slice_scatter_default_508 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_509, 1, 1008, 1024)
        slice_4206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4205, 2, 0, 16);  slice_4205 = None
        
        # No stacktrace found for following nodes
        slice_tensor_255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_509, 1, 1008, 1024)
        slice_scatter_default_510: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_255, slice_4206, 2, 0, 16);  slice_tensor_255 = slice_4206 = None
        slice_scatter_default_511: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_509, slice_scatter_default_510, 1, 1008, 1024);  slice_scatter_default_509 = slice_scatter_default_510 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4225: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1024, 1040)
        slice_4226: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4225, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_131: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4226, memory_format = torch.contiguous_format);  slice_4226 = None
        view_266: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_131, [32, 16]);  clone_131 = None
        mm_128: "f32[32, 8]" = torch.ops.aten.mm.default(view_266, slice_7)
        view_267: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_128, [2, 16, 8]);  mm_128 = None
        slice_4233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_511, 1, 1024, 1040)
        slice_4234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4233, 2, 0, 16);  slice_4233 = None
        add_130: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4234, view_267);  slice_4234 = view_267 = None
        
        # No stacktrace found for following nodes
        slice_tensor_256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_511, 1, 1024, 1040)
        slice_scatter_default_512: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_256, add_130, 2, 0, 16);  slice_tensor_256 = add_130 = None
        slice_scatter_default_513: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_511, slice_scatter_default_512, 1, 1024, 1040);  slice_scatter_default_511 = slice_scatter_default_512 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_513, 1, 1024, 1040)
        slice_4239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4238, 2, 0, 16);  slice_4238 = None
        
        # No stacktrace found for following nodes
        slice_tensor_257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_513, 1, 1024, 1040)
        slice_scatter_default_514: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_257, slice_4239, 2, 0, 16);  slice_tensor_257 = slice_4239 = None
        slice_scatter_default_515: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_513, slice_scatter_default_514, 1, 1024, 1040);  slice_scatter_default_513 = slice_scatter_default_514 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4259: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4225, 2, 16, 32);  slice_4225 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_132: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4259, memory_format = torch.contiguous_format);  slice_4259 = None
        view_268: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_132, [32, 11]);  clone_132 = None
        mm_129: "f32[32, 8]" = torch.ops.aten.mm.default(view_268, slice_37)
        view_269: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_129, [2, 16, 8]);  mm_129 = None
        slice_4266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_515, 1, 1024, 1040)
        slice_4267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4266, 2, 0, 16);  slice_4266 = None
        add_131: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4267, view_269);  slice_4267 = view_269 = None
        
        # No stacktrace found for following nodes
        slice_tensor_258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_515, 1, 1024, 1040)
        slice_scatter_default_516: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_258, add_131, 2, 0, 16);  slice_tensor_258 = add_131 = None
        slice_scatter_default_517: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_515, slice_scatter_default_516, 1, 1024, 1040);  slice_scatter_default_515 = slice_scatter_default_516 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_517, 1, 1024, 1040)
        slice_4272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4271, 2, 0, 16);  slice_4271 = None
        
        # No stacktrace found for following nodes
        slice_tensor_259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_517, 1, 1024, 1040)
        slice_scatter_default_518: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_259, slice_4272, 2, 0, 16);  slice_tensor_259 = slice_4272 = None
        slice_scatter_default_519: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_517, slice_scatter_default_518, 1, 1024, 1040);  slice_scatter_default_517 = slice_scatter_default_518 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4291: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1040, 1056)
        slice_4292: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4291, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_133: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4292, memory_format = torch.contiguous_format);  slice_4292 = None
        view_270: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_133, [32, 16]);  clone_133 = None
        mm_130: "f32[32, 8]" = torch.ops.aten.mm.default(view_270, slice_7)
        view_271: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_130, [2, 16, 8]);  mm_130 = None
        slice_4299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_519, 1, 1040, 1056)
        slice_4300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4299, 2, 0, 16);  slice_4299 = None
        add_132: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4300, view_271);  slice_4300 = view_271 = None
        
        # No stacktrace found for following nodes
        slice_tensor_260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_519, 1, 1040, 1056)
        slice_scatter_default_520: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_260, add_132, 2, 0, 16);  slice_tensor_260 = add_132 = None
        slice_scatter_default_521: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_519, slice_scatter_default_520, 1, 1040, 1056);  slice_scatter_default_519 = slice_scatter_default_520 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_521, 1, 1040, 1056)
        slice_4305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4304, 2, 0, 16);  slice_4304 = None
        
        # No stacktrace found for following nodes
        slice_tensor_261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_521, 1, 1040, 1056)
        slice_scatter_default_522: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_261, slice_4305, 2, 0, 16);  slice_tensor_261 = slice_4305 = None
        slice_scatter_default_523: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_521, slice_scatter_default_522, 1, 1040, 1056);  slice_scatter_default_521 = slice_scatter_default_522 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4325: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4291, 2, 16, 32);  slice_4291 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_134: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4325, memory_format = torch.contiguous_format);  slice_4325 = None
        view_272: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_134, [32, 11]);  clone_134 = None
        mm_131: "f32[32, 8]" = torch.ops.aten.mm.default(view_272, slice_37)
        view_273: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_131, [2, 16, 8]);  mm_131 = None
        slice_4332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_523, 1, 1040, 1056)
        slice_4333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4332, 2, 0, 16);  slice_4332 = None
        add_133: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4333, view_273);  slice_4333 = view_273 = None
        
        # No stacktrace found for following nodes
        slice_tensor_262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_523, 1, 1040, 1056)
        slice_scatter_default_524: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_262, add_133, 2, 0, 16);  slice_tensor_262 = add_133 = None
        slice_scatter_default_525: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_523, slice_scatter_default_524, 1, 1040, 1056);  slice_scatter_default_523 = slice_scatter_default_524 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_525, 1, 1040, 1056)
        slice_4338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4337, 2, 0, 16);  slice_4337 = None
        
        # No stacktrace found for following nodes
        slice_tensor_263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_525, 1, 1040, 1056)
        slice_scatter_default_526: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_263, slice_4338, 2, 0, 16);  slice_tensor_263 = slice_4338 = None
        slice_scatter_default_527: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_525, slice_scatter_default_526, 1, 1040, 1056);  slice_scatter_default_525 = slice_scatter_default_526 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4357: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1056, 1072)
        slice_4358: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4357, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_135: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4358, memory_format = torch.contiguous_format);  slice_4358 = None
        view_274: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_135, [32, 16]);  clone_135 = None
        mm_132: "f32[32, 8]" = torch.ops.aten.mm.default(view_274, slice_7)
        view_275: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_132, [2, 16, 8]);  mm_132 = None
        slice_4365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_527, 1, 1056, 1072)
        slice_4366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4365, 2, 0, 16);  slice_4365 = None
        add_134: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4366, view_275);  slice_4366 = view_275 = None
        
        # No stacktrace found for following nodes
        slice_tensor_264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_527, 1, 1056, 1072)
        slice_scatter_default_528: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_264, add_134, 2, 0, 16);  slice_tensor_264 = add_134 = None
        slice_scatter_default_529: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_527, slice_scatter_default_528, 1, 1056, 1072);  slice_scatter_default_527 = slice_scatter_default_528 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_529, 1, 1056, 1072)
        slice_4371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4370, 2, 0, 16);  slice_4370 = None
        
        # No stacktrace found for following nodes
        slice_tensor_265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_529, 1, 1056, 1072)
        slice_scatter_default_530: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_265, slice_4371, 2, 0, 16);  slice_tensor_265 = slice_4371 = None
        slice_scatter_default_531: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_529, slice_scatter_default_530, 1, 1056, 1072);  slice_scatter_default_529 = slice_scatter_default_530 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4391: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4357, 2, 16, 32);  slice_4357 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_136: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4391, memory_format = torch.contiguous_format);  slice_4391 = None
        view_276: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_136, [32, 11]);  clone_136 = None
        mm_133: "f32[32, 8]" = torch.ops.aten.mm.default(view_276, slice_37)
        view_277: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_133, [2, 16, 8]);  mm_133 = None
        slice_4398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_531, 1, 1056, 1072)
        slice_4399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4398, 2, 0, 16);  slice_4398 = None
        add_135: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4399, view_277);  slice_4399 = view_277 = None
        
        # No stacktrace found for following nodes
        slice_tensor_266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_531, 1, 1056, 1072)
        slice_scatter_default_532: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_266, add_135, 2, 0, 16);  slice_tensor_266 = add_135 = None
        slice_scatter_default_533: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_531, slice_scatter_default_532, 1, 1056, 1072);  slice_scatter_default_531 = slice_scatter_default_532 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_533, 1, 1056, 1072)
        slice_4404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4403, 2, 0, 16);  slice_4403 = None
        
        # No stacktrace found for following nodes
        slice_tensor_267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_533, 1, 1056, 1072)
        slice_scatter_default_534: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_267, slice_4404, 2, 0, 16);  slice_tensor_267 = slice_4404 = None
        slice_scatter_default_535: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_533, slice_scatter_default_534, 1, 1056, 1072);  slice_scatter_default_533 = slice_scatter_default_534 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4423: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1072, 1088)
        slice_4424: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4423, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_137: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4424, memory_format = torch.contiguous_format);  slice_4424 = None
        view_278: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_137, [32, 16]);  clone_137 = None
        mm_134: "f32[32, 8]" = torch.ops.aten.mm.default(view_278, slice_7)
        view_279: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_134, [2, 16, 8]);  mm_134 = None
        slice_4431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_535, 1, 1072, 1088)
        slice_4432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4431, 2, 0, 16);  slice_4431 = None
        add_136: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4432, view_279);  slice_4432 = view_279 = None
        
        # No stacktrace found for following nodes
        slice_tensor_268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_535, 1, 1072, 1088)
        slice_scatter_default_536: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_268, add_136, 2, 0, 16);  slice_tensor_268 = add_136 = None
        slice_scatter_default_537: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_535, slice_scatter_default_536, 1, 1072, 1088);  slice_scatter_default_535 = slice_scatter_default_536 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_537, 1, 1072, 1088)
        slice_4437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4436, 2, 0, 16);  slice_4436 = None
        
        # No stacktrace found for following nodes
        slice_tensor_269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_537, 1, 1072, 1088)
        slice_scatter_default_538: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_269, slice_4437, 2, 0, 16);  slice_tensor_269 = slice_4437 = None
        slice_scatter_default_539: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_537, slice_scatter_default_538, 1, 1072, 1088);  slice_scatter_default_537 = slice_scatter_default_538 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4457: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4423, 2, 16, 32);  slice_4423 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_138: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4457, memory_format = torch.contiguous_format);  slice_4457 = None
        view_280: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_138, [32, 11]);  clone_138 = None
        mm_135: "f32[32, 8]" = torch.ops.aten.mm.default(view_280, slice_37)
        view_281: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_135, [2, 16, 8]);  mm_135 = None
        slice_4464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_539, 1, 1072, 1088)
        slice_4465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4464, 2, 0, 16);  slice_4464 = None
        add_137: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4465, view_281);  slice_4465 = view_281 = None
        
        # No stacktrace found for following nodes
        slice_tensor_270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_539, 1, 1072, 1088)
        slice_scatter_default_540: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_270, add_137, 2, 0, 16);  slice_tensor_270 = add_137 = None
        slice_scatter_default_541: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_539, slice_scatter_default_540, 1, 1072, 1088);  slice_scatter_default_539 = slice_scatter_default_540 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_541, 1, 1072, 1088)
        slice_4470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4469, 2, 0, 16);  slice_4469 = None
        
        # No stacktrace found for following nodes
        slice_tensor_271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_541, 1, 1072, 1088)
        slice_scatter_default_542: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_271, slice_4470, 2, 0, 16);  slice_tensor_271 = slice_4470 = None
        slice_scatter_default_543: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_541, slice_scatter_default_542, 1, 1072, 1088);  slice_scatter_default_541 = slice_scatter_default_542 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4489: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1088, 1104)
        slice_4490: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4489, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_139: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4490, memory_format = torch.contiguous_format);  slice_4490 = None
        view_282: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_139, [32, 16]);  clone_139 = None
        mm_136: "f32[32, 8]" = torch.ops.aten.mm.default(view_282, slice_7)
        view_283: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_136, [2, 16, 8]);  mm_136 = None
        slice_4497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_543, 1, 1088, 1104)
        slice_4498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4497, 2, 0, 16);  slice_4497 = None
        add_138: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4498, view_283);  slice_4498 = view_283 = None
        
        # No stacktrace found for following nodes
        slice_tensor_272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_543, 1, 1088, 1104)
        slice_scatter_default_544: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_272, add_138, 2, 0, 16);  slice_tensor_272 = add_138 = None
        slice_scatter_default_545: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_543, slice_scatter_default_544, 1, 1088, 1104);  slice_scatter_default_543 = slice_scatter_default_544 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_545, 1, 1088, 1104)
        slice_4503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4502, 2, 0, 16);  slice_4502 = None
        
        # No stacktrace found for following nodes
        slice_tensor_273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_545, 1, 1088, 1104)
        slice_scatter_default_546: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_273, slice_4503, 2, 0, 16);  slice_tensor_273 = slice_4503 = None
        slice_scatter_default_547: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_545, slice_scatter_default_546, 1, 1088, 1104);  slice_scatter_default_545 = slice_scatter_default_546 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4523: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4489, 2, 16, 32);  slice_4489 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_140: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4523, memory_format = torch.contiguous_format);  slice_4523 = None
        view_284: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_140, [32, 11]);  clone_140 = None
        mm_137: "f32[32, 8]" = torch.ops.aten.mm.default(view_284, slice_37)
        view_285: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_137, [2, 16, 8]);  mm_137 = None
        slice_4530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_547, 1, 1088, 1104)
        slice_4531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4530, 2, 0, 16);  slice_4530 = None
        add_139: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4531, view_285);  slice_4531 = view_285 = None
        
        # No stacktrace found for following nodes
        slice_tensor_274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_547, 1, 1088, 1104)
        slice_scatter_default_548: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_274, add_139, 2, 0, 16);  slice_tensor_274 = add_139 = None
        slice_scatter_default_549: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_547, slice_scatter_default_548, 1, 1088, 1104);  slice_scatter_default_547 = slice_scatter_default_548 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_549, 1, 1088, 1104)
        slice_4536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4535, 2, 0, 16);  slice_4535 = None
        
        # No stacktrace found for following nodes
        slice_tensor_275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_549, 1, 1088, 1104)
        slice_scatter_default_550: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_275, slice_4536, 2, 0, 16);  slice_tensor_275 = slice_4536 = None
        slice_scatter_default_551: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_549, slice_scatter_default_550, 1, 1088, 1104);  slice_scatter_default_549 = slice_scatter_default_550 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4555: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1104, 1120)
        slice_4556: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4555, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_141: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4556, memory_format = torch.contiguous_format);  slice_4556 = None
        view_286: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_141, [32, 16]);  clone_141 = None
        mm_138: "f32[32, 8]" = torch.ops.aten.mm.default(view_286, slice_7)
        view_287: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_138, [2, 16, 8]);  mm_138 = None
        slice_4563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_551, 1, 1104, 1120)
        slice_4564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4563, 2, 0, 16);  slice_4563 = None
        add_140: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4564, view_287);  slice_4564 = view_287 = None
        
        # No stacktrace found for following nodes
        slice_tensor_276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_551, 1, 1104, 1120)
        slice_scatter_default_552: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_276, add_140, 2, 0, 16);  slice_tensor_276 = add_140 = None
        slice_scatter_default_553: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_551, slice_scatter_default_552, 1, 1104, 1120);  slice_scatter_default_551 = slice_scatter_default_552 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_553, 1, 1104, 1120)
        slice_4569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4568, 2, 0, 16);  slice_4568 = None
        
        # No stacktrace found for following nodes
        slice_tensor_277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_553, 1, 1104, 1120)
        slice_scatter_default_554: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_277, slice_4569, 2, 0, 16);  slice_tensor_277 = slice_4569 = None
        slice_scatter_default_555: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_553, slice_scatter_default_554, 1, 1104, 1120);  slice_scatter_default_553 = slice_scatter_default_554 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4589: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4555, 2, 16, 32);  slice_4555 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_142: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4589, memory_format = torch.contiguous_format);  slice_4589 = None
        view_288: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_142, [32, 11]);  clone_142 = None
        mm_139: "f32[32, 8]" = torch.ops.aten.mm.default(view_288, slice_37)
        view_289: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_139, [2, 16, 8]);  mm_139 = None
        slice_4596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_555, 1, 1104, 1120)
        slice_4597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4596, 2, 0, 16);  slice_4596 = None
        add_141: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4597, view_289);  slice_4597 = view_289 = None
        
        # No stacktrace found for following nodes
        slice_tensor_278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_555, 1, 1104, 1120)
        slice_scatter_default_556: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_278, add_141, 2, 0, 16);  slice_tensor_278 = add_141 = None
        slice_scatter_default_557: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_555, slice_scatter_default_556, 1, 1104, 1120);  slice_scatter_default_555 = slice_scatter_default_556 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_557, 1, 1104, 1120)
        slice_4602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4601, 2, 0, 16);  slice_4601 = None
        
        # No stacktrace found for following nodes
        slice_tensor_279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_557, 1, 1104, 1120)
        slice_scatter_default_558: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_279, slice_4602, 2, 0, 16);  slice_tensor_279 = slice_4602 = None
        slice_scatter_default_559: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_557, slice_scatter_default_558, 1, 1104, 1120);  slice_scatter_default_557 = slice_scatter_default_558 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4621: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1120, 1136)
        slice_4622: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4621, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_143: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4622, memory_format = torch.contiguous_format);  slice_4622 = None
        view_290: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_143, [32, 16]);  clone_143 = None
        mm_140: "f32[32, 8]" = torch.ops.aten.mm.default(view_290, slice_7)
        view_291: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_140, [2, 16, 8]);  mm_140 = None
        slice_4629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_559, 1, 1120, 1136)
        slice_4630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4629, 2, 0, 16);  slice_4629 = None
        add_142: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4630, view_291);  slice_4630 = view_291 = None
        
        # No stacktrace found for following nodes
        slice_tensor_280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_559, 1, 1120, 1136)
        slice_scatter_default_560: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_280, add_142, 2, 0, 16);  slice_tensor_280 = add_142 = None
        slice_scatter_default_561: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_559, slice_scatter_default_560, 1, 1120, 1136);  slice_scatter_default_559 = slice_scatter_default_560 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_561, 1, 1120, 1136)
        slice_4635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4634, 2, 0, 16);  slice_4634 = None
        
        # No stacktrace found for following nodes
        slice_tensor_281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_561, 1, 1120, 1136)
        slice_scatter_default_562: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_281, slice_4635, 2, 0, 16);  slice_tensor_281 = slice_4635 = None
        slice_scatter_default_563: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_561, slice_scatter_default_562, 1, 1120, 1136);  slice_scatter_default_561 = slice_scatter_default_562 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4655: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4621, 2, 16, 32);  slice_4621 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_144: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4655, memory_format = torch.contiguous_format);  slice_4655 = None
        view_292: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_144, [32, 11]);  clone_144 = None
        mm_141: "f32[32, 8]" = torch.ops.aten.mm.default(view_292, slice_37)
        view_293: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_141, [2, 16, 8]);  mm_141 = None
        slice_4662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_563, 1, 1120, 1136)
        slice_4663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4662, 2, 0, 16);  slice_4662 = None
        add_143: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4663, view_293);  slice_4663 = view_293 = None
        
        # No stacktrace found for following nodes
        slice_tensor_282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_563, 1, 1120, 1136)
        slice_scatter_default_564: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_282, add_143, 2, 0, 16);  slice_tensor_282 = add_143 = None
        slice_scatter_default_565: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_563, slice_scatter_default_564, 1, 1120, 1136);  slice_scatter_default_563 = slice_scatter_default_564 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_565, 1, 1120, 1136)
        slice_4668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4667, 2, 0, 16);  slice_4667 = None
        
        # No stacktrace found for following nodes
        slice_tensor_283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_565, 1, 1120, 1136)
        slice_scatter_default_566: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_283, slice_4668, 2, 0, 16);  slice_tensor_283 = slice_4668 = None
        slice_scatter_default_567: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_565, slice_scatter_default_566, 1, 1120, 1136);  slice_scatter_default_565 = slice_scatter_default_566 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4687: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1136, 1152)
        slice_4688: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4687, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_145: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4688, memory_format = torch.contiguous_format);  slice_4688 = None
        view_294: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_145, [32, 16]);  clone_145 = None
        mm_142: "f32[32, 8]" = torch.ops.aten.mm.default(view_294, slice_7)
        view_295: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_142, [2, 16, 8]);  mm_142 = None
        slice_4695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_567, 1, 1136, 1152)
        slice_4696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4695, 2, 0, 16);  slice_4695 = None
        add_144: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4696, view_295);  slice_4696 = view_295 = None
        
        # No stacktrace found for following nodes
        slice_tensor_284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_567, 1, 1136, 1152)
        slice_scatter_default_568: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_284, add_144, 2, 0, 16);  slice_tensor_284 = add_144 = None
        slice_scatter_default_569: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_567, slice_scatter_default_568, 1, 1136, 1152);  slice_scatter_default_567 = slice_scatter_default_568 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_569, 1, 1136, 1152)
        slice_4701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4700, 2, 0, 16);  slice_4700 = None
        
        # No stacktrace found for following nodes
        slice_tensor_285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_569, 1, 1136, 1152)
        slice_scatter_default_570: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_285, slice_4701, 2, 0, 16);  slice_tensor_285 = slice_4701 = None
        slice_scatter_default_571: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_569, slice_scatter_default_570, 1, 1136, 1152);  slice_scatter_default_569 = slice_scatter_default_570 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4721: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4687, 2, 16, 32);  slice_4687 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_146: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4721, memory_format = torch.contiguous_format);  slice_4721 = None
        view_296: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_146, [32, 11]);  clone_146 = None
        mm_143: "f32[32, 8]" = torch.ops.aten.mm.default(view_296, slice_37)
        view_297: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_143, [2, 16, 8]);  mm_143 = None
        slice_4728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_571, 1, 1136, 1152)
        slice_4729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4728, 2, 0, 16);  slice_4728 = None
        add_145: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4729, view_297);  slice_4729 = view_297 = None
        
        # No stacktrace found for following nodes
        slice_tensor_286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_571, 1, 1136, 1152)
        slice_scatter_default_572: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_286, add_145, 2, 0, 16);  slice_tensor_286 = add_145 = None
        slice_scatter_default_573: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_571, slice_scatter_default_572, 1, 1136, 1152);  slice_scatter_default_571 = slice_scatter_default_572 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_573, 1, 1136, 1152)
        slice_4734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4733, 2, 0, 16);  slice_4733 = None
        
        # No stacktrace found for following nodes
        slice_tensor_287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_573, 1, 1136, 1152)
        slice_scatter_default_574: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_287, slice_4734, 2, 0, 16);  slice_tensor_287 = slice_4734 = None
        slice_scatter_default_575: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_573, slice_scatter_default_574, 1, 1136, 1152);  slice_scatter_default_573 = slice_scatter_default_574 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4753: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1152, 1168)
        slice_4754: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4753, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_147: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4754, memory_format = torch.contiguous_format);  slice_4754 = None
        view_298: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_147, [32, 16]);  clone_147 = None
        mm_144: "f32[32, 8]" = torch.ops.aten.mm.default(view_298, slice_7)
        view_299: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_144, [2, 16, 8]);  mm_144 = None
        slice_4761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_575, 1, 1152, 1168)
        slice_4762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4761, 2, 0, 16);  slice_4761 = None
        add_146: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4762, view_299);  slice_4762 = view_299 = None
        
        # No stacktrace found for following nodes
        slice_tensor_288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_575, 1, 1152, 1168)
        slice_scatter_default_576: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_288, add_146, 2, 0, 16);  slice_tensor_288 = add_146 = None
        slice_scatter_default_577: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_575, slice_scatter_default_576, 1, 1152, 1168);  slice_scatter_default_575 = slice_scatter_default_576 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_577, 1, 1152, 1168)
        slice_4767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4766, 2, 0, 16);  slice_4766 = None
        
        # No stacktrace found for following nodes
        slice_tensor_289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_577, 1, 1152, 1168)
        slice_scatter_default_578: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_289, slice_4767, 2, 0, 16);  slice_tensor_289 = slice_4767 = None
        slice_scatter_default_579: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_577, slice_scatter_default_578, 1, 1152, 1168);  slice_scatter_default_577 = slice_scatter_default_578 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4787: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4753, 2, 16, 32);  slice_4753 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_148: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4787, memory_format = torch.contiguous_format);  slice_4787 = None
        view_300: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_148, [32, 11]);  clone_148 = None
        mm_145: "f32[32, 8]" = torch.ops.aten.mm.default(view_300, slice_37)
        view_301: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_145, [2, 16, 8]);  mm_145 = None
        slice_4794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_579, 1, 1152, 1168)
        slice_4795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4794, 2, 0, 16);  slice_4794 = None
        add_147: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4795, view_301);  slice_4795 = view_301 = None
        
        # No stacktrace found for following nodes
        slice_tensor_290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_579, 1, 1152, 1168)
        slice_scatter_default_580: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_290, add_147, 2, 0, 16);  slice_tensor_290 = add_147 = None
        slice_scatter_default_581: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_579, slice_scatter_default_580, 1, 1152, 1168);  slice_scatter_default_579 = slice_scatter_default_580 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_581, 1, 1152, 1168)
        slice_4800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4799, 2, 0, 16);  slice_4799 = None
        
        # No stacktrace found for following nodes
        slice_tensor_291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_581, 1, 1152, 1168)
        slice_scatter_default_582: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_291, slice_4800, 2, 0, 16);  slice_tensor_291 = slice_4800 = None
        slice_scatter_default_583: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_581, slice_scatter_default_582, 1, 1152, 1168);  slice_scatter_default_581 = slice_scatter_default_582 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4819: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1168, 1184)
        slice_4820: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4819, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_149: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4820, memory_format = torch.contiguous_format);  slice_4820 = None
        view_302: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_149, [32, 16]);  clone_149 = None
        mm_146: "f32[32, 8]" = torch.ops.aten.mm.default(view_302, slice_7)
        view_303: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_146, [2, 16, 8]);  mm_146 = None
        slice_4827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_583, 1, 1168, 1184)
        slice_4828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4827, 2, 0, 16);  slice_4827 = None
        add_148: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4828, view_303);  slice_4828 = view_303 = None
        
        # No stacktrace found for following nodes
        slice_tensor_292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_583, 1, 1168, 1184)
        slice_scatter_default_584: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_292, add_148, 2, 0, 16);  slice_tensor_292 = add_148 = None
        slice_scatter_default_585: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_583, slice_scatter_default_584, 1, 1168, 1184);  slice_scatter_default_583 = slice_scatter_default_584 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_585, 1, 1168, 1184)
        slice_4833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4832, 2, 0, 16);  slice_4832 = None
        
        # No stacktrace found for following nodes
        slice_tensor_293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_585, 1, 1168, 1184)
        slice_scatter_default_586: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_293, slice_4833, 2, 0, 16);  slice_tensor_293 = slice_4833 = None
        slice_scatter_default_587: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_585, slice_scatter_default_586, 1, 1168, 1184);  slice_scatter_default_585 = slice_scatter_default_586 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4853: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4819, 2, 16, 32);  slice_4819 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_150: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4853, memory_format = torch.contiguous_format);  slice_4853 = None
        view_304: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_150, [32, 11]);  clone_150 = None
        mm_147: "f32[32, 8]" = torch.ops.aten.mm.default(view_304, slice_37)
        view_305: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_147, [2, 16, 8]);  mm_147 = None
        slice_4860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_587, 1, 1168, 1184)
        slice_4861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4860, 2, 0, 16);  slice_4860 = None
        add_149: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4861, view_305);  slice_4861 = view_305 = None
        
        # No stacktrace found for following nodes
        slice_tensor_294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_587, 1, 1168, 1184)
        slice_scatter_default_588: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_294, add_149, 2, 0, 16);  slice_tensor_294 = add_149 = None
        slice_scatter_default_589: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_587, slice_scatter_default_588, 1, 1168, 1184);  slice_scatter_default_587 = slice_scatter_default_588 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_589, 1, 1168, 1184)
        slice_4866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4865, 2, 0, 16);  slice_4865 = None
        
        # No stacktrace found for following nodes
        slice_tensor_295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_589, 1, 1168, 1184)
        slice_scatter_default_590: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_295, slice_4866, 2, 0, 16);  slice_tensor_295 = slice_4866 = None
        slice_scatter_default_591: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_589, slice_scatter_default_590, 1, 1168, 1184);  slice_scatter_default_589 = slice_scatter_default_590 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4885: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1184, 1200)
        slice_4886: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4885, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_151: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4886, memory_format = torch.contiguous_format);  slice_4886 = None
        view_306: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_151, [32, 16]);  clone_151 = None
        mm_148: "f32[32, 8]" = torch.ops.aten.mm.default(view_306, slice_7)
        view_307: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_148, [2, 16, 8]);  mm_148 = None
        slice_4893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_591, 1, 1184, 1200)
        slice_4894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4893, 2, 0, 16);  slice_4893 = None
        add_150: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4894, view_307);  slice_4894 = view_307 = None
        
        # No stacktrace found for following nodes
        slice_tensor_296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_591, 1, 1184, 1200)
        slice_scatter_default_592: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_296, add_150, 2, 0, 16);  slice_tensor_296 = add_150 = None
        slice_scatter_default_593: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_591, slice_scatter_default_592, 1, 1184, 1200);  slice_scatter_default_591 = slice_scatter_default_592 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_593, 1, 1184, 1200)
        slice_4899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4898, 2, 0, 16);  slice_4898 = None
        
        # No stacktrace found for following nodes
        slice_tensor_297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_593, 1, 1184, 1200)
        slice_scatter_default_594: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_297, slice_4899, 2, 0, 16);  slice_tensor_297 = slice_4899 = None
        slice_scatter_default_595: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_593, slice_scatter_default_594, 1, 1184, 1200);  slice_scatter_default_593 = slice_scatter_default_594 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4919: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4885, 2, 16, 32);  slice_4885 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_152: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4919, memory_format = torch.contiguous_format);  slice_4919 = None
        view_308: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_152, [32, 11]);  clone_152 = None
        mm_149: "f32[32, 8]" = torch.ops.aten.mm.default(view_308, slice_37)
        view_309: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_149, [2, 16, 8]);  mm_149 = None
        slice_4926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_595, 1, 1184, 1200)
        slice_4927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4926, 2, 0, 16);  slice_4926 = None
        add_151: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4927, view_309);  slice_4927 = view_309 = None
        
        # No stacktrace found for following nodes
        slice_tensor_298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_595, 1, 1184, 1200)
        slice_scatter_default_596: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_298, add_151, 2, 0, 16);  slice_tensor_298 = add_151 = None
        slice_scatter_default_597: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_595, slice_scatter_default_596, 1, 1184, 1200);  slice_scatter_default_595 = slice_scatter_default_596 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_597, 1, 1184, 1200)
        slice_4932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4931, 2, 0, 16);  slice_4931 = None
        
        # No stacktrace found for following nodes
        slice_tensor_299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_597, 1, 1184, 1200)
        slice_scatter_default_598: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_299, slice_4932, 2, 0, 16);  slice_tensor_299 = slice_4932 = None
        slice_scatter_default_599: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_597, slice_scatter_default_598, 1, 1184, 1200);  slice_scatter_default_597 = slice_scatter_default_598 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4951: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1200, 1216)
        slice_4952: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_4951, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_153: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_4952, memory_format = torch.contiguous_format);  slice_4952 = None
        view_310: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_153, [32, 16]);  clone_153 = None
        mm_150: "f32[32, 8]" = torch.ops.aten.mm.default(view_310, slice_7)
        view_311: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_150, [2, 16, 8]);  mm_150 = None
        slice_4959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_599, 1, 1200, 1216)
        slice_4960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4959, 2, 0, 16);  slice_4959 = None
        add_152: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4960, view_311);  slice_4960 = view_311 = None
        
        # No stacktrace found for following nodes
        slice_tensor_300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_599, 1, 1200, 1216)
        slice_scatter_default_600: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_300, add_152, 2, 0, 16);  slice_tensor_300 = add_152 = None
        slice_scatter_default_601: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_599, slice_scatter_default_600, 1, 1200, 1216);  slice_scatter_default_599 = slice_scatter_default_600 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_601, 1, 1200, 1216)
        slice_4965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4964, 2, 0, 16);  slice_4964 = None
        
        # No stacktrace found for following nodes
        slice_tensor_301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_601, 1, 1200, 1216)
        slice_scatter_default_602: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_301, slice_4965, 2, 0, 16);  slice_tensor_301 = slice_4965 = None
        slice_scatter_default_603: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_601, slice_scatter_default_602, 1, 1200, 1216);  slice_scatter_default_601 = slice_scatter_default_602 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_4985: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_4951, 2, 16, 32);  slice_4951 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_154: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_4985, memory_format = torch.contiguous_format);  slice_4985 = None
        view_312: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_154, [32, 11]);  clone_154 = None
        mm_151: "f32[32, 8]" = torch.ops.aten.mm.default(view_312, slice_37)
        view_313: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_151, [2, 16, 8]);  mm_151 = None
        slice_4992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_603, 1, 1200, 1216)
        slice_4993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4992, 2, 0, 16);  slice_4992 = None
        add_153: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_4993, view_313);  slice_4993 = view_313 = None
        
        # No stacktrace found for following nodes
        slice_tensor_302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_603, 1, 1200, 1216)
        slice_scatter_default_604: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_302, add_153, 2, 0, 16);  slice_tensor_302 = add_153 = None
        slice_scatter_default_605: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_603, slice_scatter_default_604, 1, 1200, 1216);  slice_scatter_default_603 = slice_scatter_default_604 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_4997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_605, 1, 1200, 1216)
        slice_4998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_4997, 2, 0, 16);  slice_4997 = None
        
        # No stacktrace found for following nodes
        slice_tensor_303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_605, 1, 1200, 1216)
        slice_scatter_default_606: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_303, slice_4998, 2, 0, 16);  slice_tensor_303 = slice_4998 = None
        slice_scatter_default_607: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_605, slice_scatter_default_606, 1, 1200, 1216);  slice_scatter_default_605 = slice_scatter_default_606 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5017: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1216, 1232)
        slice_5018: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5017, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_155: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5018, memory_format = torch.contiguous_format);  slice_5018 = None
        view_314: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_155, [32, 16]);  clone_155 = None
        mm_152: "f32[32, 8]" = torch.ops.aten.mm.default(view_314, slice_7)
        view_315: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_152, [2, 16, 8]);  mm_152 = None
        slice_5025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_607, 1, 1216, 1232)
        slice_5026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5025, 2, 0, 16);  slice_5025 = None
        add_154: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5026, view_315);  slice_5026 = view_315 = None
        
        # No stacktrace found for following nodes
        slice_tensor_304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_607, 1, 1216, 1232)
        slice_scatter_default_608: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_304, add_154, 2, 0, 16);  slice_tensor_304 = add_154 = None
        slice_scatter_default_609: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_607, slice_scatter_default_608, 1, 1216, 1232);  slice_scatter_default_607 = slice_scatter_default_608 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_609, 1, 1216, 1232)
        slice_5031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5030, 2, 0, 16);  slice_5030 = None
        
        # No stacktrace found for following nodes
        slice_tensor_305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_609, 1, 1216, 1232)
        slice_scatter_default_610: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_305, slice_5031, 2, 0, 16);  slice_tensor_305 = slice_5031 = None
        slice_scatter_default_611: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_609, slice_scatter_default_610, 1, 1216, 1232);  slice_scatter_default_609 = slice_scatter_default_610 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5051: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5017, 2, 16, 32);  slice_5017 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_156: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5051, memory_format = torch.contiguous_format);  slice_5051 = None
        view_316: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_156, [32, 11]);  clone_156 = None
        mm_153: "f32[32, 8]" = torch.ops.aten.mm.default(view_316, slice_37)
        view_317: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_153, [2, 16, 8]);  mm_153 = None
        slice_5058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_611, 1, 1216, 1232)
        slice_5059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5058, 2, 0, 16);  slice_5058 = None
        add_155: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5059, view_317);  slice_5059 = view_317 = None
        
        # No stacktrace found for following nodes
        slice_tensor_306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_611, 1, 1216, 1232)
        slice_scatter_default_612: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_306, add_155, 2, 0, 16);  slice_tensor_306 = add_155 = None
        slice_scatter_default_613: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_611, slice_scatter_default_612, 1, 1216, 1232);  slice_scatter_default_611 = slice_scatter_default_612 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_613, 1, 1216, 1232)
        slice_5064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5063, 2, 0, 16);  slice_5063 = None
        
        # No stacktrace found for following nodes
        slice_tensor_307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_613, 1, 1216, 1232)
        slice_scatter_default_614: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_307, slice_5064, 2, 0, 16);  slice_tensor_307 = slice_5064 = None
        slice_scatter_default_615: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_613, slice_scatter_default_614, 1, 1216, 1232);  slice_scatter_default_613 = slice_scatter_default_614 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5083: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1232, 1248)
        slice_5084: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5083, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_157: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5084, memory_format = torch.contiguous_format);  slice_5084 = None
        view_318: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_157, [32, 16]);  clone_157 = None
        mm_154: "f32[32, 8]" = torch.ops.aten.mm.default(view_318, slice_7)
        view_319: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_154, [2, 16, 8]);  mm_154 = None
        slice_5091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_615, 1, 1232, 1248)
        slice_5092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5091, 2, 0, 16);  slice_5091 = None
        add_156: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5092, view_319);  slice_5092 = view_319 = None
        
        # No stacktrace found for following nodes
        slice_tensor_308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_615, 1, 1232, 1248)
        slice_scatter_default_616: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_308, add_156, 2, 0, 16);  slice_tensor_308 = add_156 = None
        slice_scatter_default_617: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_615, slice_scatter_default_616, 1, 1232, 1248);  slice_scatter_default_615 = slice_scatter_default_616 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_617, 1, 1232, 1248)
        slice_5097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5096, 2, 0, 16);  slice_5096 = None
        
        # No stacktrace found for following nodes
        slice_tensor_309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_617, 1, 1232, 1248)
        slice_scatter_default_618: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_309, slice_5097, 2, 0, 16);  slice_tensor_309 = slice_5097 = None
        slice_scatter_default_619: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_617, slice_scatter_default_618, 1, 1232, 1248);  slice_scatter_default_617 = slice_scatter_default_618 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5117: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5083, 2, 16, 32);  slice_5083 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_158: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5117, memory_format = torch.contiguous_format);  slice_5117 = None
        view_320: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_158, [32, 11]);  clone_158 = None
        mm_155: "f32[32, 8]" = torch.ops.aten.mm.default(view_320, slice_37)
        view_321: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_155, [2, 16, 8]);  mm_155 = None
        slice_5124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_619, 1, 1232, 1248)
        slice_5125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5124, 2, 0, 16);  slice_5124 = None
        add_157: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5125, view_321);  slice_5125 = view_321 = None
        
        # No stacktrace found for following nodes
        slice_tensor_310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_619, 1, 1232, 1248)
        slice_scatter_default_620: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_310, add_157, 2, 0, 16);  slice_tensor_310 = add_157 = None
        slice_scatter_default_621: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_619, slice_scatter_default_620, 1, 1232, 1248);  slice_scatter_default_619 = slice_scatter_default_620 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_621, 1, 1232, 1248)
        slice_5130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5129, 2, 0, 16);  slice_5129 = None
        
        # No stacktrace found for following nodes
        slice_tensor_311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_621, 1, 1232, 1248)
        slice_scatter_default_622: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_311, slice_5130, 2, 0, 16);  slice_tensor_311 = slice_5130 = None
        slice_scatter_default_623: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_621, slice_scatter_default_622, 1, 1232, 1248);  slice_scatter_default_621 = slice_scatter_default_622 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5149: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1248, 1264)
        slice_5150: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5149, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_159: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5150, memory_format = torch.contiguous_format);  slice_5150 = None
        view_322: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_159, [32, 16]);  clone_159 = None
        mm_156: "f32[32, 8]" = torch.ops.aten.mm.default(view_322, slice_7)
        view_323: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_156, [2, 16, 8]);  mm_156 = None
        slice_5157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_623, 1, 1248, 1264)
        slice_5158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5157, 2, 0, 16);  slice_5157 = None
        add_158: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5158, view_323);  slice_5158 = view_323 = None
        
        # No stacktrace found for following nodes
        slice_tensor_312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_623, 1, 1248, 1264)
        slice_scatter_default_624: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_312, add_158, 2, 0, 16);  slice_tensor_312 = add_158 = None
        slice_scatter_default_625: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_623, slice_scatter_default_624, 1, 1248, 1264);  slice_scatter_default_623 = slice_scatter_default_624 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_625, 1, 1248, 1264)
        slice_5163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5162, 2, 0, 16);  slice_5162 = None
        
        # No stacktrace found for following nodes
        slice_tensor_313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_625, 1, 1248, 1264)
        slice_scatter_default_626: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_313, slice_5163, 2, 0, 16);  slice_tensor_313 = slice_5163 = None
        slice_scatter_default_627: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_625, slice_scatter_default_626, 1, 1248, 1264);  slice_scatter_default_625 = slice_scatter_default_626 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5183: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5149, 2, 16, 32);  slice_5149 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_160: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5183, memory_format = torch.contiguous_format);  slice_5183 = None
        view_324: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_160, [32, 11]);  clone_160 = None
        mm_157: "f32[32, 8]" = torch.ops.aten.mm.default(view_324, slice_37)
        view_325: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_157, [2, 16, 8]);  mm_157 = None
        slice_5190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_627, 1, 1248, 1264)
        slice_5191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5190, 2, 0, 16);  slice_5190 = None
        add_159: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5191, view_325);  slice_5191 = view_325 = None
        
        # No stacktrace found for following nodes
        slice_tensor_314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_627, 1, 1248, 1264)
        slice_scatter_default_628: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_314, add_159, 2, 0, 16);  slice_tensor_314 = add_159 = None
        slice_scatter_default_629: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_627, slice_scatter_default_628, 1, 1248, 1264);  slice_scatter_default_627 = slice_scatter_default_628 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_629, 1, 1248, 1264)
        slice_5196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5195, 2, 0, 16);  slice_5195 = None
        
        # No stacktrace found for following nodes
        slice_tensor_315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_629, 1, 1248, 1264)
        slice_scatter_default_630: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_315, slice_5196, 2, 0, 16);  slice_tensor_315 = slice_5196 = None
        slice_scatter_default_631: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_629, slice_scatter_default_630, 1, 1248, 1264);  slice_scatter_default_629 = slice_scatter_default_630 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5215: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1264, 1280)
        slice_5216: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5215, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_161: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5216, memory_format = torch.contiguous_format);  slice_5216 = None
        view_326: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_161, [32, 16]);  clone_161 = None
        mm_158: "f32[32, 8]" = torch.ops.aten.mm.default(view_326, slice_7)
        view_327: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_158, [2, 16, 8]);  mm_158 = None
        slice_5223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_631, 1, 1264, 1280)
        slice_5224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5223, 2, 0, 16);  slice_5223 = None
        add_160: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5224, view_327);  slice_5224 = view_327 = None
        
        # No stacktrace found for following nodes
        slice_tensor_316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_631, 1, 1264, 1280)
        slice_scatter_default_632: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_316, add_160, 2, 0, 16);  slice_tensor_316 = add_160 = None
        slice_scatter_default_633: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_631, slice_scatter_default_632, 1, 1264, 1280);  slice_scatter_default_631 = slice_scatter_default_632 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_633, 1, 1264, 1280)
        slice_5229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5228, 2, 0, 16);  slice_5228 = None
        
        # No stacktrace found for following nodes
        slice_tensor_317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_633, 1, 1264, 1280)
        slice_scatter_default_634: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_317, slice_5229, 2, 0, 16);  slice_tensor_317 = slice_5229 = None
        slice_scatter_default_635: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_633, slice_scatter_default_634, 1, 1264, 1280);  slice_scatter_default_633 = slice_scatter_default_634 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5249: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5215, 2, 16, 32);  slice_5215 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_162: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5249, memory_format = torch.contiguous_format);  slice_5249 = None
        view_328: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_162, [32, 11]);  clone_162 = None
        mm_159: "f32[32, 8]" = torch.ops.aten.mm.default(view_328, slice_37)
        view_329: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_159, [2, 16, 8]);  mm_159 = None
        slice_5256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_635, 1, 1264, 1280)
        slice_5257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5256, 2, 0, 16);  slice_5256 = None
        add_161: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5257, view_329);  slice_5257 = view_329 = None
        
        # No stacktrace found for following nodes
        slice_tensor_318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_635, 1, 1264, 1280)
        slice_scatter_default_636: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_318, add_161, 2, 0, 16);  slice_tensor_318 = add_161 = None
        slice_scatter_default_637: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_635, slice_scatter_default_636, 1, 1264, 1280);  slice_scatter_default_635 = slice_scatter_default_636 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_637, 1, 1264, 1280)
        slice_5262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5261, 2, 0, 16);  slice_5261 = None
        
        # No stacktrace found for following nodes
        slice_tensor_319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_637, 1, 1264, 1280)
        slice_scatter_default_638: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_319, slice_5262, 2, 0, 16);  slice_tensor_319 = slice_5262 = None
        slice_scatter_default_639: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_637, slice_scatter_default_638, 1, 1264, 1280);  slice_scatter_default_637 = slice_scatter_default_638 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5281: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1280, 1296)
        slice_5282: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5281, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_163: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5282, memory_format = torch.contiguous_format);  slice_5282 = None
        view_330: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_163, [32, 16]);  clone_163 = None
        mm_160: "f32[32, 8]" = torch.ops.aten.mm.default(view_330, slice_7)
        view_331: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_160, [2, 16, 8]);  mm_160 = None
        slice_5289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_639, 1, 1280, 1296)
        slice_5290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5289, 2, 0, 16);  slice_5289 = None
        add_162: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5290, view_331);  slice_5290 = view_331 = None
        
        # No stacktrace found for following nodes
        slice_tensor_320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_639, 1, 1280, 1296)
        slice_scatter_default_640: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_320, add_162, 2, 0, 16);  slice_tensor_320 = add_162 = None
        slice_scatter_default_641: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_639, slice_scatter_default_640, 1, 1280, 1296);  slice_scatter_default_639 = slice_scatter_default_640 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_641, 1, 1280, 1296)
        slice_5295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5294, 2, 0, 16);  slice_5294 = None
        
        # No stacktrace found for following nodes
        slice_tensor_321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_641, 1, 1280, 1296)
        slice_scatter_default_642: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_321, slice_5295, 2, 0, 16);  slice_tensor_321 = slice_5295 = None
        slice_scatter_default_643: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_641, slice_scatter_default_642, 1, 1280, 1296);  slice_scatter_default_641 = slice_scatter_default_642 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5315: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5281, 2, 16, 32);  slice_5281 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_164: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5315, memory_format = torch.contiguous_format);  slice_5315 = None
        view_332: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_164, [32, 11]);  clone_164 = None
        mm_161: "f32[32, 8]" = torch.ops.aten.mm.default(view_332, slice_37)
        view_333: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_161, [2, 16, 8]);  mm_161 = None
        slice_5322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_643, 1, 1280, 1296)
        slice_5323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5322, 2, 0, 16);  slice_5322 = None
        add_163: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5323, view_333);  slice_5323 = view_333 = None
        
        # No stacktrace found for following nodes
        slice_tensor_322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_643, 1, 1280, 1296)
        slice_scatter_default_644: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_322, add_163, 2, 0, 16);  slice_tensor_322 = add_163 = None
        slice_scatter_default_645: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_643, slice_scatter_default_644, 1, 1280, 1296);  slice_scatter_default_643 = slice_scatter_default_644 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_645, 1, 1280, 1296)
        slice_5328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5327, 2, 0, 16);  slice_5327 = None
        
        # No stacktrace found for following nodes
        slice_tensor_323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_645, 1, 1280, 1296)
        slice_scatter_default_646: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_323, slice_5328, 2, 0, 16);  slice_tensor_323 = slice_5328 = None
        slice_scatter_default_647: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_645, slice_scatter_default_646, 1, 1280, 1296);  slice_scatter_default_645 = slice_scatter_default_646 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5347: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1296, 1312)
        slice_5348: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5347, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_165: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5348, memory_format = torch.contiguous_format);  slice_5348 = None
        view_334: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_165, [32, 16]);  clone_165 = None
        mm_162: "f32[32, 8]" = torch.ops.aten.mm.default(view_334, slice_7)
        view_335: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_162, [2, 16, 8]);  mm_162 = None
        slice_5355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_647, 1, 1296, 1312)
        slice_5356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5355, 2, 0, 16);  slice_5355 = None
        add_164: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5356, view_335);  slice_5356 = view_335 = None
        
        # No stacktrace found for following nodes
        slice_tensor_324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_647, 1, 1296, 1312)
        slice_scatter_default_648: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_324, add_164, 2, 0, 16);  slice_tensor_324 = add_164 = None
        slice_scatter_default_649: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_647, slice_scatter_default_648, 1, 1296, 1312);  slice_scatter_default_647 = slice_scatter_default_648 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_649, 1, 1296, 1312)
        slice_5361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5360, 2, 0, 16);  slice_5360 = None
        
        # No stacktrace found for following nodes
        slice_tensor_325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_649, 1, 1296, 1312)
        slice_scatter_default_650: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_325, slice_5361, 2, 0, 16);  slice_tensor_325 = slice_5361 = None
        slice_scatter_default_651: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_649, slice_scatter_default_650, 1, 1296, 1312);  slice_scatter_default_649 = slice_scatter_default_650 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5381: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5347, 2, 16, 32);  slice_5347 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_166: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5381, memory_format = torch.contiguous_format);  slice_5381 = None
        view_336: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_166, [32, 11]);  clone_166 = None
        mm_163: "f32[32, 8]" = torch.ops.aten.mm.default(view_336, slice_37)
        view_337: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_163, [2, 16, 8]);  mm_163 = None
        slice_5388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_651, 1, 1296, 1312)
        slice_5389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5388, 2, 0, 16);  slice_5388 = None
        add_165: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5389, view_337);  slice_5389 = view_337 = None
        
        # No stacktrace found for following nodes
        slice_tensor_326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_651, 1, 1296, 1312)
        slice_scatter_default_652: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_326, add_165, 2, 0, 16);  slice_tensor_326 = add_165 = None
        slice_scatter_default_653: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_651, slice_scatter_default_652, 1, 1296, 1312);  slice_scatter_default_651 = slice_scatter_default_652 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_653, 1, 1296, 1312)
        slice_5394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5393, 2, 0, 16);  slice_5393 = None
        
        # No stacktrace found for following nodes
        slice_tensor_327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_653, 1, 1296, 1312)
        slice_scatter_default_654: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_327, slice_5394, 2, 0, 16);  slice_tensor_327 = slice_5394 = None
        slice_scatter_default_655: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_653, slice_scatter_default_654, 1, 1296, 1312);  slice_scatter_default_653 = slice_scatter_default_654 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5413: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1312, 1328)
        slice_5414: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5413, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_167: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5414, memory_format = torch.contiguous_format);  slice_5414 = None
        view_338: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_167, [32, 16]);  clone_167 = None
        mm_164: "f32[32, 8]" = torch.ops.aten.mm.default(view_338, slice_7)
        view_339: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_164, [2, 16, 8]);  mm_164 = None
        slice_5421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_655, 1, 1312, 1328)
        slice_5422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5421, 2, 0, 16);  slice_5421 = None
        add_166: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5422, view_339);  slice_5422 = view_339 = None
        
        # No stacktrace found for following nodes
        slice_tensor_328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_655, 1, 1312, 1328)
        slice_scatter_default_656: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_328, add_166, 2, 0, 16);  slice_tensor_328 = add_166 = None
        slice_scatter_default_657: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_655, slice_scatter_default_656, 1, 1312, 1328);  slice_scatter_default_655 = slice_scatter_default_656 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_657, 1, 1312, 1328)
        slice_5427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5426, 2, 0, 16);  slice_5426 = None
        
        # No stacktrace found for following nodes
        slice_tensor_329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_657, 1, 1312, 1328)
        slice_scatter_default_658: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_329, slice_5427, 2, 0, 16);  slice_tensor_329 = slice_5427 = None
        slice_scatter_default_659: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_657, slice_scatter_default_658, 1, 1312, 1328);  slice_scatter_default_657 = slice_scatter_default_658 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5447: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5413, 2, 16, 32);  slice_5413 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_168: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5447, memory_format = torch.contiguous_format);  slice_5447 = None
        view_340: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_168, [32, 11]);  clone_168 = None
        mm_165: "f32[32, 8]" = torch.ops.aten.mm.default(view_340, slice_37)
        view_341: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_165, [2, 16, 8]);  mm_165 = None
        slice_5454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_659, 1, 1312, 1328)
        slice_5455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5454, 2, 0, 16);  slice_5454 = None
        add_167: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5455, view_341);  slice_5455 = view_341 = None
        
        # No stacktrace found for following nodes
        slice_tensor_330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_659, 1, 1312, 1328)
        slice_scatter_default_660: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_330, add_167, 2, 0, 16);  slice_tensor_330 = add_167 = None
        slice_scatter_default_661: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_659, slice_scatter_default_660, 1, 1312, 1328);  slice_scatter_default_659 = slice_scatter_default_660 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_661, 1, 1312, 1328)
        slice_5460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5459, 2, 0, 16);  slice_5459 = None
        
        # No stacktrace found for following nodes
        slice_tensor_331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_661, 1, 1312, 1328)
        slice_scatter_default_662: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_331, slice_5460, 2, 0, 16);  slice_tensor_331 = slice_5460 = None
        slice_scatter_default_663: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_661, slice_scatter_default_662, 1, 1312, 1328);  slice_scatter_default_661 = slice_scatter_default_662 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5479: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1328, 1344)
        slice_5480: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5479, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_169: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5480, memory_format = torch.contiguous_format);  slice_5480 = None
        view_342: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_169, [32, 16]);  clone_169 = None
        mm_166: "f32[32, 8]" = torch.ops.aten.mm.default(view_342, slice_7)
        view_343: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_166, [2, 16, 8]);  mm_166 = None
        slice_5487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_663, 1, 1328, 1344)
        slice_5488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5487, 2, 0, 16);  slice_5487 = None
        add_168: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5488, view_343);  slice_5488 = view_343 = None
        
        # No stacktrace found for following nodes
        slice_tensor_332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_663, 1, 1328, 1344)
        slice_scatter_default_664: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_332, add_168, 2, 0, 16);  slice_tensor_332 = add_168 = None
        slice_scatter_default_665: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_663, slice_scatter_default_664, 1, 1328, 1344);  slice_scatter_default_663 = slice_scatter_default_664 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_665, 1, 1328, 1344)
        slice_5493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5492, 2, 0, 16);  slice_5492 = None
        
        # No stacktrace found for following nodes
        slice_tensor_333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_665, 1, 1328, 1344)
        slice_scatter_default_666: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_333, slice_5493, 2, 0, 16);  slice_tensor_333 = slice_5493 = None
        slice_scatter_default_667: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_665, slice_scatter_default_666, 1, 1328, 1344);  slice_scatter_default_665 = slice_scatter_default_666 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5513: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5479, 2, 16, 32);  slice_5479 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_170: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5513, memory_format = torch.contiguous_format);  slice_5513 = None
        view_344: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_170, [32, 11]);  clone_170 = None
        mm_167: "f32[32, 8]" = torch.ops.aten.mm.default(view_344, slice_37)
        view_345: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_167, [2, 16, 8]);  mm_167 = None
        slice_5520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_667, 1, 1328, 1344)
        slice_5521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5520, 2, 0, 16);  slice_5520 = None
        add_169: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5521, view_345);  slice_5521 = view_345 = None
        
        # No stacktrace found for following nodes
        slice_tensor_334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_667, 1, 1328, 1344)
        slice_scatter_default_668: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_334, add_169, 2, 0, 16);  slice_tensor_334 = add_169 = None
        slice_scatter_default_669: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_667, slice_scatter_default_668, 1, 1328, 1344);  slice_scatter_default_667 = slice_scatter_default_668 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_669, 1, 1328, 1344)
        slice_5526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5525, 2, 0, 16);  slice_5525 = None
        
        # No stacktrace found for following nodes
        slice_tensor_335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_669, 1, 1328, 1344)
        slice_scatter_default_670: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_335, slice_5526, 2, 0, 16);  slice_tensor_335 = slice_5526 = None
        slice_scatter_default_671: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_669, slice_scatter_default_670, 1, 1328, 1344);  slice_scatter_default_669 = slice_scatter_default_670 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5545: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1344, 1360)
        slice_5546: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5545, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_171: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5546, memory_format = torch.contiguous_format);  slice_5546 = None
        view_346: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_171, [32, 16]);  clone_171 = None
        mm_168: "f32[32, 8]" = torch.ops.aten.mm.default(view_346, slice_7)
        view_347: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_168, [2, 16, 8]);  mm_168 = None
        slice_5553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_671, 1, 1344, 1360)
        slice_5554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5553, 2, 0, 16);  slice_5553 = None
        add_170: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5554, view_347);  slice_5554 = view_347 = None
        
        # No stacktrace found for following nodes
        slice_tensor_336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_671, 1, 1344, 1360)
        slice_scatter_default_672: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_336, add_170, 2, 0, 16);  slice_tensor_336 = add_170 = None
        slice_scatter_default_673: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_671, slice_scatter_default_672, 1, 1344, 1360);  slice_scatter_default_671 = slice_scatter_default_672 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_673, 1, 1344, 1360)
        slice_5559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5558, 2, 0, 16);  slice_5558 = None
        
        # No stacktrace found for following nodes
        slice_tensor_337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_673, 1, 1344, 1360)
        slice_scatter_default_674: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_337, slice_5559, 2, 0, 16);  slice_tensor_337 = slice_5559 = None
        slice_scatter_default_675: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_673, slice_scatter_default_674, 1, 1344, 1360);  slice_scatter_default_673 = slice_scatter_default_674 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5579: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5545, 2, 16, 32);  slice_5545 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_172: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5579, memory_format = torch.contiguous_format);  slice_5579 = None
        view_348: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_172, [32, 11]);  clone_172 = None
        mm_169: "f32[32, 8]" = torch.ops.aten.mm.default(view_348, slice_37)
        view_349: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_169, [2, 16, 8]);  mm_169 = None
        slice_5586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_675, 1, 1344, 1360)
        slice_5587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5586, 2, 0, 16);  slice_5586 = None
        add_171: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5587, view_349);  slice_5587 = view_349 = None
        
        # No stacktrace found for following nodes
        slice_tensor_338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_675, 1, 1344, 1360)
        slice_scatter_default_676: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_338, add_171, 2, 0, 16);  slice_tensor_338 = add_171 = None
        slice_scatter_default_677: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_675, slice_scatter_default_676, 1, 1344, 1360);  slice_scatter_default_675 = slice_scatter_default_676 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_677, 1, 1344, 1360)
        slice_5592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5591, 2, 0, 16);  slice_5591 = None
        
        # No stacktrace found for following nodes
        slice_tensor_339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_677, 1, 1344, 1360)
        slice_scatter_default_678: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_339, slice_5592, 2, 0, 16);  slice_tensor_339 = slice_5592 = None
        slice_scatter_default_679: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_677, slice_scatter_default_678, 1, 1344, 1360);  slice_scatter_default_677 = slice_scatter_default_678 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5611: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1360, 1376)
        slice_5612: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5611, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_173: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5612, memory_format = torch.contiguous_format);  slice_5612 = None
        view_350: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_173, [32, 16]);  clone_173 = None
        mm_170: "f32[32, 8]" = torch.ops.aten.mm.default(view_350, slice_7)
        view_351: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_170, [2, 16, 8]);  mm_170 = None
        slice_5619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_679, 1, 1360, 1376)
        slice_5620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5619, 2, 0, 16);  slice_5619 = None
        add_172: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5620, view_351);  slice_5620 = view_351 = None
        
        # No stacktrace found for following nodes
        slice_tensor_340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_679, 1, 1360, 1376)
        slice_scatter_default_680: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_340, add_172, 2, 0, 16);  slice_tensor_340 = add_172 = None
        slice_scatter_default_681: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_679, slice_scatter_default_680, 1, 1360, 1376);  slice_scatter_default_679 = slice_scatter_default_680 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_681, 1, 1360, 1376)
        slice_5625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5624, 2, 0, 16);  slice_5624 = None
        
        # No stacktrace found for following nodes
        slice_tensor_341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_681, 1, 1360, 1376)
        slice_scatter_default_682: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_341, slice_5625, 2, 0, 16);  slice_tensor_341 = slice_5625 = None
        slice_scatter_default_683: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_681, slice_scatter_default_682, 1, 1360, 1376);  slice_scatter_default_681 = slice_scatter_default_682 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5645: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5611, 2, 16, 32);  slice_5611 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_174: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5645, memory_format = torch.contiguous_format);  slice_5645 = None
        view_352: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_174, [32, 11]);  clone_174 = None
        mm_171: "f32[32, 8]" = torch.ops.aten.mm.default(view_352, slice_37)
        view_353: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_171, [2, 16, 8]);  mm_171 = None
        slice_5652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_683, 1, 1360, 1376)
        slice_5653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5652, 2, 0, 16);  slice_5652 = None
        add_173: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5653, view_353);  slice_5653 = view_353 = None
        
        # No stacktrace found for following nodes
        slice_tensor_342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_683, 1, 1360, 1376)
        slice_scatter_default_684: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_342, add_173, 2, 0, 16);  slice_tensor_342 = add_173 = None
        slice_scatter_default_685: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_683, slice_scatter_default_684, 1, 1360, 1376);  slice_scatter_default_683 = slice_scatter_default_684 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_685, 1, 1360, 1376)
        slice_5658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5657, 2, 0, 16);  slice_5657 = None
        
        # No stacktrace found for following nodes
        slice_tensor_343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_685, 1, 1360, 1376)
        slice_scatter_default_686: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_343, slice_5658, 2, 0, 16);  slice_tensor_343 = slice_5658 = None
        slice_scatter_default_687: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_685, slice_scatter_default_686, 1, 1360, 1376);  slice_scatter_default_685 = slice_scatter_default_686 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5677: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1376, 1392)
        slice_5678: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5677, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_175: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5678, memory_format = torch.contiguous_format);  slice_5678 = None
        view_354: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_175, [32, 16]);  clone_175 = None
        mm_172: "f32[32, 8]" = torch.ops.aten.mm.default(view_354, slice_7)
        view_355: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_172, [2, 16, 8]);  mm_172 = None
        slice_5685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_687, 1, 1376, 1392)
        slice_5686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5685, 2, 0, 16);  slice_5685 = None
        add_174: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5686, view_355);  slice_5686 = view_355 = None
        
        # No stacktrace found for following nodes
        slice_tensor_344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_687, 1, 1376, 1392)
        slice_scatter_default_688: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_344, add_174, 2, 0, 16);  slice_tensor_344 = add_174 = None
        slice_scatter_default_689: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_687, slice_scatter_default_688, 1, 1376, 1392);  slice_scatter_default_687 = slice_scatter_default_688 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_689, 1, 1376, 1392)
        slice_5691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5690, 2, 0, 16);  slice_5690 = None
        
        # No stacktrace found for following nodes
        slice_tensor_345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_689, 1, 1376, 1392)
        slice_scatter_default_690: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_345, slice_5691, 2, 0, 16);  slice_tensor_345 = slice_5691 = None
        slice_scatter_default_691: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_689, slice_scatter_default_690, 1, 1376, 1392);  slice_scatter_default_689 = slice_scatter_default_690 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5711: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5677, 2, 16, 32);  slice_5677 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_176: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5711, memory_format = torch.contiguous_format);  slice_5711 = None
        view_356: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_176, [32, 11]);  clone_176 = None
        mm_173: "f32[32, 8]" = torch.ops.aten.mm.default(view_356, slice_37)
        view_357: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_173, [2, 16, 8]);  mm_173 = None
        slice_5718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_691, 1, 1376, 1392)
        slice_5719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5718, 2, 0, 16);  slice_5718 = None
        add_175: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5719, view_357);  slice_5719 = view_357 = None
        
        # No stacktrace found for following nodes
        slice_tensor_346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_691, 1, 1376, 1392)
        slice_scatter_default_692: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_346, add_175, 2, 0, 16);  slice_tensor_346 = add_175 = None
        slice_scatter_default_693: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_691, slice_scatter_default_692, 1, 1376, 1392);  slice_scatter_default_691 = slice_scatter_default_692 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_693, 1, 1376, 1392)
        slice_5724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5723, 2, 0, 16);  slice_5723 = None
        
        # No stacktrace found for following nodes
        slice_tensor_347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_693, 1, 1376, 1392)
        slice_scatter_default_694: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_347, slice_5724, 2, 0, 16);  slice_tensor_347 = slice_5724 = None
        slice_scatter_default_695: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_693, slice_scatter_default_694, 1, 1376, 1392);  slice_scatter_default_693 = slice_scatter_default_694 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5743: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1392, 1408)
        slice_5744: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5743, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_177: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5744, memory_format = torch.contiguous_format);  slice_5744 = None
        view_358: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_177, [32, 16]);  clone_177 = None
        mm_174: "f32[32, 8]" = torch.ops.aten.mm.default(view_358, slice_7)
        view_359: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_174, [2, 16, 8]);  mm_174 = None
        slice_5751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_695, 1, 1392, 1408)
        slice_5752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5751, 2, 0, 16);  slice_5751 = None
        add_176: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5752, view_359);  slice_5752 = view_359 = None
        
        # No stacktrace found for following nodes
        slice_tensor_348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_695, 1, 1392, 1408)
        slice_scatter_default_696: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_348, add_176, 2, 0, 16);  slice_tensor_348 = add_176 = None
        slice_scatter_default_697: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_695, slice_scatter_default_696, 1, 1392, 1408);  slice_scatter_default_695 = slice_scatter_default_696 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_697, 1, 1392, 1408)
        slice_5757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5756, 2, 0, 16);  slice_5756 = None
        
        # No stacktrace found for following nodes
        slice_tensor_349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_697, 1, 1392, 1408)
        slice_scatter_default_698: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_349, slice_5757, 2, 0, 16);  slice_tensor_349 = slice_5757 = None
        slice_scatter_default_699: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_697, slice_scatter_default_698, 1, 1392, 1408);  slice_scatter_default_697 = slice_scatter_default_698 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5777: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5743, 2, 16, 32);  slice_5743 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_178: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5777, memory_format = torch.contiguous_format);  slice_5777 = None
        view_360: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_178, [32, 11]);  clone_178 = None
        mm_175: "f32[32, 8]" = torch.ops.aten.mm.default(view_360, slice_37)
        view_361: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_175, [2, 16, 8]);  mm_175 = None
        slice_5784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_699, 1, 1392, 1408)
        slice_5785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5784, 2, 0, 16);  slice_5784 = None
        add_177: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5785, view_361);  slice_5785 = view_361 = None
        
        # No stacktrace found for following nodes
        slice_tensor_350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_699, 1, 1392, 1408)
        slice_scatter_default_700: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_350, add_177, 2, 0, 16);  slice_tensor_350 = add_177 = None
        slice_scatter_default_701: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_699, slice_scatter_default_700, 1, 1392, 1408);  slice_scatter_default_699 = slice_scatter_default_700 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_701, 1, 1392, 1408)
        slice_5790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5789, 2, 0, 16);  slice_5789 = None
        
        # No stacktrace found for following nodes
        slice_tensor_351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_701, 1, 1392, 1408)
        slice_scatter_default_702: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_351, slice_5790, 2, 0, 16);  slice_tensor_351 = slice_5790 = None
        slice_scatter_default_703: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_701, slice_scatter_default_702, 1, 1392, 1408);  slice_scatter_default_701 = slice_scatter_default_702 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5809: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1408, 1424)
        slice_5810: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5809, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_179: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5810, memory_format = torch.contiguous_format);  slice_5810 = None
        view_362: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_179, [32, 16]);  clone_179 = None
        mm_176: "f32[32, 8]" = torch.ops.aten.mm.default(view_362, slice_7)
        view_363: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_176, [2, 16, 8]);  mm_176 = None
        slice_5817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_703, 1, 1408, 1424)
        slice_5818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5817, 2, 0, 16);  slice_5817 = None
        add_178: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5818, view_363);  slice_5818 = view_363 = None
        
        # No stacktrace found for following nodes
        slice_tensor_352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_703, 1, 1408, 1424)
        slice_scatter_default_704: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_352, add_178, 2, 0, 16);  slice_tensor_352 = add_178 = None
        slice_scatter_default_705: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_703, slice_scatter_default_704, 1, 1408, 1424);  slice_scatter_default_703 = slice_scatter_default_704 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_705, 1, 1408, 1424)
        slice_5823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5822, 2, 0, 16);  slice_5822 = None
        
        # No stacktrace found for following nodes
        slice_tensor_353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_705, 1, 1408, 1424)
        slice_scatter_default_706: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_353, slice_5823, 2, 0, 16);  slice_tensor_353 = slice_5823 = None
        slice_scatter_default_707: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_705, slice_scatter_default_706, 1, 1408, 1424);  slice_scatter_default_705 = slice_scatter_default_706 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5843: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5809, 2, 16, 32);  slice_5809 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_180: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5843, memory_format = torch.contiguous_format);  slice_5843 = None
        view_364: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_180, [32, 11]);  clone_180 = None
        mm_177: "f32[32, 8]" = torch.ops.aten.mm.default(view_364, slice_37)
        view_365: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_177, [2, 16, 8]);  mm_177 = None
        slice_5850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_707, 1, 1408, 1424)
        slice_5851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5850, 2, 0, 16);  slice_5850 = None
        add_179: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5851, view_365);  slice_5851 = view_365 = None
        
        # No stacktrace found for following nodes
        slice_tensor_354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_707, 1, 1408, 1424)
        slice_scatter_default_708: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_354, add_179, 2, 0, 16);  slice_tensor_354 = add_179 = None
        slice_scatter_default_709: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_707, slice_scatter_default_708, 1, 1408, 1424);  slice_scatter_default_707 = slice_scatter_default_708 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_709, 1, 1408, 1424)
        slice_5856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5855, 2, 0, 16);  slice_5855 = None
        
        # No stacktrace found for following nodes
        slice_tensor_355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_709, 1, 1408, 1424)
        slice_scatter_default_710: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_355, slice_5856, 2, 0, 16);  slice_tensor_355 = slice_5856 = None
        slice_scatter_default_711: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_709, slice_scatter_default_710, 1, 1408, 1424);  slice_scatter_default_709 = slice_scatter_default_710 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5875: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1424, 1440)
        slice_5876: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5875, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_181: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5876, memory_format = torch.contiguous_format);  slice_5876 = None
        view_366: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_181, [32, 16]);  clone_181 = None
        mm_178: "f32[32, 8]" = torch.ops.aten.mm.default(view_366, slice_7)
        view_367: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_178, [2, 16, 8]);  mm_178 = None
        slice_5883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_711, 1, 1424, 1440)
        slice_5884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5883, 2, 0, 16);  slice_5883 = None
        add_180: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5884, view_367);  slice_5884 = view_367 = None
        
        # No stacktrace found for following nodes
        slice_tensor_356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_711, 1, 1424, 1440)
        slice_scatter_default_712: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_356, add_180, 2, 0, 16);  slice_tensor_356 = add_180 = None
        slice_scatter_default_713: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_711, slice_scatter_default_712, 1, 1424, 1440);  slice_scatter_default_711 = slice_scatter_default_712 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_713, 1, 1424, 1440)
        slice_5889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5888, 2, 0, 16);  slice_5888 = None
        
        # No stacktrace found for following nodes
        slice_tensor_357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_713, 1, 1424, 1440)
        slice_scatter_default_714: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_357, slice_5889, 2, 0, 16);  slice_tensor_357 = slice_5889 = None
        slice_scatter_default_715: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_713, slice_scatter_default_714, 1, 1424, 1440);  slice_scatter_default_713 = slice_scatter_default_714 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5909: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5875, 2, 16, 32);  slice_5875 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_182: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5909, memory_format = torch.contiguous_format);  slice_5909 = None
        view_368: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_182, [32, 11]);  clone_182 = None
        mm_179: "f32[32, 8]" = torch.ops.aten.mm.default(view_368, slice_37)
        view_369: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_179, [2, 16, 8]);  mm_179 = None
        slice_5916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_715, 1, 1424, 1440)
        slice_5917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5916, 2, 0, 16);  slice_5916 = None
        add_181: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5917, view_369);  slice_5917 = view_369 = None
        
        # No stacktrace found for following nodes
        slice_tensor_358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_715, 1, 1424, 1440)
        slice_scatter_default_716: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_358, add_181, 2, 0, 16);  slice_tensor_358 = add_181 = None
        slice_scatter_default_717: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_715, slice_scatter_default_716, 1, 1424, 1440);  slice_scatter_default_715 = slice_scatter_default_716 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_717, 1, 1424, 1440)
        slice_5922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5921, 2, 0, 16);  slice_5921 = None
        
        # No stacktrace found for following nodes
        slice_tensor_359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_717, 1, 1424, 1440)
        slice_scatter_default_718: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_359, slice_5922, 2, 0, 16);  slice_tensor_359 = slice_5922 = None
        slice_scatter_default_719: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_717, slice_scatter_default_718, 1, 1424, 1440);  slice_scatter_default_717 = slice_scatter_default_718 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5941: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1440, 1456)
        slice_5942: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_5941, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_183: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_5942, memory_format = torch.contiguous_format);  slice_5942 = None
        view_370: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_183, [32, 16]);  clone_183 = None
        mm_180: "f32[32, 8]" = torch.ops.aten.mm.default(view_370, slice_7)
        view_371: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_180, [2, 16, 8]);  mm_180 = None
        slice_5949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_719, 1, 1440, 1456)
        slice_5950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5949, 2, 0, 16);  slice_5949 = None
        add_182: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5950, view_371);  slice_5950 = view_371 = None
        
        # No stacktrace found for following nodes
        slice_tensor_360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_719, 1, 1440, 1456)
        slice_scatter_default_720: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_360, add_182, 2, 0, 16);  slice_tensor_360 = add_182 = None
        slice_scatter_default_721: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_719, slice_scatter_default_720, 1, 1440, 1456);  slice_scatter_default_719 = slice_scatter_default_720 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_721, 1, 1440, 1456)
        slice_5955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5954, 2, 0, 16);  slice_5954 = None
        
        # No stacktrace found for following nodes
        slice_tensor_361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_721, 1, 1440, 1456)
        slice_scatter_default_722: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_361, slice_5955, 2, 0, 16);  slice_tensor_361 = slice_5955 = None
        slice_scatter_default_723: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_721, slice_scatter_default_722, 1, 1440, 1456);  slice_scatter_default_721 = slice_scatter_default_722 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_5975: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_5941, 2, 16, 32);  slice_5941 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_184: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_5975, memory_format = torch.contiguous_format);  slice_5975 = None
        view_372: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_184, [32, 11]);  clone_184 = None
        mm_181: "f32[32, 8]" = torch.ops.aten.mm.default(view_372, slice_37)
        view_373: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_181, [2, 16, 8]);  mm_181 = None
        slice_5982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_723, 1, 1440, 1456)
        slice_5983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5982, 2, 0, 16);  slice_5982 = None
        add_183: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_5983, view_373);  slice_5983 = view_373 = None
        
        # No stacktrace found for following nodes
        slice_tensor_362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_723, 1, 1440, 1456)
        slice_scatter_default_724: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_362, add_183, 2, 0, 16);  slice_tensor_362 = add_183 = None
        slice_scatter_default_725: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_723, slice_scatter_default_724, 1, 1440, 1456);  slice_scatter_default_723 = slice_scatter_default_724 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_5987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_725, 1, 1440, 1456)
        slice_5988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_5987, 2, 0, 16);  slice_5987 = None
        
        # No stacktrace found for following nodes
        slice_tensor_363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_725, 1, 1440, 1456)
        slice_scatter_default_726: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_363, slice_5988, 2, 0, 16);  slice_tensor_363 = slice_5988 = None
        slice_scatter_default_727: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_725, slice_scatter_default_726, 1, 1440, 1456);  slice_scatter_default_725 = slice_scatter_default_726 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6007: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1456, 1472)
        slice_6008: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6007, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_185: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6008, memory_format = torch.contiguous_format);  slice_6008 = None
        view_374: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_185, [32, 16]);  clone_185 = None
        mm_182: "f32[32, 8]" = torch.ops.aten.mm.default(view_374, slice_7)
        view_375: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_182, [2, 16, 8]);  mm_182 = None
        slice_6015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_727, 1, 1456, 1472)
        slice_6016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6015, 2, 0, 16);  slice_6015 = None
        add_184: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6016, view_375);  slice_6016 = view_375 = None
        
        # No stacktrace found for following nodes
        slice_tensor_364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_727, 1, 1456, 1472)
        slice_scatter_default_728: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_364, add_184, 2, 0, 16);  slice_tensor_364 = add_184 = None
        slice_scatter_default_729: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_727, slice_scatter_default_728, 1, 1456, 1472);  slice_scatter_default_727 = slice_scatter_default_728 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_729, 1, 1456, 1472)
        slice_6021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6020, 2, 0, 16);  slice_6020 = None
        
        # No stacktrace found for following nodes
        slice_tensor_365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_729, 1, 1456, 1472)
        slice_scatter_default_730: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_365, slice_6021, 2, 0, 16);  slice_tensor_365 = slice_6021 = None
        slice_scatter_default_731: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_729, slice_scatter_default_730, 1, 1456, 1472);  slice_scatter_default_729 = slice_scatter_default_730 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6041: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6007, 2, 16, 32);  slice_6007 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_186: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6041, memory_format = torch.contiguous_format);  slice_6041 = None
        view_376: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_186, [32, 11]);  clone_186 = None
        mm_183: "f32[32, 8]" = torch.ops.aten.mm.default(view_376, slice_37)
        view_377: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_183, [2, 16, 8]);  mm_183 = None
        slice_6048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_731, 1, 1456, 1472)
        slice_6049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6048, 2, 0, 16);  slice_6048 = None
        add_185: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6049, view_377);  slice_6049 = view_377 = None
        
        # No stacktrace found for following nodes
        slice_tensor_366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_731, 1, 1456, 1472)
        slice_scatter_default_732: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_366, add_185, 2, 0, 16);  slice_tensor_366 = add_185 = None
        slice_scatter_default_733: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_731, slice_scatter_default_732, 1, 1456, 1472);  slice_scatter_default_731 = slice_scatter_default_732 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_733, 1, 1456, 1472)
        slice_6054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6053, 2, 0, 16);  slice_6053 = None
        
        # No stacktrace found for following nodes
        slice_tensor_367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_733, 1, 1456, 1472)
        slice_scatter_default_734: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_367, slice_6054, 2, 0, 16);  slice_tensor_367 = slice_6054 = None
        slice_scatter_default_735: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_733, slice_scatter_default_734, 1, 1456, 1472);  slice_scatter_default_733 = slice_scatter_default_734 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6073: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1472, 1488)
        slice_6074: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6073, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_187: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6074, memory_format = torch.contiguous_format);  slice_6074 = None
        view_378: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_187, [32, 16]);  clone_187 = None
        mm_184: "f32[32, 8]" = torch.ops.aten.mm.default(view_378, slice_7)
        view_379: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_184, [2, 16, 8]);  mm_184 = None
        slice_6081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_735, 1, 1472, 1488)
        slice_6082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6081, 2, 0, 16);  slice_6081 = None
        add_186: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6082, view_379);  slice_6082 = view_379 = None
        
        # No stacktrace found for following nodes
        slice_tensor_368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_735, 1, 1472, 1488)
        slice_scatter_default_736: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_368, add_186, 2, 0, 16);  slice_tensor_368 = add_186 = None
        slice_scatter_default_737: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_735, slice_scatter_default_736, 1, 1472, 1488);  slice_scatter_default_735 = slice_scatter_default_736 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_737, 1, 1472, 1488)
        slice_6087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6086, 2, 0, 16);  slice_6086 = None
        
        # No stacktrace found for following nodes
        slice_tensor_369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_737, 1, 1472, 1488)
        slice_scatter_default_738: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_369, slice_6087, 2, 0, 16);  slice_tensor_369 = slice_6087 = None
        slice_scatter_default_739: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_737, slice_scatter_default_738, 1, 1472, 1488);  slice_scatter_default_737 = slice_scatter_default_738 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6107: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6073, 2, 16, 32);  slice_6073 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_188: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6107, memory_format = torch.contiguous_format);  slice_6107 = None
        view_380: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_188, [32, 11]);  clone_188 = None
        mm_185: "f32[32, 8]" = torch.ops.aten.mm.default(view_380, slice_37)
        view_381: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_185, [2, 16, 8]);  mm_185 = None
        slice_6114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_739, 1, 1472, 1488)
        slice_6115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6114, 2, 0, 16);  slice_6114 = None
        add_187: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6115, view_381);  slice_6115 = view_381 = None
        
        # No stacktrace found for following nodes
        slice_tensor_370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_739, 1, 1472, 1488)
        slice_scatter_default_740: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_370, add_187, 2, 0, 16);  slice_tensor_370 = add_187 = None
        slice_scatter_default_741: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_739, slice_scatter_default_740, 1, 1472, 1488);  slice_scatter_default_739 = slice_scatter_default_740 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_741, 1, 1472, 1488)
        slice_6120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6119, 2, 0, 16);  slice_6119 = None
        
        # No stacktrace found for following nodes
        slice_tensor_371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_741, 1, 1472, 1488)
        slice_scatter_default_742: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_371, slice_6120, 2, 0, 16);  slice_tensor_371 = slice_6120 = None
        slice_scatter_default_743: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_741, slice_scatter_default_742, 1, 1472, 1488);  slice_scatter_default_741 = slice_scatter_default_742 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6139: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1488, 1504)
        slice_6140: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6139, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_189: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6140, memory_format = torch.contiguous_format);  slice_6140 = None
        view_382: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_189, [32, 16]);  clone_189 = None
        mm_186: "f32[32, 8]" = torch.ops.aten.mm.default(view_382, slice_7)
        view_383: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_186, [2, 16, 8]);  mm_186 = None
        slice_6147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_743, 1, 1488, 1504)
        slice_6148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6147, 2, 0, 16);  slice_6147 = None
        add_188: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6148, view_383);  slice_6148 = view_383 = None
        
        # No stacktrace found for following nodes
        slice_tensor_372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_743, 1, 1488, 1504)
        slice_scatter_default_744: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_372, add_188, 2, 0, 16);  slice_tensor_372 = add_188 = None
        slice_scatter_default_745: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_743, slice_scatter_default_744, 1, 1488, 1504);  slice_scatter_default_743 = slice_scatter_default_744 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_745, 1, 1488, 1504)
        slice_6153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6152, 2, 0, 16);  slice_6152 = None
        
        # No stacktrace found for following nodes
        slice_tensor_373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_745, 1, 1488, 1504)
        slice_scatter_default_746: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_373, slice_6153, 2, 0, 16);  slice_tensor_373 = slice_6153 = None
        slice_scatter_default_747: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_745, slice_scatter_default_746, 1, 1488, 1504);  slice_scatter_default_745 = slice_scatter_default_746 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6173: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6139, 2, 16, 32);  slice_6139 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_190: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6173, memory_format = torch.contiguous_format);  slice_6173 = None
        view_384: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_190, [32, 11]);  clone_190 = None
        mm_187: "f32[32, 8]" = torch.ops.aten.mm.default(view_384, slice_37)
        view_385: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_187, [2, 16, 8]);  mm_187 = None
        slice_6180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_747, 1, 1488, 1504)
        slice_6181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6180, 2, 0, 16);  slice_6180 = None
        add_189: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6181, view_385);  slice_6181 = view_385 = None
        
        # No stacktrace found for following nodes
        slice_tensor_374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_747, 1, 1488, 1504)
        slice_scatter_default_748: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_374, add_189, 2, 0, 16);  slice_tensor_374 = add_189 = None
        slice_scatter_default_749: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_747, slice_scatter_default_748, 1, 1488, 1504);  slice_scatter_default_747 = slice_scatter_default_748 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_749, 1, 1488, 1504)
        slice_6186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6185, 2, 0, 16);  slice_6185 = None
        
        # No stacktrace found for following nodes
        slice_tensor_375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_749, 1, 1488, 1504)
        slice_scatter_default_750: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_375, slice_6186, 2, 0, 16);  slice_tensor_375 = slice_6186 = None
        slice_scatter_default_751: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_749, slice_scatter_default_750, 1, 1488, 1504);  slice_scatter_default_749 = slice_scatter_default_750 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6205: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1504, 1520)
        slice_6206: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6205, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_191: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6206, memory_format = torch.contiguous_format);  slice_6206 = None
        view_386: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_191, [32, 16]);  clone_191 = None
        mm_188: "f32[32, 8]" = torch.ops.aten.mm.default(view_386, slice_7)
        view_387: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_188, [2, 16, 8]);  mm_188 = None
        slice_6213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_751, 1, 1504, 1520)
        slice_6214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6213, 2, 0, 16);  slice_6213 = None
        add_190: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6214, view_387);  slice_6214 = view_387 = None
        
        # No stacktrace found for following nodes
        slice_tensor_376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_751, 1, 1504, 1520)
        slice_scatter_default_752: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_376, add_190, 2, 0, 16);  slice_tensor_376 = add_190 = None
        slice_scatter_default_753: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_751, slice_scatter_default_752, 1, 1504, 1520);  slice_scatter_default_751 = slice_scatter_default_752 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_753, 1, 1504, 1520)
        slice_6219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6218, 2, 0, 16);  slice_6218 = None
        
        # No stacktrace found for following nodes
        slice_tensor_377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_753, 1, 1504, 1520)
        slice_scatter_default_754: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_377, slice_6219, 2, 0, 16);  slice_tensor_377 = slice_6219 = None
        slice_scatter_default_755: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_753, slice_scatter_default_754, 1, 1504, 1520);  slice_scatter_default_753 = slice_scatter_default_754 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6239: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6205, 2, 16, 32);  slice_6205 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_192: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6239, memory_format = torch.contiguous_format);  slice_6239 = None
        view_388: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_192, [32, 11]);  clone_192 = None
        mm_189: "f32[32, 8]" = torch.ops.aten.mm.default(view_388, slice_37)
        view_389: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_189, [2, 16, 8]);  mm_189 = None
        slice_6246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_755, 1, 1504, 1520)
        slice_6247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6246, 2, 0, 16);  slice_6246 = None
        add_191: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6247, view_389);  slice_6247 = view_389 = None
        
        # No stacktrace found for following nodes
        slice_tensor_378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_755, 1, 1504, 1520)
        slice_scatter_default_756: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_378, add_191, 2, 0, 16);  slice_tensor_378 = add_191 = None
        slice_scatter_default_757: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_755, slice_scatter_default_756, 1, 1504, 1520);  slice_scatter_default_755 = slice_scatter_default_756 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_757, 1, 1504, 1520)
        slice_6252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6251, 2, 0, 16);  slice_6251 = None
        
        # No stacktrace found for following nodes
        slice_tensor_379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_757, 1, 1504, 1520)
        slice_scatter_default_758: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_379, slice_6252, 2, 0, 16);  slice_tensor_379 = slice_6252 = None
        slice_scatter_default_759: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_757, slice_scatter_default_758, 1, 1504, 1520);  slice_scatter_default_757 = slice_scatter_default_758 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6271: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1520, 1536)
        slice_6272: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6271, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_193: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6272, memory_format = torch.contiguous_format);  slice_6272 = None
        view_390: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_193, [32, 16]);  clone_193 = None
        mm_190: "f32[32, 8]" = torch.ops.aten.mm.default(view_390, slice_7)
        view_391: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_190, [2, 16, 8]);  mm_190 = None
        slice_6279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_759, 1, 1520, 1536)
        slice_6280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6279, 2, 0, 16);  slice_6279 = None
        add_192: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6280, view_391);  slice_6280 = view_391 = None
        
        # No stacktrace found for following nodes
        slice_tensor_380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_759, 1, 1520, 1536)
        slice_scatter_default_760: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_380, add_192, 2, 0, 16);  slice_tensor_380 = add_192 = None
        slice_scatter_default_761: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_759, slice_scatter_default_760, 1, 1520, 1536);  slice_scatter_default_759 = slice_scatter_default_760 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_761, 1, 1520, 1536)
        slice_6285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6284, 2, 0, 16);  slice_6284 = None
        
        # No stacktrace found for following nodes
        slice_tensor_381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_761, 1, 1520, 1536)
        slice_scatter_default_762: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_381, slice_6285, 2, 0, 16);  slice_tensor_381 = slice_6285 = None
        slice_scatter_default_763: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_761, slice_scatter_default_762, 1, 1520, 1536);  slice_scatter_default_761 = slice_scatter_default_762 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6305: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6271, 2, 16, 32);  slice_6271 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_194: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6305, memory_format = torch.contiguous_format);  slice_6305 = None
        view_392: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_194, [32, 11]);  clone_194 = None
        mm_191: "f32[32, 8]" = torch.ops.aten.mm.default(view_392, slice_37)
        view_393: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_191, [2, 16, 8]);  mm_191 = None
        slice_6312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_763, 1, 1520, 1536)
        slice_6313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6312, 2, 0, 16);  slice_6312 = None
        add_193: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6313, view_393);  slice_6313 = view_393 = None
        
        # No stacktrace found for following nodes
        slice_tensor_382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_763, 1, 1520, 1536)
        slice_scatter_default_764: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_382, add_193, 2, 0, 16);  slice_tensor_382 = add_193 = None
        slice_scatter_default_765: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_763, slice_scatter_default_764, 1, 1520, 1536);  slice_scatter_default_763 = slice_scatter_default_764 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_765, 1, 1520, 1536)
        slice_6318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6317, 2, 0, 16);  slice_6317 = None
        
        # No stacktrace found for following nodes
        slice_tensor_383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_765, 1, 1520, 1536)
        slice_scatter_default_766: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_383, slice_6318, 2, 0, 16);  slice_tensor_383 = slice_6318 = None
        slice_scatter_default_767: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_765, slice_scatter_default_766, 1, 1520, 1536);  slice_scatter_default_765 = slice_scatter_default_766 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6337: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1536, 1552)
        slice_6338: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6337, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_195: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6338, memory_format = torch.contiguous_format);  slice_6338 = None
        view_394: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_195, [32, 16]);  clone_195 = None
        mm_192: "f32[32, 8]" = torch.ops.aten.mm.default(view_394, slice_7)
        view_395: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_192, [2, 16, 8]);  mm_192 = None
        slice_6345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_767, 1, 1536, 1552)
        slice_6346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6345, 2, 0, 16);  slice_6345 = None
        add_194: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6346, view_395);  slice_6346 = view_395 = None
        
        # No stacktrace found for following nodes
        slice_tensor_384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_767, 1, 1536, 1552)
        slice_scatter_default_768: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_384, add_194, 2, 0, 16);  slice_tensor_384 = add_194 = None
        slice_scatter_default_769: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_767, slice_scatter_default_768, 1, 1536, 1552);  slice_scatter_default_767 = slice_scatter_default_768 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_769, 1, 1536, 1552)
        slice_6351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6350, 2, 0, 16);  slice_6350 = None
        
        # No stacktrace found for following nodes
        slice_tensor_385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_769, 1, 1536, 1552)
        slice_scatter_default_770: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_385, slice_6351, 2, 0, 16);  slice_tensor_385 = slice_6351 = None
        slice_scatter_default_771: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_769, slice_scatter_default_770, 1, 1536, 1552);  slice_scatter_default_769 = slice_scatter_default_770 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6371: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6337, 2, 16, 32);  slice_6337 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_196: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6371, memory_format = torch.contiguous_format);  slice_6371 = None
        view_396: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_196, [32, 11]);  clone_196 = None
        mm_193: "f32[32, 8]" = torch.ops.aten.mm.default(view_396, slice_37)
        view_397: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_193, [2, 16, 8]);  mm_193 = None
        slice_6378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_771, 1, 1536, 1552)
        slice_6379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6378, 2, 0, 16);  slice_6378 = None
        add_195: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6379, view_397);  slice_6379 = view_397 = None
        
        # No stacktrace found for following nodes
        slice_tensor_386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_771, 1, 1536, 1552)
        slice_scatter_default_772: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_386, add_195, 2, 0, 16);  slice_tensor_386 = add_195 = None
        slice_scatter_default_773: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_771, slice_scatter_default_772, 1, 1536, 1552);  slice_scatter_default_771 = slice_scatter_default_772 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_773, 1, 1536, 1552)
        slice_6384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6383, 2, 0, 16);  slice_6383 = None
        
        # No stacktrace found for following nodes
        slice_tensor_387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_773, 1, 1536, 1552)
        slice_scatter_default_774: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_387, slice_6384, 2, 0, 16);  slice_tensor_387 = slice_6384 = None
        slice_scatter_default_775: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_773, slice_scatter_default_774, 1, 1536, 1552);  slice_scatter_default_773 = slice_scatter_default_774 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6403: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1552, 1568)
        slice_6404: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6403, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_197: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6404, memory_format = torch.contiguous_format);  slice_6404 = None
        view_398: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_197, [32, 16]);  clone_197 = None
        mm_194: "f32[32, 8]" = torch.ops.aten.mm.default(view_398, slice_7)
        view_399: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_194, [2, 16, 8]);  mm_194 = None
        slice_6411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_775, 1, 1552, 1568)
        slice_6412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6411, 2, 0, 16);  slice_6411 = None
        add_196: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6412, view_399);  slice_6412 = view_399 = None
        
        # No stacktrace found for following nodes
        slice_tensor_388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_775, 1, 1552, 1568)
        slice_scatter_default_776: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_388, add_196, 2, 0, 16);  slice_tensor_388 = add_196 = None
        slice_scatter_default_777: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_775, slice_scatter_default_776, 1, 1552, 1568);  slice_scatter_default_775 = slice_scatter_default_776 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_777, 1, 1552, 1568)
        slice_6417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6416, 2, 0, 16);  slice_6416 = None
        
        # No stacktrace found for following nodes
        slice_tensor_389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_777, 1, 1552, 1568)
        slice_scatter_default_778: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_389, slice_6417, 2, 0, 16);  slice_tensor_389 = slice_6417 = None
        slice_scatter_default_779: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_777, slice_scatter_default_778, 1, 1552, 1568);  slice_scatter_default_777 = slice_scatter_default_778 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6437: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6403, 2, 16, 32);  slice_6403 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_198: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6437, memory_format = torch.contiguous_format);  slice_6437 = None
        view_400: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_198, [32, 11]);  clone_198 = None
        mm_195: "f32[32, 8]" = torch.ops.aten.mm.default(view_400, slice_37)
        view_401: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_195, [2, 16, 8]);  mm_195 = None
        slice_6444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_779, 1, 1552, 1568)
        slice_6445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6444, 2, 0, 16);  slice_6444 = None
        add_197: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6445, view_401);  slice_6445 = view_401 = None
        
        # No stacktrace found for following nodes
        slice_tensor_390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_779, 1, 1552, 1568)
        slice_scatter_default_780: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_390, add_197, 2, 0, 16);  slice_tensor_390 = add_197 = None
        slice_scatter_default_781: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_779, slice_scatter_default_780, 1, 1552, 1568);  slice_scatter_default_779 = slice_scatter_default_780 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_781, 1, 1552, 1568)
        slice_6450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6449, 2, 0, 16);  slice_6449 = None
        
        # No stacktrace found for following nodes
        slice_tensor_391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_781, 1, 1552, 1568)
        slice_scatter_default_782: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_391, slice_6450, 2, 0, 16);  slice_tensor_391 = slice_6450 = None
        slice_scatter_default_783: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_781, slice_scatter_default_782, 1, 1552, 1568);  slice_scatter_default_781 = slice_scatter_default_782 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6469: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1568, 1584)
        slice_6470: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6469, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_199: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6470, memory_format = torch.contiguous_format);  slice_6470 = None
        view_402: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_199, [32, 16]);  clone_199 = None
        mm_196: "f32[32, 8]" = torch.ops.aten.mm.default(view_402, slice_7)
        view_403: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_196, [2, 16, 8]);  mm_196 = None
        slice_6477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_783, 1, 1568, 1584)
        slice_6478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6477, 2, 0, 16);  slice_6477 = None
        add_198: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6478, view_403);  slice_6478 = view_403 = None
        
        # No stacktrace found for following nodes
        slice_tensor_392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_783, 1, 1568, 1584)
        slice_scatter_default_784: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_392, add_198, 2, 0, 16);  slice_tensor_392 = add_198 = None
        slice_scatter_default_785: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_783, slice_scatter_default_784, 1, 1568, 1584);  slice_scatter_default_783 = slice_scatter_default_784 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_785, 1, 1568, 1584)
        slice_6483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6482, 2, 0, 16);  slice_6482 = None
        
        # No stacktrace found for following nodes
        slice_tensor_393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_785, 1, 1568, 1584)
        slice_scatter_default_786: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_393, slice_6483, 2, 0, 16);  slice_tensor_393 = slice_6483 = None
        slice_scatter_default_787: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_785, slice_scatter_default_786, 1, 1568, 1584);  slice_scatter_default_785 = slice_scatter_default_786 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6503: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6469, 2, 16, 32);  slice_6469 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_200: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6503, memory_format = torch.contiguous_format);  slice_6503 = None
        view_404: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_200, [32, 11]);  clone_200 = None
        mm_197: "f32[32, 8]" = torch.ops.aten.mm.default(view_404, slice_37)
        view_405: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_197, [2, 16, 8]);  mm_197 = None
        slice_6510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_787, 1, 1568, 1584)
        slice_6511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6510, 2, 0, 16);  slice_6510 = None
        add_199: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6511, view_405);  slice_6511 = view_405 = None
        
        # No stacktrace found for following nodes
        slice_tensor_394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_787, 1, 1568, 1584)
        slice_scatter_default_788: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_394, add_199, 2, 0, 16);  slice_tensor_394 = add_199 = None
        slice_scatter_default_789: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_787, slice_scatter_default_788, 1, 1568, 1584);  slice_scatter_default_787 = slice_scatter_default_788 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_789, 1, 1568, 1584)
        slice_6516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6515, 2, 0, 16);  slice_6515 = None
        
        # No stacktrace found for following nodes
        slice_tensor_395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_789, 1, 1568, 1584)
        slice_scatter_default_790: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_395, slice_6516, 2, 0, 16);  slice_tensor_395 = slice_6516 = None
        slice_scatter_default_791: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_789, slice_scatter_default_790, 1, 1568, 1584);  slice_scatter_default_789 = slice_scatter_default_790 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6535: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1584, 1600)
        slice_6536: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6535, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_201: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6536, memory_format = torch.contiguous_format);  slice_6536 = None
        view_406: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_201, [32, 16]);  clone_201 = None
        mm_198: "f32[32, 8]" = torch.ops.aten.mm.default(view_406, slice_7)
        view_407: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_198, [2, 16, 8]);  mm_198 = None
        slice_6543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_791, 1, 1584, 1600)
        slice_6544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6543, 2, 0, 16);  slice_6543 = None
        add_200: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6544, view_407);  slice_6544 = view_407 = None
        
        # No stacktrace found for following nodes
        slice_tensor_396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_791, 1, 1584, 1600)
        slice_scatter_default_792: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_396, add_200, 2, 0, 16);  slice_tensor_396 = add_200 = None
        slice_scatter_default_793: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_791, slice_scatter_default_792, 1, 1584, 1600);  slice_scatter_default_791 = slice_scatter_default_792 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_793, 1, 1584, 1600)
        slice_6549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6548, 2, 0, 16);  slice_6548 = None
        
        # No stacktrace found for following nodes
        slice_tensor_397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_793, 1, 1584, 1600)
        slice_scatter_default_794: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_397, slice_6549, 2, 0, 16);  slice_tensor_397 = slice_6549 = None
        slice_scatter_default_795: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_793, slice_scatter_default_794, 1, 1584, 1600);  slice_scatter_default_793 = slice_scatter_default_794 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6569: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6535, 2, 16, 32);  slice_6535 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_202: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6569, memory_format = torch.contiguous_format);  slice_6569 = None
        view_408: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_202, [32, 11]);  clone_202 = None
        mm_199: "f32[32, 8]" = torch.ops.aten.mm.default(view_408, slice_37)
        view_409: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_199, [2, 16, 8]);  mm_199 = None
        slice_6576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_795, 1, 1584, 1600)
        slice_6577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6576, 2, 0, 16);  slice_6576 = None
        add_201: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6577, view_409);  slice_6577 = view_409 = None
        
        # No stacktrace found for following nodes
        slice_tensor_398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_795, 1, 1584, 1600)
        slice_scatter_default_796: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_398, add_201, 2, 0, 16);  slice_tensor_398 = add_201 = None
        slice_scatter_default_797: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_795, slice_scatter_default_796, 1, 1584, 1600);  slice_scatter_default_795 = slice_scatter_default_796 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_797, 1, 1584, 1600)
        slice_6582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6581, 2, 0, 16);  slice_6581 = None
        
        # No stacktrace found for following nodes
        slice_tensor_399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_797, 1, 1584, 1600)
        slice_scatter_default_798: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_399, slice_6582, 2, 0, 16);  slice_tensor_399 = slice_6582 = None
        slice_scatter_default_799: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_797, slice_scatter_default_798, 1, 1584, 1600);  slice_scatter_default_797 = slice_scatter_default_798 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6601: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1600, 1616)
        slice_6602: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6601, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_203: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6602, memory_format = torch.contiguous_format);  slice_6602 = None
        view_410: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_203, [32, 16]);  clone_203 = None
        mm_200: "f32[32, 8]" = torch.ops.aten.mm.default(view_410, slice_7)
        view_411: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_200, [2, 16, 8]);  mm_200 = None
        slice_6609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_799, 1, 1600, 1616)
        slice_6610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6609, 2, 0, 16);  slice_6609 = None
        add_202: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6610, view_411);  slice_6610 = view_411 = None
        
        # No stacktrace found for following nodes
        slice_tensor_400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_799, 1, 1600, 1616)
        slice_scatter_default_800: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_400, add_202, 2, 0, 16);  slice_tensor_400 = add_202 = None
        slice_scatter_default_801: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_799, slice_scatter_default_800, 1, 1600, 1616);  slice_scatter_default_799 = slice_scatter_default_800 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_801, 1, 1600, 1616)
        slice_6615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6614, 2, 0, 16);  slice_6614 = None
        
        # No stacktrace found for following nodes
        slice_tensor_401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_801, 1, 1600, 1616)
        slice_scatter_default_802: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_401, slice_6615, 2, 0, 16);  slice_tensor_401 = slice_6615 = None
        slice_scatter_default_803: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_801, slice_scatter_default_802, 1, 1600, 1616);  slice_scatter_default_801 = slice_scatter_default_802 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6635: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6601, 2, 16, 32);  slice_6601 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_204: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6635, memory_format = torch.contiguous_format);  slice_6635 = None
        view_412: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_204, [32, 11]);  clone_204 = None
        mm_201: "f32[32, 8]" = torch.ops.aten.mm.default(view_412, slice_37)
        view_413: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_201, [2, 16, 8]);  mm_201 = None
        slice_6642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_803, 1, 1600, 1616)
        slice_6643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6642, 2, 0, 16);  slice_6642 = None
        add_203: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6643, view_413);  slice_6643 = view_413 = None
        
        # No stacktrace found for following nodes
        slice_tensor_402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_803, 1, 1600, 1616)
        slice_scatter_default_804: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_402, add_203, 2, 0, 16);  slice_tensor_402 = add_203 = None
        slice_scatter_default_805: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_803, slice_scatter_default_804, 1, 1600, 1616);  slice_scatter_default_803 = slice_scatter_default_804 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_805, 1, 1600, 1616)
        slice_6648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6647, 2, 0, 16);  slice_6647 = None
        
        # No stacktrace found for following nodes
        slice_tensor_403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_805, 1, 1600, 1616)
        slice_scatter_default_806: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_403, slice_6648, 2, 0, 16);  slice_tensor_403 = slice_6648 = None
        slice_scatter_default_807: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_805, slice_scatter_default_806, 1, 1600, 1616);  slice_scatter_default_805 = slice_scatter_default_806 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6667: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1616, 1632)
        slice_6668: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6667, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_205: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6668, memory_format = torch.contiguous_format);  slice_6668 = None
        view_414: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_205, [32, 16]);  clone_205 = None
        mm_202: "f32[32, 8]" = torch.ops.aten.mm.default(view_414, slice_7)
        view_415: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_202, [2, 16, 8]);  mm_202 = None
        slice_6675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_807, 1, 1616, 1632)
        slice_6676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6675, 2, 0, 16);  slice_6675 = None
        add_204: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6676, view_415);  slice_6676 = view_415 = None
        
        # No stacktrace found for following nodes
        slice_tensor_404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_807, 1, 1616, 1632)
        slice_scatter_default_808: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_404, add_204, 2, 0, 16);  slice_tensor_404 = add_204 = None
        slice_scatter_default_809: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_807, slice_scatter_default_808, 1, 1616, 1632);  slice_scatter_default_807 = slice_scatter_default_808 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_809, 1, 1616, 1632)
        slice_6681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6680, 2, 0, 16);  slice_6680 = None
        
        # No stacktrace found for following nodes
        slice_tensor_405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_809, 1, 1616, 1632)
        slice_scatter_default_810: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_405, slice_6681, 2, 0, 16);  slice_tensor_405 = slice_6681 = None
        slice_scatter_default_811: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_809, slice_scatter_default_810, 1, 1616, 1632);  slice_scatter_default_809 = slice_scatter_default_810 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6701: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6667, 2, 16, 32);  slice_6667 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_206: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6701, memory_format = torch.contiguous_format);  slice_6701 = None
        view_416: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_206, [32, 11]);  clone_206 = None
        mm_203: "f32[32, 8]" = torch.ops.aten.mm.default(view_416, slice_37)
        view_417: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_203, [2, 16, 8]);  mm_203 = None
        slice_6708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_811, 1, 1616, 1632)
        slice_6709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6708, 2, 0, 16);  slice_6708 = None
        add_205: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6709, view_417);  slice_6709 = view_417 = None
        
        # No stacktrace found for following nodes
        slice_tensor_406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_811, 1, 1616, 1632)
        slice_scatter_default_812: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_406, add_205, 2, 0, 16);  slice_tensor_406 = add_205 = None
        slice_scatter_default_813: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_811, slice_scatter_default_812, 1, 1616, 1632);  slice_scatter_default_811 = slice_scatter_default_812 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_813, 1, 1616, 1632)
        slice_6714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6713, 2, 0, 16);  slice_6713 = None
        
        # No stacktrace found for following nodes
        slice_tensor_407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_813, 1, 1616, 1632)
        slice_scatter_default_814: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_407, slice_6714, 2, 0, 16);  slice_tensor_407 = slice_6714 = None
        slice_scatter_default_815: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_813, slice_scatter_default_814, 1, 1616, 1632);  slice_scatter_default_813 = slice_scatter_default_814 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6733: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1632, 1648)
        slice_6734: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6733, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_207: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6734, memory_format = torch.contiguous_format);  slice_6734 = None
        view_418: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_207, [32, 16]);  clone_207 = None
        mm_204: "f32[32, 8]" = torch.ops.aten.mm.default(view_418, slice_7)
        view_419: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_204, [2, 16, 8]);  mm_204 = None
        slice_6741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_815, 1, 1632, 1648)
        slice_6742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6741, 2, 0, 16);  slice_6741 = None
        add_206: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6742, view_419);  slice_6742 = view_419 = None
        
        # No stacktrace found for following nodes
        slice_tensor_408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_815, 1, 1632, 1648)
        slice_scatter_default_816: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_408, add_206, 2, 0, 16);  slice_tensor_408 = add_206 = None
        slice_scatter_default_817: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_815, slice_scatter_default_816, 1, 1632, 1648);  slice_scatter_default_815 = slice_scatter_default_816 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_817, 1, 1632, 1648)
        slice_6747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6746, 2, 0, 16);  slice_6746 = None
        
        # No stacktrace found for following nodes
        slice_tensor_409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_817, 1, 1632, 1648)
        slice_scatter_default_818: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_409, slice_6747, 2, 0, 16);  slice_tensor_409 = slice_6747 = None
        slice_scatter_default_819: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_817, slice_scatter_default_818, 1, 1632, 1648);  slice_scatter_default_817 = slice_scatter_default_818 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6767: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6733, 2, 16, 32);  slice_6733 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_208: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6767, memory_format = torch.contiguous_format);  slice_6767 = None
        view_420: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_208, [32, 11]);  clone_208 = None
        mm_205: "f32[32, 8]" = torch.ops.aten.mm.default(view_420, slice_37)
        view_421: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_205, [2, 16, 8]);  mm_205 = None
        slice_6774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_819, 1, 1632, 1648)
        slice_6775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6774, 2, 0, 16);  slice_6774 = None
        add_207: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6775, view_421);  slice_6775 = view_421 = None
        
        # No stacktrace found for following nodes
        slice_tensor_410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_819, 1, 1632, 1648)
        slice_scatter_default_820: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_410, add_207, 2, 0, 16);  slice_tensor_410 = add_207 = None
        slice_scatter_default_821: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_819, slice_scatter_default_820, 1, 1632, 1648);  slice_scatter_default_819 = slice_scatter_default_820 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_821, 1, 1632, 1648)
        slice_6780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6779, 2, 0, 16);  slice_6779 = None
        
        # No stacktrace found for following nodes
        slice_tensor_411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_821, 1, 1632, 1648)
        slice_scatter_default_822: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_411, slice_6780, 2, 0, 16);  slice_tensor_411 = slice_6780 = None
        slice_scatter_default_823: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_821, slice_scatter_default_822, 1, 1632, 1648);  slice_scatter_default_821 = slice_scatter_default_822 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6799: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1648, 1664)
        slice_6800: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6799, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_209: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6800, memory_format = torch.contiguous_format);  slice_6800 = None
        view_422: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_209, [32, 16]);  clone_209 = None
        mm_206: "f32[32, 8]" = torch.ops.aten.mm.default(view_422, slice_7)
        view_423: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_206, [2, 16, 8]);  mm_206 = None
        slice_6807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_823, 1, 1648, 1664)
        slice_6808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6807, 2, 0, 16);  slice_6807 = None
        add_208: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6808, view_423);  slice_6808 = view_423 = None
        
        # No stacktrace found for following nodes
        slice_tensor_412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_823, 1, 1648, 1664)
        slice_scatter_default_824: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_412, add_208, 2, 0, 16);  slice_tensor_412 = add_208 = None
        slice_scatter_default_825: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_823, slice_scatter_default_824, 1, 1648, 1664);  slice_scatter_default_823 = slice_scatter_default_824 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_825, 1, 1648, 1664)
        slice_6813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6812, 2, 0, 16);  slice_6812 = None
        
        # No stacktrace found for following nodes
        slice_tensor_413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_825, 1, 1648, 1664)
        slice_scatter_default_826: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_413, slice_6813, 2, 0, 16);  slice_tensor_413 = slice_6813 = None
        slice_scatter_default_827: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_825, slice_scatter_default_826, 1, 1648, 1664);  slice_scatter_default_825 = slice_scatter_default_826 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6833: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6799, 2, 16, 32);  slice_6799 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_210: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6833, memory_format = torch.contiguous_format);  slice_6833 = None
        view_424: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_210, [32, 11]);  clone_210 = None
        mm_207: "f32[32, 8]" = torch.ops.aten.mm.default(view_424, slice_37)
        view_425: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_207, [2, 16, 8]);  mm_207 = None
        slice_6840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_827, 1, 1648, 1664)
        slice_6841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6840, 2, 0, 16);  slice_6840 = None
        add_209: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6841, view_425);  slice_6841 = view_425 = None
        
        # No stacktrace found for following nodes
        slice_tensor_414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_827, 1, 1648, 1664)
        slice_scatter_default_828: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_414, add_209, 2, 0, 16);  slice_tensor_414 = add_209 = None
        slice_scatter_default_829: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_827, slice_scatter_default_828, 1, 1648, 1664);  slice_scatter_default_827 = slice_scatter_default_828 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_829, 1, 1648, 1664)
        slice_6846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6845, 2, 0, 16);  slice_6845 = None
        
        # No stacktrace found for following nodes
        slice_tensor_415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_829, 1, 1648, 1664)
        slice_scatter_default_830: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_415, slice_6846, 2, 0, 16);  slice_tensor_415 = slice_6846 = None
        slice_scatter_default_831: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_829, slice_scatter_default_830, 1, 1648, 1664);  slice_scatter_default_829 = slice_scatter_default_830 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6865: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1664, 1680)
        slice_6866: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6865, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_211: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6866, memory_format = torch.contiguous_format);  slice_6866 = None
        view_426: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_211, [32, 16]);  clone_211 = None
        mm_208: "f32[32, 8]" = torch.ops.aten.mm.default(view_426, slice_7)
        view_427: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_208, [2, 16, 8]);  mm_208 = None
        slice_6873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_831, 1, 1664, 1680)
        slice_6874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6873, 2, 0, 16);  slice_6873 = None
        add_210: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6874, view_427);  slice_6874 = view_427 = None
        
        # No stacktrace found for following nodes
        slice_tensor_416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_831, 1, 1664, 1680)
        slice_scatter_default_832: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_416, add_210, 2, 0, 16);  slice_tensor_416 = add_210 = None
        slice_scatter_default_833: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_831, slice_scatter_default_832, 1, 1664, 1680);  slice_scatter_default_831 = slice_scatter_default_832 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_833, 1, 1664, 1680)
        slice_6879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6878, 2, 0, 16);  slice_6878 = None
        
        # No stacktrace found for following nodes
        slice_tensor_417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_833, 1, 1664, 1680)
        slice_scatter_default_834: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_417, slice_6879, 2, 0, 16);  slice_tensor_417 = slice_6879 = None
        slice_scatter_default_835: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_833, slice_scatter_default_834, 1, 1664, 1680);  slice_scatter_default_833 = slice_scatter_default_834 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6899: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6865, 2, 16, 32);  slice_6865 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_212: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6899, memory_format = torch.contiguous_format);  slice_6899 = None
        view_428: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_212, [32, 11]);  clone_212 = None
        mm_209: "f32[32, 8]" = torch.ops.aten.mm.default(view_428, slice_37)
        view_429: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_209, [2, 16, 8]);  mm_209 = None
        slice_6906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_835, 1, 1664, 1680)
        slice_6907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6906, 2, 0, 16);  slice_6906 = None
        add_211: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6907, view_429);  slice_6907 = view_429 = None
        
        # No stacktrace found for following nodes
        slice_tensor_418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_835, 1, 1664, 1680)
        slice_scatter_default_836: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_418, add_211, 2, 0, 16);  slice_tensor_418 = add_211 = None
        slice_scatter_default_837: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_835, slice_scatter_default_836, 1, 1664, 1680);  slice_scatter_default_835 = slice_scatter_default_836 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_837, 1, 1664, 1680)
        slice_6912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6911, 2, 0, 16);  slice_6911 = None
        
        # No stacktrace found for following nodes
        slice_tensor_419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_837, 1, 1664, 1680)
        slice_scatter_default_838: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_419, slice_6912, 2, 0, 16);  slice_tensor_419 = slice_6912 = None
        slice_scatter_default_839: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_837, slice_scatter_default_838, 1, 1664, 1680);  slice_scatter_default_837 = slice_scatter_default_838 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6931: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1680, 1696)
        slice_6932: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6931, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_213: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6932, memory_format = torch.contiguous_format);  slice_6932 = None
        view_430: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_213, [32, 16]);  clone_213 = None
        mm_210: "f32[32, 8]" = torch.ops.aten.mm.default(view_430, slice_7)
        view_431: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_210, [2, 16, 8]);  mm_210 = None
        slice_6939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_839, 1, 1680, 1696)
        slice_6940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6939, 2, 0, 16);  slice_6939 = None
        add_212: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6940, view_431);  slice_6940 = view_431 = None
        
        # No stacktrace found for following nodes
        slice_tensor_420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_839, 1, 1680, 1696)
        slice_scatter_default_840: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_420, add_212, 2, 0, 16);  slice_tensor_420 = add_212 = None
        slice_scatter_default_841: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_839, slice_scatter_default_840, 1, 1680, 1696);  slice_scatter_default_839 = slice_scatter_default_840 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_841, 1, 1680, 1696)
        slice_6945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6944, 2, 0, 16);  slice_6944 = None
        
        # No stacktrace found for following nodes
        slice_tensor_421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_841, 1, 1680, 1696)
        slice_scatter_default_842: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_421, slice_6945, 2, 0, 16);  slice_tensor_421 = slice_6945 = None
        slice_scatter_default_843: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_841, slice_scatter_default_842, 1, 1680, 1696);  slice_scatter_default_841 = slice_scatter_default_842 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6965: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6931, 2, 16, 32);  slice_6931 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_214: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_6965, memory_format = torch.contiguous_format);  slice_6965 = None
        view_432: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_214, [32, 11]);  clone_214 = None
        mm_211: "f32[32, 8]" = torch.ops.aten.mm.default(view_432, slice_37)
        view_433: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_211, [2, 16, 8]);  mm_211 = None
        slice_6972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_843, 1, 1680, 1696)
        slice_6973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6972, 2, 0, 16);  slice_6972 = None
        add_213: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_6973, view_433);  slice_6973 = view_433 = None
        
        # No stacktrace found for following nodes
        slice_tensor_422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_843, 1, 1680, 1696)
        slice_scatter_default_844: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_422, add_213, 2, 0, 16);  slice_tensor_422 = add_213 = None
        slice_scatter_default_845: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_843, slice_scatter_default_844, 1, 1680, 1696);  slice_scatter_default_843 = slice_scatter_default_844 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_6977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_845, 1, 1680, 1696)
        slice_6978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_6977, 2, 0, 16);  slice_6977 = None
        
        # No stacktrace found for following nodes
        slice_tensor_423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_845, 1, 1680, 1696)
        slice_scatter_default_846: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_423, slice_6978, 2, 0, 16);  slice_tensor_423 = slice_6978 = None
        slice_scatter_default_847: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_845, slice_scatter_default_846, 1, 1680, 1696);  slice_scatter_default_845 = slice_scatter_default_846 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_6997: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1696, 1712)
        slice_6998: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_6997, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_215: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_6998, memory_format = torch.contiguous_format);  slice_6998 = None
        view_434: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_215, [32, 16]);  clone_215 = None
        mm_212: "f32[32, 8]" = torch.ops.aten.mm.default(view_434, slice_7)
        view_435: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_212, [2, 16, 8]);  mm_212 = None
        slice_7005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_847, 1, 1696, 1712)
        slice_7006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7005, 2, 0, 16);  slice_7005 = None
        add_214: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7006, view_435);  slice_7006 = view_435 = None
        
        # No stacktrace found for following nodes
        slice_tensor_424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_847, 1, 1696, 1712)
        slice_scatter_default_848: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_424, add_214, 2, 0, 16);  slice_tensor_424 = add_214 = None
        slice_scatter_default_849: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_847, slice_scatter_default_848, 1, 1696, 1712);  slice_scatter_default_847 = slice_scatter_default_848 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_849, 1, 1696, 1712)
        slice_7011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7010, 2, 0, 16);  slice_7010 = None
        
        # No stacktrace found for following nodes
        slice_tensor_425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_849, 1, 1696, 1712)
        slice_scatter_default_850: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_425, slice_7011, 2, 0, 16);  slice_tensor_425 = slice_7011 = None
        slice_scatter_default_851: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_849, slice_scatter_default_850, 1, 1696, 1712);  slice_scatter_default_849 = slice_scatter_default_850 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7031: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_6997, 2, 16, 32);  slice_6997 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_216: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7031, memory_format = torch.contiguous_format);  slice_7031 = None
        view_436: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_216, [32, 11]);  clone_216 = None
        mm_213: "f32[32, 8]" = torch.ops.aten.mm.default(view_436, slice_37)
        view_437: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_213, [2, 16, 8]);  mm_213 = None
        slice_7038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_851, 1, 1696, 1712)
        slice_7039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7038, 2, 0, 16);  slice_7038 = None
        add_215: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7039, view_437);  slice_7039 = view_437 = None
        
        # No stacktrace found for following nodes
        slice_tensor_426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_851, 1, 1696, 1712)
        slice_scatter_default_852: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_426, add_215, 2, 0, 16);  slice_tensor_426 = add_215 = None
        slice_scatter_default_853: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_851, slice_scatter_default_852, 1, 1696, 1712);  slice_scatter_default_851 = slice_scatter_default_852 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_853, 1, 1696, 1712)
        slice_7044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7043, 2, 0, 16);  slice_7043 = None
        
        # No stacktrace found for following nodes
        slice_tensor_427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_853, 1, 1696, 1712)
        slice_scatter_default_854: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_427, slice_7044, 2, 0, 16);  slice_tensor_427 = slice_7044 = None
        slice_scatter_default_855: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_853, slice_scatter_default_854, 1, 1696, 1712);  slice_scatter_default_853 = slice_scatter_default_854 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7063: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1712, 1728)
        slice_7064: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7063, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_217: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7064, memory_format = torch.contiguous_format);  slice_7064 = None
        view_438: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_217, [32, 16]);  clone_217 = None
        mm_214: "f32[32, 8]" = torch.ops.aten.mm.default(view_438, slice_7)
        view_439: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_214, [2, 16, 8]);  mm_214 = None
        slice_7071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_855, 1, 1712, 1728)
        slice_7072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7071, 2, 0, 16);  slice_7071 = None
        add_216: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7072, view_439);  slice_7072 = view_439 = None
        
        # No stacktrace found for following nodes
        slice_tensor_428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_855, 1, 1712, 1728)
        slice_scatter_default_856: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_428, add_216, 2, 0, 16);  slice_tensor_428 = add_216 = None
        slice_scatter_default_857: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_855, slice_scatter_default_856, 1, 1712, 1728);  slice_scatter_default_855 = slice_scatter_default_856 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_857, 1, 1712, 1728)
        slice_7077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7076, 2, 0, 16);  slice_7076 = None
        
        # No stacktrace found for following nodes
        slice_tensor_429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_857, 1, 1712, 1728)
        slice_scatter_default_858: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_429, slice_7077, 2, 0, 16);  slice_tensor_429 = slice_7077 = None
        slice_scatter_default_859: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_857, slice_scatter_default_858, 1, 1712, 1728);  slice_scatter_default_857 = slice_scatter_default_858 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7097: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7063, 2, 16, 32);  slice_7063 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_218: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7097, memory_format = torch.contiguous_format);  slice_7097 = None
        view_440: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_218, [32, 11]);  clone_218 = None
        mm_215: "f32[32, 8]" = torch.ops.aten.mm.default(view_440, slice_37)
        view_441: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_215, [2, 16, 8]);  mm_215 = None
        slice_7104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_859, 1, 1712, 1728)
        slice_7105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7104, 2, 0, 16);  slice_7104 = None
        add_217: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7105, view_441);  slice_7105 = view_441 = None
        
        # No stacktrace found for following nodes
        slice_tensor_430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_859, 1, 1712, 1728)
        slice_scatter_default_860: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_430, add_217, 2, 0, 16);  slice_tensor_430 = add_217 = None
        slice_scatter_default_861: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_859, slice_scatter_default_860, 1, 1712, 1728);  slice_scatter_default_859 = slice_scatter_default_860 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_861, 1, 1712, 1728)
        slice_7110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7109, 2, 0, 16);  slice_7109 = None
        
        # No stacktrace found for following nodes
        slice_tensor_431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_861, 1, 1712, 1728)
        slice_scatter_default_862: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_431, slice_7110, 2, 0, 16);  slice_tensor_431 = slice_7110 = None
        slice_scatter_default_863: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_861, slice_scatter_default_862, 1, 1712, 1728);  slice_scatter_default_861 = slice_scatter_default_862 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7129: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1728, 1744)
        slice_7130: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7129, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_219: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7130, memory_format = torch.contiguous_format);  slice_7130 = None
        view_442: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_219, [32, 16]);  clone_219 = None
        mm_216: "f32[32, 8]" = torch.ops.aten.mm.default(view_442, slice_7)
        view_443: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_216, [2, 16, 8]);  mm_216 = None
        slice_7137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_863, 1, 1728, 1744)
        slice_7138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7137, 2, 0, 16);  slice_7137 = None
        add_218: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7138, view_443);  slice_7138 = view_443 = None
        
        # No stacktrace found for following nodes
        slice_tensor_432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_863, 1, 1728, 1744)
        slice_scatter_default_864: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_432, add_218, 2, 0, 16);  slice_tensor_432 = add_218 = None
        slice_scatter_default_865: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_863, slice_scatter_default_864, 1, 1728, 1744);  slice_scatter_default_863 = slice_scatter_default_864 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_865, 1, 1728, 1744)
        slice_7143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7142, 2, 0, 16);  slice_7142 = None
        
        # No stacktrace found for following nodes
        slice_tensor_433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_865, 1, 1728, 1744)
        slice_scatter_default_866: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_433, slice_7143, 2, 0, 16);  slice_tensor_433 = slice_7143 = None
        slice_scatter_default_867: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_865, slice_scatter_default_866, 1, 1728, 1744);  slice_scatter_default_865 = slice_scatter_default_866 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7163: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7129, 2, 16, 32);  slice_7129 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_220: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7163, memory_format = torch.contiguous_format);  slice_7163 = None
        view_444: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_220, [32, 11]);  clone_220 = None
        mm_217: "f32[32, 8]" = torch.ops.aten.mm.default(view_444, slice_37)
        view_445: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_217, [2, 16, 8]);  mm_217 = None
        slice_7170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_867, 1, 1728, 1744)
        slice_7171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7170, 2, 0, 16);  slice_7170 = None
        add_219: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7171, view_445);  slice_7171 = view_445 = None
        
        # No stacktrace found for following nodes
        slice_tensor_434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_867, 1, 1728, 1744)
        slice_scatter_default_868: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_434, add_219, 2, 0, 16);  slice_tensor_434 = add_219 = None
        slice_scatter_default_869: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_867, slice_scatter_default_868, 1, 1728, 1744);  slice_scatter_default_867 = slice_scatter_default_868 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_869, 1, 1728, 1744)
        slice_7176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7175, 2, 0, 16);  slice_7175 = None
        
        # No stacktrace found for following nodes
        slice_tensor_435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_869, 1, 1728, 1744)
        slice_scatter_default_870: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_435, slice_7176, 2, 0, 16);  slice_tensor_435 = slice_7176 = None
        slice_scatter_default_871: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_869, slice_scatter_default_870, 1, 1728, 1744);  slice_scatter_default_869 = slice_scatter_default_870 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7195: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1744, 1760)
        slice_7196: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7195, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_221: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7196, memory_format = torch.contiguous_format);  slice_7196 = None
        view_446: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_221, [32, 16]);  clone_221 = None
        mm_218: "f32[32, 8]" = torch.ops.aten.mm.default(view_446, slice_7)
        view_447: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_218, [2, 16, 8]);  mm_218 = None
        slice_7203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_871, 1, 1744, 1760)
        slice_7204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7203, 2, 0, 16);  slice_7203 = None
        add_220: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7204, view_447);  slice_7204 = view_447 = None
        
        # No stacktrace found for following nodes
        slice_tensor_436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_871, 1, 1744, 1760)
        slice_scatter_default_872: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_436, add_220, 2, 0, 16);  slice_tensor_436 = add_220 = None
        slice_scatter_default_873: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_871, slice_scatter_default_872, 1, 1744, 1760);  slice_scatter_default_871 = slice_scatter_default_872 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_873, 1, 1744, 1760)
        slice_7209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7208, 2, 0, 16);  slice_7208 = None
        
        # No stacktrace found for following nodes
        slice_tensor_437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_873, 1, 1744, 1760)
        slice_scatter_default_874: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_437, slice_7209, 2, 0, 16);  slice_tensor_437 = slice_7209 = None
        slice_scatter_default_875: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_873, slice_scatter_default_874, 1, 1744, 1760);  slice_scatter_default_873 = slice_scatter_default_874 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7229: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7195, 2, 16, 32);  slice_7195 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_222: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7229, memory_format = torch.contiguous_format);  slice_7229 = None
        view_448: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_222, [32, 11]);  clone_222 = None
        mm_219: "f32[32, 8]" = torch.ops.aten.mm.default(view_448, slice_37)
        view_449: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_219, [2, 16, 8]);  mm_219 = None
        slice_7236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_875, 1, 1744, 1760)
        slice_7237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7236, 2, 0, 16);  slice_7236 = None
        add_221: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7237, view_449);  slice_7237 = view_449 = None
        
        # No stacktrace found for following nodes
        slice_tensor_438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_875, 1, 1744, 1760)
        slice_scatter_default_876: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_438, add_221, 2, 0, 16);  slice_tensor_438 = add_221 = None
        slice_scatter_default_877: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_875, slice_scatter_default_876, 1, 1744, 1760);  slice_scatter_default_875 = slice_scatter_default_876 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_877, 1, 1744, 1760)
        slice_7242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7241, 2, 0, 16);  slice_7241 = None
        
        # No stacktrace found for following nodes
        slice_tensor_439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_877, 1, 1744, 1760)
        slice_scatter_default_878: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_439, slice_7242, 2, 0, 16);  slice_tensor_439 = slice_7242 = None
        slice_scatter_default_879: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_877, slice_scatter_default_878, 1, 1744, 1760);  slice_scatter_default_877 = slice_scatter_default_878 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7261: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1760, 1776)
        slice_7262: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7261, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_223: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7262, memory_format = torch.contiguous_format);  slice_7262 = None
        view_450: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_223, [32, 16]);  clone_223 = None
        mm_220: "f32[32, 8]" = torch.ops.aten.mm.default(view_450, slice_7)
        view_451: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_220, [2, 16, 8]);  mm_220 = None
        slice_7269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_879, 1, 1760, 1776)
        slice_7270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7269, 2, 0, 16);  slice_7269 = None
        add_222: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7270, view_451);  slice_7270 = view_451 = None
        
        # No stacktrace found for following nodes
        slice_tensor_440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_879, 1, 1760, 1776)
        slice_scatter_default_880: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_440, add_222, 2, 0, 16);  slice_tensor_440 = add_222 = None
        slice_scatter_default_881: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_879, slice_scatter_default_880, 1, 1760, 1776);  slice_scatter_default_879 = slice_scatter_default_880 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_881, 1, 1760, 1776)
        slice_7275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7274, 2, 0, 16);  slice_7274 = None
        
        # No stacktrace found for following nodes
        slice_tensor_441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_881, 1, 1760, 1776)
        slice_scatter_default_882: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_441, slice_7275, 2, 0, 16);  slice_tensor_441 = slice_7275 = None
        slice_scatter_default_883: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_881, slice_scatter_default_882, 1, 1760, 1776);  slice_scatter_default_881 = slice_scatter_default_882 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7295: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7261, 2, 16, 32);  slice_7261 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_224: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7295, memory_format = torch.contiguous_format);  slice_7295 = None
        view_452: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_224, [32, 11]);  clone_224 = None
        mm_221: "f32[32, 8]" = torch.ops.aten.mm.default(view_452, slice_37)
        view_453: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_221, [2, 16, 8]);  mm_221 = None
        slice_7302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_883, 1, 1760, 1776)
        slice_7303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7302, 2, 0, 16);  slice_7302 = None
        add_223: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7303, view_453);  slice_7303 = view_453 = None
        
        # No stacktrace found for following nodes
        slice_tensor_442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_883, 1, 1760, 1776)
        slice_scatter_default_884: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_442, add_223, 2, 0, 16);  slice_tensor_442 = add_223 = None
        slice_scatter_default_885: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_883, slice_scatter_default_884, 1, 1760, 1776);  slice_scatter_default_883 = slice_scatter_default_884 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_885, 1, 1760, 1776)
        slice_7308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7307, 2, 0, 16);  slice_7307 = None
        
        # No stacktrace found for following nodes
        slice_tensor_443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_885, 1, 1760, 1776)
        slice_scatter_default_886: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_443, slice_7308, 2, 0, 16);  slice_tensor_443 = slice_7308 = None
        slice_scatter_default_887: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_885, slice_scatter_default_886, 1, 1760, 1776);  slice_scatter_default_885 = slice_scatter_default_886 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7327: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1776, 1792)
        slice_7328: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7327, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_225: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7328, memory_format = torch.contiguous_format);  slice_7328 = None
        view_454: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_225, [32, 16]);  clone_225 = None
        mm_222: "f32[32, 8]" = torch.ops.aten.mm.default(view_454, slice_7)
        view_455: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_222, [2, 16, 8]);  mm_222 = None
        slice_7335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_887, 1, 1776, 1792)
        slice_7336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7335, 2, 0, 16);  slice_7335 = None
        add_224: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7336, view_455);  slice_7336 = view_455 = None
        
        # No stacktrace found for following nodes
        slice_tensor_444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_887, 1, 1776, 1792)
        slice_scatter_default_888: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_444, add_224, 2, 0, 16);  slice_tensor_444 = add_224 = None
        slice_scatter_default_889: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_887, slice_scatter_default_888, 1, 1776, 1792);  slice_scatter_default_887 = slice_scatter_default_888 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_889, 1, 1776, 1792)
        slice_7341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7340, 2, 0, 16);  slice_7340 = None
        
        # No stacktrace found for following nodes
        slice_tensor_445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_889, 1, 1776, 1792)
        slice_scatter_default_890: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_445, slice_7341, 2, 0, 16);  slice_tensor_445 = slice_7341 = None
        slice_scatter_default_891: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_889, slice_scatter_default_890, 1, 1776, 1792);  slice_scatter_default_889 = slice_scatter_default_890 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7361: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7327, 2, 16, 32);  slice_7327 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_226: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7361, memory_format = torch.contiguous_format);  slice_7361 = None
        view_456: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_226, [32, 11]);  clone_226 = None
        mm_223: "f32[32, 8]" = torch.ops.aten.mm.default(view_456, slice_37)
        view_457: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_223, [2, 16, 8]);  mm_223 = None
        slice_7368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_891, 1, 1776, 1792)
        slice_7369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7368, 2, 0, 16);  slice_7368 = None
        add_225: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7369, view_457);  slice_7369 = view_457 = None
        
        # No stacktrace found for following nodes
        slice_tensor_446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_891, 1, 1776, 1792)
        slice_scatter_default_892: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_446, add_225, 2, 0, 16);  slice_tensor_446 = add_225 = None
        slice_scatter_default_893: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_891, slice_scatter_default_892, 1, 1776, 1792);  slice_scatter_default_891 = slice_scatter_default_892 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_893, 1, 1776, 1792)
        slice_7374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7373, 2, 0, 16);  slice_7373 = None
        
        # No stacktrace found for following nodes
        slice_tensor_447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_893, 1, 1776, 1792)
        slice_scatter_default_894: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_447, slice_7374, 2, 0, 16);  slice_tensor_447 = slice_7374 = None
        slice_scatter_default_895: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_893, slice_scatter_default_894, 1, 1776, 1792);  slice_scatter_default_893 = slice_scatter_default_894 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7393: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1792, 1808)
        slice_7394: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7393, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_227: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7394, memory_format = torch.contiguous_format);  slice_7394 = None
        view_458: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_227, [32, 16]);  clone_227 = None
        mm_224: "f32[32, 8]" = torch.ops.aten.mm.default(view_458, slice_7)
        view_459: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_224, [2, 16, 8]);  mm_224 = None
        slice_7401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_895, 1, 1792, 1808)
        slice_7402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7401, 2, 0, 16);  slice_7401 = None
        add_226: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7402, view_459);  slice_7402 = view_459 = None
        
        # No stacktrace found for following nodes
        slice_tensor_448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_895, 1, 1792, 1808)
        slice_scatter_default_896: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_448, add_226, 2, 0, 16);  slice_tensor_448 = add_226 = None
        slice_scatter_default_897: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_895, slice_scatter_default_896, 1, 1792, 1808);  slice_scatter_default_895 = slice_scatter_default_896 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_897, 1, 1792, 1808)
        slice_7407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7406, 2, 0, 16);  slice_7406 = None
        
        # No stacktrace found for following nodes
        slice_tensor_449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_897, 1, 1792, 1808)
        slice_scatter_default_898: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_449, slice_7407, 2, 0, 16);  slice_tensor_449 = slice_7407 = None
        slice_scatter_default_899: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_897, slice_scatter_default_898, 1, 1792, 1808);  slice_scatter_default_897 = slice_scatter_default_898 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7427: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7393, 2, 16, 32);  slice_7393 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_228: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7427, memory_format = torch.contiguous_format);  slice_7427 = None
        view_460: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_228, [32, 11]);  clone_228 = None
        mm_225: "f32[32, 8]" = torch.ops.aten.mm.default(view_460, slice_37)
        view_461: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_225, [2, 16, 8]);  mm_225 = None
        slice_7434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_899, 1, 1792, 1808)
        slice_7435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7434, 2, 0, 16);  slice_7434 = None
        add_227: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7435, view_461);  slice_7435 = view_461 = None
        
        # No stacktrace found for following nodes
        slice_tensor_450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_899, 1, 1792, 1808)
        slice_scatter_default_900: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_450, add_227, 2, 0, 16);  slice_tensor_450 = add_227 = None
        slice_scatter_default_901: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_899, slice_scatter_default_900, 1, 1792, 1808);  slice_scatter_default_899 = slice_scatter_default_900 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_901, 1, 1792, 1808)
        slice_7440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7439, 2, 0, 16);  slice_7439 = None
        
        # No stacktrace found for following nodes
        slice_tensor_451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_901, 1, 1792, 1808)
        slice_scatter_default_902: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_451, slice_7440, 2, 0, 16);  slice_tensor_451 = slice_7440 = None
        slice_scatter_default_903: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_901, slice_scatter_default_902, 1, 1792, 1808);  slice_scatter_default_901 = slice_scatter_default_902 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7459: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1808, 1824)
        slice_7460: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7459, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_229: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7460, memory_format = torch.contiguous_format);  slice_7460 = None
        view_462: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_229, [32, 16]);  clone_229 = None
        mm_226: "f32[32, 8]" = torch.ops.aten.mm.default(view_462, slice_7)
        view_463: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_226, [2, 16, 8]);  mm_226 = None
        slice_7467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_903, 1, 1808, 1824)
        slice_7468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7467, 2, 0, 16);  slice_7467 = None
        add_228: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7468, view_463);  slice_7468 = view_463 = None
        
        # No stacktrace found for following nodes
        slice_tensor_452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_903, 1, 1808, 1824)
        slice_scatter_default_904: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_452, add_228, 2, 0, 16);  slice_tensor_452 = add_228 = None
        slice_scatter_default_905: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_903, slice_scatter_default_904, 1, 1808, 1824);  slice_scatter_default_903 = slice_scatter_default_904 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_905, 1, 1808, 1824)
        slice_7473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7472, 2, 0, 16);  slice_7472 = None
        
        # No stacktrace found for following nodes
        slice_tensor_453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_905, 1, 1808, 1824)
        slice_scatter_default_906: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_453, slice_7473, 2, 0, 16);  slice_tensor_453 = slice_7473 = None
        slice_scatter_default_907: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_905, slice_scatter_default_906, 1, 1808, 1824);  slice_scatter_default_905 = slice_scatter_default_906 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7493: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7459, 2, 16, 32);  slice_7459 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_230: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7493, memory_format = torch.contiguous_format);  slice_7493 = None
        view_464: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_230, [32, 11]);  clone_230 = None
        mm_227: "f32[32, 8]" = torch.ops.aten.mm.default(view_464, slice_37)
        view_465: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_227, [2, 16, 8]);  mm_227 = None
        slice_7500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_907, 1, 1808, 1824)
        slice_7501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7500, 2, 0, 16);  slice_7500 = None
        add_229: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7501, view_465);  slice_7501 = view_465 = None
        
        # No stacktrace found for following nodes
        slice_tensor_454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_907, 1, 1808, 1824)
        slice_scatter_default_908: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_454, add_229, 2, 0, 16);  slice_tensor_454 = add_229 = None
        slice_scatter_default_909: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_907, slice_scatter_default_908, 1, 1808, 1824);  slice_scatter_default_907 = slice_scatter_default_908 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_909, 1, 1808, 1824)
        slice_7506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7505, 2, 0, 16);  slice_7505 = None
        
        # No stacktrace found for following nodes
        slice_tensor_455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_909, 1, 1808, 1824)
        slice_scatter_default_910: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_455, slice_7506, 2, 0, 16);  slice_tensor_455 = slice_7506 = None
        slice_scatter_default_911: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_909, slice_scatter_default_910, 1, 1808, 1824);  slice_scatter_default_909 = slice_scatter_default_910 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7525: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1824, 1840)
        slice_7526: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7525, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_231: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7526, memory_format = torch.contiguous_format);  slice_7526 = None
        view_466: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_231, [32, 16]);  clone_231 = None
        mm_228: "f32[32, 8]" = torch.ops.aten.mm.default(view_466, slice_7)
        view_467: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_228, [2, 16, 8]);  mm_228 = None
        slice_7533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_911, 1, 1824, 1840)
        slice_7534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7533, 2, 0, 16);  slice_7533 = None
        add_230: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7534, view_467);  slice_7534 = view_467 = None
        
        # No stacktrace found for following nodes
        slice_tensor_456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_911, 1, 1824, 1840)
        slice_scatter_default_912: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_456, add_230, 2, 0, 16);  slice_tensor_456 = add_230 = None
        slice_scatter_default_913: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_911, slice_scatter_default_912, 1, 1824, 1840);  slice_scatter_default_911 = slice_scatter_default_912 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_913, 1, 1824, 1840)
        slice_7539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7538, 2, 0, 16);  slice_7538 = None
        
        # No stacktrace found for following nodes
        slice_tensor_457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_913, 1, 1824, 1840)
        slice_scatter_default_914: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_457, slice_7539, 2, 0, 16);  slice_tensor_457 = slice_7539 = None
        slice_scatter_default_915: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_913, slice_scatter_default_914, 1, 1824, 1840);  slice_scatter_default_913 = slice_scatter_default_914 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7559: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7525, 2, 16, 32);  slice_7525 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_232: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7559, memory_format = torch.contiguous_format);  slice_7559 = None
        view_468: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_232, [32, 11]);  clone_232 = None
        mm_229: "f32[32, 8]" = torch.ops.aten.mm.default(view_468, slice_37)
        view_469: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_229, [2, 16, 8]);  mm_229 = None
        slice_7566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_915, 1, 1824, 1840)
        slice_7567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7566, 2, 0, 16);  slice_7566 = None
        add_231: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7567, view_469);  slice_7567 = view_469 = None
        
        # No stacktrace found for following nodes
        slice_tensor_458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_915, 1, 1824, 1840)
        slice_scatter_default_916: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_458, add_231, 2, 0, 16);  slice_tensor_458 = add_231 = None
        slice_scatter_default_917: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_915, slice_scatter_default_916, 1, 1824, 1840);  slice_scatter_default_915 = slice_scatter_default_916 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_917, 1, 1824, 1840)
        slice_7572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7571, 2, 0, 16);  slice_7571 = None
        
        # No stacktrace found for following nodes
        slice_tensor_459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_917, 1, 1824, 1840)
        slice_scatter_default_918: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_459, slice_7572, 2, 0, 16);  slice_tensor_459 = slice_7572 = None
        slice_scatter_default_919: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_917, slice_scatter_default_918, 1, 1824, 1840);  slice_scatter_default_917 = slice_scatter_default_918 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7591: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1840, 1856)
        slice_7592: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7591, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_233: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7592, memory_format = torch.contiguous_format);  slice_7592 = None
        view_470: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_233, [32, 16]);  clone_233 = None
        mm_230: "f32[32, 8]" = torch.ops.aten.mm.default(view_470, slice_7)
        view_471: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_230, [2, 16, 8]);  mm_230 = None
        slice_7599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_919, 1, 1840, 1856)
        slice_7600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7599, 2, 0, 16);  slice_7599 = None
        add_232: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7600, view_471);  slice_7600 = view_471 = None
        
        # No stacktrace found for following nodes
        slice_tensor_460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_919, 1, 1840, 1856)
        slice_scatter_default_920: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_460, add_232, 2, 0, 16);  slice_tensor_460 = add_232 = None
        slice_scatter_default_921: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_919, slice_scatter_default_920, 1, 1840, 1856);  slice_scatter_default_919 = slice_scatter_default_920 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_921, 1, 1840, 1856)
        slice_7605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7604, 2, 0, 16);  slice_7604 = None
        
        # No stacktrace found for following nodes
        slice_tensor_461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_921, 1, 1840, 1856)
        slice_scatter_default_922: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_461, slice_7605, 2, 0, 16);  slice_tensor_461 = slice_7605 = None
        slice_scatter_default_923: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_921, slice_scatter_default_922, 1, 1840, 1856);  slice_scatter_default_921 = slice_scatter_default_922 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7625: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7591, 2, 16, 32);  slice_7591 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_234: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7625, memory_format = torch.contiguous_format);  slice_7625 = None
        view_472: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_234, [32, 11]);  clone_234 = None
        mm_231: "f32[32, 8]" = torch.ops.aten.mm.default(view_472, slice_37)
        view_473: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_231, [2, 16, 8]);  mm_231 = None
        slice_7632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_923, 1, 1840, 1856)
        slice_7633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7632, 2, 0, 16);  slice_7632 = None
        add_233: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7633, view_473);  slice_7633 = view_473 = None
        
        # No stacktrace found for following nodes
        slice_tensor_462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_923, 1, 1840, 1856)
        slice_scatter_default_924: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_462, add_233, 2, 0, 16);  slice_tensor_462 = add_233 = None
        slice_scatter_default_925: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_923, slice_scatter_default_924, 1, 1840, 1856);  slice_scatter_default_923 = slice_scatter_default_924 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_925, 1, 1840, 1856)
        slice_7638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7637, 2, 0, 16);  slice_7637 = None
        
        # No stacktrace found for following nodes
        slice_tensor_463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_925, 1, 1840, 1856)
        slice_scatter_default_926: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_463, slice_7638, 2, 0, 16);  slice_tensor_463 = slice_7638 = None
        slice_scatter_default_927: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_925, slice_scatter_default_926, 1, 1840, 1856);  slice_scatter_default_925 = slice_scatter_default_926 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7657: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1856, 1872)
        slice_7658: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7657, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_235: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7658, memory_format = torch.contiguous_format);  slice_7658 = None
        view_474: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_235, [32, 16]);  clone_235 = None
        mm_232: "f32[32, 8]" = torch.ops.aten.mm.default(view_474, slice_7)
        view_475: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_232, [2, 16, 8]);  mm_232 = None
        slice_7665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_927, 1, 1856, 1872)
        slice_7666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7665, 2, 0, 16);  slice_7665 = None
        add_234: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7666, view_475);  slice_7666 = view_475 = None
        
        # No stacktrace found for following nodes
        slice_tensor_464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_927, 1, 1856, 1872)
        slice_scatter_default_928: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_464, add_234, 2, 0, 16);  slice_tensor_464 = add_234 = None
        slice_scatter_default_929: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_927, slice_scatter_default_928, 1, 1856, 1872);  slice_scatter_default_927 = slice_scatter_default_928 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_929, 1, 1856, 1872)
        slice_7671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7670, 2, 0, 16);  slice_7670 = None
        
        # No stacktrace found for following nodes
        slice_tensor_465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_929, 1, 1856, 1872)
        slice_scatter_default_930: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_465, slice_7671, 2, 0, 16);  slice_tensor_465 = slice_7671 = None
        slice_scatter_default_931: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_929, slice_scatter_default_930, 1, 1856, 1872);  slice_scatter_default_929 = slice_scatter_default_930 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7691: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7657, 2, 16, 32);  slice_7657 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_236: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7691, memory_format = torch.contiguous_format);  slice_7691 = None
        view_476: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_236, [32, 11]);  clone_236 = None
        mm_233: "f32[32, 8]" = torch.ops.aten.mm.default(view_476, slice_37)
        view_477: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_233, [2, 16, 8]);  mm_233 = None
        slice_7698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_931, 1, 1856, 1872)
        slice_7699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7698, 2, 0, 16);  slice_7698 = None
        add_235: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7699, view_477);  slice_7699 = view_477 = None
        
        # No stacktrace found for following nodes
        slice_tensor_466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_931, 1, 1856, 1872)
        slice_scatter_default_932: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_466, add_235, 2, 0, 16);  slice_tensor_466 = add_235 = None
        slice_scatter_default_933: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_931, slice_scatter_default_932, 1, 1856, 1872);  slice_scatter_default_931 = slice_scatter_default_932 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_933, 1, 1856, 1872)
        slice_7704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7703, 2, 0, 16);  slice_7703 = None
        
        # No stacktrace found for following nodes
        slice_tensor_467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_933, 1, 1856, 1872)
        slice_scatter_default_934: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_467, slice_7704, 2, 0, 16);  slice_tensor_467 = slice_7704 = None
        slice_scatter_default_935: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_933, slice_scatter_default_934, 1, 1856, 1872);  slice_scatter_default_933 = slice_scatter_default_934 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7723: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1872, 1888)
        slice_7724: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7723, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_237: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7724, memory_format = torch.contiguous_format);  slice_7724 = None
        view_478: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_237, [32, 16]);  clone_237 = None
        mm_234: "f32[32, 8]" = torch.ops.aten.mm.default(view_478, slice_7)
        view_479: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_234, [2, 16, 8]);  mm_234 = None
        slice_7731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_935, 1, 1872, 1888)
        slice_7732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7731, 2, 0, 16);  slice_7731 = None
        add_236: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7732, view_479);  slice_7732 = view_479 = None
        
        # No stacktrace found for following nodes
        slice_tensor_468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_935, 1, 1872, 1888)
        slice_scatter_default_936: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_468, add_236, 2, 0, 16);  slice_tensor_468 = add_236 = None
        slice_scatter_default_937: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_935, slice_scatter_default_936, 1, 1872, 1888);  slice_scatter_default_935 = slice_scatter_default_936 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_937, 1, 1872, 1888)
        slice_7737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7736, 2, 0, 16);  slice_7736 = None
        
        # No stacktrace found for following nodes
        slice_tensor_469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_937, 1, 1872, 1888)
        slice_scatter_default_938: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_469, slice_7737, 2, 0, 16);  slice_tensor_469 = slice_7737 = None
        slice_scatter_default_939: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_937, slice_scatter_default_938, 1, 1872, 1888);  slice_scatter_default_937 = slice_scatter_default_938 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7757: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7723, 2, 16, 32);  slice_7723 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_238: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7757, memory_format = torch.contiguous_format);  slice_7757 = None
        view_480: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_238, [32, 11]);  clone_238 = None
        mm_235: "f32[32, 8]" = torch.ops.aten.mm.default(view_480, slice_37)
        view_481: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_235, [2, 16, 8]);  mm_235 = None
        slice_7764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_939, 1, 1872, 1888)
        slice_7765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7764, 2, 0, 16);  slice_7764 = None
        add_237: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7765, view_481);  slice_7765 = view_481 = None
        
        # No stacktrace found for following nodes
        slice_tensor_470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_939, 1, 1872, 1888)
        slice_scatter_default_940: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_470, add_237, 2, 0, 16);  slice_tensor_470 = add_237 = None
        slice_scatter_default_941: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_939, slice_scatter_default_940, 1, 1872, 1888);  slice_scatter_default_939 = slice_scatter_default_940 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_941, 1, 1872, 1888)
        slice_7770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7769, 2, 0, 16);  slice_7769 = None
        
        # No stacktrace found for following nodes
        slice_tensor_471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_941, 1, 1872, 1888)
        slice_scatter_default_942: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_471, slice_7770, 2, 0, 16);  slice_tensor_471 = slice_7770 = None
        slice_scatter_default_943: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_941, slice_scatter_default_942, 1, 1872, 1888);  slice_scatter_default_941 = slice_scatter_default_942 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7789: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1888, 1904)
        slice_7790: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7789, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_239: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7790, memory_format = torch.contiguous_format);  slice_7790 = None
        view_482: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_239, [32, 16]);  clone_239 = None
        mm_236: "f32[32, 8]" = torch.ops.aten.mm.default(view_482, slice_7)
        view_483: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_236, [2, 16, 8]);  mm_236 = None
        slice_7797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_943, 1, 1888, 1904)
        slice_7798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7797, 2, 0, 16);  slice_7797 = None
        add_238: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7798, view_483);  slice_7798 = view_483 = None
        
        # No stacktrace found for following nodes
        slice_tensor_472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_943, 1, 1888, 1904)
        slice_scatter_default_944: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_472, add_238, 2, 0, 16);  slice_tensor_472 = add_238 = None
        slice_scatter_default_945: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_943, slice_scatter_default_944, 1, 1888, 1904);  slice_scatter_default_943 = slice_scatter_default_944 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_945, 1, 1888, 1904)
        slice_7803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7802, 2, 0, 16);  slice_7802 = None
        
        # No stacktrace found for following nodes
        slice_tensor_473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_945, 1, 1888, 1904)
        slice_scatter_default_946: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_473, slice_7803, 2, 0, 16);  slice_tensor_473 = slice_7803 = None
        slice_scatter_default_947: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_945, slice_scatter_default_946, 1, 1888, 1904);  slice_scatter_default_945 = slice_scatter_default_946 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7823: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7789, 2, 16, 32);  slice_7789 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_240: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7823, memory_format = torch.contiguous_format);  slice_7823 = None
        view_484: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_240, [32, 11]);  clone_240 = None
        mm_237: "f32[32, 8]" = torch.ops.aten.mm.default(view_484, slice_37)
        view_485: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_237, [2, 16, 8]);  mm_237 = None
        slice_7830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_947, 1, 1888, 1904)
        slice_7831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7830, 2, 0, 16);  slice_7830 = None
        add_239: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7831, view_485);  slice_7831 = view_485 = None
        
        # No stacktrace found for following nodes
        slice_tensor_474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_947, 1, 1888, 1904)
        slice_scatter_default_948: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_474, add_239, 2, 0, 16);  slice_tensor_474 = add_239 = None
        slice_scatter_default_949: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_947, slice_scatter_default_948, 1, 1888, 1904);  slice_scatter_default_947 = slice_scatter_default_948 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_949, 1, 1888, 1904)
        slice_7836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7835, 2, 0, 16);  slice_7835 = None
        
        # No stacktrace found for following nodes
        slice_tensor_475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_949, 1, 1888, 1904)
        slice_scatter_default_950: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_475, slice_7836, 2, 0, 16);  slice_tensor_475 = slice_7836 = None
        slice_scatter_default_951: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_949, slice_scatter_default_950, 1, 1888, 1904);  slice_scatter_default_949 = slice_scatter_default_950 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7855: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1904, 1920)
        slice_7856: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7855, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_241: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7856, memory_format = torch.contiguous_format);  slice_7856 = None
        view_486: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_241, [32, 16]);  clone_241 = None
        mm_238: "f32[32, 8]" = torch.ops.aten.mm.default(view_486, slice_7)
        view_487: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_238, [2, 16, 8]);  mm_238 = None
        slice_7863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_951, 1, 1904, 1920)
        slice_7864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7863, 2, 0, 16);  slice_7863 = None
        add_240: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7864, view_487);  slice_7864 = view_487 = None
        
        # No stacktrace found for following nodes
        slice_tensor_476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_951, 1, 1904, 1920)
        slice_scatter_default_952: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_476, add_240, 2, 0, 16);  slice_tensor_476 = add_240 = None
        slice_scatter_default_953: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_951, slice_scatter_default_952, 1, 1904, 1920);  slice_scatter_default_951 = slice_scatter_default_952 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_953, 1, 1904, 1920)
        slice_7869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7868, 2, 0, 16);  slice_7868 = None
        
        # No stacktrace found for following nodes
        slice_tensor_477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_953, 1, 1904, 1920)
        slice_scatter_default_954: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_477, slice_7869, 2, 0, 16);  slice_tensor_477 = slice_7869 = None
        slice_scatter_default_955: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_953, slice_scatter_default_954, 1, 1904, 1920);  slice_scatter_default_953 = slice_scatter_default_954 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7889: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7855, 2, 16, 32);  slice_7855 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_242: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7889, memory_format = torch.contiguous_format);  slice_7889 = None
        view_488: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_242, [32, 11]);  clone_242 = None
        mm_239: "f32[32, 8]" = torch.ops.aten.mm.default(view_488, slice_37)
        view_489: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_239, [2, 16, 8]);  mm_239 = None
        slice_7896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_955, 1, 1904, 1920)
        slice_7897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7896, 2, 0, 16);  slice_7896 = None
        add_241: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7897, view_489);  slice_7897 = view_489 = None
        
        # No stacktrace found for following nodes
        slice_tensor_478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_955, 1, 1904, 1920)
        slice_scatter_default_956: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_478, add_241, 2, 0, 16);  slice_tensor_478 = add_241 = None
        slice_scatter_default_957: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_955, slice_scatter_default_956, 1, 1904, 1920);  slice_scatter_default_955 = slice_scatter_default_956 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_957, 1, 1904, 1920)
        slice_7902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7901, 2, 0, 16);  slice_7901 = None
        
        # No stacktrace found for following nodes
        slice_tensor_479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_957, 1, 1904, 1920)
        slice_scatter_default_958: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_479, slice_7902, 2, 0, 16);  slice_tensor_479 = slice_7902 = None
        slice_scatter_default_959: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_957, slice_scatter_default_958, 1, 1904, 1920);  slice_scatter_default_957 = slice_scatter_default_958 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7921: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1920, 1936)
        slice_7922: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7921, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_243: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7922, memory_format = torch.contiguous_format);  slice_7922 = None
        view_490: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_243, [32, 16]);  clone_243 = None
        mm_240: "f32[32, 8]" = torch.ops.aten.mm.default(view_490, slice_7)
        view_491: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_240, [2, 16, 8]);  mm_240 = None
        slice_7929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_959, 1, 1920, 1936)
        slice_7930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7929, 2, 0, 16);  slice_7929 = None
        add_242: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7930, view_491);  slice_7930 = view_491 = None
        
        # No stacktrace found for following nodes
        slice_tensor_480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_959, 1, 1920, 1936)
        slice_scatter_default_960: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_480, add_242, 2, 0, 16);  slice_tensor_480 = add_242 = None
        slice_scatter_default_961: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_959, slice_scatter_default_960, 1, 1920, 1936);  slice_scatter_default_959 = slice_scatter_default_960 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_961, 1, 1920, 1936)
        slice_7935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7934, 2, 0, 16);  slice_7934 = None
        
        # No stacktrace found for following nodes
        slice_tensor_481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_961, 1, 1920, 1936)
        slice_scatter_default_962: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_481, slice_7935, 2, 0, 16);  slice_tensor_481 = slice_7935 = None
        slice_scatter_default_963: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_961, slice_scatter_default_962, 1, 1920, 1936);  slice_scatter_default_961 = slice_scatter_default_962 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7955: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7921, 2, 16, 32);  slice_7921 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_244: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_7955, memory_format = torch.contiguous_format);  slice_7955 = None
        view_492: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_244, [32, 11]);  clone_244 = None
        mm_241: "f32[32, 8]" = torch.ops.aten.mm.default(view_492, slice_37)
        view_493: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_241, [2, 16, 8]);  mm_241 = None
        slice_7962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_963, 1, 1920, 1936)
        slice_7963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7962, 2, 0, 16);  slice_7962 = None
        add_243: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7963, view_493);  slice_7963 = view_493 = None
        
        # No stacktrace found for following nodes
        slice_tensor_482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_963, 1, 1920, 1936)
        slice_scatter_default_964: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_482, add_243, 2, 0, 16);  slice_tensor_482 = add_243 = None
        slice_scatter_default_965: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_963, slice_scatter_default_964, 1, 1920, 1936);  slice_scatter_default_963 = slice_scatter_default_964 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_7967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_965, 1, 1920, 1936)
        slice_7968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7967, 2, 0, 16);  slice_7967 = None
        
        # No stacktrace found for following nodes
        slice_tensor_483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_965, 1, 1920, 1936)
        slice_scatter_default_966: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_483, slice_7968, 2, 0, 16);  slice_tensor_483 = slice_7968 = None
        slice_scatter_default_967: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_965, slice_scatter_default_966, 1, 1920, 1936);  slice_scatter_default_965 = slice_scatter_default_966 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_7987: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1936, 1952)
        slice_7988: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_7987, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_245: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_7988, memory_format = torch.contiguous_format);  slice_7988 = None
        view_494: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_245, [32, 16]);  clone_245 = None
        mm_242: "f32[32, 8]" = torch.ops.aten.mm.default(view_494, slice_7)
        view_495: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_242, [2, 16, 8]);  mm_242 = None
        slice_7995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_967, 1, 1936, 1952)
        slice_7996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_7995, 2, 0, 16);  slice_7995 = None
        add_244: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_7996, view_495);  slice_7996 = view_495 = None
        
        # No stacktrace found for following nodes
        slice_tensor_484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_967, 1, 1936, 1952)
        slice_scatter_default_968: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_484, add_244, 2, 0, 16);  slice_tensor_484 = add_244 = None
        slice_scatter_default_969: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_967, slice_scatter_default_968, 1, 1936, 1952);  slice_scatter_default_967 = slice_scatter_default_968 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_969, 1, 1936, 1952)
        slice_8001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8000, 2, 0, 16);  slice_8000 = None
        
        # No stacktrace found for following nodes
        slice_tensor_485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_969, 1, 1936, 1952)
        slice_scatter_default_970: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_485, slice_8001, 2, 0, 16);  slice_tensor_485 = slice_8001 = None
        slice_scatter_default_971: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_969, slice_scatter_default_970, 1, 1936, 1952);  slice_scatter_default_969 = slice_scatter_default_970 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8021: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_7987, 2, 16, 32);  slice_7987 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_246: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8021, memory_format = torch.contiguous_format);  slice_8021 = None
        view_496: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_246, [32, 11]);  clone_246 = None
        mm_243: "f32[32, 8]" = torch.ops.aten.mm.default(view_496, slice_37)
        view_497: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_243, [2, 16, 8]);  mm_243 = None
        slice_8028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_971, 1, 1936, 1952)
        slice_8029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8028, 2, 0, 16);  slice_8028 = None
        add_245: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8029, view_497);  slice_8029 = view_497 = None
        
        # No stacktrace found for following nodes
        slice_tensor_486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_971, 1, 1936, 1952)
        slice_scatter_default_972: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_486, add_245, 2, 0, 16);  slice_tensor_486 = add_245 = None
        slice_scatter_default_973: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_971, slice_scatter_default_972, 1, 1936, 1952);  slice_scatter_default_971 = slice_scatter_default_972 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_973, 1, 1936, 1952)
        slice_8034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8033, 2, 0, 16);  slice_8033 = None
        
        # No stacktrace found for following nodes
        slice_tensor_487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_973, 1, 1936, 1952)
        slice_scatter_default_974: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_487, slice_8034, 2, 0, 16);  slice_tensor_487 = slice_8034 = None
        slice_scatter_default_975: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_973, slice_scatter_default_974, 1, 1936, 1952);  slice_scatter_default_973 = slice_scatter_default_974 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8053: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1952, 1968)
        slice_8054: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8053, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_247: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8054, memory_format = torch.contiguous_format);  slice_8054 = None
        view_498: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_247, [32, 16]);  clone_247 = None
        mm_244: "f32[32, 8]" = torch.ops.aten.mm.default(view_498, slice_7)
        view_499: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_244, [2, 16, 8]);  mm_244 = None
        slice_8061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_975, 1, 1952, 1968)
        slice_8062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8061, 2, 0, 16);  slice_8061 = None
        add_246: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8062, view_499);  slice_8062 = view_499 = None
        
        # No stacktrace found for following nodes
        slice_tensor_488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_975, 1, 1952, 1968)
        slice_scatter_default_976: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_488, add_246, 2, 0, 16);  slice_tensor_488 = add_246 = None
        slice_scatter_default_977: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_975, slice_scatter_default_976, 1, 1952, 1968);  slice_scatter_default_975 = slice_scatter_default_976 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_977, 1, 1952, 1968)
        slice_8067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8066, 2, 0, 16);  slice_8066 = None
        
        # No stacktrace found for following nodes
        slice_tensor_489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_977, 1, 1952, 1968)
        slice_scatter_default_978: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_489, slice_8067, 2, 0, 16);  slice_tensor_489 = slice_8067 = None
        slice_scatter_default_979: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_977, slice_scatter_default_978, 1, 1952, 1968);  slice_scatter_default_977 = slice_scatter_default_978 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8087: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8053, 2, 16, 32);  slice_8053 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_248: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8087, memory_format = torch.contiguous_format);  slice_8087 = None
        view_500: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_248, [32, 11]);  clone_248 = None
        mm_245: "f32[32, 8]" = torch.ops.aten.mm.default(view_500, slice_37)
        view_501: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_245, [2, 16, 8]);  mm_245 = None
        slice_8094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_979, 1, 1952, 1968)
        slice_8095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8094, 2, 0, 16);  slice_8094 = None
        add_247: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8095, view_501);  slice_8095 = view_501 = None
        
        # No stacktrace found for following nodes
        slice_tensor_490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_979, 1, 1952, 1968)
        slice_scatter_default_980: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_490, add_247, 2, 0, 16);  slice_tensor_490 = add_247 = None
        slice_scatter_default_981: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_979, slice_scatter_default_980, 1, 1952, 1968);  slice_scatter_default_979 = slice_scatter_default_980 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_981, 1, 1952, 1968)
        slice_8100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8099, 2, 0, 16);  slice_8099 = None
        
        # No stacktrace found for following nodes
        slice_tensor_491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_981, 1, 1952, 1968)
        slice_scatter_default_982: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_491, slice_8100, 2, 0, 16);  slice_tensor_491 = slice_8100 = None
        slice_scatter_default_983: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_981, slice_scatter_default_982, 1, 1952, 1968);  slice_scatter_default_981 = slice_scatter_default_982 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8119: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1968, 1984)
        slice_8120: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8119, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_249: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8120, memory_format = torch.contiguous_format);  slice_8120 = None
        view_502: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_249, [32, 16]);  clone_249 = None
        mm_246: "f32[32, 8]" = torch.ops.aten.mm.default(view_502, slice_7)
        view_503: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_246, [2, 16, 8]);  mm_246 = None
        slice_8127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_983, 1, 1968, 1984)
        slice_8128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8127, 2, 0, 16);  slice_8127 = None
        add_248: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8128, view_503);  slice_8128 = view_503 = None
        
        # No stacktrace found for following nodes
        slice_tensor_492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_983, 1, 1968, 1984)
        slice_scatter_default_984: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_492, add_248, 2, 0, 16);  slice_tensor_492 = add_248 = None
        slice_scatter_default_985: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_983, slice_scatter_default_984, 1, 1968, 1984);  slice_scatter_default_983 = slice_scatter_default_984 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_985, 1, 1968, 1984)
        slice_8133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8132, 2, 0, 16);  slice_8132 = None
        
        # No stacktrace found for following nodes
        slice_tensor_493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_985, 1, 1968, 1984)
        slice_scatter_default_986: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_493, slice_8133, 2, 0, 16);  slice_tensor_493 = slice_8133 = None
        slice_scatter_default_987: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_985, slice_scatter_default_986, 1, 1968, 1984);  slice_scatter_default_985 = slice_scatter_default_986 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8153: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8119, 2, 16, 32);  slice_8119 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_250: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8153, memory_format = torch.contiguous_format);  slice_8153 = None
        view_504: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_250, [32, 11]);  clone_250 = None
        mm_247: "f32[32, 8]" = torch.ops.aten.mm.default(view_504, slice_37)
        view_505: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_247, [2, 16, 8]);  mm_247 = None
        slice_8160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_987, 1, 1968, 1984)
        slice_8161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8160, 2, 0, 16);  slice_8160 = None
        add_249: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8161, view_505);  slice_8161 = view_505 = None
        
        # No stacktrace found for following nodes
        slice_tensor_494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_987, 1, 1968, 1984)
        slice_scatter_default_988: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_494, add_249, 2, 0, 16);  slice_tensor_494 = add_249 = None
        slice_scatter_default_989: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_987, slice_scatter_default_988, 1, 1968, 1984);  slice_scatter_default_987 = slice_scatter_default_988 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_989, 1, 1968, 1984)
        slice_8166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8165, 2, 0, 16);  slice_8165 = None
        
        # No stacktrace found for following nodes
        slice_tensor_495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_989, 1, 1968, 1984)
        slice_scatter_default_990: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_495, slice_8166, 2, 0, 16);  slice_tensor_495 = slice_8166 = None
        slice_scatter_default_991: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_989, slice_scatter_default_990, 1, 1968, 1984);  slice_scatter_default_989 = slice_scatter_default_990 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8185: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 1984, 2000)
        slice_8186: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8185, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_251: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8186, memory_format = torch.contiguous_format);  slice_8186 = None
        view_506: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_251, [32, 16]);  clone_251 = None
        mm_248: "f32[32, 8]" = torch.ops.aten.mm.default(view_506, slice_7)
        view_507: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_248, [2, 16, 8]);  mm_248 = None
        slice_8193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_991, 1, 1984, 2000)
        slice_8194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8193, 2, 0, 16);  slice_8193 = None
        add_250: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8194, view_507);  slice_8194 = view_507 = None
        
        # No stacktrace found for following nodes
        slice_tensor_496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_991, 1, 1984, 2000)
        slice_scatter_default_992: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_496, add_250, 2, 0, 16);  slice_tensor_496 = add_250 = None
        slice_scatter_default_993: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_991, slice_scatter_default_992, 1, 1984, 2000);  slice_scatter_default_991 = slice_scatter_default_992 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_993, 1, 1984, 2000)
        slice_8199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8198, 2, 0, 16);  slice_8198 = None
        
        # No stacktrace found for following nodes
        slice_tensor_497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_993, 1, 1984, 2000)
        slice_scatter_default_994: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_497, slice_8199, 2, 0, 16);  slice_tensor_497 = slice_8199 = None
        slice_scatter_default_995: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_993, slice_scatter_default_994, 1, 1984, 2000);  slice_scatter_default_993 = slice_scatter_default_994 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8219: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8185, 2, 16, 32);  slice_8185 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_252: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8219, memory_format = torch.contiguous_format);  slice_8219 = None
        view_508: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_252, [32, 11]);  clone_252 = None
        mm_249: "f32[32, 8]" = torch.ops.aten.mm.default(view_508, slice_37)
        view_509: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_249, [2, 16, 8]);  mm_249 = None
        slice_8226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_995, 1, 1984, 2000)
        slice_8227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8226, 2, 0, 16);  slice_8226 = None
        add_251: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8227, view_509);  slice_8227 = view_509 = None
        
        # No stacktrace found for following nodes
        slice_tensor_498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_995, 1, 1984, 2000)
        slice_scatter_default_996: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_498, add_251, 2, 0, 16);  slice_tensor_498 = add_251 = None
        slice_scatter_default_997: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_995, slice_scatter_default_996, 1, 1984, 2000);  slice_scatter_default_995 = slice_scatter_default_996 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_997, 1, 1984, 2000)
        slice_8232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8231, 2, 0, 16);  slice_8231 = None
        
        # No stacktrace found for following nodes
        slice_tensor_499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_997, 1, 1984, 2000)
        slice_scatter_default_998: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_499, slice_8232, 2, 0, 16);  slice_tensor_499 = slice_8232 = None
        slice_scatter_default_999: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_997, slice_scatter_default_998, 1, 1984, 2000);  slice_scatter_default_997 = slice_scatter_default_998 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8251: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2000, 2016)
        slice_8252: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8251, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_253: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8252, memory_format = torch.contiguous_format);  slice_8252 = None
        view_510: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_253, [32, 16]);  clone_253 = None
        mm_250: "f32[32, 8]" = torch.ops.aten.mm.default(view_510, slice_7)
        view_511: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_250, [2, 16, 8]);  mm_250 = None
        slice_8259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_999, 1, 2000, 2016)
        slice_8260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8259, 2, 0, 16);  slice_8259 = None
        add_252: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8260, view_511);  slice_8260 = view_511 = None
        
        # No stacktrace found for following nodes
        slice_tensor_500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_999, 1, 2000, 2016)
        slice_scatter_default_1000: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_500, add_252, 2, 0, 16);  slice_tensor_500 = add_252 = None
        slice_scatter_default_1001: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_999, slice_scatter_default_1000, 1, 2000, 2016);  slice_scatter_default_999 = slice_scatter_default_1000 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1001, 1, 2000, 2016)
        slice_8265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8264, 2, 0, 16);  slice_8264 = None
        
        # No stacktrace found for following nodes
        slice_tensor_501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1001, 1, 2000, 2016)
        slice_scatter_default_1002: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_501, slice_8265, 2, 0, 16);  slice_tensor_501 = slice_8265 = None
        slice_scatter_default_1003: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1001, slice_scatter_default_1002, 1, 2000, 2016);  slice_scatter_default_1001 = slice_scatter_default_1002 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8285: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8251, 2, 16, 32);  slice_8251 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_254: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8285, memory_format = torch.contiguous_format);  slice_8285 = None
        view_512: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_254, [32, 11]);  clone_254 = None
        mm_251: "f32[32, 8]" = torch.ops.aten.mm.default(view_512, slice_37)
        view_513: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_251, [2, 16, 8]);  mm_251 = None
        slice_8292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1003, 1, 2000, 2016)
        slice_8293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8292, 2, 0, 16);  slice_8292 = None
        add_253: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8293, view_513);  slice_8293 = view_513 = None
        
        # No stacktrace found for following nodes
        slice_tensor_502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1003, 1, 2000, 2016)
        slice_scatter_default_1004: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_502, add_253, 2, 0, 16);  slice_tensor_502 = add_253 = None
        slice_scatter_default_1005: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1003, slice_scatter_default_1004, 1, 2000, 2016);  slice_scatter_default_1003 = slice_scatter_default_1004 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1005, 1, 2000, 2016)
        slice_8298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8297, 2, 0, 16);  slice_8297 = None
        
        # No stacktrace found for following nodes
        slice_tensor_503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1005, 1, 2000, 2016)
        slice_scatter_default_1006: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_503, slice_8298, 2, 0, 16);  slice_tensor_503 = slice_8298 = None
        slice_scatter_default_1007: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1005, slice_scatter_default_1006, 1, 2000, 2016);  slice_scatter_default_1005 = slice_scatter_default_1006 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8317: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2016, 2032)
        slice_8318: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8317, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_255: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8318, memory_format = torch.contiguous_format);  slice_8318 = None
        view_514: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_255, [32, 16]);  clone_255 = None
        mm_252: "f32[32, 8]" = torch.ops.aten.mm.default(view_514, slice_7)
        view_515: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_252, [2, 16, 8]);  mm_252 = None
        slice_8325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1007, 1, 2016, 2032)
        slice_8326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8325, 2, 0, 16);  slice_8325 = None
        add_254: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8326, view_515);  slice_8326 = view_515 = None
        
        # No stacktrace found for following nodes
        slice_tensor_504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1007, 1, 2016, 2032)
        slice_scatter_default_1008: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_504, add_254, 2, 0, 16);  slice_tensor_504 = add_254 = None
        slice_scatter_default_1009: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1007, slice_scatter_default_1008, 1, 2016, 2032);  slice_scatter_default_1007 = slice_scatter_default_1008 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1009, 1, 2016, 2032)
        slice_8331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8330, 2, 0, 16);  slice_8330 = None
        
        # No stacktrace found for following nodes
        slice_tensor_505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1009, 1, 2016, 2032)
        slice_scatter_default_1010: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_505, slice_8331, 2, 0, 16);  slice_tensor_505 = slice_8331 = None
        slice_scatter_default_1011: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1009, slice_scatter_default_1010, 1, 2016, 2032);  slice_scatter_default_1009 = slice_scatter_default_1010 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8351: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8317, 2, 16, 32);  slice_8317 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_256: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8351, memory_format = torch.contiguous_format);  slice_8351 = None
        view_516: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_256, [32, 11]);  clone_256 = None
        mm_253: "f32[32, 8]" = torch.ops.aten.mm.default(view_516, slice_37)
        view_517: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_253, [2, 16, 8]);  mm_253 = None
        slice_8358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1011, 1, 2016, 2032)
        slice_8359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8358, 2, 0, 16);  slice_8358 = None
        add_255: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8359, view_517);  slice_8359 = view_517 = None
        
        # No stacktrace found for following nodes
        slice_tensor_506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1011, 1, 2016, 2032)
        slice_scatter_default_1012: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_506, add_255, 2, 0, 16);  slice_tensor_506 = add_255 = None
        slice_scatter_default_1013: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1011, slice_scatter_default_1012, 1, 2016, 2032);  slice_scatter_default_1011 = slice_scatter_default_1012 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1013, 1, 2016, 2032)
        slice_8364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8363, 2, 0, 16);  slice_8363 = None
        
        # No stacktrace found for following nodes
        slice_tensor_507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1013, 1, 2016, 2032)
        slice_scatter_default_1014: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_507, slice_8364, 2, 0, 16);  slice_tensor_507 = slice_8364 = None
        slice_scatter_default_1015: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1013, slice_scatter_default_1014, 1, 2016, 2032);  slice_scatter_default_1013 = slice_scatter_default_1014 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8383: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2032, 2048)
        slice_8384: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8383, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_257: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8384, memory_format = torch.contiguous_format);  slice_8384 = None
        view_518: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_257, [32, 16]);  clone_257 = None
        mm_254: "f32[32, 8]" = torch.ops.aten.mm.default(view_518, slice_7)
        view_519: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_254, [2, 16, 8]);  mm_254 = None
        slice_8391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1015, 1, 2032, 2048)
        slice_8392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8391, 2, 0, 16);  slice_8391 = None
        add_256: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8392, view_519);  slice_8392 = view_519 = None
        
        # No stacktrace found for following nodes
        slice_tensor_508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1015, 1, 2032, 2048)
        slice_scatter_default_1016: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_508, add_256, 2, 0, 16);  slice_tensor_508 = add_256 = None
        slice_scatter_default_1017: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1015, slice_scatter_default_1016, 1, 2032, 2048);  slice_scatter_default_1015 = slice_scatter_default_1016 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1017, 1, 2032, 2048)
        slice_8397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8396, 2, 0, 16);  slice_8396 = None
        
        # No stacktrace found for following nodes
        slice_tensor_509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1017, 1, 2032, 2048)
        slice_scatter_default_1018: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_509, slice_8397, 2, 0, 16);  slice_tensor_509 = slice_8397 = None
        slice_scatter_default_1019: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1017, slice_scatter_default_1018, 1, 2032, 2048);  slice_scatter_default_1017 = slice_scatter_default_1018 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8417: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8383, 2, 16, 32);  slice_8383 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_258: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8417, memory_format = torch.contiguous_format);  slice_8417 = None
        view_520: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_258, [32, 11]);  clone_258 = None
        mm_255: "f32[32, 8]" = torch.ops.aten.mm.default(view_520, slice_37)
        view_521: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_255, [2, 16, 8]);  mm_255 = None
        slice_8424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1019, 1, 2032, 2048)
        slice_8425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8424, 2, 0, 16);  slice_8424 = None
        add_257: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8425, view_521);  slice_8425 = view_521 = None
        
        # No stacktrace found for following nodes
        slice_tensor_510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1019, 1, 2032, 2048)
        slice_scatter_default_1020: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_510, add_257, 2, 0, 16);  slice_tensor_510 = add_257 = None
        slice_scatter_default_1021: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1019, slice_scatter_default_1020, 1, 2032, 2048);  slice_scatter_default_1019 = slice_scatter_default_1020 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1021, 1, 2032, 2048)
        slice_8430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8429, 2, 0, 16);  slice_8429 = None
        
        # No stacktrace found for following nodes
        slice_tensor_511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1021, 1, 2032, 2048)
        slice_scatter_default_1022: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_511, slice_8430, 2, 0, 16);  slice_tensor_511 = slice_8430 = None
        slice_scatter_default_1023: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1021, slice_scatter_default_1022, 1, 2032, 2048);  slice_scatter_default_1021 = slice_scatter_default_1022 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8449: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2048, 2064)
        slice_8450: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8449, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_259: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8450, memory_format = torch.contiguous_format);  slice_8450 = None
        view_522: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_259, [32, 16]);  clone_259 = None
        mm_256: "f32[32, 8]" = torch.ops.aten.mm.default(view_522, slice_7)
        view_523: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_256, [2, 16, 8]);  mm_256 = None
        slice_8457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1023, 1, 2048, 2064)
        slice_8458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8457, 2, 0, 16);  slice_8457 = None
        add_258: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8458, view_523);  slice_8458 = view_523 = None
        
        # No stacktrace found for following nodes
        slice_tensor_512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1023, 1, 2048, 2064)
        slice_scatter_default_1024: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_512, add_258, 2, 0, 16);  slice_tensor_512 = add_258 = None
        slice_scatter_default_1025: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1023, slice_scatter_default_1024, 1, 2048, 2064);  slice_scatter_default_1023 = slice_scatter_default_1024 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1025, 1, 2048, 2064)
        slice_8463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8462, 2, 0, 16);  slice_8462 = None
        
        # No stacktrace found for following nodes
        slice_tensor_513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1025, 1, 2048, 2064)
        slice_scatter_default_1026: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_513, slice_8463, 2, 0, 16);  slice_tensor_513 = slice_8463 = None
        slice_scatter_default_1027: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1025, slice_scatter_default_1026, 1, 2048, 2064);  slice_scatter_default_1025 = slice_scatter_default_1026 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8483: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8449, 2, 16, 32);  slice_8449 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_260: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8483, memory_format = torch.contiguous_format);  slice_8483 = None
        view_524: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_260, [32, 11]);  clone_260 = None
        mm_257: "f32[32, 8]" = torch.ops.aten.mm.default(view_524, slice_37)
        view_525: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_257, [2, 16, 8]);  mm_257 = None
        slice_8490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1027, 1, 2048, 2064)
        slice_8491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8490, 2, 0, 16);  slice_8490 = None
        add_259: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8491, view_525);  slice_8491 = view_525 = None
        
        # No stacktrace found for following nodes
        slice_tensor_514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1027, 1, 2048, 2064)
        slice_scatter_default_1028: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_514, add_259, 2, 0, 16);  slice_tensor_514 = add_259 = None
        slice_scatter_default_1029: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1027, slice_scatter_default_1028, 1, 2048, 2064);  slice_scatter_default_1027 = slice_scatter_default_1028 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1029, 1, 2048, 2064)
        slice_8496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8495, 2, 0, 16);  slice_8495 = None
        
        # No stacktrace found for following nodes
        slice_tensor_515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1029, 1, 2048, 2064)
        slice_scatter_default_1030: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_515, slice_8496, 2, 0, 16);  slice_tensor_515 = slice_8496 = None
        slice_scatter_default_1031: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1029, slice_scatter_default_1030, 1, 2048, 2064);  slice_scatter_default_1029 = slice_scatter_default_1030 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8515: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2064, 2080)
        slice_8516: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8515, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_261: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8516, memory_format = torch.contiguous_format);  slice_8516 = None
        view_526: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_261, [32, 16]);  clone_261 = None
        mm_258: "f32[32, 8]" = torch.ops.aten.mm.default(view_526, slice_7)
        view_527: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_258, [2, 16, 8]);  mm_258 = None
        slice_8523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1031, 1, 2064, 2080)
        slice_8524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8523, 2, 0, 16);  slice_8523 = None
        add_260: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8524, view_527);  slice_8524 = view_527 = None
        
        # No stacktrace found for following nodes
        slice_tensor_516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1031, 1, 2064, 2080)
        slice_scatter_default_1032: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_516, add_260, 2, 0, 16);  slice_tensor_516 = add_260 = None
        slice_scatter_default_1033: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1031, slice_scatter_default_1032, 1, 2064, 2080);  slice_scatter_default_1031 = slice_scatter_default_1032 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1033, 1, 2064, 2080)
        slice_8529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8528, 2, 0, 16);  slice_8528 = None
        
        # No stacktrace found for following nodes
        slice_tensor_517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1033, 1, 2064, 2080)
        slice_scatter_default_1034: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_517, slice_8529, 2, 0, 16);  slice_tensor_517 = slice_8529 = None
        slice_scatter_default_1035: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1033, slice_scatter_default_1034, 1, 2064, 2080);  slice_scatter_default_1033 = slice_scatter_default_1034 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8549: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8515, 2, 16, 32);  slice_8515 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_262: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8549, memory_format = torch.contiguous_format);  slice_8549 = None
        view_528: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_262, [32, 11]);  clone_262 = None
        mm_259: "f32[32, 8]" = torch.ops.aten.mm.default(view_528, slice_37)
        view_529: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_259, [2, 16, 8]);  mm_259 = None
        slice_8556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1035, 1, 2064, 2080)
        slice_8557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8556, 2, 0, 16);  slice_8556 = None
        add_261: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8557, view_529);  slice_8557 = view_529 = None
        
        # No stacktrace found for following nodes
        slice_tensor_518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1035, 1, 2064, 2080)
        slice_scatter_default_1036: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_518, add_261, 2, 0, 16);  slice_tensor_518 = add_261 = None
        slice_scatter_default_1037: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1035, slice_scatter_default_1036, 1, 2064, 2080);  slice_scatter_default_1035 = slice_scatter_default_1036 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1037, 1, 2064, 2080)
        slice_8562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8561, 2, 0, 16);  slice_8561 = None
        
        # No stacktrace found for following nodes
        slice_tensor_519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1037, 1, 2064, 2080)
        slice_scatter_default_1038: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_519, slice_8562, 2, 0, 16);  slice_tensor_519 = slice_8562 = None
        slice_scatter_default_1039: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1037, slice_scatter_default_1038, 1, 2064, 2080);  slice_scatter_default_1037 = slice_scatter_default_1038 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8581: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2080, 2096)
        slice_8582: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8581, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_263: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8582, memory_format = torch.contiguous_format);  slice_8582 = None
        view_530: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_263, [32, 16]);  clone_263 = None
        mm_260: "f32[32, 8]" = torch.ops.aten.mm.default(view_530, slice_7)
        view_531: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_260, [2, 16, 8]);  mm_260 = None
        slice_8589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1039, 1, 2080, 2096)
        slice_8590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8589, 2, 0, 16);  slice_8589 = None
        add_262: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8590, view_531);  slice_8590 = view_531 = None
        
        # No stacktrace found for following nodes
        slice_tensor_520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1039, 1, 2080, 2096)
        slice_scatter_default_1040: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_520, add_262, 2, 0, 16);  slice_tensor_520 = add_262 = None
        slice_scatter_default_1041: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1039, slice_scatter_default_1040, 1, 2080, 2096);  slice_scatter_default_1039 = slice_scatter_default_1040 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1041, 1, 2080, 2096)
        slice_8595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8594, 2, 0, 16);  slice_8594 = None
        
        # No stacktrace found for following nodes
        slice_tensor_521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1041, 1, 2080, 2096)
        slice_scatter_default_1042: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_521, slice_8595, 2, 0, 16);  slice_tensor_521 = slice_8595 = None
        slice_scatter_default_1043: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1041, slice_scatter_default_1042, 1, 2080, 2096);  slice_scatter_default_1041 = slice_scatter_default_1042 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8615: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8581, 2, 16, 32);  slice_8581 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_264: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8615, memory_format = torch.contiguous_format);  slice_8615 = None
        view_532: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_264, [32, 11]);  clone_264 = None
        mm_261: "f32[32, 8]" = torch.ops.aten.mm.default(view_532, slice_37)
        view_533: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_261, [2, 16, 8]);  mm_261 = None
        slice_8622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1043, 1, 2080, 2096)
        slice_8623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8622, 2, 0, 16);  slice_8622 = None
        add_263: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8623, view_533);  slice_8623 = view_533 = None
        
        # No stacktrace found for following nodes
        slice_tensor_522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1043, 1, 2080, 2096)
        slice_scatter_default_1044: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_522, add_263, 2, 0, 16);  slice_tensor_522 = add_263 = None
        slice_scatter_default_1045: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1043, slice_scatter_default_1044, 1, 2080, 2096);  slice_scatter_default_1043 = slice_scatter_default_1044 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1045, 1, 2080, 2096)
        slice_8628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8627, 2, 0, 16);  slice_8627 = None
        
        # No stacktrace found for following nodes
        slice_tensor_523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1045, 1, 2080, 2096)
        slice_scatter_default_1046: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_523, slice_8628, 2, 0, 16);  slice_tensor_523 = slice_8628 = None
        slice_scatter_default_1047: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1045, slice_scatter_default_1046, 1, 2080, 2096);  slice_scatter_default_1045 = slice_scatter_default_1046 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8647: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2096, 2112)
        slice_8648: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8647, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_265: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8648, memory_format = torch.contiguous_format);  slice_8648 = None
        view_534: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_265, [32, 16]);  clone_265 = None
        mm_262: "f32[32, 8]" = torch.ops.aten.mm.default(view_534, slice_7)
        view_535: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_262, [2, 16, 8]);  mm_262 = None
        slice_8655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1047, 1, 2096, 2112)
        slice_8656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8655, 2, 0, 16);  slice_8655 = None
        add_264: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8656, view_535);  slice_8656 = view_535 = None
        
        # No stacktrace found for following nodes
        slice_tensor_524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1047, 1, 2096, 2112)
        slice_scatter_default_1048: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_524, add_264, 2, 0, 16);  slice_tensor_524 = add_264 = None
        slice_scatter_default_1049: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1047, slice_scatter_default_1048, 1, 2096, 2112);  slice_scatter_default_1047 = slice_scatter_default_1048 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1049, 1, 2096, 2112)
        slice_8661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8660, 2, 0, 16);  slice_8660 = None
        
        # No stacktrace found for following nodes
        slice_tensor_525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1049, 1, 2096, 2112)
        slice_scatter_default_1050: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_525, slice_8661, 2, 0, 16);  slice_tensor_525 = slice_8661 = None
        slice_scatter_default_1051: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1049, slice_scatter_default_1050, 1, 2096, 2112);  slice_scatter_default_1049 = slice_scatter_default_1050 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8681: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8647, 2, 16, 32);  slice_8647 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_266: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8681, memory_format = torch.contiguous_format);  slice_8681 = None
        view_536: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_266, [32, 11]);  clone_266 = None
        mm_263: "f32[32, 8]" = torch.ops.aten.mm.default(view_536, slice_37)
        view_537: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_263, [2, 16, 8]);  mm_263 = None
        slice_8688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1051, 1, 2096, 2112)
        slice_8689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8688, 2, 0, 16);  slice_8688 = None
        add_265: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8689, view_537);  slice_8689 = view_537 = None
        
        # No stacktrace found for following nodes
        slice_tensor_526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1051, 1, 2096, 2112)
        slice_scatter_default_1052: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_526, add_265, 2, 0, 16);  slice_tensor_526 = add_265 = None
        slice_scatter_default_1053: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1051, slice_scatter_default_1052, 1, 2096, 2112);  slice_scatter_default_1051 = slice_scatter_default_1052 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1053, 1, 2096, 2112)
        slice_8694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8693, 2, 0, 16);  slice_8693 = None
        
        # No stacktrace found for following nodes
        slice_tensor_527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1053, 1, 2096, 2112)
        slice_scatter_default_1054: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_527, slice_8694, 2, 0, 16);  slice_tensor_527 = slice_8694 = None
        slice_scatter_default_1055: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1053, slice_scatter_default_1054, 1, 2096, 2112);  slice_scatter_default_1053 = slice_scatter_default_1054 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8713: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2112, 2128)
        slice_8714: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8713, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_267: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8714, memory_format = torch.contiguous_format);  slice_8714 = None
        view_538: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_267, [32, 16]);  clone_267 = None
        mm_264: "f32[32, 8]" = torch.ops.aten.mm.default(view_538, slice_7)
        view_539: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_264, [2, 16, 8]);  mm_264 = None
        slice_8721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1055, 1, 2112, 2128)
        slice_8722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8721, 2, 0, 16);  slice_8721 = None
        add_266: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8722, view_539);  slice_8722 = view_539 = None
        
        # No stacktrace found for following nodes
        slice_tensor_528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1055, 1, 2112, 2128)
        slice_scatter_default_1056: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_528, add_266, 2, 0, 16);  slice_tensor_528 = add_266 = None
        slice_scatter_default_1057: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1055, slice_scatter_default_1056, 1, 2112, 2128);  slice_scatter_default_1055 = slice_scatter_default_1056 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1057, 1, 2112, 2128)
        slice_8727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8726, 2, 0, 16);  slice_8726 = None
        
        # No stacktrace found for following nodes
        slice_tensor_529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1057, 1, 2112, 2128)
        slice_scatter_default_1058: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_529, slice_8727, 2, 0, 16);  slice_tensor_529 = slice_8727 = None
        slice_scatter_default_1059: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1057, slice_scatter_default_1058, 1, 2112, 2128);  slice_scatter_default_1057 = slice_scatter_default_1058 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8747: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8713, 2, 16, 32);  slice_8713 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_268: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8747, memory_format = torch.contiguous_format);  slice_8747 = None
        view_540: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_268, [32, 11]);  clone_268 = None
        mm_265: "f32[32, 8]" = torch.ops.aten.mm.default(view_540, slice_37)
        view_541: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_265, [2, 16, 8]);  mm_265 = None
        slice_8754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1059, 1, 2112, 2128)
        slice_8755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8754, 2, 0, 16);  slice_8754 = None
        add_267: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8755, view_541);  slice_8755 = view_541 = None
        
        # No stacktrace found for following nodes
        slice_tensor_530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1059, 1, 2112, 2128)
        slice_scatter_default_1060: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_530, add_267, 2, 0, 16);  slice_tensor_530 = add_267 = None
        slice_scatter_default_1061: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1059, slice_scatter_default_1060, 1, 2112, 2128);  slice_scatter_default_1059 = slice_scatter_default_1060 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1061, 1, 2112, 2128)
        slice_8760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8759, 2, 0, 16);  slice_8759 = None
        
        # No stacktrace found for following nodes
        slice_tensor_531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1061, 1, 2112, 2128)
        slice_scatter_default_1062: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_531, slice_8760, 2, 0, 16);  slice_tensor_531 = slice_8760 = None
        slice_scatter_default_1063: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1061, slice_scatter_default_1062, 1, 2112, 2128);  slice_scatter_default_1061 = slice_scatter_default_1062 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8779: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2128, 2144)
        slice_8780: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8779, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_269: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8780, memory_format = torch.contiguous_format);  slice_8780 = None
        view_542: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_269, [32, 16]);  clone_269 = None
        mm_266: "f32[32, 8]" = torch.ops.aten.mm.default(view_542, slice_7)
        view_543: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_266, [2, 16, 8]);  mm_266 = None
        slice_8787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1063, 1, 2128, 2144)
        slice_8788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8787, 2, 0, 16);  slice_8787 = None
        add_268: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8788, view_543);  slice_8788 = view_543 = None
        
        # No stacktrace found for following nodes
        slice_tensor_532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1063, 1, 2128, 2144)
        slice_scatter_default_1064: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_532, add_268, 2, 0, 16);  slice_tensor_532 = add_268 = None
        slice_scatter_default_1065: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1063, slice_scatter_default_1064, 1, 2128, 2144);  slice_scatter_default_1063 = slice_scatter_default_1064 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1065, 1, 2128, 2144)
        slice_8793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8792, 2, 0, 16);  slice_8792 = None
        
        # No stacktrace found for following nodes
        slice_tensor_533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1065, 1, 2128, 2144)
        slice_scatter_default_1066: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_533, slice_8793, 2, 0, 16);  slice_tensor_533 = slice_8793 = None
        slice_scatter_default_1067: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1065, slice_scatter_default_1066, 1, 2128, 2144);  slice_scatter_default_1065 = slice_scatter_default_1066 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8813: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8779, 2, 16, 32);  slice_8779 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_270: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8813, memory_format = torch.contiguous_format);  slice_8813 = None
        view_544: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_270, [32, 11]);  clone_270 = None
        mm_267: "f32[32, 8]" = torch.ops.aten.mm.default(view_544, slice_37)
        view_545: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_267, [2, 16, 8]);  mm_267 = None
        slice_8820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1067, 1, 2128, 2144)
        slice_8821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8820, 2, 0, 16);  slice_8820 = None
        add_269: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8821, view_545);  slice_8821 = view_545 = None
        
        # No stacktrace found for following nodes
        slice_tensor_534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1067, 1, 2128, 2144)
        slice_scatter_default_1068: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_534, add_269, 2, 0, 16);  slice_tensor_534 = add_269 = None
        slice_scatter_default_1069: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1067, slice_scatter_default_1068, 1, 2128, 2144);  slice_scatter_default_1067 = slice_scatter_default_1068 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1069, 1, 2128, 2144)
        slice_8826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8825, 2, 0, 16);  slice_8825 = None
        
        # No stacktrace found for following nodes
        slice_tensor_535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1069, 1, 2128, 2144)
        slice_scatter_default_1070: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_535, slice_8826, 2, 0, 16);  slice_tensor_535 = slice_8826 = None
        slice_scatter_default_1071: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1069, slice_scatter_default_1070, 1, 2128, 2144);  slice_scatter_default_1069 = slice_scatter_default_1070 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8845: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2144, 2160)
        slice_8846: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8845, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_271: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8846, memory_format = torch.contiguous_format);  slice_8846 = None
        view_546: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_271, [32, 16]);  clone_271 = None
        mm_268: "f32[32, 8]" = torch.ops.aten.mm.default(view_546, slice_7)
        view_547: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_268, [2, 16, 8]);  mm_268 = None
        slice_8853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1071, 1, 2144, 2160)
        slice_8854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8853, 2, 0, 16);  slice_8853 = None
        add_270: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8854, view_547);  slice_8854 = view_547 = None
        
        # No stacktrace found for following nodes
        slice_tensor_536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1071, 1, 2144, 2160)
        slice_scatter_default_1072: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_536, add_270, 2, 0, 16);  slice_tensor_536 = add_270 = None
        slice_scatter_default_1073: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1071, slice_scatter_default_1072, 1, 2144, 2160);  slice_scatter_default_1071 = slice_scatter_default_1072 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1073, 1, 2144, 2160)
        slice_8859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8858, 2, 0, 16);  slice_8858 = None
        
        # No stacktrace found for following nodes
        slice_tensor_537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1073, 1, 2144, 2160)
        slice_scatter_default_1074: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_537, slice_8859, 2, 0, 16);  slice_tensor_537 = slice_8859 = None
        slice_scatter_default_1075: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1073, slice_scatter_default_1074, 1, 2144, 2160);  slice_scatter_default_1073 = slice_scatter_default_1074 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8879: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8845, 2, 16, 32);  slice_8845 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_272: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8879, memory_format = torch.contiguous_format);  slice_8879 = None
        view_548: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_272, [32, 11]);  clone_272 = None
        mm_269: "f32[32, 8]" = torch.ops.aten.mm.default(view_548, slice_37)
        view_549: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_269, [2, 16, 8]);  mm_269 = None
        slice_8886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1075, 1, 2144, 2160)
        slice_8887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8886, 2, 0, 16);  slice_8886 = None
        add_271: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8887, view_549);  slice_8887 = view_549 = None
        
        # No stacktrace found for following nodes
        slice_tensor_538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1075, 1, 2144, 2160)
        slice_scatter_default_1076: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_538, add_271, 2, 0, 16);  slice_tensor_538 = add_271 = None
        slice_scatter_default_1077: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1075, slice_scatter_default_1076, 1, 2144, 2160);  slice_scatter_default_1075 = slice_scatter_default_1076 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1077, 1, 2144, 2160)
        slice_8892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8891, 2, 0, 16);  slice_8891 = None
        
        # No stacktrace found for following nodes
        slice_tensor_539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1077, 1, 2144, 2160)
        slice_scatter_default_1078: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_539, slice_8892, 2, 0, 16);  slice_tensor_539 = slice_8892 = None
        slice_scatter_default_1079: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1077, slice_scatter_default_1078, 1, 2144, 2160);  slice_scatter_default_1077 = slice_scatter_default_1078 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8911: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2160, 2176)
        slice_8912: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8911, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_273: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8912, memory_format = torch.contiguous_format);  slice_8912 = None
        view_550: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_273, [32, 16]);  clone_273 = None
        mm_270: "f32[32, 8]" = torch.ops.aten.mm.default(view_550, slice_7)
        view_551: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_270, [2, 16, 8]);  mm_270 = None
        slice_8919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1079, 1, 2160, 2176)
        slice_8920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8919, 2, 0, 16);  slice_8919 = None
        add_272: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8920, view_551);  slice_8920 = view_551 = None
        
        # No stacktrace found for following nodes
        slice_tensor_540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1079, 1, 2160, 2176)
        slice_scatter_default_1080: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_540, add_272, 2, 0, 16);  slice_tensor_540 = add_272 = None
        slice_scatter_default_1081: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1079, slice_scatter_default_1080, 1, 2160, 2176);  slice_scatter_default_1079 = slice_scatter_default_1080 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1081, 1, 2160, 2176)
        slice_8925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8924, 2, 0, 16);  slice_8924 = None
        
        # No stacktrace found for following nodes
        slice_tensor_541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1081, 1, 2160, 2176)
        slice_scatter_default_1082: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_541, slice_8925, 2, 0, 16);  slice_tensor_541 = slice_8925 = None
        slice_scatter_default_1083: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1081, slice_scatter_default_1082, 1, 2160, 2176);  slice_scatter_default_1081 = slice_scatter_default_1082 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8945: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8911, 2, 16, 32);  slice_8911 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_274: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_8945, memory_format = torch.contiguous_format);  slice_8945 = None
        view_552: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_274, [32, 11]);  clone_274 = None
        mm_271: "f32[32, 8]" = torch.ops.aten.mm.default(view_552, slice_37)
        view_553: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_271, [2, 16, 8]);  mm_271 = None
        slice_8952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1083, 1, 2160, 2176)
        slice_8953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8952, 2, 0, 16);  slice_8952 = None
        add_273: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8953, view_553);  slice_8953 = view_553 = None
        
        # No stacktrace found for following nodes
        slice_tensor_542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1083, 1, 2160, 2176)
        slice_scatter_default_1084: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_542, add_273, 2, 0, 16);  slice_tensor_542 = add_273 = None
        slice_scatter_default_1085: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1083, slice_scatter_default_1084, 1, 2160, 2176);  slice_scatter_default_1083 = slice_scatter_default_1084 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1085, 1, 2160, 2176)
        slice_8958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8957, 2, 0, 16);  slice_8957 = None
        
        # No stacktrace found for following nodes
        slice_tensor_543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1085, 1, 2160, 2176)
        slice_scatter_default_1086: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_543, slice_8958, 2, 0, 16);  slice_tensor_543 = slice_8958 = None
        slice_scatter_default_1087: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1085, slice_scatter_default_1086, 1, 2160, 2176);  slice_scatter_default_1085 = slice_scatter_default_1086 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_8977: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2176, 2192)
        slice_8978: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_8977, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_275: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_8978, memory_format = torch.contiguous_format);  slice_8978 = None
        view_554: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_275, [32, 16]);  clone_275 = None
        mm_272: "f32[32, 8]" = torch.ops.aten.mm.default(view_554, slice_7)
        view_555: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_272, [2, 16, 8]);  mm_272 = None
        slice_8985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1087, 1, 2176, 2192)
        slice_8986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8985, 2, 0, 16);  slice_8985 = None
        add_274: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_8986, view_555);  slice_8986 = view_555 = None
        
        # No stacktrace found for following nodes
        slice_tensor_544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1087, 1, 2176, 2192)
        slice_scatter_default_1088: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_544, add_274, 2, 0, 16);  slice_tensor_544 = add_274 = None
        slice_scatter_default_1089: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1087, slice_scatter_default_1088, 1, 2176, 2192);  slice_scatter_default_1087 = slice_scatter_default_1088 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_8990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1089, 1, 2176, 2192)
        slice_8991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_8990, 2, 0, 16);  slice_8990 = None
        
        # No stacktrace found for following nodes
        slice_tensor_545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1089, 1, 2176, 2192)
        slice_scatter_default_1090: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_545, slice_8991, 2, 0, 16);  slice_tensor_545 = slice_8991 = None
        slice_scatter_default_1091: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1089, slice_scatter_default_1090, 1, 2176, 2192);  slice_scatter_default_1089 = slice_scatter_default_1090 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9011: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_8977, 2, 16, 32);  slice_8977 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_276: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9011, memory_format = torch.contiguous_format);  slice_9011 = None
        view_556: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_276, [32, 11]);  clone_276 = None
        mm_273: "f32[32, 8]" = torch.ops.aten.mm.default(view_556, slice_37)
        view_557: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_273, [2, 16, 8]);  mm_273 = None
        slice_9018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1091, 1, 2176, 2192)
        slice_9019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9018, 2, 0, 16);  slice_9018 = None
        add_275: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9019, view_557);  slice_9019 = view_557 = None
        
        # No stacktrace found for following nodes
        slice_tensor_546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1091, 1, 2176, 2192)
        slice_scatter_default_1092: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_546, add_275, 2, 0, 16);  slice_tensor_546 = add_275 = None
        slice_scatter_default_1093: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1091, slice_scatter_default_1092, 1, 2176, 2192);  slice_scatter_default_1091 = slice_scatter_default_1092 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1093, 1, 2176, 2192)
        slice_9024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9023, 2, 0, 16);  slice_9023 = None
        
        # No stacktrace found for following nodes
        slice_tensor_547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1093, 1, 2176, 2192)
        slice_scatter_default_1094: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_547, slice_9024, 2, 0, 16);  slice_tensor_547 = slice_9024 = None
        slice_scatter_default_1095: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1093, slice_scatter_default_1094, 1, 2176, 2192);  slice_scatter_default_1093 = slice_scatter_default_1094 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9043: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2192, 2208)
        slice_9044: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9043, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_277: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9044, memory_format = torch.contiguous_format);  slice_9044 = None
        view_558: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_277, [32, 16]);  clone_277 = None
        mm_274: "f32[32, 8]" = torch.ops.aten.mm.default(view_558, slice_7)
        view_559: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_274, [2, 16, 8]);  mm_274 = None
        slice_9051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1095, 1, 2192, 2208)
        slice_9052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9051, 2, 0, 16);  slice_9051 = None
        add_276: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9052, view_559);  slice_9052 = view_559 = None
        
        # No stacktrace found for following nodes
        slice_tensor_548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1095, 1, 2192, 2208)
        slice_scatter_default_1096: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_548, add_276, 2, 0, 16);  slice_tensor_548 = add_276 = None
        slice_scatter_default_1097: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1095, slice_scatter_default_1096, 1, 2192, 2208);  slice_scatter_default_1095 = slice_scatter_default_1096 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1097, 1, 2192, 2208)
        slice_9057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9056, 2, 0, 16);  slice_9056 = None
        
        # No stacktrace found for following nodes
        slice_tensor_549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1097, 1, 2192, 2208)
        slice_scatter_default_1098: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_549, slice_9057, 2, 0, 16);  slice_tensor_549 = slice_9057 = None
        slice_scatter_default_1099: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1097, slice_scatter_default_1098, 1, 2192, 2208);  slice_scatter_default_1097 = slice_scatter_default_1098 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9077: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9043, 2, 16, 32);  slice_9043 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_278: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9077, memory_format = torch.contiguous_format);  slice_9077 = None
        view_560: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_278, [32, 11]);  clone_278 = None
        mm_275: "f32[32, 8]" = torch.ops.aten.mm.default(view_560, slice_37)
        view_561: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_275, [2, 16, 8]);  mm_275 = None
        slice_9084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1099, 1, 2192, 2208)
        slice_9085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9084, 2, 0, 16);  slice_9084 = None
        add_277: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9085, view_561);  slice_9085 = view_561 = None
        
        # No stacktrace found for following nodes
        slice_tensor_550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1099, 1, 2192, 2208)
        slice_scatter_default_1100: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_550, add_277, 2, 0, 16);  slice_tensor_550 = add_277 = None
        slice_scatter_default_1101: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1099, slice_scatter_default_1100, 1, 2192, 2208);  slice_scatter_default_1099 = slice_scatter_default_1100 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1101, 1, 2192, 2208)
        slice_9090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9089, 2, 0, 16);  slice_9089 = None
        
        # No stacktrace found for following nodes
        slice_tensor_551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1101, 1, 2192, 2208)
        slice_scatter_default_1102: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_551, slice_9090, 2, 0, 16);  slice_tensor_551 = slice_9090 = None
        slice_scatter_default_1103: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1101, slice_scatter_default_1102, 1, 2192, 2208);  slice_scatter_default_1101 = slice_scatter_default_1102 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9109: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2208, 2224)
        slice_9110: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9109, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_279: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9110, memory_format = torch.contiguous_format);  slice_9110 = None
        view_562: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_279, [32, 16]);  clone_279 = None
        mm_276: "f32[32, 8]" = torch.ops.aten.mm.default(view_562, slice_7)
        view_563: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_276, [2, 16, 8]);  mm_276 = None
        slice_9117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1103, 1, 2208, 2224)
        slice_9118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9117, 2, 0, 16);  slice_9117 = None
        add_278: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9118, view_563);  slice_9118 = view_563 = None
        
        # No stacktrace found for following nodes
        slice_tensor_552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1103, 1, 2208, 2224)
        slice_scatter_default_1104: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_552, add_278, 2, 0, 16);  slice_tensor_552 = add_278 = None
        slice_scatter_default_1105: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1103, slice_scatter_default_1104, 1, 2208, 2224);  slice_scatter_default_1103 = slice_scatter_default_1104 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1105, 1, 2208, 2224)
        slice_9123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9122, 2, 0, 16);  slice_9122 = None
        
        # No stacktrace found for following nodes
        slice_tensor_553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1105, 1, 2208, 2224)
        slice_scatter_default_1106: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_553, slice_9123, 2, 0, 16);  slice_tensor_553 = slice_9123 = None
        slice_scatter_default_1107: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1105, slice_scatter_default_1106, 1, 2208, 2224);  slice_scatter_default_1105 = slice_scatter_default_1106 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9143: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9109, 2, 16, 32);  slice_9109 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_280: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9143, memory_format = torch.contiguous_format);  slice_9143 = None
        view_564: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_280, [32, 11]);  clone_280 = None
        mm_277: "f32[32, 8]" = torch.ops.aten.mm.default(view_564, slice_37)
        view_565: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_277, [2, 16, 8]);  mm_277 = None
        slice_9150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1107, 1, 2208, 2224)
        slice_9151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9150, 2, 0, 16);  slice_9150 = None
        add_279: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9151, view_565);  slice_9151 = view_565 = None
        
        # No stacktrace found for following nodes
        slice_tensor_554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1107, 1, 2208, 2224)
        slice_scatter_default_1108: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_554, add_279, 2, 0, 16);  slice_tensor_554 = add_279 = None
        slice_scatter_default_1109: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1107, slice_scatter_default_1108, 1, 2208, 2224);  slice_scatter_default_1107 = slice_scatter_default_1108 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1109, 1, 2208, 2224)
        slice_9156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9155, 2, 0, 16);  slice_9155 = None
        
        # No stacktrace found for following nodes
        slice_tensor_555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1109, 1, 2208, 2224)
        slice_scatter_default_1110: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_555, slice_9156, 2, 0, 16);  slice_tensor_555 = slice_9156 = None
        slice_scatter_default_1111: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1109, slice_scatter_default_1110, 1, 2208, 2224);  slice_scatter_default_1109 = slice_scatter_default_1110 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9175: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2224, 2240)
        slice_9176: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9175, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_281: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9176, memory_format = torch.contiguous_format);  slice_9176 = None
        view_566: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_281, [32, 16]);  clone_281 = None
        mm_278: "f32[32, 8]" = torch.ops.aten.mm.default(view_566, slice_7)
        view_567: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_278, [2, 16, 8]);  mm_278 = None
        slice_9183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1111, 1, 2224, 2240)
        slice_9184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9183, 2, 0, 16);  slice_9183 = None
        add_280: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9184, view_567);  slice_9184 = view_567 = None
        
        # No stacktrace found for following nodes
        slice_tensor_556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1111, 1, 2224, 2240)
        slice_scatter_default_1112: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_556, add_280, 2, 0, 16);  slice_tensor_556 = add_280 = None
        slice_scatter_default_1113: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1111, slice_scatter_default_1112, 1, 2224, 2240);  slice_scatter_default_1111 = slice_scatter_default_1112 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1113, 1, 2224, 2240)
        slice_9189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9188, 2, 0, 16);  slice_9188 = None
        
        # No stacktrace found for following nodes
        slice_tensor_557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1113, 1, 2224, 2240)
        slice_scatter_default_1114: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_557, slice_9189, 2, 0, 16);  slice_tensor_557 = slice_9189 = None
        slice_scatter_default_1115: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1113, slice_scatter_default_1114, 1, 2224, 2240);  slice_scatter_default_1113 = slice_scatter_default_1114 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9209: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9175, 2, 16, 32);  slice_9175 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_282: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9209, memory_format = torch.contiguous_format);  slice_9209 = None
        view_568: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_282, [32, 11]);  clone_282 = None
        mm_279: "f32[32, 8]" = torch.ops.aten.mm.default(view_568, slice_37)
        view_569: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_279, [2, 16, 8]);  mm_279 = None
        slice_9216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1115, 1, 2224, 2240)
        slice_9217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9216, 2, 0, 16);  slice_9216 = None
        add_281: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9217, view_569);  slice_9217 = view_569 = None
        
        # No stacktrace found for following nodes
        slice_tensor_558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1115, 1, 2224, 2240)
        slice_scatter_default_1116: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_558, add_281, 2, 0, 16);  slice_tensor_558 = add_281 = None
        slice_scatter_default_1117: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1115, slice_scatter_default_1116, 1, 2224, 2240);  slice_scatter_default_1115 = slice_scatter_default_1116 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1117, 1, 2224, 2240)
        slice_9222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9221, 2, 0, 16);  slice_9221 = None
        
        # No stacktrace found for following nodes
        slice_tensor_559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1117, 1, 2224, 2240)
        slice_scatter_default_1118: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_559, slice_9222, 2, 0, 16);  slice_tensor_559 = slice_9222 = None
        slice_scatter_default_1119: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1117, slice_scatter_default_1118, 1, 2224, 2240);  slice_scatter_default_1117 = slice_scatter_default_1118 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9241: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2240, 2256)
        slice_9242: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9241, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_283: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9242, memory_format = torch.contiguous_format);  slice_9242 = None
        view_570: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_283, [32, 16]);  clone_283 = None
        mm_280: "f32[32, 8]" = torch.ops.aten.mm.default(view_570, slice_7)
        view_571: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_280, [2, 16, 8]);  mm_280 = None
        slice_9249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1119, 1, 2240, 2256)
        slice_9250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9249, 2, 0, 16);  slice_9249 = None
        add_282: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9250, view_571);  slice_9250 = view_571 = None
        
        # No stacktrace found for following nodes
        slice_tensor_560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1119, 1, 2240, 2256)
        slice_scatter_default_1120: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_560, add_282, 2, 0, 16);  slice_tensor_560 = add_282 = None
        slice_scatter_default_1121: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1119, slice_scatter_default_1120, 1, 2240, 2256);  slice_scatter_default_1119 = slice_scatter_default_1120 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1121, 1, 2240, 2256)
        slice_9255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9254, 2, 0, 16);  slice_9254 = None
        
        # No stacktrace found for following nodes
        slice_tensor_561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1121, 1, 2240, 2256)
        slice_scatter_default_1122: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_561, slice_9255, 2, 0, 16);  slice_tensor_561 = slice_9255 = None
        slice_scatter_default_1123: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1121, slice_scatter_default_1122, 1, 2240, 2256);  slice_scatter_default_1121 = slice_scatter_default_1122 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9275: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9241, 2, 16, 32);  slice_9241 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_284: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9275, memory_format = torch.contiguous_format);  slice_9275 = None
        view_572: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_284, [32, 11]);  clone_284 = None
        mm_281: "f32[32, 8]" = torch.ops.aten.mm.default(view_572, slice_37)
        view_573: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_281, [2, 16, 8]);  mm_281 = None
        slice_9282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1123, 1, 2240, 2256)
        slice_9283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9282, 2, 0, 16);  slice_9282 = None
        add_283: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9283, view_573);  slice_9283 = view_573 = None
        
        # No stacktrace found for following nodes
        slice_tensor_562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1123, 1, 2240, 2256)
        slice_scatter_default_1124: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_562, add_283, 2, 0, 16);  slice_tensor_562 = add_283 = None
        slice_scatter_default_1125: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1123, slice_scatter_default_1124, 1, 2240, 2256);  slice_scatter_default_1123 = slice_scatter_default_1124 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1125, 1, 2240, 2256)
        slice_9288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9287, 2, 0, 16);  slice_9287 = None
        
        # No stacktrace found for following nodes
        slice_tensor_563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1125, 1, 2240, 2256)
        slice_scatter_default_1126: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_563, slice_9288, 2, 0, 16);  slice_tensor_563 = slice_9288 = None
        slice_scatter_default_1127: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1125, slice_scatter_default_1126, 1, 2240, 2256);  slice_scatter_default_1125 = slice_scatter_default_1126 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9307: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2256, 2272)
        slice_9308: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9307, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_285: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9308, memory_format = torch.contiguous_format);  slice_9308 = None
        view_574: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_285, [32, 16]);  clone_285 = None
        mm_282: "f32[32, 8]" = torch.ops.aten.mm.default(view_574, slice_7)
        view_575: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_282, [2, 16, 8]);  mm_282 = None
        slice_9315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1127, 1, 2256, 2272)
        slice_9316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9315, 2, 0, 16);  slice_9315 = None
        add_284: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9316, view_575);  slice_9316 = view_575 = None
        
        # No stacktrace found for following nodes
        slice_tensor_564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1127, 1, 2256, 2272)
        slice_scatter_default_1128: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_564, add_284, 2, 0, 16);  slice_tensor_564 = add_284 = None
        slice_scatter_default_1129: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1127, slice_scatter_default_1128, 1, 2256, 2272);  slice_scatter_default_1127 = slice_scatter_default_1128 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1129, 1, 2256, 2272)
        slice_9321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9320, 2, 0, 16);  slice_9320 = None
        
        # No stacktrace found for following nodes
        slice_tensor_565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1129, 1, 2256, 2272)
        slice_scatter_default_1130: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_565, slice_9321, 2, 0, 16);  slice_tensor_565 = slice_9321 = None
        slice_scatter_default_1131: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1129, slice_scatter_default_1130, 1, 2256, 2272);  slice_scatter_default_1129 = slice_scatter_default_1130 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9341: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9307, 2, 16, 32);  slice_9307 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_286: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9341, memory_format = torch.contiguous_format);  slice_9341 = None
        view_576: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_286, [32, 11]);  clone_286 = None
        mm_283: "f32[32, 8]" = torch.ops.aten.mm.default(view_576, slice_37)
        view_577: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_283, [2, 16, 8]);  mm_283 = None
        slice_9348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1131, 1, 2256, 2272)
        slice_9349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9348, 2, 0, 16);  slice_9348 = None
        add_285: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9349, view_577);  slice_9349 = view_577 = None
        
        # No stacktrace found for following nodes
        slice_tensor_566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1131, 1, 2256, 2272)
        slice_scatter_default_1132: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_566, add_285, 2, 0, 16);  slice_tensor_566 = add_285 = None
        slice_scatter_default_1133: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1131, slice_scatter_default_1132, 1, 2256, 2272);  slice_scatter_default_1131 = slice_scatter_default_1132 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1133, 1, 2256, 2272)
        slice_9354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9353, 2, 0, 16);  slice_9353 = None
        
        # No stacktrace found for following nodes
        slice_tensor_567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1133, 1, 2256, 2272)
        slice_scatter_default_1134: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_567, slice_9354, 2, 0, 16);  slice_tensor_567 = slice_9354 = None
        slice_scatter_default_1135: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1133, slice_scatter_default_1134, 1, 2256, 2272);  slice_scatter_default_1133 = slice_scatter_default_1134 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9373: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2272, 2288)
        slice_9374: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9373, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_287: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9374, memory_format = torch.contiguous_format);  slice_9374 = None
        view_578: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_287, [32, 16]);  clone_287 = None
        mm_284: "f32[32, 8]" = torch.ops.aten.mm.default(view_578, slice_7)
        view_579: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_284, [2, 16, 8]);  mm_284 = None
        slice_9381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1135, 1, 2272, 2288)
        slice_9382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9381, 2, 0, 16);  slice_9381 = None
        add_286: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9382, view_579);  slice_9382 = view_579 = None
        
        # No stacktrace found for following nodes
        slice_tensor_568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1135, 1, 2272, 2288)
        slice_scatter_default_1136: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_568, add_286, 2, 0, 16);  slice_tensor_568 = add_286 = None
        slice_scatter_default_1137: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1135, slice_scatter_default_1136, 1, 2272, 2288);  slice_scatter_default_1135 = slice_scatter_default_1136 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1137, 1, 2272, 2288)
        slice_9387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9386, 2, 0, 16);  slice_9386 = None
        
        # No stacktrace found for following nodes
        slice_tensor_569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1137, 1, 2272, 2288)
        slice_scatter_default_1138: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_569, slice_9387, 2, 0, 16);  slice_tensor_569 = slice_9387 = None
        slice_scatter_default_1139: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1137, slice_scatter_default_1138, 1, 2272, 2288);  slice_scatter_default_1137 = slice_scatter_default_1138 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9407: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9373, 2, 16, 32);  slice_9373 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_288: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9407, memory_format = torch.contiguous_format);  slice_9407 = None
        view_580: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_288, [32, 11]);  clone_288 = None
        mm_285: "f32[32, 8]" = torch.ops.aten.mm.default(view_580, slice_37)
        view_581: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_285, [2, 16, 8]);  mm_285 = None
        slice_9414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1139, 1, 2272, 2288)
        slice_9415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9414, 2, 0, 16);  slice_9414 = None
        add_287: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9415, view_581);  slice_9415 = view_581 = None
        
        # No stacktrace found for following nodes
        slice_tensor_570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1139, 1, 2272, 2288)
        slice_scatter_default_1140: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_570, add_287, 2, 0, 16);  slice_tensor_570 = add_287 = None
        slice_scatter_default_1141: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1139, slice_scatter_default_1140, 1, 2272, 2288);  slice_scatter_default_1139 = slice_scatter_default_1140 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1141, 1, 2272, 2288)
        slice_9420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9419, 2, 0, 16);  slice_9419 = None
        
        # No stacktrace found for following nodes
        slice_tensor_571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1141, 1, 2272, 2288)
        slice_scatter_default_1142: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_571, slice_9420, 2, 0, 16);  slice_tensor_571 = slice_9420 = None
        slice_scatter_default_1143: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1141, slice_scatter_default_1142, 1, 2272, 2288);  slice_scatter_default_1141 = slice_scatter_default_1142 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9439: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2288, 2304)
        slice_9440: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9439, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_289: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9440, memory_format = torch.contiguous_format);  slice_9440 = None
        view_582: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_289, [32, 16]);  clone_289 = None
        mm_286: "f32[32, 8]" = torch.ops.aten.mm.default(view_582, slice_7)
        view_583: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_286, [2, 16, 8]);  mm_286 = None
        slice_9447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1143, 1, 2288, 2304)
        slice_9448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9447, 2, 0, 16);  slice_9447 = None
        add_288: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9448, view_583);  slice_9448 = view_583 = None
        
        # No stacktrace found for following nodes
        slice_tensor_572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1143, 1, 2288, 2304)
        slice_scatter_default_1144: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_572, add_288, 2, 0, 16);  slice_tensor_572 = add_288 = None
        slice_scatter_default_1145: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1143, slice_scatter_default_1144, 1, 2288, 2304);  slice_scatter_default_1143 = slice_scatter_default_1144 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1145, 1, 2288, 2304)
        slice_9453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9452, 2, 0, 16);  slice_9452 = None
        
        # No stacktrace found for following nodes
        slice_tensor_573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1145, 1, 2288, 2304)
        slice_scatter_default_1146: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_573, slice_9453, 2, 0, 16);  slice_tensor_573 = slice_9453 = None
        slice_scatter_default_1147: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1145, slice_scatter_default_1146, 1, 2288, 2304);  slice_scatter_default_1145 = slice_scatter_default_1146 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9473: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9439, 2, 16, 32);  slice_9439 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_290: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9473, memory_format = torch.contiguous_format);  slice_9473 = None
        view_584: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_290, [32, 11]);  clone_290 = None
        mm_287: "f32[32, 8]" = torch.ops.aten.mm.default(view_584, slice_37)
        view_585: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_287, [2, 16, 8]);  mm_287 = None
        slice_9480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1147, 1, 2288, 2304)
        slice_9481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9480, 2, 0, 16);  slice_9480 = None
        add_289: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9481, view_585);  slice_9481 = view_585 = None
        
        # No stacktrace found for following nodes
        slice_tensor_574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1147, 1, 2288, 2304)
        slice_scatter_default_1148: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_574, add_289, 2, 0, 16);  slice_tensor_574 = add_289 = None
        slice_scatter_default_1149: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1147, slice_scatter_default_1148, 1, 2288, 2304);  slice_scatter_default_1147 = slice_scatter_default_1148 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1149, 1, 2288, 2304)
        slice_9486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9485, 2, 0, 16);  slice_9485 = None
        
        # No stacktrace found for following nodes
        slice_tensor_575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1149, 1, 2288, 2304)
        slice_scatter_default_1150: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_575, slice_9486, 2, 0, 16);  slice_tensor_575 = slice_9486 = None
        slice_scatter_default_1151: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1149, slice_scatter_default_1150, 1, 2288, 2304);  slice_scatter_default_1149 = slice_scatter_default_1150 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9505: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2304, 2320)
        slice_9506: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9505, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_291: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9506, memory_format = torch.contiguous_format);  slice_9506 = None
        view_586: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_291, [32, 16]);  clone_291 = None
        mm_288: "f32[32, 8]" = torch.ops.aten.mm.default(view_586, slice_7)
        view_587: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_288, [2, 16, 8]);  mm_288 = None
        slice_9513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1151, 1, 2304, 2320)
        slice_9514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9513, 2, 0, 16);  slice_9513 = None
        add_290: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9514, view_587);  slice_9514 = view_587 = None
        
        # No stacktrace found for following nodes
        slice_tensor_576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1151, 1, 2304, 2320)
        slice_scatter_default_1152: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_576, add_290, 2, 0, 16);  slice_tensor_576 = add_290 = None
        slice_scatter_default_1153: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1151, slice_scatter_default_1152, 1, 2304, 2320);  slice_scatter_default_1151 = slice_scatter_default_1152 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1153, 1, 2304, 2320)
        slice_9519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9518, 2, 0, 16);  slice_9518 = None
        
        # No stacktrace found for following nodes
        slice_tensor_577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1153, 1, 2304, 2320)
        slice_scatter_default_1154: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_577, slice_9519, 2, 0, 16);  slice_tensor_577 = slice_9519 = None
        slice_scatter_default_1155: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1153, slice_scatter_default_1154, 1, 2304, 2320);  slice_scatter_default_1153 = slice_scatter_default_1154 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9539: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9505, 2, 16, 32);  slice_9505 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_292: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9539, memory_format = torch.contiguous_format);  slice_9539 = None
        view_588: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_292, [32, 11]);  clone_292 = None
        mm_289: "f32[32, 8]" = torch.ops.aten.mm.default(view_588, slice_37)
        view_589: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_289, [2, 16, 8]);  mm_289 = None
        slice_9546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1155, 1, 2304, 2320)
        slice_9547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9546, 2, 0, 16);  slice_9546 = None
        add_291: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9547, view_589);  slice_9547 = view_589 = None
        
        # No stacktrace found for following nodes
        slice_tensor_578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1155, 1, 2304, 2320)
        slice_scatter_default_1156: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_578, add_291, 2, 0, 16);  slice_tensor_578 = add_291 = None
        slice_scatter_default_1157: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1155, slice_scatter_default_1156, 1, 2304, 2320);  slice_scatter_default_1155 = slice_scatter_default_1156 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1157, 1, 2304, 2320)
        slice_9552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9551, 2, 0, 16);  slice_9551 = None
        
        # No stacktrace found for following nodes
        slice_tensor_579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1157, 1, 2304, 2320)
        slice_scatter_default_1158: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_579, slice_9552, 2, 0, 16);  slice_tensor_579 = slice_9552 = None
        slice_scatter_default_1159: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1157, slice_scatter_default_1158, 1, 2304, 2320);  slice_scatter_default_1157 = slice_scatter_default_1158 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9571: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2320, 2336)
        slice_9572: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9571, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_293: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9572, memory_format = torch.contiguous_format);  slice_9572 = None
        view_590: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_293, [32, 16]);  clone_293 = None
        mm_290: "f32[32, 8]" = torch.ops.aten.mm.default(view_590, slice_7)
        view_591: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_290, [2, 16, 8]);  mm_290 = None
        slice_9579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1159, 1, 2320, 2336)
        slice_9580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9579, 2, 0, 16);  slice_9579 = None
        add_292: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9580, view_591);  slice_9580 = view_591 = None
        
        # No stacktrace found for following nodes
        slice_tensor_580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1159, 1, 2320, 2336)
        slice_scatter_default_1160: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_580, add_292, 2, 0, 16);  slice_tensor_580 = add_292 = None
        slice_scatter_default_1161: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1159, slice_scatter_default_1160, 1, 2320, 2336);  slice_scatter_default_1159 = slice_scatter_default_1160 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1161, 1, 2320, 2336)
        slice_9585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9584, 2, 0, 16);  slice_9584 = None
        
        # No stacktrace found for following nodes
        slice_tensor_581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1161, 1, 2320, 2336)
        slice_scatter_default_1162: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_581, slice_9585, 2, 0, 16);  slice_tensor_581 = slice_9585 = None
        slice_scatter_default_1163: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1161, slice_scatter_default_1162, 1, 2320, 2336);  slice_scatter_default_1161 = slice_scatter_default_1162 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9605: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9571, 2, 16, 32);  slice_9571 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_294: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9605, memory_format = torch.contiguous_format);  slice_9605 = None
        view_592: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_294, [32, 11]);  clone_294 = None
        mm_291: "f32[32, 8]" = torch.ops.aten.mm.default(view_592, slice_37)
        view_593: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_291, [2, 16, 8]);  mm_291 = None
        slice_9612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1163, 1, 2320, 2336)
        slice_9613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9612, 2, 0, 16);  slice_9612 = None
        add_293: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9613, view_593);  slice_9613 = view_593 = None
        
        # No stacktrace found for following nodes
        slice_tensor_582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1163, 1, 2320, 2336)
        slice_scatter_default_1164: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_582, add_293, 2, 0, 16);  slice_tensor_582 = add_293 = None
        slice_scatter_default_1165: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1163, slice_scatter_default_1164, 1, 2320, 2336);  slice_scatter_default_1163 = slice_scatter_default_1164 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1165, 1, 2320, 2336)
        slice_9618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9617, 2, 0, 16);  slice_9617 = None
        
        # No stacktrace found for following nodes
        slice_tensor_583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1165, 1, 2320, 2336)
        slice_scatter_default_1166: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_583, slice_9618, 2, 0, 16);  slice_tensor_583 = slice_9618 = None
        slice_scatter_default_1167: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1165, slice_scatter_default_1166, 1, 2320, 2336);  slice_scatter_default_1165 = slice_scatter_default_1166 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9637: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2336, 2352)
        slice_9638: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9637, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_295: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9638, memory_format = torch.contiguous_format);  slice_9638 = None
        view_594: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_295, [32, 16]);  clone_295 = None
        mm_292: "f32[32, 8]" = torch.ops.aten.mm.default(view_594, slice_7)
        view_595: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_292, [2, 16, 8]);  mm_292 = None
        slice_9645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1167, 1, 2336, 2352)
        slice_9646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9645, 2, 0, 16);  slice_9645 = None
        add_294: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9646, view_595);  slice_9646 = view_595 = None
        
        # No stacktrace found for following nodes
        slice_tensor_584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1167, 1, 2336, 2352)
        slice_scatter_default_1168: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_584, add_294, 2, 0, 16);  slice_tensor_584 = add_294 = None
        slice_scatter_default_1169: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1167, slice_scatter_default_1168, 1, 2336, 2352);  slice_scatter_default_1167 = slice_scatter_default_1168 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1169, 1, 2336, 2352)
        slice_9651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9650, 2, 0, 16);  slice_9650 = None
        
        # No stacktrace found for following nodes
        slice_tensor_585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1169, 1, 2336, 2352)
        slice_scatter_default_1170: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_585, slice_9651, 2, 0, 16);  slice_tensor_585 = slice_9651 = None
        slice_scatter_default_1171: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1169, slice_scatter_default_1170, 1, 2336, 2352);  slice_scatter_default_1169 = slice_scatter_default_1170 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9671: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9637, 2, 16, 32);  slice_9637 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_296: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9671, memory_format = torch.contiguous_format);  slice_9671 = None
        view_596: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_296, [32, 11]);  clone_296 = None
        mm_293: "f32[32, 8]" = torch.ops.aten.mm.default(view_596, slice_37)
        view_597: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_293, [2, 16, 8]);  mm_293 = None
        slice_9678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1171, 1, 2336, 2352)
        slice_9679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9678, 2, 0, 16);  slice_9678 = None
        add_295: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9679, view_597);  slice_9679 = view_597 = None
        
        # No stacktrace found for following nodes
        slice_tensor_586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1171, 1, 2336, 2352)
        slice_scatter_default_1172: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_586, add_295, 2, 0, 16);  slice_tensor_586 = add_295 = None
        slice_scatter_default_1173: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1171, slice_scatter_default_1172, 1, 2336, 2352);  slice_scatter_default_1171 = slice_scatter_default_1172 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1173, 1, 2336, 2352)
        slice_9684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9683, 2, 0, 16);  slice_9683 = None
        
        # No stacktrace found for following nodes
        slice_tensor_587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1173, 1, 2336, 2352)
        slice_scatter_default_1174: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_587, slice_9684, 2, 0, 16);  slice_tensor_587 = slice_9684 = None
        slice_scatter_default_1175: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1173, slice_scatter_default_1174, 1, 2336, 2352);  slice_scatter_default_1173 = slice_scatter_default_1174 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9703: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2352, 2368)
        slice_9704: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9703, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_297: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9704, memory_format = torch.contiguous_format);  slice_9704 = None
        view_598: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_297, [32, 16]);  clone_297 = None
        mm_294: "f32[32, 8]" = torch.ops.aten.mm.default(view_598, slice_7)
        view_599: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_294, [2, 16, 8]);  mm_294 = None
        slice_9711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1175, 1, 2352, 2368)
        slice_9712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9711, 2, 0, 16);  slice_9711 = None
        add_296: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9712, view_599);  slice_9712 = view_599 = None
        
        # No stacktrace found for following nodes
        slice_tensor_588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1175, 1, 2352, 2368)
        slice_scatter_default_1176: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_588, add_296, 2, 0, 16);  slice_tensor_588 = add_296 = None
        slice_scatter_default_1177: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1175, slice_scatter_default_1176, 1, 2352, 2368);  slice_scatter_default_1175 = slice_scatter_default_1176 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1177, 1, 2352, 2368)
        slice_9717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9716, 2, 0, 16);  slice_9716 = None
        
        # No stacktrace found for following nodes
        slice_tensor_589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1177, 1, 2352, 2368)
        slice_scatter_default_1178: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_589, slice_9717, 2, 0, 16);  slice_tensor_589 = slice_9717 = None
        slice_scatter_default_1179: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1177, slice_scatter_default_1178, 1, 2352, 2368);  slice_scatter_default_1177 = slice_scatter_default_1178 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9737: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9703, 2, 16, 32);  slice_9703 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_298: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9737, memory_format = torch.contiguous_format);  slice_9737 = None
        view_600: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_298, [32, 11]);  clone_298 = None
        mm_295: "f32[32, 8]" = torch.ops.aten.mm.default(view_600, slice_37)
        view_601: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_295, [2, 16, 8]);  mm_295 = None
        slice_9744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1179, 1, 2352, 2368)
        slice_9745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9744, 2, 0, 16);  slice_9744 = None
        add_297: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9745, view_601);  slice_9745 = view_601 = None
        
        # No stacktrace found for following nodes
        slice_tensor_590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1179, 1, 2352, 2368)
        slice_scatter_default_1180: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_590, add_297, 2, 0, 16);  slice_tensor_590 = add_297 = None
        slice_scatter_default_1181: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1179, slice_scatter_default_1180, 1, 2352, 2368);  slice_scatter_default_1179 = slice_scatter_default_1180 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1181, 1, 2352, 2368)
        slice_9750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9749, 2, 0, 16);  slice_9749 = None
        
        # No stacktrace found for following nodes
        slice_tensor_591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1181, 1, 2352, 2368)
        slice_scatter_default_1182: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_591, slice_9750, 2, 0, 16);  slice_tensor_591 = slice_9750 = None
        slice_scatter_default_1183: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1181, slice_scatter_default_1182, 1, 2352, 2368);  slice_scatter_default_1181 = slice_scatter_default_1182 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9769: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2368, 2384)
        slice_9770: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9769, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_299: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9770, memory_format = torch.contiguous_format);  slice_9770 = None
        view_602: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_299, [32, 16]);  clone_299 = None
        mm_296: "f32[32, 8]" = torch.ops.aten.mm.default(view_602, slice_7)
        view_603: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_296, [2, 16, 8]);  mm_296 = None
        slice_9777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1183, 1, 2368, 2384)
        slice_9778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9777, 2, 0, 16);  slice_9777 = None
        add_298: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9778, view_603);  slice_9778 = view_603 = None
        
        # No stacktrace found for following nodes
        slice_tensor_592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1183, 1, 2368, 2384)
        slice_scatter_default_1184: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_592, add_298, 2, 0, 16);  slice_tensor_592 = add_298 = None
        slice_scatter_default_1185: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1183, slice_scatter_default_1184, 1, 2368, 2384);  slice_scatter_default_1183 = slice_scatter_default_1184 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1185, 1, 2368, 2384)
        slice_9783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9782, 2, 0, 16);  slice_9782 = None
        
        # No stacktrace found for following nodes
        slice_tensor_593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1185, 1, 2368, 2384)
        slice_scatter_default_1186: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_593, slice_9783, 2, 0, 16);  slice_tensor_593 = slice_9783 = None
        slice_scatter_default_1187: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1185, slice_scatter_default_1186, 1, 2368, 2384);  slice_scatter_default_1185 = slice_scatter_default_1186 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9803: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9769, 2, 16, 32);  slice_9769 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_300: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9803, memory_format = torch.contiguous_format);  slice_9803 = None
        view_604: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_300, [32, 11]);  clone_300 = None
        mm_297: "f32[32, 8]" = torch.ops.aten.mm.default(view_604, slice_37)
        view_605: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_297, [2, 16, 8]);  mm_297 = None
        slice_9810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1187, 1, 2368, 2384)
        slice_9811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9810, 2, 0, 16);  slice_9810 = None
        add_299: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9811, view_605);  slice_9811 = view_605 = None
        
        # No stacktrace found for following nodes
        slice_tensor_594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1187, 1, 2368, 2384)
        slice_scatter_default_1188: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_594, add_299, 2, 0, 16);  slice_tensor_594 = add_299 = None
        slice_scatter_default_1189: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1187, slice_scatter_default_1188, 1, 2368, 2384);  slice_scatter_default_1187 = slice_scatter_default_1188 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1189, 1, 2368, 2384)
        slice_9816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9815, 2, 0, 16);  slice_9815 = None
        
        # No stacktrace found for following nodes
        slice_tensor_595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1189, 1, 2368, 2384)
        slice_scatter_default_1190: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_595, slice_9816, 2, 0, 16);  slice_tensor_595 = slice_9816 = None
        slice_scatter_default_1191: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1189, slice_scatter_default_1190, 1, 2368, 2384);  slice_scatter_default_1189 = slice_scatter_default_1190 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9835: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2384, 2400)
        slice_9836: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9835, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_301: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9836, memory_format = torch.contiguous_format);  slice_9836 = None
        view_606: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_301, [32, 16]);  clone_301 = None
        mm_298: "f32[32, 8]" = torch.ops.aten.mm.default(view_606, slice_7)
        view_607: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_298, [2, 16, 8]);  mm_298 = None
        slice_9843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1191, 1, 2384, 2400)
        slice_9844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9843, 2, 0, 16);  slice_9843 = None
        add_300: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9844, view_607);  slice_9844 = view_607 = None
        
        # No stacktrace found for following nodes
        slice_tensor_596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1191, 1, 2384, 2400)
        slice_scatter_default_1192: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_596, add_300, 2, 0, 16);  slice_tensor_596 = add_300 = None
        slice_scatter_default_1193: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1191, slice_scatter_default_1192, 1, 2384, 2400);  slice_scatter_default_1191 = slice_scatter_default_1192 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1193, 1, 2384, 2400)
        slice_9849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9848, 2, 0, 16);  slice_9848 = None
        
        # No stacktrace found for following nodes
        slice_tensor_597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1193, 1, 2384, 2400)
        slice_scatter_default_1194: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_597, slice_9849, 2, 0, 16);  slice_tensor_597 = slice_9849 = None
        slice_scatter_default_1195: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1193, slice_scatter_default_1194, 1, 2384, 2400);  slice_scatter_default_1193 = slice_scatter_default_1194 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9869: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9835, 2, 16, 32);  slice_9835 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_302: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9869, memory_format = torch.contiguous_format);  slice_9869 = None
        view_608: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_302, [32, 11]);  clone_302 = None
        mm_299: "f32[32, 8]" = torch.ops.aten.mm.default(view_608, slice_37)
        view_609: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_299, [2, 16, 8]);  mm_299 = None
        slice_9876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1195, 1, 2384, 2400)
        slice_9877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9876, 2, 0, 16);  slice_9876 = None
        add_301: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9877, view_609);  slice_9877 = view_609 = None
        
        # No stacktrace found for following nodes
        slice_tensor_598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1195, 1, 2384, 2400)
        slice_scatter_default_1196: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_598, add_301, 2, 0, 16);  slice_tensor_598 = add_301 = None
        slice_scatter_default_1197: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1195, slice_scatter_default_1196, 1, 2384, 2400);  slice_scatter_default_1195 = slice_scatter_default_1196 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1197, 1, 2384, 2400)
        slice_9882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9881, 2, 0, 16);  slice_9881 = None
        
        # No stacktrace found for following nodes
        slice_tensor_599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1197, 1, 2384, 2400)
        slice_scatter_default_1198: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_599, slice_9882, 2, 0, 16);  slice_tensor_599 = slice_9882 = None
        slice_scatter_default_1199: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1197, slice_scatter_default_1198, 1, 2384, 2400);  slice_scatter_default_1197 = slice_scatter_default_1198 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9901: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2400, 2416)
        slice_9902: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9901, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_303: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9902, memory_format = torch.contiguous_format);  slice_9902 = None
        view_610: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_303, [32, 16]);  clone_303 = None
        mm_300: "f32[32, 8]" = torch.ops.aten.mm.default(view_610, slice_7)
        view_611: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_300, [2, 16, 8]);  mm_300 = None
        slice_9909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1199, 1, 2400, 2416)
        slice_9910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9909, 2, 0, 16);  slice_9909 = None
        add_302: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9910, view_611);  slice_9910 = view_611 = None
        
        # No stacktrace found for following nodes
        slice_tensor_600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1199, 1, 2400, 2416)
        slice_scatter_default_1200: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_600, add_302, 2, 0, 16);  slice_tensor_600 = add_302 = None
        slice_scatter_default_1201: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1199, slice_scatter_default_1200, 1, 2400, 2416);  slice_scatter_default_1199 = slice_scatter_default_1200 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1201, 1, 2400, 2416)
        slice_9915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9914, 2, 0, 16);  slice_9914 = None
        
        # No stacktrace found for following nodes
        slice_tensor_601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1201, 1, 2400, 2416)
        slice_scatter_default_1202: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_601, slice_9915, 2, 0, 16);  slice_tensor_601 = slice_9915 = None
        slice_scatter_default_1203: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1201, slice_scatter_default_1202, 1, 2400, 2416);  slice_scatter_default_1201 = slice_scatter_default_1202 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9935: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9901, 2, 16, 32);  slice_9901 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_304: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_9935, memory_format = torch.contiguous_format);  slice_9935 = None
        view_612: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_304, [32, 11]);  clone_304 = None
        mm_301: "f32[32, 8]" = torch.ops.aten.mm.default(view_612, slice_37)
        view_613: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_301, [2, 16, 8]);  mm_301 = None
        slice_9942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1203, 1, 2400, 2416)
        slice_9943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9942, 2, 0, 16);  slice_9942 = None
        add_303: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9943, view_613);  slice_9943 = view_613 = None
        
        # No stacktrace found for following nodes
        slice_tensor_602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1203, 1, 2400, 2416)
        slice_scatter_default_1204: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_602, add_303, 2, 0, 16);  slice_tensor_602 = add_303 = None
        slice_scatter_default_1205: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1203, slice_scatter_default_1204, 1, 2400, 2416);  slice_scatter_default_1203 = slice_scatter_default_1204 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1205, 1, 2400, 2416)
        slice_9948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9947, 2, 0, 16);  slice_9947 = None
        
        # No stacktrace found for following nodes
        slice_tensor_603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1205, 1, 2400, 2416)
        slice_scatter_default_1206: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_603, slice_9948, 2, 0, 16);  slice_tensor_603 = slice_9948 = None
        slice_scatter_default_1207: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1205, slice_scatter_default_1206, 1, 2400, 2416);  slice_scatter_default_1205 = slice_scatter_default_1206 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_9967: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2416, 2432)
        slice_9968: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_9967, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_305: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_9968, memory_format = torch.contiguous_format);  slice_9968 = None
        view_614: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_305, [32, 16]);  clone_305 = None
        mm_302: "f32[32, 8]" = torch.ops.aten.mm.default(view_614, slice_7)
        view_615: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_302, [2, 16, 8]);  mm_302 = None
        slice_9975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1207, 1, 2416, 2432)
        slice_9976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9975, 2, 0, 16);  slice_9975 = None
        add_304: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_9976, view_615);  slice_9976 = view_615 = None
        
        # No stacktrace found for following nodes
        slice_tensor_604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1207, 1, 2416, 2432)
        slice_scatter_default_1208: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_604, add_304, 2, 0, 16);  slice_tensor_604 = add_304 = None
        slice_scatter_default_1209: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1207, slice_scatter_default_1208, 1, 2416, 2432);  slice_scatter_default_1207 = slice_scatter_default_1208 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_9980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1209, 1, 2416, 2432)
        slice_9981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_9980, 2, 0, 16);  slice_9980 = None
        
        # No stacktrace found for following nodes
        slice_tensor_605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1209, 1, 2416, 2432)
        slice_scatter_default_1210: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_605, slice_9981, 2, 0, 16);  slice_tensor_605 = slice_9981 = None
        slice_scatter_default_1211: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1209, slice_scatter_default_1210, 1, 2416, 2432);  slice_scatter_default_1209 = slice_scatter_default_1210 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10001: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_9967, 2, 16, 32);  slice_9967 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_306: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10001, memory_format = torch.contiguous_format);  slice_10001 = None
        view_616: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_306, [32, 11]);  clone_306 = None
        mm_303: "f32[32, 8]" = torch.ops.aten.mm.default(view_616, slice_37)
        view_617: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_303, [2, 16, 8]);  mm_303 = None
        slice_10008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1211, 1, 2416, 2432)
        slice_10009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10008, 2, 0, 16);  slice_10008 = None
        add_305: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10009, view_617);  slice_10009 = view_617 = None
        
        # No stacktrace found for following nodes
        slice_tensor_606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1211, 1, 2416, 2432)
        slice_scatter_default_1212: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_606, add_305, 2, 0, 16);  slice_tensor_606 = add_305 = None
        slice_scatter_default_1213: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1211, slice_scatter_default_1212, 1, 2416, 2432);  slice_scatter_default_1211 = slice_scatter_default_1212 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1213, 1, 2416, 2432)
        slice_10014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10013, 2, 0, 16);  slice_10013 = None
        
        # No stacktrace found for following nodes
        slice_tensor_607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1213, 1, 2416, 2432)
        slice_scatter_default_1214: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_607, slice_10014, 2, 0, 16);  slice_tensor_607 = slice_10014 = None
        slice_scatter_default_1215: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1213, slice_scatter_default_1214, 1, 2416, 2432);  slice_scatter_default_1213 = slice_scatter_default_1214 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10033: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2432, 2448)
        slice_10034: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10033, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_307: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10034, memory_format = torch.contiguous_format);  slice_10034 = None
        view_618: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_307, [32, 16]);  clone_307 = None
        mm_304: "f32[32, 8]" = torch.ops.aten.mm.default(view_618, slice_7)
        view_619: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_304, [2, 16, 8]);  mm_304 = None
        slice_10041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1215, 1, 2432, 2448)
        slice_10042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10041, 2, 0, 16);  slice_10041 = None
        add_306: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10042, view_619);  slice_10042 = view_619 = None
        
        # No stacktrace found for following nodes
        slice_tensor_608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1215, 1, 2432, 2448)
        slice_scatter_default_1216: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_608, add_306, 2, 0, 16);  slice_tensor_608 = add_306 = None
        slice_scatter_default_1217: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1215, slice_scatter_default_1216, 1, 2432, 2448);  slice_scatter_default_1215 = slice_scatter_default_1216 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1217, 1, 2432, 2448)
        slice_10047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10046, 2, 0, 16);  slice_10046 = None
        
        # No stacktrace found for following nodes
        slice_tensor_609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1217, 1, 2432, 2448)
        slice_scatter_default_1218: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_609, slice_10047, 2, 0, 16);  slice_tensor_609 = slice_10047 = None
        slice_scatter_default_1219: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1217, slice_scatter_default_1218, 1, 2432, 2448);  slice_scatter_default_1217 = slice_scatter_default_1218 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10067: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10033, 2, 16, 32);  slice_10033 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_308: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10067, memory_format = torch.contiguous_format);  slice_10067 = None
        view_620: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_308, [32, 11]);  clone_308 = None
        mm_305: "f32[32, 8]" = torch.ops.aten.mm.default(view_620, slice_37)
        view_621: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_305, [2, 16, 8]);  mm_305 = None
        slice_10074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1219, 1, 2432, 2448)
        slice_10075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10074, 2, 0, 16);  slice_10074 = None
        add_307: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10075, view_621);  slice_10075 = view_621 = None
        
        # No stacktrace found for following nodes
        slice_tensor_610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1219, 1, 2432, 2448)
        slice_scatter_default_1220: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_610, add_307, 2, 0, 16);  slice_tensor_610 = add_307 = None
        slice_scatter_default_1221: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1219, slice_scatter_default_1220, 1, 2432, 2448);  slice_scatter_default_1219 = slice_scatter_default_1220 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1221, 1, 2432, 2448)
        slice_10080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10079, 2, 0, 16);  slice_10079 = None
        
        # No stacktrace found for following nodes
        slice_tensor_611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1221, 1, 2432, 2448)
        slice_scatter_default_1222: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_611, slice_10080, 2, 0, 16);  slice_tensor_611 = slice_10080 = None
        slice_scatter_default_1223: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1221, slice_scatter_default_1222, 1, 2432, 2448);  slice_scatter_default_1221 = slice_scatter_default_1222 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10099: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2448, 2464)
        slice_10100: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10099, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_309: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10100, memory_format = torch.contiguous_format);  slice_10100 = None
        view_622: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_309, [32, 16]);  clone_309 = None
        mm_306: "f32[32, 8]" = torch.ops.aten.mm.default(view_622, slice_7)
        view_623: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_306, [2, 16, 8]);  mm_306 = None
        slice_10107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1223, 1, 2448, 2464)
        slice_10108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10107, 2, 0, 16);  slice_10107 = None
        add_308: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10108, view_623);  slice_10108 = view_623 = None
        
        # No stacktrace found for following nodes
        slice_tensor_612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1223, 1, 2448, 2464)
        slice_scatter_default_1224: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_612, add_308, 2, 0, 16);  slice_tensor_612 = add_308 = None
        slice_scatter_default_1225: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1223, slice_scatter_default_1224, 1, 2448, 2464);  slice_scatter_default_1223 = slice_scatter_default_1224 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1225, 1, 2448, 2464)
        slice_10113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10112, 2, 0, 16);  slice_10112 = None
        
        # No stacktrace found for following nodes
        slice_tensor_613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1225, 1, 2448, 2464)
        slice_scatter_default_1226: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_613, slice_10113, 2, 0, 16);  slice_tensor_613 = slice_10113 = None
        slice_scatter_default_1227: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1225, slice_scatter_default_1226, 1, 2448, 2464);  slice_scatter_default_1225 = slice_scatter_default_1226 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10133: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10099, 2, 16, 32);  slice_10099 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_310: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10133, memory_format = torch.contiguous_format);  slice_10133 = None
        view_624: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_310, [32, 11]);  clone_310 = None
        mm_307: "f32[32, 8]" = torch.ops.aten.mm.default(view_624, slice_37)
        view_625: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_307, [2, 16, 8]);  mm_307 = None
        slice_10140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1227, 1, 2448, 2464)
        slice_10141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10140, 2, 0, 16);  slice_10140 = None
        add_309: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10141, view_625);  slice_10141 = view_625 = None
        
        # No stacktrace found for following nodes
        slice_tensor_614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1227, 1, 2448, 2464)
        slice_scatter_default_1228: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_614, add_309, 2, 0, 16);  slice_tensor_614 = add_309 = None
        slice_scatter_default_1229: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1227, slice_scatter_default_1228, 1, 2448, 2464);  slice_scatter_default_1227 = slice_scatter_default_1228 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1229, 1, 2448, 2464)
        slice_10146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10145, 2, 0, 16);  slice_10145 = None
        
        # No stacktrace found for following nodes
        slice_tensor_615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1229, 1, 2448, 2464)
        slice_scatter_default_1230: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_615, slice_10146, 2, 0, 16);  slice_tensor_615 = slice_10146 = None
        slice_scatter_default_1231: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1229, slice_scatter_default_1230, 1, 2448, 2464);  slice_scatter_default_1229 = slice_scatter_default_1230 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10165: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2464, 2480)
        slice_10166: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10165, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_311: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10166, memory_format = torch.contiguous_format);  slice_10166 = None
        view_626: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_311, [32, 16]);  clone_311 = None
        mm_308: "f32[32, 8]" = torch.ops.aten.mm.default(view_626, slice_7)
        view_627: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_308, [2, 16, 8]);  mm_308 = None
        slice_10173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1231, 1, 2464, 2480)
        slice_10174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10173, 2, 0, 16);  slice_10173 = None
        add_310: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10174, view_627);  slice_10174 = view_627 = None
        
        # No stacktrace found for following nodes
        slice_tensor_616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1231, 1, 2464, 2480)
        slice_scatter_default_1232: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_616, add_310, 2, 0, 16);  slice_tensor_616 = add_310 = None
        slice_scatter_default_1233: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1231, slice_scatter_default_1232, 1, 2464, 2480);  slice_scatter_default_1231 = slice_scatter_default_1232 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1233, 1, 2464, 2480)
        slice_10179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10178, 2, 0, 16);  slice_10178 = None
        
        # No stacktrace found for following nodes
        slice_tensor_617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1233, 1, 2464, 2480)
        slice_scatter_default_1234: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_617, slice_10179, 2, 0, 16);  slice_tensor_617 = slice_10179 = None
        slice_scatter_default_1235: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1233, slice_scatter_default_1234, 1, 2464, 2480);  slice_scatter_default_1233 = slice_scatter_default_1234 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10199: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10165, 2, 16, 32);  slice_10165 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_312: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10199, memory_format = torch.contiguous_format);  slice_10199 = None
        view_628: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_312, [32, 11]);  clone_312 = None
        mm_309: "f32[32, 8]" = torch.ops.aten.mm.default(view_628, slice_37)
        view_629: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_309, [2, 16, 8]);  mm_309 = None
        slice_10206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1235, 1, 2464, 2480)
        slice_10207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10206, 2, 0, 16);  slice_10206 = None
        add_311: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10207, view_629);  slice_10207 = view_629 = None
        
        # No stacktrace found for following nodes
        slice_tensor_618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1235, 1, 2464, 2480)
        slice_scatter_default_1236: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_618, add_311, 2, 0, 16);  slice_tensor_618 = add_311 = None
        slice_scatter_default_1237: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1235, slice_scatter_default_1236, 1, 2464, 2480);  slice_scatter_default_1235 = slice_scatter_default_1236 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1237, 1, 2464, 2480)
        slice_10212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10211, 2, 0, 16);  slice_10211 = None
        
        # No stacktrace found for following nodes
        slice_tensor_619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1237, 1, 2464, 2480)
        slice_scatter_default_1238: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_619, slice_10212, 2, 0, 16);  slice_tensor_619 = slice_10212 = None
        slice_scatter_default_1239: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1237, slice_scatter_default_1238, 1, 2464, 2480);  slice_scatter_default_1237 = slice_scatter_default_1238 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10231: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2480, 2496)
        slice_10232: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10231, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_313: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10232, memory_format = torch.contiguous_format);  slice_10232 = None
        view_630: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_313, [32, 16]);  clone_313 = None
        mm_310: "f32[32, 8]" = torch.ops.aten.mm.default(view_630, slice_7)
        view_631: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_310, [2, 16, 8]);  mm_310 = None
        slice_10239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1239, 1, 2480, 2496)
        slice_10240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10239, 2, 0, 16);  slice_10239 = None
        add_312: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10240, view_631);  slice_10240 = view_631 = None
        
        # No stacktrace found for following nodes
        slice_tensor_620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1239, 1, 2480, 2496)
        slice_scatter_default_1240: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_620, add_312, 2, 0, 16);  slice_tensor_620 = add_312 = None
        slice_scatter_default_1241: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1239, slice_scatter_default_1240, 1, 2480, 2496);  slice_scatter_default_1239 = slice_scatter_default_1240 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1241, 1, 2480, 2496)
        slice_10245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10244, 2, 0, 16);  slice_10244 = None
        
        # No stacktrace found for following nodes
        slice_tensor_621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1241, 1, 2480, 2496)
        slice_scatter_default_1242: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_621, slice_10245, 2, 0, 16);  slice_tensor_621 = slice_10245 = None
        slice_scatter_default_1243: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1241, slice_scatter_default_1242, 1, 2480, 2496);  slice_scatter_default_1241 = slice_scatter_default_1242 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10265: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10231, 2, 16, 32);  slice_10231 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_314: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10265, memory_format = torch.contiguous_format);  slice_10265 = None
        view_632: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_314, [32, 11]);  clone_314 = None
        mm_311: "f32[32, 8]" = torch.ops.aten.mm.default(view_632, slice_37)
        view_633: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_311, [2, 16, 8]);  mm_311 = None
        slice_10272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1243, 1, 2480, 2496)
        slice_10273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10272, 2, 0, 16);  slice_10272 = None
        add_313: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10273, view_633);  slice_10273 = view_633 = None
        
        # No stacktrace found for following nodes
        slice_tensor_622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1243, 1, 2480, 2496)
        slice_scatter_default_1244: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_622, add_313, 2, 0, 16);  slice_tensor_622 = add_313 = None
        slice_scatter_default_1245: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1243, slice_scatter_default_1244, 1, 2480, 2496);  slice_scatter_default_1243 = slice_scatter_default_1244 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1245, 1, 2480, 2496)
        slice_10278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10277, 2, 0, 16);  slice_10277 = None
        
        # No stacktrace found for following nodes
        slice_tensor_623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1245, 1, 2480, 2496)
        slice_scatter_default_1246: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_623, slice_10278, 2, 0, 16);  slice_tensor_623 = slice_10278 = None
        slice_scatter_default_1247: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1245, slice_scatter_default_1246, 1, 2480, 2496);  slice_scatter_default_1245 = slice_scatter_default_1246 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10297: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2496, 2512)
        slice_10298: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10297, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_315: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10298, memory_format = torch.contiguous_format);  slice_10298 = None
        view_634: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_315, [32, 16]);  clone_315 = None
        mm_312: "f32[32, 8]" = torch.ops.aten.mm.default(view_634, slice_7)
        view_635: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_312, [2, 16, 8]);  mm_312 = None
        slice_10305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1247, 1, 2496, 2512)
        slice_10306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10305, 2, 0, 16);  slice_10305 = None
        add_314: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10306, view_635);  slice_10306 = view_635 = None
        
        # No stacktrace found for following nodes
        slice_tensor_624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1247, 1, 2496, 2512)
        slice_scatter_default_1248: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_624, add_314, 2, 0, 16);  slice_tensor_624 = add_314 = None
        slice_scatter_default_1249: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1247, slice_scatter_default_1248, 1, 2496, 2512);  slice_scatter_default_1247 = slice_scatter_default_1248 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1249, 1, 2496, 2512)
        slice_10311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10310, 2, 0, 16);  slice_10310 = None
        
        # No stacktrace found for following nodes
        slice_tensor_625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1249, 1, 2496, 2512)
        slice_scatter_default_1250: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_625, slice_10311, 2, 0, 16);  slice_tensor_625 = slice_10311 = None
        slice_scatter_default_1251: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1249, slice_scatter_default_1250, 1, 2496, 2512);  slice_scatter_default_1249 = slice_scatter_default_1250 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10331: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10297, 2, 16, 32);  slice_10297 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_316: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10331, memory_format = torch.contiguous_format);  slice_10331 = None
        view_636: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_316, [32, 11]);  clone_316 = None
        mm_313: "f32[32, 8]" = torch.ops.aten.mm.default(view_636, slice_37)
        view_637: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_313, [2, 16, 8]);  mm_313 = None
        slice_10338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1251, 1, 2496, 2512)
        slice_10339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10338, 2, 0, 16);  slice_10338 = None
        add_315: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10339, view_637);  slice_10339 = view_637 = None
        
        # No stacktrace found for following nodes
        slice_tensor_626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1251, 1, 2496, 2512)
        slice_scatter_default_1252: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_626, add_315, 2, 0, 16);  slice_tensor_626 = add_315 = None
        slice_scatter_default_1253: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1251, slice_scatter_default_1252, 1, 2496, 2512);  slice_scatter_default_1251 = slice_scatter_default_1252 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1253, 1, 2496, 2512)
        slice_10344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10343, 2, 0, 16);  slice_10343 = None
        
        # No stacktrace found for following nodes
        slice_tensor_627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1253, 1, 2496, 2512)
        slice_scatter_default_1254: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_627, slice_10344, 2, 0, 16);  slice_tensor_627 = slice_10344 = None
        slice_scatter_default_1255: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1253, slice_scatter_default_1254, 1, 2496, 2512);  slice_scatter_default_1253 = slice_scatter_default_1254 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10363: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2512, 2528)
        slice_10364: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10363, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_317: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10364, memory_format = torch.contiguous_format);  slice_10364 = None
        view_638: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_317, [32, 16]);  clone_317 = None
        mm_314: "f32[32, 8]" = torch.ops.aten.mm.default(view_638, slice_7)
        view_639: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_314, [2, 16, 8]);  mm_314 = None
        slice_10371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1255, 1, 2512, 2528)
        slice_10372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10371, 2, 0, 16);  slice_10371 = None
        add_316: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10372, view_639);  slice_10372 = view_639 = None
        
        # No stacktrace found for following nodes
        slice_tensor_628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1255, 1, 2512, 2528)
        slice_scatter_default_1256: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_628, add_316, 2, 0, 16);  slice_tensor_628 = add_316 = None
        slice_scatter_default_1257: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1255, slice_scatter_default_1256, 1, 2512, 2528);  slice_scatter_default_1255 = slice_scatter_default_1256 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1257, 1, 2512, 2528)
        slice_10377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10376, 2, 0, 16);  slice_10376 = None
        
        # No stacktrace found for following nodes
        slice_tensor_629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1257, 1, 2512, 2528)
        slice_scatter_default_1258: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_629, slice_10377, 2, 0, 16);  slice_tensor_629 = slice_10377 = None
        slice_scatter_default_1259: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1257, slice_scatter_default_1258, 1, 2512, 2528);  slice_scatter_default_1257 = slice_scatter_default_1258 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10397: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10363, 2, 16, 32);  slice_10363 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_318: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10397, memory_format = torch.contiguous_format);  slice_10397 = None
        view_640: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_318, [32, 11]);  clone_318 = None
        mm_315: "f32[32, 8]" = torch.ops.aten.mm.default(view_640, slice_37)
        view_641: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_315, [2, 16, 8]);  mm_315 = None
        slice_10404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1259, 1, 2512, 2528)
        slice_10405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10404, 2, 0, 16);  slice_10404 = None
        add_317: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10405, view_641);  slice_10405 = view_641 = None
        
        # No stacktrace found for following nodes
        slice_tensor_630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1259, 1, 2512, 2528)
        slice_scatter_default_1260: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_630, add_317, 2, 0, 16);  slice_tensor_630 = add_317 = None
        slice_scatter_default_1261: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1259, slice_scatter_default_1260, 1, 2512, 2528);  slice_scatter_default_1259 = slice_scatter_default_1260 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1261, 1, 2512, 2528)
        slice_10410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10409, 2, 0, 16);  slice_10409 = None
        
        # No stacktrace found for following nodes
        slice_tensor_631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1261, 1, 2512, 2528)
        slice_scatter_default_1262: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_631, slice_10410, 2, 0, 16);  slice_tensor_631 = slice_10410 = None
        slice_scatter_default_1263: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1261, slice_scatter_default_1262, 1, 2512, 2528);  slice_scatter_default_1261 = slice_scatter_default_1262 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10429: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2528, 2544)
        slice_10430: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10429, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_319: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10430, memory_format = torch.contiguous_format);  slice_10430 = None
        view_642: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_319, [32, 16]);  clone_319 = None
        mm_316: "f32[32, 8]" = torch.ops.aten.mm.default(view_642, slice_7)
        view_643: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_316, [2, 16, 8]);  mm_316 = None
        slice_10437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1263, 1, 2528, 2544)
        slice_10438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10437, 2, 0, 16);  slice_10437 = None
        add_318: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10438, view_643);  slice_10438 = view_643 = None
        
        # No stacktrace found for following nodes
        slice_tensor_632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1263, 1, 2528, 2544)
        slice_scatter_default_1264: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_632, add_318, 2, 0, 16);  slice_tensor_632 = add_318 = None
        slice_scatter_default_1265: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1263, slice_scatter_default_1264, 1, 2528, 2544);  slice_scatter_default_1263 = slice_scatter_default_1264 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1265, 1, 2528, 2544)
        slice_10443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10442, 2, 0, 16);  slice_10442 = None
        
        # No stacktrace found for following nodes
        slice_tensor_633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1265, 1, 2528, 2544)
        slice_scatter_default_1266: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_633, slice_10443, 2, 0, 16);  slice_tensor_633 = slice_10443 = None
        slice_scatter_default_1267: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1265, slice_scatter_default_1266, 1, 2528, 2544);  slice_scatter_default_1265 = slice_scatter_default_1266 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10463: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10429, 2, 16, 32);  slice_10429 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_320: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10463, memory_format = torch.contiguous_format);  slice_10463 = None
        view_644: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_320, [32, 11]);  clone_320 = None
        mm_317: "f32[32, 8]" = torch.ops.aten.mm.default(view_644, slice_37)
        view_645: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_317, [2, 16, 8]);  mm_317 = None
        slice_10470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1267, 1, 2528, 2544)
        slice_10471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10470, 2, 0, 16);  slice_10470 = None
        add_319: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10471, view_645);  slice_10471 = view_645 = None
        
        # No stacktrace found for following nodes
        slice_tensor_634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1267, 1, 2528, 2544)
        slice_scatter_default_1268: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_634, add_319, 2, 0, 16);  slice_tensor_634 = add_319 = None
        slice_scatter_default_1269: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1267, slice_scatter_default_1268, 1, 2528, 2544);  slice_scatter_default_1267 = slice_scatter_default_1268 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1269, 1, 2528, 2544)
        slice_10476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10475, 2, 0, 16);  slice_10475 = None
        
        # No stacktrace found for following nodes
        slice_tensor_635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1269, 1, 2528, 2544)
        slice_scatter_default_1270: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_635, slice_10476, 2, 0, 16);  slice_tensor_635 = slice_10476 = None
        slice_scatter_default_1271: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1269, slice_scatter_default_1270, 1, 2528, 2544);  slice_scatter_default_1269 = slice_scatter_default_1270 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10495: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2544, 2560)
        slice_10496: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10495, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_321: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10496, memory_format = torch.contiguous_format);  slice_10496 = None
        view_646: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_321, [32, 16]);  clone_321 = None
        mm_318: "f32[32, 8]" = torch.ops.aten.mm.default(view_646, slice_7)
        view_647: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_318, [2, 16, 8]);  mm_318 = None
        slice_10503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1271, 1, 2544, 2560)
        slice_10504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10503, 2, 0, 16);  slice_10503 = None
        add_320: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10504, view_647);  slice_10504 = view_647 = None
        
        # No stacktrace found for following nodes
        slice_tensor_636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1271, 1, 2544, 2560)
        slice_scatter_default_1272: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_636, add_320, 2, 0, 16);  slice_tensor_636 = add_320 = None
        slice_scatter_default_1273: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1271, slice_scatter_default_1272, 1, 2544, 2560);  slice_scatter_default_1271 = slice_scatter_default_1272 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1273, 1, 2544, 2560)
        slice_10509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10508, 2, 0, 16);  slice_10508 = None
        
        # No stacktrace found for following nodes
        slice_tensor_637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1273, 1, 2544, 2560)
        slice_scatter_default_1274: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_637, slice_10509, 2, 0, 16);  slice_tensor_637 = slice_10509 = None
        slice_scatter_default_1275: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1273, slice_scatter_default_1274, 1, 2544, 2560);  slice_scatter_default_1273 = slice_scatter_default_1274 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10529: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10495, 2, 16, 32);  slice_10495 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_322: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10529, memory_format = torch.contiguous_format);  slice_10529 = None
        view_648: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_322, [32, 11]);  clone_322 = None
        mm_319: "f32[32, 8]" = torch.ops.aten.mm.default(view_648, slice_37)
        view_649: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_319, [2, 16, 8]);  mm_319 = None
        slice_10536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1275, 1, 2544, 2560)
        slice_10537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10536, 2, 0, 16);  slice_10536 = None
        add_321: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10537, view_649);  slice_10537 = view_649 = None
        
        # No stacktrace found for following nodes
        slice_tensor_638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1275, 1, 2544, 2560)
        slice_scatter_default_1276: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_638, add_321, 2, 0, 16);  slice_tensor_638 = add_321 = None
        slice_scatter_default_1277: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1275, slice_scatter_default_1276, 1, 2544, 2560);  slice_scatter_default_1275 = slice_scatter_default_1276 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1277, 1, 2544, 2560)
        slice_10542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10541, 2, 0, 16);  slice_10541 = None
        
        # No stacktrace found for following nodes
        slice_tensor_639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1277, 1, 2544, 2560)
        slice_scatter_default_1278: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_639, slice_10542, 2, 0, 16);  slice_tensor_639 = slice_10542 = None
        slice_scatter_default_1279: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1277, slice_scatter_default_1278, 1, 2544, 2560);  slice_scatter_default_1277 = slice_scatter_default_1278 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10561: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2560, 2576)
        slice_10562: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10561, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_323: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10562, memory_format = torch.contiguous_format);  slice_10562 = None
        view_650: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_323, [32, 16]);  clone_323 = None
        mm_320: "f32[32, 8]" = torch.ops.aten.mm.default(view_650, slice_7)
        view_651: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_320, [2, 16, 8]);  mm_320 = None
        slice_10569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1279, 1, 2560, 2576)
        slice_10570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10569, 2, 0, 16);  slice_10569 = None
        add_322: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10570, view_651);  slice_10570 = view_651 = None
        
        # No stacktrace found for following nodes
        slice_tensor_640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1279, 1, 2560, 2576)
        slice_scatter_default_1280: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_640, add_322, 2, 0, 16);  slice_tensor_640 = add_322 = None
        slice_scatter_default_1281: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1279, slice_scatter_default_1280, 1, 2560, 2576);  slice_scatter_default_1279 = slice_scatter_default_1280 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1281, 1, 2560, 2576)
        slice_10575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10574, 2, 0, 16);  slice_10574 = None
        
        # No stacktrace found for following nodes
        slice_tensor_641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1281, 1, 2560, 2576)
        slice_scatter_default_1282: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_641, slice_10575, 2, 0, 16);  slice_tensor_641 = slice_10575 = None
        slice_scatter_default_1283: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1281, slice_scatter_default_1282, 1, 2560, 2576);  slice_scatter_default_1281 = slice_scatter_default_1282 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10595: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10561, 2, 16, 32);  slice_10561 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_324: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10595, memory_format = torch.contiguous_format);  slice_10595 = None
        view_652: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_324, [32, 11]);  clone_324 = None
        mm_321: "f32[32, 8]" = torch.ops.aten.mm.default(view_652, slice_37)
        view_653: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_321, [2, 16, 8]);  mm_321 = None
        slice_10602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1283, 1, 2560, 2576)
        slice_10603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10602, 2, 0, 16);  slice_10602 = None
        add_323: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10603, view_653);  slice_10603 = view_653 = None
        
        # No stacktrace found for following nodes
        slice_tensor_642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1283, 1, 2560, 2576)
        slice_scatter_default_1284: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_642, add_323, 2, 0, 16);  slice_tensor_642 = add_323 = None
        slice_scatter_default_1285: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1283, slice_scatter_default_1284, 1, 2560, 2576);  slice_scatter_default_1283 = slice_scatter_default_1284 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1285, 1, 2560, 2576)
        slice_10608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10607, 2, 0, 16);  slice_10607 = None
        
        # No stacktrace found for following nodes
        slice_tensor_643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1285, 1, 2560, 2576)
        slice_scatter_default_1286: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_643, slice_10608, 2, 0, 16);  slice_tensor_643 = slice_10608 = None
        slice_scatter_default_1287: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1285, slice_scatter_default_1286, 1, 2560, 2576);  slice_scatter_default_1285 = slice_scatter_default_1286 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10627: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2576, 2592)
        slice_10628: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10627, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_325: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10628, memory_format = torch.contiguous_format);  slice_10628 = None
        view_654: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_325, [32, 16]);  clone_325 = None
        mm_322: "f32[32, 8]" = torch.ops.aten.mm.default(view_654, slice_7)
        view_655: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_322, [2, 16, 8]);  mm_322 = None
        slice_10635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1287, 1, 2576, 2592)
        slice_10636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10635, 2, 0, 16);  slice_10635 = None
        add_324: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10636, view_655);  slice_10636 = view_655 = None
        
        # No stacktrace found for following nodes
        slice_tensor_644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1287, 1, 2576, 2592)
        slice_scatter_default_1288: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_644, add_324, 2, 0, 16);  slice_tensor_644 = add_324 = None
        slice_scatter_default_1289: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1287, slice_scatter_default_1288, 1, 2576, 2592);  slice_scatter_default_1287 = slice_scatter_default_1288 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1289, 1, 2576, 2592)
        slice_10641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10640, 2, 0, 16);  slice_10640 = None
        
        # No stacktrace found for following nodes
        slice_tensor_645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1289, 1, 2576, 2592)
        slice_scatter_default_1290: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_645, slice_10641, 2, 0, 16);  slice_tensor_645 = slice_10641 = None
        slice_scatter_default_1291: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1289, slice_scatter_default_1290, 1, 2576, 2592);  slice_scatter_default_1289 = slice_scatter_default_1290 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10661: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10627, 2, 16, 32);  slice_10627 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_326: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10661, memory_format = torch.contiguous_format);  slice_10661 = None
        view_656: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_326, [32, 11]);  clone_326 = None
        mm_323: "f32[32, 8]" = torch.ops.aten.mm.default(view_656, slice_37)
        view_657: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_323, [2, 16, 8]);  mm_323 = None
        slice_10668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1291, 1, 2576, 2592)
        slice_10669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10668, 2, 0, 16);  slice_10668 = None
        add_325: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10669, view_657);  slice_10669 = view_657 = None
        
        # No stacktrace found for following nodes
        slice_tensor_646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1291, 1, 2576, 2592)
        slice_scatter_default_1292: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_646, add_325, 2, 0, 16);  slice_tensor_646 = add_325 = None
        slice_scatter_default_1293: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1291, slice_scatter_default_1292, 1, 2576, 2592);  slice_scatter_default_1291 = slice_scatter_default_1292 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1293, 1, 2576, 2592)
        slice_10674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10673, 2, 0, 16);  slice_10673 = None
        
        # No stacktrace found for following nodes
        slice_tensor_647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1293, 1, 2576, 2592)
        slice_scatter_default_1294: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_647, slice_10674, 2, 0, 16);  slice_tensor_647 = slice_10674 = None
        slice_scatter_default_1295: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1293, slice_scatter_default_1294, 1, 2576, 2592);  slice_scatter_default_1293 = slice_scatter_default_1294 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10693: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2592, 2608)
        slice_10694: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10693, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_327: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10694, memory_format = torch.contiguous_format);  slice_10694 = None
        view_658: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_327, [32, 16]);  clone_327 = None
        mm_324: "f32[32, 8]" = torch.ops.aten.mm.default(view_658, slice_7)
        view_659: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_324, [2, 16, 8]);  mm_324 = None
        slice_10701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1295, 1, 2592, 2608)
        slice_10702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10701, 2, 0, 16);  slice_10701 = None
        add_326: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10702, view_659);  slice_10702 = view_659 = None
        
        # No stacktrace found for following nodes
        slice_tensor_648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1295, 1, 2592, 2608)
        slice_scatter_default_1296: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_648, add_326, 2, 0, 16);  slice_tensor_648 = add_326 = None
        slice_scatter_default_1297: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1295, slice_scatter_default_1296, 1, 2592, 2608);  slice_scatter_default_1295 = slice_scatter_default_1296 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1297, 1, 2592, 2608)
        slice_10707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10706, 2, 0, 16);  slice_10706 = None
        
        # No stacktrace found for following nodes
        slice_tensor_649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1297, 1, 2592, 2608)
        slice_scatter_default_1298: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_649, slice_10707, 2, 0, 16);  slice_tensor_649 = slice_10707 = None
        slice_scatter_default_1299: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1297, slice_scatter_default_1298, 1, 2592, 2608);  slice_scatter_default_1297 = slice_scatter_default_1298 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10727: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10693, 2, 16, 32);  slice_10693 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_328: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10727, memory_format = torch.contiguous_format);  slice_10727 = None
        view_660: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_328, [32, 11]);  clone_328 = None
        mm_325: "f32[32, 8]" = torch.ops.aten.mm.default(view_660, slice_37)
        view_661: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_325, [2, 16, 8]);  mm_325 = None
        slice_10734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1299, 1, 2592, 2608)
        slice_10735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10734, 2, 0, 16);  slice_10734 = None
        add_327: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10735, view_661);  slice_10735 = view_661 = None
        
        # No stacktrace found for following nodes
        slice_tensor_650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1299, 1, 2592, 2608)
        slice_scatter_default_1300: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_650, add_327, 2, 0, 16);  slice_tensor_650 = add_327 = None
        slice_scatter_default_1301: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1299, slice_scatter_default_1300, 1, 2592, 2608);  slice_scatter_default_1299 = slice_scatter_default_1300 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1301, 1, 2592, 2608)
        slice_10740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10739, 2, 0, 16);  slice_10739 = None
        
        # No stacktrace found for following nodes
        slice_tensor_651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1301, 1, 2592, 2608)
        slice_scatter_default_1302: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_651, slice_10740, 2, 0, 16);  slice_tensor_651 = slice_10740 = None
        slice_scatter_default_1303: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1301, slice_scatter_default_1302, 1, 2592, 2608);  slice_scatter_default_1301 = slice_scatter_default_1302 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10759: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2608, 2624)
        slice_10760: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10759, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_329: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10760, memory_format = torch.contiguous_format);  slice_10760 = None
        view_662: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_329, [32, 16]);  clone_329 = None
        mm_326: "f32[32, 8]" = torch.ops.aten.mm.default(view_662, slice_7)
        view_663: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_326, [2, 16, 8]);  mm_326 = None
        slice_10767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1303, 1, 2608, 2624)
        slice_10768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10767, 2, 0, 16);  slice_10767 = None
        add_328: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10768, view_663);  slice_10768 = view_663 = None
        
        # No stacktrace found for following nodes
        slice_tensor_652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1303, 1, 2608, 2624)
        slice_scatter_default_1304: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_652, add_328, 2, 0, 16);  slice_tensor_652 = add_328 = None
        slice_scatter_default_1305: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1303, slice_scatter_default_1304, 1, 2608, 2624);  slice_scatter_default_1303 = slice_scatter_default_1304 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1305, 1, 2608, 2624)
        slice_10773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10772, 2, 0, 16);  slice_10772 = None
        
        # No stacktrace found for following nodes
        slice_tensor_653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1305, 1, 2608, 2624)
        slice_scatter_default_1306: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_653, slice_10773, 2, 0, 16);  slice_tensor_653 = slice_10773 = None
        slice_scatter_default_1307: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1305, slice_scatter_default_1306, 1, 2608, 2624);  slice_scatter_default_1305 = slice_scatter_default_1306 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10793: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10759, 2, 16, 32);  slice_10759 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_330: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10793, memory_format = torch.contiguous_format);  slice_10793 = None
        view_664: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_330, [32, 11]);  clone_330 = None
        mm_327: "f32[32, 8]" = torch.ops.aten.mm.default(view_664, slice_37)
        view_665: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_327, [2, 16, 8]);  mm_327 = None
        slice_10800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1307, 1, 2608, 2624)
        slice_10801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10800, 2, 0, 16);  slice_10800 = None
        add_329: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10801, view_665);  slice_10801 = view_665 = None
        
        # No stacktrace found for following nodes
        slice_tensor_654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1307, 1, 2608, 2624)
        slice_scatter_default_1308: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_654, add_329, 2, 0, 16);  slice_tensor_654 = add_329 = None
        slice_scatter_default_1309: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1307, slice_scatter_default_1308, 1, 2608, 2624);  slice_scatter_default_1307 = slice_scatter_default_1308 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1309, 1, 2608, 2624)
        slice_10806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10805, 2, 0, 16);  slice_10805 = None
        
        # No stacktrace found for following nodes
        slice_tensor_655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1309, 1, 2608, 2624)
        slice_scatter_default_1310: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_655, slice_10806, 2, 0, 16);  slice_tensor_655 = slice_10806 = None
        slice_scatter_default_1311: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1309, slice_scatter_default_1310, 1, 2608, 2624);  slice_scatter_default_1309 = slice_scatter_default_1310 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10825: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2624, 2640)
        slice_10826: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10825, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_331: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10826, memory_format = torch.contiguous_format);  slice_10826 = None
        view_666: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_331, [32, 16]);  clone_331 = None
        mm_328: "f32[32, 8]" = torch.ops.aten.mm.default(view_666, slice_7)
        view_667: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_328, [2, 16, 8]);  mm_328 = None
        slice_10833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1311, 1, 2624, 2640)
        slice_10834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10833, 2, 0, 16);  slice_10833 = None
        add_330: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10834, view_667);  slice_10834 = view_667 = None
        
        # No stacktrace found for following nodes
        slice_tensor_656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1311, 1, 2624, 2640)
        slice_scatter_default_1312: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_656, add_330, 2, 0, 16);  slice_tensor_656 = add_330 = None
        slice_scatter_default_1313: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1311, slice_scatter_default_1312, 1, 2624, 2640);  slice_scatter_default_1311 = slice_scatter_default_1312 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1313, 1, 2624, 2640)
        slice_10839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10838, 2, 0, 16);  slice_10838 = None
        
        # No stacktrace found for following nodes
        slice_tensor_657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1313, 1, 2624, 2640)
        slice_scatter_default_1314: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_657, slice_10839, 2, 0, 16);  slice_tensor_657 = slice_10839 = None
        slice_scatter_default_1315: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1313, slice_scatter_default_1314, 1, 2624, 2640);  slice_scatter_default_1313 = slice_scatter_default_1314 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10859: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10825, 2, 16, 32);  slice_10825 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_332: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10859, memory_format = torch.contiguous_format);  slice_10859 = None
        view_668: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_332, [32, 11]);  clone_332 = None
        mm_329: "f32[32, 8]" = torch.ops.aten.mm.default(view_668, slice_37)
        view_669: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_329, [2, 16, 8]);  mm_329 = None
        slice_10866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1315, 1, 2624, 2640)
        slice_10867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10866, 2, 0, 16);  slice_10866 = None
        add_331: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10867, view_669);  slice_10867 = view_669 = None
        
        # No stacktrace found for following nodes
        slice_tensor_658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1315, 1, 2624, 2640)
        slice_scatter_default_1316: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_658, add_331, 2, 0, 16);  slice_tensor_658 = add_331 = None
        slice_scatter_default_1317: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1315, slice_scatter_default_1316, 1, 2624, 2640);  slice_scatter_default_1315 = slice_scatter_default_1316 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1317, 1, 2624, 2640)
        slice_10872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10871, 2, 0, 16);  slice_10871 = None
        
        # No stacktrace found for following nodes
        slice_tensor_659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1317, 1, 2624, 2640)
        slice_scatter_default_1318: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_659, slice_10872, 2, 0, 16);  slice_tensor_659 = slice_10872 = None
        slice_scatter_default_1319: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1317, slice_scatter_default_1318, 1, 2624, 2640);  slice_scatter_default_1317 = slice_scatter_default_1318 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10891: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2640, 2656)
        slice_10892: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10891, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_333: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10892, memory_format = torch.contiguous_format);  slice_10892 = None
        view_670: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_333, [32, 16]);  clone_333 = None
        mm_330: "f32[32, 8]" = torch.ops.aten.mm.default(view_670, slice_7)
        view_671: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_330, [2, 16, 8]);  mm_330 = None
        slice_10899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1319, 1, 2640, 2656)
        slice_10900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10899, 2, 0, 16);  slice_10899 = None
        add_332: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10900, view_671);  slice_10900 = view_671 = None
        
        # No stacktrace found for following nodes
        slice_tensor_660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1319, 1, 2640, 2656)
        slice_scatter_default_1320: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_660, add_332, 2, 0, 16);  slice_tensor_660 = add_332 = None
        slice_scatter_default_1321: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1319, slice_scatter_default_1320, 1, 2640, 2656);  slice_scatter_default_1319 = slice_scatter_default_1320 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1321, 1, 2640, 2656)
        slice_10905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10904, 2, 0, 16);  slice_10904 = None
        
        # No stacktrace found for following nodes
        slice_tensor_661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1321, 1, 2640, 2656)
        slice_scatter_default_1322: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_661, slice_10905, 2, 0, 16);  slice_tensor_661 = slice_10905 = None
        slice_scatter_default_1323: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1321, slice_scatter_default_1322, 1, 2640, 2656);  slice_scatter_default_1321 = slice_scatter_default_1322 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10925: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10891, 2, 16, 32);  slice_10891 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_334: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10925, memory_format = torch.contiguous_format);  slice_10925 = None
        view_672: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_334, [32, 11]);  clone_334 = None
        mm_331: "f32[32, 8]" = torch.ops.aten.mm.default(view_672, slice_37)
        view_673: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_331, [2, 16, 8]);  mm_331 = None
        slice_10932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1323, 1, 2640, 2656)
        slice_10933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10932, 2, 0, 16);  slice_10932 = None
        add_333: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10933, view_673);  slice_10933 = view_673 = None
        
        # No stacktrace found for following nodes
        slice_tensor_662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1323, 1, 2640, 2656)
        slice_scatter_default_1324: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_662, add_333, 2, 0, 16);  slice_tensor_662 = add_333 = None
        slice_scatter_default_1325: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1323, slice_scatter_default_1324, 1, 2640, 2656);  slice_scatter_default_1323 = slice_scatter_default_1324 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1325, 1, 2640, 2656)
        slice_10938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10937, 2, 0, 16);  slice_10937 = None
        
        # No stacktrace found for following nodes
        slice_tensor_663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1325, 1, 2640, 2656)
        slice_scatter_default_1326: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_663, slice_10938, 2, 0, 16);  slice_tensor_663 = slice_10938 = None
        slice_scatter_default_1327: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1325, slice_scatter_default_1326, 1, 2640, 2656);  slice_scatter_default_1325 = slice_scatter_default_1326 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10957: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2656, 2672)
        slice_10958: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_10957, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_335: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_10958, memory_format = torch.contiguous_format);  slice_10958 = None
        view_674: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_335, [32, 16]);  clone_335 = None
        mm_332: "f32[32, 8]" = torch.ops.aten.mm.default(view_674, slice_7)
        view_675: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_332, [2, 16, 8]);  mm_332 = None
        slice_10965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1327, 1, 2656, 2672)
        slice_10966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10965, 2, 0, 16);  slice_10965 = None
        add_334: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10966, view_675);  slice_10966 = view_675 = None
        
        # No stacktrace found for following nodes
        slice_tensor_664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1327, 1, 2656, 2672)
        slice_scatter_default_1328: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_664, add_334, 2, 0, 16);  slice_tensor_664 = add_334 = None
        slice_scatter_default_1329: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1327, slice_scatter_default_1328, 1, 2656, 2672);  slice_scatter_default_1327 = slice_scatter_default_1328 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_10970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1329, 1, 2656, 2672)
        slice_10971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10970, 2, 0, 16);  slice_10970 = None
        
        # No stacktrace found for following nodes
        slice_tensor_665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1329, 1, 2656, 2672)
        slice_scatter_default_1330: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_665, slice_10971, 2, 0, 16);  slice_tensor_665 = slice_10971 = None
        slice_scatter_default_1331: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1329, slice_scatter_default_1330, 1, 2656, 2672);  slice_scatter_default_1329 = slice_scatter_default_1330 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_10991: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_10957, 2, 16, 32);  slice_10957 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_336: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_10991, memory_format = torch.contiguous_format);  slice_10991 = None
        view_676: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_336, [32, 11]);  clone_336 = None
        mm_333: "f32[32, 8]" = torch.ops.aten.mm.default(view_676, slice_37)
        view_677: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_333, [2, 16, 8]);  mm_333 = None
        slice_10998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1331, 1, 2656, 2672)
        slice_10999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_10998, 2, 0, 16);  slice_10998 = None
        add_335: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_10999, view_677);  slice_10999 = view_677 = None
        
        # No stacktrace found for following nodes
        slice_tensor_666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1331, 1, 2656, 2672)
        slice_scatter_default_1332: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_666, add_335, 2, 0, 16);  slice_tensor_666 = add_335 = None
        slice_scatter_default_1333: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1331, slice_scatter_default_1332, 1, 2656, 2672);  slice_scatter_default_1331 = slice_scatter_default_1332 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1333, 1, 2656, 2672)
        slice_11004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11003, 2, 0, 16);  slice_11003 = None
        
        # No stacktrace found for following nodes
        slice_tensor_667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1333, 1, 2656, 2672)
        slice_scatter_default_1334: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_667, slice_11004, 2, 0, 16);  slice_tensor_667 = slice_11004 = None
        slice_scatter_default_1335: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1333, slice_scatter_default_1334, 1, 2656, 2672);  slice_scatter_default_1333 = slice_scatter_default_1334 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11023: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2672, 2688)
        slice_11024: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11023, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_337: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11024, memory_format = torch.contiguous_format);  slice_11024 = None
        view_678: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_337, [32, 16]);  clone_337 = None
        mm_334: "f32[32, 8]" = torch.ops.aten.mm.default(view_678, slice_7)
        view_679: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_334, [2, 16, 8]);  mm_334 = None
        slice_11031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1335, 1, 2672, 2688)
        slice_11032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11031, 2, 0, 16);  slice_11031 = None
        add_336: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11032, view_679);  slice_11032 = view_679 = None
        
        # No stacktrace found for following nodes
        slice_tensor_668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1335, 1, 2672, 2688)
        slice_scatter_default_1336: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_668, add_336, 2, 0, 16);  slice_tensor_668 = add_336 = None
        slice_scatter_default_1337: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1335, slice_scatter_default_1336, 1, 2672, 2688);  slice_scatter_default_1335 = slice_scatter_default_1336 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1337, 1, 2672, 2688)
        slice_11037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11036, 2, 0, 16);  slice_11036 = None
        
        # No stacktrace found for following nodes
        slice_tensor_669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1337, 1, 2672, 2688)
        slice_scatter_default_1338: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_669, slice_11037, 2, 0, 16);  slice_tensor_669 = slice_11037 = None
        slice_scatter_default_1339: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1337, slice_scatter_default_1338, 1, 2672, 2688);  slice_scatter_default_1337 = slice_scatter_default_1338 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11057: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11023, 2, 16, 32);  slice_11023 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_338: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11057, memory_format = torch.contiguous_format);  slice_11057 = None
        view_680: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_338, [32, 11]);  clone_338 = None
        mm_335: "f32[32, 8]" = torch.ops.aten.mm.default(view_680, slice_37)
        view_681: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_335, [2, 16, 8]);  mm_335 = None
        slice_11064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1339, 1, 2672, 2688)
        slice_11065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11064, 2, 0, 16);  slice_11064 = None
        add_337: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11065, view_681);  slice_11065 = view_681 = None
        
        # No stacktrace found for following nodes
        slice_tensor_670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1339, 1, 2672, 2688)
        slice_scatter_default_1340: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_670, add_337, 2, 0, 16);  slice_tensor_670 = add_337 = None
        slice_scatter_default_1341: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1339, slice_scatter_default_1340, 1, 2672, 2688);  slice_scatter_default_1339 = slice_scatter_default_1340 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1341, 1, 2672, 2688)
        slice_11070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11069, 2, 0, 16);  slice_11069 = None
        
        # No stacktrace found for following nodes
        slice_tensor_671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1341, 1, 2672, 2688)
        slice_scatter_default_1342: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_671, slice_11070, 2, 0, 16);  slice_tensor_671 = slice_11070 = None
        slice_scatter_default_1343: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1341, slice_scatter_default_1342, 1, 2672, 2688);  slice_scatter_default_1341 = slice_scatter_default_1342 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11089: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2688, 2704)
        slice_11090: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11089, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_339: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11090, memory_format = torch.contiguous_format);  slice_11090 = None
        view_682: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_339, [32, 16]);  clone_339 = None
        mm_336: "f32[32, 8]" = torch.ops.aten.mm.default(view_682, slice_7)
        view_683: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_336, [2, 16, 8]);  mm_336 = None
        slice_11097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1343, 1, 2688, 2704)
        slice_11098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11097, 2, 0, 16);  slice_11097 = None
        add_338: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11098, view_683);  slice_11098 = view_683 = None
        
        # No stacktrace found for following nodes
        slice_tensor_672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1343, 1, 2688, 2704)
        slice_scatter_default_1344: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_672, add_338, 2, 0, 16);  slice_tensor_672 = add_338 = None
        slice_scatter_default_1345: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1343, slice_scatter_default_1344, 1, 2688, 2704);  slice_scatter_default_1343 = slice_scatter_default_1344 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1345, 1, 2688, 2704)
        slice_11103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11102, 2, 0, 16);  slice_11102 = None
        
        # No stacktrace found for following nodes
        slice_tensor_673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1345, 1, 2688, 2704)
        slice_scatter_default_1346: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_673, slice_11103, 2, 0, 16);  slice_tensor_673 = slice_11103 = None
        slice_scatter_default_1347: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1345, slice_scatter_default_1346, 1, 2688, 2704);  slice_scatter_default_1345 = slice_scatter_default_1346 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11123: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11089, 2, 16, 32);  slice_11089 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_340: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11123, memory_format = torch.contiguous_format);  slice_11123 = None
        view_684: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_340, [32, 11]);  clone_340 = None
        mm_337: "f32[32, 8]" = torch.ops.aten.mm.default(view_684, slice_37)
        view_685: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_337, [2, 16, 8]);  mm_337 = None
        slice_11130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1347, 1, 2688, 2704)
        slice_11131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11130, 2, 0, 16);  slice_11130 = None
        add_339: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11131, view_685);  slice_11131 = view_685 = None
        
        # No stacktrace found for following nodes
        slice_tensor_674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1347, 1, 2688, 2704)
        slice_scatter_default_1348: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_674, add_339, 2, 0, 16);  slice_tensor_674 = add_339 = None
        slice_scatter_default_1349: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1347, slice_scatter_default_1348, 1, 2688, 2704);  slice_scatter_default_1347 = slice_scatter_default_1348 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1349, 1, 2688, 2704)
        slice_11136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11135, 2, 0, 16);  slice_11135 = None
        
        # No stacktrace found for following nodes
        slice_tensor_675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1349, 1, 2688, 2704)
        slice_scatter_default_1350: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_675, slice_11136, 2, 0, 16);  slice_tensor_675 = slice_11136 = None
        slice_scatter_default_1351: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1349, slice_scatter_default_1350, 1, 2688, 2704);  slice_scatter_default_1349 = slice_scatter_default_1350 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11155: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2704, 2720)
        slice_11156: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11155, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_341: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11156, memory_format = torch.contiguous_format);  slice_11156 = None
        view_686: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_341, [32, 16]);  clone_341 = None
        mm_338: "f32[32, 8]" = torch.ops.aten.mm.default(view_686, slice_7)
        view_687: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_338, [2, 16, 8]);  mm_338 = None
        slice_11163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1351, 1, 2704, 2720)
        slice_11164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11163, 2, 0, 16);  slice_11163 = None
        add_340: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11164, view_687);  slice_11164 = view_687 = None
        
        # No stacktrace found for following nodes
        slice_tensor_676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1351, 1, 2704, 2720)
        slice_scatter_default_1352: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_676, add_340, 2, 0, 16);  slice_tensor_676 = add_340 = None
        slice_scatter_default_1353: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1351, slice_scatter_default_1352, 1, 2704, 2720);  slice_scatter_default_1351 = slice_scatter_default_1352 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1353, 1, 2704, 2720)
        slice_11169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11168, 2, 0, 16);  slice_11168 = None
        
        # No stacktrace found for following nodes
        slice_tensor_677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1353, 1, 2704, 2720)
        slice_scatter_default_1354: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_677, slice_11169, 2, 0, 16);  slice_tensor_677 = slice_11169 = None
        slice_scatter_default_1355: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1353, slice_scatter_default_1354, 1, 2704, 2720);  slice_scatter_default_1353 = slice_scatter_default_1354 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11189: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11155, 2, 16, 32);  slice_11155 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_342: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11189, memory_format = torch.contiguous_format);  slice_11189 = None
        view_688: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_342, [32, 11]);  clone_342 = None
        mm_339: "f32[32, 8]" = torch.ops.aten.mm.default(view_688, slice_37)
        view_689: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_339, [2, 16, 8]);  mm_339 = None
        slice_11196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1355, 1, 2704, 2720)
        slice_11197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11196, 2, 0, 16);  slice_11196 = None
        add_341: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11197, view_689);  slice_11197 = view_689 = None
        
        # No stacktrace found for following nodes
        slice_tensor_678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1355, 1, 2704, 2720)
        slice_scatter_default_1356: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_678, add_341, 2, 0, 16);  slice_tensor_678 = add_341 = None
        slice_scatter_default_1357: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1355, slice_scatter_default_1356, 1, 2704, 2720);  slice_scatter_default_1355 = slice_scatter_default_1356 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1357, 1, 2704, 2720)
        slice_11202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11201, 2, 0, 16);  slice_11201 = None
        
        # No stacktrace found for following nodes
        slice_tensor_679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1357, 1, 2704, 2720)
        slice_scatter_default_1358: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_679, slice_11202, 2, 0, 16);  slice_tensor_679 = slice_11202 = None
        slice_scatter_default_1359: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1357, slice_scatter_default_1358, 1, 2704, 2720);  slice_scatter_default_1357 = slice_scatter_default_1358 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11221: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2720, 2736)
        slice_11222: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11221, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_343: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11222, memory_format = torch.contiguous_format);  slice_11222 = None
        view_690: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_343, [32, 16]);  clone_343 = None
        mm_340: "f32[32, 8]" = torch.ops.aten.mm.default(view_690, slice_7)
        view_691: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_340, [2, 16, 8]);  mm_340 = None
        slice_11229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1359, 1, 2720, 2736)
        slice_11230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11229, 2, 0, 16);  slice_11229 = None
        add_342: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11230, view_691);  slice_11230 = view_691 = None
        
        # No stacktrace found for following nodes
        slice_tensor_680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1359, 1, 2720, 2736)
        slice_scatter_default_1360: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_680, add_342, 2, 0, 16);  slice_tensor_680 = add_342 = None
        slice_scatter_default_1361: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1359, slice_scatter_default_1360, 1, 2720, 2736);  slice_scatter_default_1359 = slice_scatter_default_1360 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1361, 1, 2720, 2736)
        slice_11235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11234, 2, 0, 16);  slice_11234 = None
        
        # No stacktrace found for following nodes
        slice_tensor_681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1361, 1, 2720, 2736)
        slice_scatter_default_1362: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_681, slice_11235, 2, 0, 16);  slice_tensor_681 = slice_11235 = None
        slice_scatter_default_1363: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1361, slice_scatter_default_1362, 1, 2720, 2736);  slice_scatter_default_1361 = slice_scatter_default_1362 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11255: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11221, 2, 16, 32);  slice_11221 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_344: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11255, memory_format = torch.contiguous_format);  slice_11255 = None
        view_692: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_344, [32, 11]);  clone_344 = None
        mm_341: "f32[32, 8]" = torch.ops.aten.mm.default(view_692, slice_37)
        view_693: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_341, [2, 16, 8]);  mm_341 = None
        slice_11262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1363, 1, 2720, 2736)
        slice_11263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11262, 2, 0, 16);  slice_11262 = None
        add_343: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11263, view_693);  slice_11263 = view_693 = None
        
        # No stacktrace found for following nodes
        slice_tensor_682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1363, 1, 2720, 2736)
        slice_scatter_default_1364: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_682, add_343, 2, 0, 16);  slice_tensor_682 = add_343 = None
        slice_scatter_default_1365: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1363, slice_scatter_default_1364, 1, 2720, 2736);  slice_scatter_default_1363 = slice_scatter_default_1364 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1365, 1, 2720, 2736)
        slice_11268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11267, 2, 0, 16);  slice_11267 = None
        
        # No stacktrace found for following nodes
        slice_tensor_683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1365, 1, 2720, 2736)
        slice_scatter_default_1366: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_683, slice_11268, 2, 0, 16);  slice_tensor_683 = slice_11268 = None
        slice_scatter_default_1367: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1365, slice_scatter_default_1366, 1, 2720, 2736);  slice_scatter_default_1365 = slice_scatter_default_1366 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11287: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2736, 2752)
        slice_11288: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11287, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_345: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11288, memory_format = torch.contiguous_format);  slice_11288 = None
        view_694: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_345, [32, 16]);  clone_345 = None
        mm_342: "f32[32, 8]" = torch.ops.aten.mm.default(view_694, slice_7)
        view_695: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_342, [2, 16, 8]);  mm_342 = None
        slice_11295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1367, 1, 2736, 2752)
        slice_11296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11295, 2, 0, 16);  slice_11295 = None
        add_344: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11296, view_695);  slice_11296 = view_695 = None
        
        # No stacktrace found for following nodes
        slice_tensor_684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1367, 1, 2736, 2752)
        slice_scatter_default_1368: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_684, add_344, 2, 0, 16);  slice_tensor_684 = add_344 = None
        slice_scatter_default_1369: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1367, slice_scatter_default_1368, 1, 2736, 2752);  slice_scatter_default_1367 = slice_scatter_default_1368 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1369, 1, 2736, 2752)
        slice_11301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11300, 2, 0, 16);  slice_11300 = None
        
        # No stacktrace found for following nodes
        slice_tensor_685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1369, 1, 2736, 2752)
        slice_scatter_default_1370: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_685, slice_11301, 2, 0, 16);  slice_tensor_685 = slice_11301 = None
        slice_scatter_default_1371: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1369, slice_scatter_default_1370, 1, 2736, 2752);  slice_scatter_default_1369 = slice_scatter_default_1370 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11321: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11287, 2, 16, 32);  slice_11287 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_346: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11321, memory_format = torch.contiguous_format);  slice_11321 = None
        view_696: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_346, [32, 11]);  clone_346 = None
        mm_343: "f32[32, 8]" = torch.ops.aten.mm.default(view_696, slice_37)
        view_697: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_343, [2, 16, 8]);  mm_343 = None
        slice_11328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1371, 1, 2736, 2752)
        slice_11329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11328, 2, 0, 16);  slice_11328 = None
        add_345: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11329, view_697);  slice_11329 = view_697 = None
        
        # No stacktrace found for following nodes
        slice_tensor_686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1371, 1, 2736, 2752)
        slice_scatter_default_1372: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_686, add_345, 2, 0, 16);  slice_tensor_686 = add_345 = None
        slice_scatter_default_1373: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1371, slice_scatter_default_1372, 1, 2736, 2752);  slice_scatter_default_1371 = slice_scatter_default_1372 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1373, 1, 2736, 2752)
        slice_11334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11333, 2, 0, 16);  slice_11333 = None
        
        # No stacktrace found for following nodes
        slice_tensor_687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1373, 1, 2736, 2752)
        slice_scatter_default_1374: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_687, slice_11334, 2, 0, 16);  slice_tensor_687 = slice_11334 = None
        slice_scatter_default_1375: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1373, slice_scatter_default_1374, 1, 2736, 2752);  slice_scatter_default_1373 = slice_scatter_default_1374 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11353: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2752, 2768)
        slice_11354: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11353, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_347: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11354, memory_format = torch.contiguous_format);  slice_11354 = None
        view_698: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_347, [32, 16]);  clone_347 = None
        mm_344: "f32[32, 8]" = torch.ops.aten.mm.default(view_698, slice_7)
        view_699: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_344, [2, 16, 8]);  mm_344 = None
        slice_11361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1375, 1, 2752, 2768)
        slice_11362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11361, 2, 0, 16);  slice_11361 = None
        add_346: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11362, view_699);  slice_11362 = view_699 = None
        
        # No stacktrace found for following nodes
        slice_tensor_688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1375, 1, 2752, 2768)
        slice_scatter_default_1376: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_688, add_346, 2, 0, 16);  slice_tensor_688 = add_346 = None
        slice_scatter_default_1377: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1375, slice_scatter_default_1376, 1, 2752, 2768);  slice_scatter_default_1375 = slice_scatter_default_1376 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1377, 1, 2752, 2768)
        slice_11367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11366, 2, 0, 16);  slice_11366 = None
        
        # No stacktrace found for following nodes
        slice_tensor_689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1377, 1, 2752, 2768)
        slice_scatter_default_1378: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_689, slice_11367, 2, 0, 16);  slice_tensor_689 = slice_11367 = None
        slice_scatter_default_1379: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1377, slice_scatter_default_1378, 1, 2752, 2768);  slice_scatter_default_1377 = slice_scatter_default_1378 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11387: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11353, 2, 16, 32);  slice_11353 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_348: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11387, memory_format = torch.contiguous_format);  slice_11387 = None
        view_700: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_348, [32, 11]);  clone_348 = None
        mm_345: "f32[32, 8]" = torch.ops.aten.mm.default(view_700, slice_37)
        view_701: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_345, [2, 16, 8]);  mm_345 = None
        slice_11394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1379, 1, 2752, 2768)
        slice_11395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11394, 2, 0, 16);  slice_11394 = None
        add_347: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11395, view_701);  slice_11395 = view_701 = None
        
        # No stacktrace found for following nodes
        slice_tensor_690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1379, 1, 2752, 2768)
        slice_scatter_default_1380: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_690, add_347, 2, 0, 16);  slice_tensor_690 = add_347 = None
        slice_scatter_default_1381: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1379, slice_scatter_default_1380, 1, 2752, 2768);  slice_scatter_default_1379 = slice_scatter_default_1380 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1381, 1, 2752, 2768)
        slice_11400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11399, 2, 0, 16);  slice_11399 = None
        
        # No stacktrace found for following nodes
        slice_tensor_691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1381, 1, 2752, 2768)
        slice_scatter_default_1382: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_691, slice_11400, 2, 0, 16);  slice_tensor_691 = slice_11400 = None
        slice_scatter_default_1383: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1381, slice_scatter_default_1382, 1, 2752, 2768);  slice_scatter_default_1381 = slice_scatter_default_1382 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11419: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2768, 2784)
        slice_11420: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11419, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_349: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11420, memory_format = torch.contiguous_format);  slice_11420 = None
        view_702: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_349, [32, 16]);  clone_349 = None
        mm_346: "f32[32, 8]" = torch.ops.aten.mm.default(view_702, slice_7)
        view_703: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_346, [2, 16, 8]);  mm_346 = None
        slice_11427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1383, 1, 2768, 2784)
        slice_11428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11427, 2, 0, 16);  slice_11427 = None
        add_348: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11428, view_703);  slice_11428 = view_703 = None
        
        # No stacktrace found for following nodes
        slice_tensor_692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1383, 1, 2768, 2784)
        slice_scatter_default_1384: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_692, add_348, 2, 0, 16);  slice_tensor_692 = add_348 = None
        slice_scatter_default_1385: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1383, slice_scatter_default_1384, 1, 2768, 2784);  slice_scatter_default_1383 = slice_scatter_default_1384 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1385, 1, 2768, 2784)
        slice_11433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11432, 2, 0, 16);  slice_11432 = None
        
        # No stacktrace found for following nodes
        slice_tensor_693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1385, 1, 2768, 2784)
        slice_scatter_default_1386: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_693, slice_11433, 2, 0, 16);  slice_tensor_693 = slice_11433 = None
        slice_scatter_default_1387: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1385, slice_scatter_default_1386, 1, 2768, 2784);  slice_scatter_default_1385 = slice_scatter_default_1386 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11453: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11419, 2, 16, 32);  slice_11419 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_350: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11453, memory_format = torch.contiguous_format);  slice_11453 = None
        view_704: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_350, [32, 11]);  clone_350 = None
        mm_347: "f32[32, 8]" = torch.ops.aten.mm.default(view_704, slice_37)
        view_705: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_347, [2, 16, 8]);  mm_347 = None
        slice_11460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1387, 1, 2768, 2784)
        slice_11461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11460, 2, 0, 16);  slice_11460 = None
        add_349: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11461, view_705);  slice_11461 = view_705 = None
        
        # No stacktrace found for following nodes
        slice_tensor_694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1387, 1, 2768, 2784)
        slice_scatter_default_1388: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_694, add_349, 2, 0, 16);  slice_tensor_694 = add_349 = None
        slice_scatter_default_1389: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1387, slice_scatter_default_1388, 1, 2768, 2784);  slice_scatter_default_1387 = slice_scatter_default_1388 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1389, 1, 2768, 2784)
        slice_11466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11465, 2, 0, 16);  slice_11465 = None
        
        # No stacktrace found for following nodes
        slice_tensor_695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1389, 1, 2768, 2784)
        slice_scatter_default_1390: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_695, slice_11466, 2, 0, 16);  slice_tensor_695 = slice_11466 = None
        slice_scatter_default_1391: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1389, slice_scatter_default_1390, 1, 2768, 2784);  slice_scatter_default_1389 = slice_scatter_default_1390 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11485: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2784, 2800)
        slice_11486: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11485, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_351: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11486, memory_format = torch.contiguous_format);  slice_11486 = None
        view_706: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_351, [32, 16]);  clone_351 = None
        mm_348: "f32[32, 8]" = torch.ops.aten.mm.default(view_706, slice_7)
        view_707: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_348, [2, 16, 8]);  mm_348 = None
        slice_11493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1391, 1, 2784, 2800)
        slice_11494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11493, 2, 0, 16);  slice_11493 = None
        add_350: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11494, view_707);  slice_11494 = view_707 = None
        
        # No stacktrace found for following nodes
        slice_tensor_696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1391, 1, 2784, 2800)
        slice_scatter_default_1392: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_696, add_350, 2, 0, 16);  slice_tensor_696 = add_350 = None
        slice_scatter_default_1393: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1391, slice_scatter_default_1392, 1, 2784, 2800);  slice_scatter_default_1391 = slice_scatter_default_1392 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1393, 1, 2784, 2800)
        slice_11499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11498, 2, 0, 16);  slice_11498 = None
        
        # No stacktrace found for following nodes
        slice_tensor_697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1393, 1, 2784, 2800)
        slice_scatter_default_1394: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_697, slice_11499, 2, 0, 16);  slice_tensor_697 = slice_11499 = None
        slice_scatter_default_1395: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1393, slice_scatter_default_1394, 1, 2784, 2800);  slice_scatter_default_1393 = slice_scatter_default_1394 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11519: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11485, 2, 16, 32);  slice_11485 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_352: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11519, memory_format = torch.contiguous_format);  slice_11519 = None
        view_708: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_352, [32, 11]);  clone_352 = None
        mm_349: "f32[32, 8]" = torch.ops.aten.mm.default(view_708, slice_37)
        view_709: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_349, [2, 16, 8]);  mm_349 = None
        slice_11526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1395, 1, 2784, 2800)
        slice_11527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11526, 2, 0, 16);  slice_11526 = None
        add_351: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11527, view_709);  slice_11527 = view_709 = None
        
        # No stacktrace found for following nodes
        slice_tensor_698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1395, 1, 2784, 2800)
        slice_scatter_default_1396: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_698, add_351, 2, 0, 16);  slice_tensor_698 = add_351 = None
        slice_scatter_default_1397: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1395, slice_scatter_default_1396, 1, 2784, 2800);  slice_scatter_default_1395 = slice_scatter_default_1396 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1397, 1, 2784, 2800)
        slice_11532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11531, 2, 0, 16);  slice_11531 = None
        
        # No stacktrace found for following nodes
        slice_tensor_699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1397, 1, 2784, 2800)
        slice_scatter_default_1398: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_699, slice_11532, 2, 0, 16);  slice_tensor_699 = slice_11532 = None
        slice_scatter_default_1399: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1397, slice_scatter_default_1398, 1, 2784, 2800);  slice_scatter_default_1397 = slice_scatter_default_1398 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11551: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2800, 2816)
        slice_11552: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11551, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_353: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11552, memory_format = torch.contiguous_format);  slice_11552 = None
        view_710: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_353, [32, 16]);  clone_353 = None
        mm_350: "f32[32, 8]" = torch.ops.aten.mm.default(view_710, slice_7)
        view_711: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_350, [2, 16, 8]);  mm_350 = None
        slice_11559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1399, 1, 2800, 2816)
        slice_11560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11559, 2, 0, 16);  slice_11559 = None
        add_352: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11560, view_711);  slice_11560 = view_711 = None
        
        # No stacktrace found for following nodes
        slice_tensor_700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1399, 1, 2800, 2816)
        slice_scatter_default_1400: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_700, add_352, 2, 0, 16);  slice_tensor_700 = add_352 = None
        slice_scatter_default_1401: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1399, slice_scatter_default_1400, 1, 2800, 2816);  slice_scatter_default_1399 = slice_scatter_default_1400 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1401, 1, 2800, 2816)
        slice_11565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11564, 2, 0, 16);  slice_11564 = None
        
        # No stacktrace found for following nodes
        slice_tensor_701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1401, 1, 2800, 2816)
        slice_scatter_default_1402: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_701, slice_11565, 2, 0, 16);  slice_tensor_701 = slice_11565 = None
        slice_scatter_default_1403: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1401, slice_scatter_default_1402, 1, 2800, 2816);  slice_scatter_default_1401 = slice_scatter_default_1402 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11585: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11551, 2, 16, 32);  slice_11551 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_354: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11585, memory_format = torch.contiguous_format);  slice_11585 = None
        view_712: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_354, [32, 11]);  clone_354 = None
        mm_351: "f32[32, 8]" = torch.ops.aten.mm.default(view_712, slice_37)
        view_713: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_351, [2, 16, 8]);  mm_351 = None
        slice_11592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1403, 1, 2800, 2816)
        slice_11593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11592, 2, 0, 16);  slice_11592 = None
        add_353: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11593, view_713);  slice_11593 = view_713 = None
        
        # No stacktrace found for following nodes
        slice_tensor_702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1403, 1, 2800, 2816)
        slice_scatter_default_1404: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_702, add_353, 2, 0, 16);  slice_tensor_702 = add_353 = None
        slice_scatter_default_1405: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1403, slice_scatter_default_1404, 1, 2800, 2816);  slice_scatter_default_1403 = slice_scatter_default_1404 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1405, 1, 2800, 2816)
        slice_11598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11597, 2, 0, 16);  slice_11597 = None
        
        # No stacktrace found for following nodes
        slice_tensor_703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1405, 1, 2800, 2816)
        slice_scatter_default_1406: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_703, slice_11598, 2, 0, 16);  slice_tensor_703 = slice_11598 = None
        slice_scatter_default_1407: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1405, slice_scatter_default_1406, 1, 2800, 2816);  slice_scatter_default_1405 = slice_scatter_default_1406 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11617: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2816, 2832)
        slice_11618: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11617, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_355: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11618, memory_format = torch.contiguous_format);  slice_11618 = None
        view_714: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_355, [32, 16]);  clone_355 = None
        mm_352: "f32[32, 8]" = torch.ops.aten.mm.default(view_714, slice_7)
        view_715: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_352, [2, 16, 8]);  mm_352 = None
        slice_11625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1407, 1, 2816, 2832)
        slice_11626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11625, 2, 0, 16);  slice_11625 = None
        add_354: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11626, view_715);  slice_11626 = view_715 = None
        
        # No stacktrace found for following nodes
        slice_tensor_704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1407, 1, 2816, 2832)
        slice_scatter_default_1408: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_704, add_354, 2, 0, 16);  slice_tensor_704 = add_354 = None
        slice_scatter_default_1409: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1407, slice_scatter_default_1408, 1, 2816, 2832);  slice_scatter_default_1407 = slice_scatter_default_1408 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1409, 1, 2816, 2832)
        slice_11631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11630, 2, 0, 16);  slice_11630 = None
        
        # No stacktrace found for following nodes
        slice_tensor_705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1409, 1, 2816, 2832)
        slice_scatter_default_1410: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_705, slice_11631, 2, 0, 16);  slice_tensor_705 = slice_11631 = None
        slice_scatter_default_1411: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1409, slice_scatter_default_1410, 1, 2816, 2832);  slice_scatter_default_1409 = slice_scatter_default_1410 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11651: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11617, 2, 16, 32);  slice_11617 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_356: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11651, memory_format = torch.contiguous_format);  slice_11651 = None
        view_716: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_356, [32, 11]);  clone_356 = None
        mm_353: "f32[32, 8]" = torch.ops.aten.mm.default(view_716, slice_37)
        view_717: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_353, [2, 16, 8]);  mm_353 = None
        slice_11658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1411, 1, 2816, 2832)
        slice_11659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11658, 2, 0, 16);  slice_11658 = None
        add_355: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11659, view_717);  slice_11659 = view_717 = None
        
        # No stacktrace found for following nodes
        slice_tensor_706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1411, 1, 2816, 2832)
        slice_scatter_default_1412: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_706, add_355, 2, 0, 16);  slice_tensor_706 = add_355 = None
        slice_scatter_default_1413: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1411, slice_scatter_default_1412, 1, 2816, 2832);  slice_scatter_default_1411 = slice_scatter_default_1412 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1413, 1, 2816, 2832)
        slice_11664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11663, 2, 0, 16);  slice_11663 = None
        
        # No stacktrace found for following nodes
        slice_tensor_707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1413, 1, 2816, 2832)
        slice_scatter_default_1414: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_707, slice_11664, 2, 0, 16);  slice_tensor_707 = slice_11664 = None
        slice_scatter_default_1415: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1413, slice_scatter_default_1414, 1, 2816, 2832);  slice_scatter_default_1413 = slice_scatter_default_1414 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11683: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2832, 2848)
        slice_11684: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11683, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_357: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11684, memory_format = torch.contiguous_format);  slice_11684 = None
        view_718: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_357, [32, 16]);  clone_357 = None
        mm_354: "f32[32, 8]" = torch.ops.aten.mm.default(view_718, slice_7)
        view_719: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_354, [2, 16, 8]);  mm_354 = None
        slice_11691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1415, 1, 2832, 2848)
        slice_11692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11691, 2, 0, 16);  slice_11691 = None
        add_356: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11692, view_719);  slice_11692 = view_719 = None
        
        # No stacktrace found for following nodes
        slice_tensor_708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1415, 1, 2832, 2848)
        slice_scatter_default_1416: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_708, add_356, 2, 0, 16);  slice_tensor_708 = add_356 = None
        slice_scatter_default_1417: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1415, slice_scatter_default_1416, 1, 2832, 2848);  slice_scatter_default_1415 = slice_scatter_default_1416 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1417, 1, 2832, 2848)
        slice_11697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11696, 2, 0, 16);  slice_11696 = None
        
        # No stacktrace found for following nodes
        slice_tensor_709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1417, 1, 2832, 2848)
        slice_scatter_default_1418: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_709, slice_11697, 2, 0, 16);  slice_tensor_709 = slice_11697 = None
        slice_scatter_default_1419: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1417, slice_scatter_default_1418, 1, 2832, 2848);  slice_scatter_default_1417 = slice_scatter_default_1418 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11717: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11683, 2, 16, 32);  slice_11683 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_358: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11717, memory_format = torch.contiguous_format);  slice_11717 = None
        view_720: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_358, [32, 11]);  clone_358 = None
        mm_355: "f32[32, 8]" = torch.ops.aten.mm.default(view_720, slice_37)
        view_721: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_355, [2, 16, 8]);  mm_355 = None
        slice_11724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1419, 1, 2832, 2848)
        slice_11725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11724, 2, 0, 16);  slice_11724 = None
        add_357: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11725, view_721);  slice_11725 = view_721 = None
        
        # No stacktrace found for following nodes
        slice_tensor_710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1419, 1, 2832, 2848)
        slice_scatter_default_1420: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_710, add_357, 2, 0, 16);  slice_tensor_710 = add_357 = None
        slice_scatter_default_1421: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1419, slice_scatter_default_1420, 1, 2832, 2848);  slice_scatter_default_1419 = slice_scatter_default_1420 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1421, 1, 2832, 2848)
        slice_11730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11729, 2, 0, 16);  slice_11729 = None
        
        # No stacktrace found for following nodes
        slice_tensor_711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1421, 1, 2832, 2848)
        slice_scatter_default_1422: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_711, slice_11730, 2, 0, 16);  slice_tensor_711 = slice_11730 = None
        slice_scatter_default_1423: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1421, slice_scatter_default_1422, 1, 2832, 2848);  slice_scatter_default_1421 = slice_scatter_default_1422 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11749: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2848, 2864)
        slice_11750: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11749, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_359: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11750, memory_format = torch.contiguous_format);  slice_11750 = None
        view_722: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_359, [32, 16]);  clone_359 = None
        mm_356: "f32[32, 8]" = torch.ops.aten.mm.default(view_722, slice_7)
        view_723: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_356, [2, 16, 8]);  mm_356 = None
        slice_11757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1423, 1, 2848, 2864)
        slice_11758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11757, 2, 0, 16);  slice_11757 = None
        add_358: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11758, view_723);  slice_11758 = view_723 = None
        
        # No stacktrace found for following nodes
        slice_tensor_712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1423, 1, 2848, 2864)
        slice_scatter_default_1424: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_712, add_358, 2, 0, 16);  slice_tensor_712 = add_358 = None
        slice_scatter_default_1425: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1423, slice_scatter_default_1424, 1, 2848, 2864);  slice_scatter_default_1423 = slice_scatter_default_1424 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1425, 1, 2848, 2864)
        slice_11763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11762, 2, 0, 16);  slice_11762 = None
        
        # No stacktrace found for following nodes
        slice_tensor_713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1425, 1, 2848, 2864)
        slice_scatter_default_1426: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_713, slice_11763, 2, 0, 16);  slice_tensor_713 = slice_11763 = None
        slice_scatter_default_1427: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1425, slice_scatter_default_1426, 1, 2848, 2864);  slice_scatter_default_1425 = slice_scatter_default_1426 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11783: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11749, 2, 16, 32);  slice_11749 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_360: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11783, memory_format = torch.contiguous_format);  slice_11783 = None
        view_724: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_360, [32, 11]);  clone_360 = None
        mm_357: "f32[32, 8]" = torch.ops.aten.mm.default(view_724, slice_37)
        view_725: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_357, [2, 16, 8]);  mm_357 = None
        slice_11790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1427, 1, 2848, 2864)
        slice_11791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11790, 2, 0, 16);  slice_11790 = None
        add_359: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11791, view_725);  slice_11791 = view_725 = None
        
        # No stacktrace found for following nodes
        slice_tensor_714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1427, 1, 2848, 2864)
        slice_scatter_default_1428: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_714, add_359, 2, 0, 16);  slice_tensor_714 = add_359 = None
        slice_scatter_default_1429: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1427, slice_scatter_default_1428, 1, 2848, 2864);  slice_scatter_default_1427 = slice_scatter_default_1428 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1429, 1, 2848, 2864)
        slice_11796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11795, 2, 0, 16);  slice_11795 = None
        
        # No stacktrace found for following nodes
        slice_tensor_715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1429, 1, 2848, 2864)
        slice_scatter_default_1430: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_715, slice_11796, 2, 0, 16);  slice_tensor_715 = slice_11796 = None
        slice_scatter_default_1431: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1429, slice_scatter_default_1430, 1, 2848, 2864);  slice_scatter_default_1429 = slice_scatter_default_1430 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11815: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2864, 2880)
        slice_11816: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11815, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_361: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11816, memory_format = torch.contiguous_format);  slice_11816 = None
        view_726: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_361, [32, 16]);  clone_361 = None
        mm_358: "f32[32, 8]" = torch.ops.aten.mm.default(view_726, slice_7)
        view_727: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_358, [2, 16, 8]);  mm_358 = None
        slice_11823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1431, 1, 2864, 2880)
        slice_11824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11823, 2, 0, 16);  slice_11823 = None
        add_360: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11824, view_727);  slice_11824 = view_727 = None
        
        # No stacktrace found for following nodes
        slice_tensor_716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1431, 1, 2864, 2880)
        slice_scatter_default_1432: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_716, add_360, 2, 0, 16);  slice_tensor_716 = add_360 = None
        slice_scatter_default_1433: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1431, slice_scatter_default_1432, 1, 2864, 2880);  slice_scatter_default_1431 = slice_scatter_default_1432 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1433, 1, 2864, 2880)
        slice_11829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11828, 2, 0, 16);  slice_11828 = None
        
        # No stacktrace found for following nodes
        slice_tensor_717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1433, 1, 2864, 2880)
        slice_scatter_default_1434: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_717, slice_11829, 2, 0, 16);  slice_tensor_717 = slice_11829 = None
        slice_scatter_default_1435: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1433, slice_scatter_default_1434, 1, 2864, 2880);  slice_scatter_default_1433 = slice_scatter_default_1434 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11849: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11815, 2, 16, 32);  slice_11815 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_362: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11849, memory_format = torch.contiguous_format);  slice_11849 = None
        view_728: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_362, [32, 11]);  clone_362 = None
        mm_359: "f32[32, 8]" = torch.ops.aten.mm.default(view_728, slice_37)
        view_729: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_359, [2, 16, 8]);  mm_359 = None
        slice_11856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1435, 1, 2864, 2880)
        slice_11857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11856, 2, 0, 16);  slice_11856 = None
        add_361: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11857, view_729);  slice_11857 = view_729 = None
        
        # No stacktrace found for following nodes
        slice_tensor_718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1435, 1, 2864, 2880)
        slice_scatter_default_1436: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_718, add_361, 2, 0, 16);  slice_tensor_718 = add_361 = None
        slice_scatter_default_1437: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1435, slice_scatter_default_1436, 1, 2864, 2880);  slice_scatter_default_1435 = slice_scatter_default_1436 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1437, 1, 2864, 2880)
        slice_11862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11861, 2, 0, 16);  slice_11861 = None
        
        # No stacktrace found for following nodes
        slice_tensor_719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1437, 1, 2864, 2880)
        slice_scatter_default_1438: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_719, slice_11862, 2, 0, 16);  slice_tensor_719 = slice_11862 = None
        slice_scatter_default_1439: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1437, slice_scatter_default_1438, 1, 2864, 2880);  slice_scatter_default_1437 = slice_scatter_default_1438 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11881: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2880, 2896)
        slice_11882: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11881, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_363: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11882, memory_format = torch.contiguous_format);  slice_11882 = None
        view_730: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_363, [32, 16]);  clone_363 = None
        mm_360: "f32[32, 8]" = torch.ops.aten.mm.default(view_730, slice_7)
        view_731: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_360, [2, 16, 8]);  mm_360 = None
        slice_11889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1439, 1, 2880, 2896)
        slice_11890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11889, 2, 0, 16);  slice_11889 = None
        add_362: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11890, view_731);  slice_11890 = view_731 = None
        
        # No stacktrace found for following nodes
        slice_tensor_720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1439, 1, 2880, 2896)
        slice_scatter_default_1440: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_720, add_362, 2, 0, 16);  slice_tensor_720 = add_362 = None
        slice_scatter_default_1441: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1439, slice_scatter_default_1440, 1, 2880, 2896);  slice_scatter_default_1439 = slice_scatter_default_1440 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1441, 1, 2880, 2896)
        slice_11895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11894, 2, 0, 16);  slice_11894 = None
        
        # No stacktrace found for following nodes
        slice_tensor_721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1441, 1, 2880, 2896)
        slice_scatter_default_1442: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_721, slice_11895, 2, 0, 16);  slice_tensor_721 = slice_11895 = None
        slice_scatter_default_1443: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1441, slice_scatter_default_1442, 1, 2880, 2896);  slice_scatter_default_1441 = slice_scatter_default_1442 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11915: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11881, 2, 16, 32);  slice_11881 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_364: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11915, memory_format = torch.contiguous_format);  slice_11915 = None
        view_732: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_364, [32, 11]);  clone_364 = None
        mm_361: "f32[32, 8]" = torch.ops.aten.mm.default(view_732, slice_37)
        view_733: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_361, [2, 16, 8]);  mm_361 = None
        slice_11922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1443, 1, 2880, 2896)
        slice_11923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11922, 2, 0, 16);  slice_11922 = None
        add_363: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11923, view_733);  slice_11923 = view_733 = None
        
        # No stacktrace found for following nodes
        slice_tensor_722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1443, 1, 2880, 2896)
        slice_scatter_default_1444: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_722, add_363, 2, 0, 16);  slice_tensor_722 = add_363 = None
        slice_scatter_default_1445: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1443, slice_scatter_default_1444, 1, 2880, 2896);  slice_scatter_default_1443 = slice_scatter_default_1444 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1445, 1, 2880, 2896)
        slice_11928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11927, 2, 0, 16);  slice_11927 = None
        
        # No stacktrace found for following nodes
        slice_tensor_723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1445, 1, 2880, 2896)
        slice_scatter_default_1446: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_723, slice_11928, 2, 0, 16);  slice_tensor_723 = slice_11928 = None
        slice_scatter_default_1447: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1445, slice_scatter_default_1446, 1, 2880, 2896);  slice_scatter_default_1445 = slice_scatter_default_1446 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11947: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2896, 2912)
        slice_11948: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_11947, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_365: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_11948, memory_format = torch.contiguous_format);  slice_11948 = None
        view_734: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_365, [32, 16]);  clone_365 = None
        mm_362: "f32[32, 8]" = torch.ops.aten.mm.default(view_734, slice_7)
        view_735: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_362, [2, 16, 8]);  mm_362 = None
        slice_11955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1447, 1, 2896, 2912)
        slice_11956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11955, 2, 0, 16);  slice_11955 = None
        add_364: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11956, view_735);  slice_11956 = view_735 = None
        
        # No stacktrace found for following nodes
        slice_tensor_724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1447, 1, 2896, 2912)
        slice_scatter_default_1448: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_724, add_364, 2, 0, 16);  slice_tensor_724 = add_364 = None
        slice_scatter_default_1449: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1447, slice_scatter_default_1448, 1, 2896, 2912);  slice_scatter_default_1447 = slice_scatter_default_1448 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1449, 1, 2896, 2912)
        slice_11961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11960, 2, 0, 16);  slice_11960 = None
        
        # No stacktrace found for following nodes
        slice_tensor_725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1449, 1, 2896, 2912)
        slice_scatter_default_1450: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_725, slice_11961, 2, 0, 16);  slice_tensor_725 = slice_11961 = None
        slice_scatter_default_1451: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1449, slice_scatter_default_1450, 1, 2896, 2912);  slice_scatter_default_1449 = slice_scatter_default_1450 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_11981: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_11947, 2, 16, 32);  slice_11947 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_366: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_11981, memory_format = torch.contiguous_format);  slice_11981 = None
        view_736: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_366, [32, 11]);  clone_366 = None
        mm_363: "f32[32, 8]" = torch.ops.aten.mm.default(view_736, slice_37)
        view_737: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_363, [2, 16, 8]);  mm_363 = None
        slice_11988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1451, 1, 2896, 2912)
        slice_11989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11988, 2, 0, 16);  slice_11988 = None
        add_365: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_11989, view_737);  slice_11989 = view_737 = None
        
        # No stacktrace found for following nodes
        slice_tensor_726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1451, 1, 2896, 2912)
        slice_scatter_default_1452: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_726, add_365, 2, 0, 16);  slice_tensor_726 = add_365 = None
        slice_scatter_default_1453: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1451, slice_scatter_default_1452, 1, 2896, 2912);  slice_scatter_default_1451 = slice_scatter_default_1452 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_11993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1453, 1, 2896, 2912)
        slice_11994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_11993, 2, 0, 16);  slice_11993 = None
        
        # No stacktrace found for following nodes
        slice_tensor_727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1453, 1, 2896, 2912)
        slice_scatter_default_1454: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_727, slice_11994, 2, 0, 16);  slice_tensor_727 = slice_11994 = None
        slice_scatter_default_1455: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1453, slice_scatter_default_1454, 1, 2896, 2912);  slice_scatter_default_1453 = slice_scatter_default_1454 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12013: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2912, 2928)
        slice_12014: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12013, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_367: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12014, memory_format = torch.contiguous_format);  slice_12014 = None
        view_738: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_367, [32, 16]);  clone_367 = None
        mm_364: "f32[32, 8]" = torch.ops.aten.mm.default(view_738, slice_7)
        view_739: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_364, [2, 16, 8]);  mm_364 = None
        slice_12021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1455, 1, 2912, 2928)
        slice_12022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12021, 2, 0, 16);  slice_12021 = None
        add_366: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12022, view_739);  slice_12022 = view_739 = None
        
        # No stacktrace found for following nodes
        slice_tensor_728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1455, 1, 2912, 2928)
        slice_scatter_default_1456: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_728, add_366, 2, 0, 16);  slice_tensor_728 = add_366 = None
        slice_scatter_default_1457: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1455, slice_scatter_default_1456, 1, 2912, 2928);  slice_scatter_default_1455 = slice_scatter_default_1456 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1457, 1, 2912, 2928)
        slice_12027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12026, 2, 0, 16);  slice_12026 = None
        
        # No stacktrace found for following nodes
        slice_tensor_729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1457, 1, 2912, 2928)
        slice_scatter_default_1458: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_729, slice_12027, 2, 0, 16);  slice_tensor_729 = slice_12027 = None
        slice_scatter_default_1459: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1457, slice_scatter_default_1458, 1, 2912, 2928);  slice_scatter_default_1457 = slice_scatter_default_1458 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12047: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12013, 2, 16, 32);  slice_12013 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_368: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12047, memory_format = torch.contiguous_format);  slice_12047 = None
        view_740: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_368, [32, 11]);  clone_368 = None
        mm_365: "f32[32, 8]" = torch.ops.aten.mm.default(view_740, slice_37)
        view_741: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_365, [2, 16, 8]);  mm_365 = None
        slice_12054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1459, 1, 2912, 2928)
        slice_12055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12054, 2, 0, 16);  slice_12054 = None
        add_367: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12055, view_741);  slice_12055 = view_741 = None
        
        # No stacktrace found for following nodes
        slice_tensor_730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1459, 1, 2912, 2928)
        slice_scatter_default_1460: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_730, add_367, 2, 0, 16);  slice_tensor_730 = add_367 = None
        slice_scatter_default_1461: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1459, slice_scatter_default_1460, 1, 2912, 2928);  slice_scatter_default_1459 = slice_scatter_default_1460 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1461, 1, 2912, 2928)
        slice_12060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12059, 2, 0, 16);  slice_12059 = None
        
        # No stacktrace found for following nodes
        slice_tensor_731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1461, 1, 2912, 2928)
        slice_scatter_default_1462: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_731, slice_12060, 2, 0, 16);  slice_tensor_731 = slice_12060 = None
        slice_scatter_default_1463: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1461, slice_scatter_default_1462, 1, 2912, 2928);  slice_scatter_default_1461 = slice_scatter_default_1462 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12079: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2928, 2944)
        slice_12080: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12079, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_369: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12080, memory_format = torch.contiguous_format);  slice_12080 = None
        view_742: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_369, [32, 16]);  clone_369 = None
        mm_366: "f32[32, 8]" = torch.ops.aten.mm.default(view_742, slice_7)
        view_743: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_366, [2, 16, 8]);  mm_366 = None
        slice_12087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1463, 1, 2928, 2944)
        slice_12088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12087, 2, 0, 16);  slice_12087 = None
        add_368: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12088, view_743);  slice_12088 = view_743 = None
        
        # No stacktrace found for following nodes
        slice_tensor_732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1463, 1, 2928, 2944)
        slice_scatter_default_1464: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_732, add_368, 2, 0, 16);  slice_tensor_732 = add_368 = None
        slice_scatter_default_1465: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1463, slice_scatter_default_1464, 1, 2928, 2944);  slice_scatter_default_1463 = slice_scatter_default_1464 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1465, 1, 2928, 2944)
        slice_12093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12092, 2, 0, 16);  slice_12092 = None
        
        # No stacktrace found for following nodes
        slice_tensor_733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1465, 1, 2928, 2944)
        slice_scatter_default_1466: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_733, slice_12093, 2, 0, 16);  slice_tensor_733 = slice_12093 = None
        slice_scatter_default_1467: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1465, slice_scatter_default_1466, 1, 2928, 2944);  slice_scatter_default_1465 = slice_scatter_default_1466 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12113: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12079, 2, 16, 32);  slice_12079 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_370: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12113, memory_format = torch.contiguous_format);  slice_12113 = None
        view_744: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_370, [32, 11]);  clone_370 = None
        mm_367: "f32[32, 8]" = torch.ops.aten.mm.default(view_744, slice_37)
        view_745: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_367, [2, 16, 8]);  mm_367 = None
        slice_12120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1467, 1, 2928, 2944)
        slice_12121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12120, 2, 0, 16);  slice_12120 = None
        add_369: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12121, view_745);  slice_12121 = view_745 = None
        
        # No stacktrace found for following nodes
        slice_tensor_734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1467, 1, 2928, 2944)
        slice_scatter_default_1468: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_734, add_369, 2, 0, 16);  slice_tensor_734 = add_369 = None
        slice_scatter_default_1469: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1467, slice_scatter_default_1468, 1, 2928, 2944);  slice_scatter_default_1467 = slice_scatter_default_1468 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1469, 1, 2928, 2944)
        slice_12126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12125, 2, 0, 16);  slice_12125 = None
        
        # No stacktrace found for following nodes
        slice_tensor_735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1469, 1, 2928, 2944)
        slice_scatter_default_1470: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_735, slice_12126, 2, 0, 16);  slice_tensor_735 = slice_12126 = None
        slice_scatter_default_1471: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1469, slice_scatter_default_1470, 1, 2928, 2944);  slice_scatter_default_1469 = slice_scatter_default_1470 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12145: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2944, 2960)
        slice_12146: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12145, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_371: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12146, memory_format = torch.contiguous_format);  slice_12146 = None
        view_746: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_371, [32, 16]);  clone_371 = None
        mm_368: "f32[32, 8]" = torch.ops.aten.mm.default(view_746, slice_7)
        view_747: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_368, [2, 16, 8]);  mm_368 = None
        slice_12153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1471, 1, 2944, 2960)
        slice_12154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12153, 2, 0, 16);  slice_12153 = None
        add_370: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12154, view_747);  slice_12154 = view_747 = None
        
        # No stacktrace found for following nodes
        slice_tensor_736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1471, 1, 2944, 2960)
        slice_scatter_default_1472: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_736, add_370, 2, 0, 16);  slice_tensor_736 = add_370 = None
        slice_scatter_default_1473: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1471, slice_scatter_default_1472, 1, 2944, 2960);  slice_scatter_default_1471 = slice_scatter_default_1472 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1473, 1, 2944, 2960)
        slice_12159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12158, 2, 0, 16);  slice_12158 = None
        
        # No stacktrace found for following nodes
        slice_tensor_737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1473, 1, 2944, 2960)
        slice_scatter_default_1474: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_737, slice_12159, 2, 0, 16);  slice_tensor_737 = slice_12159 = None
        slice_scatter_default_1475: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1473, slice_scatter_default_1474, 1, 2944, 2960);  slice_scatter_default_1473 = slice_scatter_default_1474 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12179: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12145, 2, 16, 32);  slice_12145 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_372: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12179, memory_format = torch.contiguous_format);  slice_12179 = None
        view_748: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_372, [32, 11]);  clone_372 = None
        mm_369: "f32[32, 8]" = torch.ops.aten.mm.default(view_748, slice_37)
        view_749: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_369, [2, 16, 8]);  mm_369 = None
        slice_12186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1475, 1, 2944, 2960)
        slice_12187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12186, 2, 0, 16);  slice_12186 = None
        add_371: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12187, view_749);  slice_12187 = view_749 = None
        
        # No stacktrace found for following nodes
        slice_tensor_738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1475, 1, 2944, 2960)
        slice_scatter_default_1476: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_738, add_371, 2, 0, 16);  slice_tensor_738 = add_371 = None
        slice_scatter_default_1477: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1475, slice_scatter_default_1476, 1, 2944, 2960);  slice_scatter_default_1475 = slice_scatter_default_1476 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1477, 1, 2944, 2960)
        slice_12192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12191, 2, 0, 16);  slice_12191 = None
        
        # No stacktrace found for following nodes
        slice_tensor_739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1477, 1, 2944, 2960)
        slice_scatter_default_1478: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_739, slice_12192, 2, 0, 16);  slice_tensor_739 = slice_12192 = None
        slice_scatter_default_1479: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1477, slice_scatter_default_1478, 1, 2944, 2960);  slice_scatter_default_1477 = slice_scatter_default_1478 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12211: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2960, 2976)
        slice_12212: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12211, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_373: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12212, memory_format = torch.contiguous_format);  slice_12212 = None
        view_750: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_373, [32, 16]);  clone_373 = None
        mm_370: "f32[32, 8]" = torch.ops.aten.mm.default(view_750, slice_7)
        view_751: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_370, [2, 16, 8]);  mm_370 = None
        slice_12219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1479, 1, 2960, 2976)
        slice_12220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12219, 2, 0, 16);  slice_12219 = None
        add_372: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12220, view_751);  slice_12220 = view_751 = None
        
        # No stacktrace found for following nodes
        slice_tensor_740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1479, 1, 2960, 2976)
        slice_scatter_default_1480: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_740, add_372, 2, 0, 16);  slice_tensor_740 = add_372 = None
        slice_scatter_default_1481: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1479, slice_scatter_default_1480, 1, 2960, 2976);  slice_scatter_default_1479 = slice_scatter_default_1480 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1481, 1, 2960, 2976)
        slice_12225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12224, 2, 0, 16);  slice_12224 = None
        
        # No stacktrace found for following nodes
        slice_tensor_741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1481, 1, 2960, 2976)
        slice_scatter_default_1482: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_741, slice_12225, 2, 0, 16);  slice_tensor_741 = slice_12225 = None
        slice_scatter_default_1483: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1481, slice_scatter_default_1482, 1, 2960, 2976);  slice_scatter_default_1481 = slice_scatter_default_1482 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12245: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12211, 2, 16, 32);  slice_12211 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_374: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12245, memory_format = torch.contiguous_format);  slice_12245 = None
        view_752: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_374, [32, 11]);  clone_374 = None
        mm_371: "f32[32, 8]" = torch.ops.aten.mm.default(view_752, slice_37)
        view_753: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_371, [2, 16, 8]);  mm_371 = None
        slice_12252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1483, 1, 2960, 2976)
        slice_12253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12252, 2, 0, 16);  slice_12252 = None
        add_373: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12253, view_753);  slice_12253 = view_753 = None
        
        # No stacktrace found for following nodes
        slice_tensor_742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1483, 1, 2960, 2976)
        slice_scatter_default_1484: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_742, add_373, 2, 0, 16);  slice_tensor_742 = add_373 = None
        slice_scatter_default_1485: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1483, slice_scatter_default_1484, 1, 2960, 2976);  slice_scatter_default_1483 = slice_scatter_default_1484 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1485, 1, 2960, 2976)
        slice_12258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12257, 2, 0, 16);  slice_12257 = None
        
        # No stacktrace found for following nodes
        slice_tensor_743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1485, 1, 2960, 2976)
        slice_scatter_default_1486: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_743, slice_12258, 2, 0, 16);  slice_tensor_743 = slice_12258 = None
        slice_scatter_default_1487: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1485, slice_scatter_default_1486, 1, 2960, 2976);  slice_scatter_default_1485 = slice_scatter_default_1486 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12277: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2976, 2992)
        slice_12278: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12277, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_375: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12278, memory_format = torch.contiguous_format);  slice_12278 = None
        view_754: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_375, [32, 16]);  clone_375 = None
        mm_372: "f32[32, 8]" = torch.ops.aten.mm.default(view_754, slice_7)
        view_755: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_372, [2, 16, 8]);  mm_372 = None
        slice_12285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1487, 1, 2976, 2992)
        slice_12286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12285, 2, 0, 16);  slice_12285 = None
        add_374: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12286, view_755);  slice_12286 = view_755 = None
        
        # No stacktrace found for following nodes
        slice_tensor_744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1487, 1, 2976, 2992)
        slice_scatter_default_1488: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_744, add_374, 2, 0, 16);  slice_tensor_744 = add_374 = None
        slice_scatter_default_1489: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1487, slice_scatter_default_1488, 1, 2976, 2992);  slice_scatter_default_1487 = slice_scatter_default_1488 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1489, 1, 2976, 2992)
        slice_12291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12290, 2, 0, 16);  slice_12290 = None
        
        # No stacktrace found for following nodes
        slice_tensor_745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1489, 1, 2976, 2992)
        slice_scatter_default_1490: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_745, slice_12291, 2, 0, 16);  slice_tensor_745 = slice_12291 = None
        slice_scatter_default_1491: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1489, slice_scatter_default_1490, 1, 2976, 2992);  slice_scatter_default_1489 = slice_scatter_default_1490 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12311: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12277, 2, 16, 32);  slice_12277 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_376: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12311, memory_format = torch.contiguous_format);  slice_12311 = None
        view_756: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_376, [32, 11]);  clone_376 = None
        mm_373: "f32[32, 8]" = torch.ops.aten.mm.default(view_756, slice_37)
        view_757: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_373, [2, 16, 8]);  mm_373 = None
        slice_12318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1491, 1, 2976, 2992)
        slice_12319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12318, 2, 0, 16);  slice_12318 = None
        add_375: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12319, view_757);  slice_12319 = view_757 = None
        
        # No stacktrace found for following nodes
        slice_tensor_746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1491, 1, 2976, 2992)
        slice_scatter_default_1492: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_746, add_375, 2, 0, 16);  slice_tensor_746 = add_375 = None
        slice_scatter_default_1493: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1491, slice_scatter_default_1492, 1, 2976, 2992);  slice_scatter_default_1491 = slice_scatter_default_1492 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1493, 1, 2976, 2992)
        slice_12324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12323, 2, 0, 16);  slice_12323 = None
        
        # No stacktrace found for following nodes
        slice_tensor_747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1493, 1, 2976, 2992)
        slice_scatter_default_1494: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_747, slice_12324, 2, 0, 16);  slice_tensor_747 = slice_12324 = None
        slice_scatter_default_1495: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1493, slice_scatter_default_1494, 1, 2976, 2992);  slice_scatter_default_1493 = slice_scatter_default_1494 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12343: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 2992, 3008)
        slice_12344: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12343, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_377: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12344, memory_format = torch.contiguous_format);  slice_12344 = None
        view_758: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_377, [32, 16]);  clone_377 = None
        mm_374: "f32[32, 8]" = torch.ops.aten.mm.default(view_758, slice_7)
        view_759: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_374, [2, 16, 8]);  mm_374 = None
        slice_12351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1495, 1, 2992, 3008)
        slice_12352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12351, 2, 0, 16);  slice_12351 = None
        add_376: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12352, view_759);  slice_12352 = view_759 = None
        
        # No stacktrace found for following nodes
        slice_tensor_748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1495, 1, 2992, 3008)
        slice_scatter_default_1496: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_748, add_376, 2, 0, 16);  slice_tensor_748 = add_376 = None
        slice_scatter_default_1497: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1495, slice_scatter_default_1496, 1, 2992, 3008);  slice_scatter_default_1495 = slice_scatter_default_1496 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1497, 1, 2992, 3008)
        slice_12357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12356, 2, 0, 16);  slice_12356 = None
        
        # No stacktrace found for following nodes
        slice_tensor_749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1497, 1, 2992, 3008)
        slice_scatter_default_1498: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_749, slice_12357, 2, 0, 16);  slice_tensor_749 = slice_12357 = None
        slice_scatter_default_1499: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1497, slice_scatter_default_1498, 1, 2992, 3008);  slice_scatter_default_1497 = slice_scatter_default_1498 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12377: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12343, 2, 16, 32);  slice_12343 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_378: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12377, memory_format = torch.contiguous_format);  slice_12377 = None
        view_760: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_378, [32, 11]);  clone_378 = None
        mm_375: "f32[32, 8]" = torch.ops.aten.mm.default(view_760, slice_37)
        view_761: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_375, [2, 16, 8]);  mm_375 = None
        slice_12384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1499, 1, 2992, 3008)
        slice_12385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12384, 2, 0, 16);  slice_12384 = None
        add_377: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12385, view_761);  slice_12385 = view_761 = None
        
        # No stacktrace found for following nodes
        slice_tensor_750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1499, 1, 2992, 3008)
        slice_scatter_default_1500: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_750, add_377, 2, 0, 16);  slice_tensor_750 = add_377 = None
        slice_scatter_default_1501: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1499, slice_scatter_default_1500, 1, 2992, 3008);  slice_scatter_default_1499 = slice_scatter_default_1500 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1501, 1, 2992, 3008)
        slice_12390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12389, 2, 0, 16);  slice_12389 = None
        
        # No stacktrace found for following nodes
        slice_tensor_751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1501, 1, 2992, 3008)
        slice_scatter_default_1502: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_751, slice_12390, 2, 0, 16);  slice_tensor_751 = slice_12390 = None
        slice_scatter_default_1503: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1501, slice_scatter_default_1502, 1, 2992, 3008);  slice_scatter_default_1501 = slice_scatter_default_1502 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12409: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3008, 3024)
        slice_12410: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12409, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_379: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12410, memory_format = torch.contiguous_format);  slice_12410 = None
        view_762: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_379, [32, 16]);  clone_379 = None
        mm_376: "f32[32, 8]" = torch.ops.aten.mm.default(view_762, slice_7)
        view_763: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_376, [2, 16, 8]);  mm_376 = None
        slice_12417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1503, 1, 3008, 3024)
        slice_12418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12417, 2, 0, 16);  slice_12417 = None
        add_378: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12418, view_763);  slice_12418 = view_763 = None
        
        # No stacktrace found for following nodes
        slice_tensor_752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1503, 1, 3008, 3024)
        slice_scatter_default_1504: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_752, add_378, 2, 0, 16);  slice_tensor_752 = add_378 = None
        slice_scatter_default_1505: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1503, slice_scatter_default_1504, 1, 3008, 3024);  slice_scatter_default_1503 = slice_scatter_default_1504 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1505, 1, 3008, 3024)
        slice_12423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12422, 2, 0, 16);  slice_12422 = None
        
        # No stacktrace found for following nodes
        slice_tensor_753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1505, 1, 3008, 3024)
        slice_scatter_default_1506: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_753, slice_12423, 2, 0, 16);  slice_tensor_753 = slice_12423 = None
        slice_scatter_default_1507: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1505, slice_scatter_default_1506, 1, 3008, 3024);  slice_scatter_default_1505 = slice_scatter_default_1506 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12443: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12409, 2, 16, 32);  slice_12409 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_380: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12443, memory_format = torch.contiguous_format);  slice_12443 = None
        view_764: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_380, [32, 11]);  clone_380 = None
        mm_377: "f32[32, 8]" = torch.ops.aten.mm.default(view_764, slice_37)
        view_765: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_377, [2, 16, 8]);  mm_377 = None
        slice_12450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1507, 1, 3008, 3024)
        slice_12451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12450, 2, 0, 16);  slice_12450 = None
        add_379: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12451, view_765);  slice_12451 = view_765 = None
        
        # No stacktrace found for following nodes
        slice_tensor_754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1507, 1, 3008, 3024)
        slice_scatter_default_1508: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_754, add_379, 2, 0, 16);  slice_tensor_754 = add_379 = None
        slice_scatter_default_1509: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1507, slice_scatter_default_1508, 1, 3008, 3024);  slice_scatter_default_1507 = slice_scatter_default_1508 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1509, 1, 3008, 3024)
        slice_12456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12455, 2, 0, 16);  slice_12455 = None
        
        # No stacktrace found for following nodes
        slice_tensor_755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1509, 1, 3008, 3024)
        slice_scatter_default_1510: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_755, slice_12456, 2, 0, 16);  slice_tensor_755 = slice_12456 = None
        slice_scatter_default_1511: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1509, slice_scatter_default_1510, 1, 3008, 3024);  slice_scatter_default_1509 = slice_scatter_default_1510 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12475: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3024, 3040)
        slice_12476: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12475, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_381: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12476, memory_format = torch.contiguous_format);  slice_12476 = None
        view_766: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_381, [32, 16]);  clone_381 = None
        mm_378: "f32[32, 8]" = torch.ops.aten.mm.default(view_766, slice_7)
        view_767: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_378, [2, 16, 8]);  mm_378 = None
        slice_12483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1511, 1, 3024, 3040)
        slice_12484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12483, 2, 0, 16);  slice_12483 = None
        add_380: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12484, view_767);  slice_12484 = view_767 = None
        
        # No stacktrace found for following nodes
        slice_tensor_756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1511, 1, 3024, 3040)
        slice_scatter_default_1512: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_756, add_380, 2, 0, 16);  slice_tensor_756 = add_380 = None
        slice_scatter_default_1513: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1511, slice_scatter_default_1512, 1, 3024, 3040);  slice_scatter_default_1511 = slice_scatter_default_1512 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1513, 1, 3024, 3040)
        slice_12489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12488, 2, 0, 16);  slice_12488 = None
        
        # No stacktrace found for following nodes
        slice_tensor_757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1513, 1, 3024, 3040)
        slice_scatter_default_1514: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_757, slice_12489, 2, 0, 16);  slice_tensor_757 = slice_12489 = None
        slice_scatter_default_1515: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1513, slice_scatter_default_1514, 1, 3024, 3040);  slice_scatter_default_1513 = slice_scatter_default_1514 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12509: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12475, 2, 16, 32);  slice_12475 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_382: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12509, memory_format = torch.contiguous_format);  slice_12509 = None
        view_768: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_382, [32, 11]);  clone_382 = None
        mm_379: "f32[32, 8]" = torch.ops.aten.mm.default(view_768, slice_37)
        view_769: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_379, [2, 16, 8]);  mm_379 = None
        slice_12516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1515, 1, 3024, 3040)
        slice_12517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12516, 2, 0, 16);  slice_12516 = None
        add_381: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12517, view_769);  slice_12517 = view_769 = None
        
        # No stacktrace found for following nodes
        slice_tensor_758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1515, 1, 3024, 3040)
        slice_scatter_default_1516: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_758, add_381, 2, 0, 16);  slice_tensor_758 = add_381 = None
        slice_scatter_default_1517: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1515, slice_scatter_default_1516, 1, 3024, 3040);  slice_scatter_default_1515 = slice_scatter_default_1516 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1517, 1, 3024, 3040)
        slice_12522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12521, 2, 0, 16);  slice_12521 = None
        
        # No stacktrace found for following nodes
        slice_tensor_759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1517, 1, 3024, 3040)
        slice_scatter_default_1518: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_759, slice_12522, 2, 0, 16);  slice_tensor_759 = slice_12522 = None
        slice_scatter_default_1519: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1517, slice_scatter_default_1518, 1, 3024, 3040);  slice_scatter_default_1517 = slice_scatter_default_1518 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12541: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3040, 3056)
        slice_12542: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12541, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_383: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12542, memory_format = torch.contiguous_format);  slice_12542 = None
        view_770: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_383, [32, 16]);  clone_383 = None
        mm_380: "f32[32, 8]" = torch.ops.aten.mm.default(view_770, slice_7)
        view_771: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_380, [2, 16, 8]);  mm_380 = None
        slice_12549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1519, 1, 3040, 3056)
        slice_12550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12549, 2, 0, 16);  slice_12549 = None
        add_382: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12550, view_771);  slice_12550 = view_771 = None
        
        # No stacktrace found for following nodes
        slice_tensor_760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1519, 1, 3040, 3056)
        slice_scatter_default_1520: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_760, add_382, 2, 0, 16);  slice_tensor_760 = add_382 = None
        slice_scatter_default_1521: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1519, slice_scatter_default_1520, 1, 3040, 3056);  slice_scatter_default_1519 = slice_scatter_default_1520 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1521, 1, 3040, 3056)
        slice_12555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12554, 2, 0, 16);  slice_12554 = None
        
        # No stacktrace found for following nodes
        slice_tensor_761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1521, 1, 3040, 3056)
        slice_scatter_default_1522: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_761, slice_12555, 2, 0, 16);  slice_tensor_761 = slice_12555 = None
        slice_scatter_default_1523: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1521, slice_scatter_default_1522, 1, 3040, 3056);  slice_scatter_default_1521 = slice_scatter_default_1522 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12575: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12541, 2, 16, 32);  slice_12541 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_384: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12575, memory_format = torch.contiguous_format);  slice_12575 = None
        view_772: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_384, [32, 11]);  clone_384 = None
        mm_381: "f32[32, 8]" = torch.ops.aten.mm.default(view_772, slice_37)
        view_773: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_381, [2, 16, 8]);  mm_381 = None
        slice_12582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1523, 1, 3040, 3056)
        slice_12583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12582, 2, 0, 16);  slice_12582 = None
        add_383: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12583, view_773);  slice_12583 = view_773 = None
        
        # No stacktrace found for following nodes
        slice_tensor_762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1523, 1, 3040, 3056)
        slice_scatter_default_1524: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_762, add_383, 2, 0, 16);  slice_tensor_762 = add_383 = None
        slice_scatter_default_1525: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1523, slice_scatter_default_1524, 1, 3040, 3056);  slice_scatter_default_1523 = slice_scatter_default_1524 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1525, 1, 3040, 3056)
        slice_12588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12587, 2, 0, 16);  slice_12587 = None
        
        # No stacktrace found for following nodes
        slice_tensor_763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1525, 1, 3040, 3056)
        slice_scatter_default_1526: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_763, slice_12588, 2, 0, 16);  slice_tensor_763 = slice_12588 = None
        slice_scatter_default_1527: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1525, slice_scatter_default_1526, 1, 3040, 3056);  slice_scatter_default_1525 = slice_scatter_default_1526 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12607: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3056, 3072)
        slice_12608: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12607, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_385: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12608, memory_format = torch.contiguous_format);  slice_12608 = None
        view_774: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_385, [32, 16]);  clone_385 = None
        mm_382: "f32[32, 8]" = torch.ops.aten.mm.default(view_774, slice_7)
        view_775: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_382, [2, 16, 8]);  mm_382 = None
        slice_12615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1527, 1, 3056, 3072)
        slice_12616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12615, 2, 0, 16);  slice_12615 = None
        add_384: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12616, view_775);  slice_12616 = view_775 = None
        
        # No stacktrace found for following nodes
        slice_tensor_764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1527, 1, 3056, 3072)
        slice_scatter_default_1528: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_764, add_384, 2, 0, 16);  slice_tensor_764 = add_384 = None
        slice_scatter_default_1529: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1527, slice_scatter_default_1528, 1, 3056, 3072);  slice_scatter_default_1527 = slice_scatter_default_1528 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1529, 1, 3056, 3072)
        slice_12621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12620, 2, 0, 16);  slice_12620 = None
        
        # No stacktrace found for following nodes
        slice_tensor_765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1529, 1, 3056, 3072)
        slice_scatter_default_1530: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_765, slice_12621, 2, 0, 16);  slice_tensor_765 = slice_12621 = None
        slice_scatter_default_1531: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1529, slice_scatter_default_1530, 1, 3056, 3072);  slice_scatter_default_1529 = slice_scatter_default_1530 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12641: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12607, 2, 16, 32);  slice_12607 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_386: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12641, memory_format = torch.contiguous_format);  slice_12641 = None
        view_776: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_386, [32, 11]);  clone_386 = None
        mm_383: "f32[32, 8]" = torch.ops.aten.mm.default(view_776, slice_37)
        view_777: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_383, [2, 16, 8]);  mm_383 = None
        slice_12648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1531, 1, 3056, 3072)
        slice_12649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12648, 2, 0, 16);  slice_12648 = None
        add_385: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12649, view_777);  slice_12649 = view_777 = None
        
        # No stacktrace found for following nodes
        slice_tensor_766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1531, 1, 3056, 3072)
        slice_scatter_default_1532: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_766, add_385, 2, 0, 16);  slice_tensor_766 = add_385 = None
        slice_scatter_default_1533: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1531, slice_scatter_default_1532, 1, 3056, 3072);  slice_scatter_default_1531 = slice_scatter_default_1532 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1533, 1, 3056, 3072)
        slice_12654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12653, 2, 0, 16);  slice_12653 = None
        
        # No stacktrace found for following nodes
        slice_tensor_767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1533, 1, 3056, 3072)
        slice_scatter_default_1534: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_767, slice_12654, 2, 0, 16);  slice_tensor_767 = slice_12654 = None
        slice_scatter_default_1535: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1533, slice_scatter_default_1534, 1, 3056, 3072);  slice_scatter_default_1533 = slice_scatter_default_1534 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12673: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3072, 3088)
        slice_12674: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12673, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_387: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12674, memory_format = torch.contiguous_format);  slice_12674 = None
        view_778: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_387, [32, 16]);  clone_387 = None
        mm_384: "f32[32, 8]" = torch.ops.aten.mm.default(view_778, slice_7)
        view_779: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_384, [2, 16, 8]);  mm_384 = None
        slice_12681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1535, 1, 3072, 3088)
        slice_12682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12681, 2, 0, 16);  slice_12681 = None
        add_386: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12682, view_779);  slice_12682 = view_779 = None
        
        # No stacktrace found for following nodes
        slice_tensor_768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1535, 1, 3072, 3088)
        slice_scatter_default_1536: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_768, add_386, 2, 0, 16);  slice_tensor_768 = add_386 = None
        slice_scatter_default_1537: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1535, slice_scatter_default_1536, 1, 3072, 3088);  slice_scatter_default_1535 = slice_scatter_default_1536 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1537, 1, 3072, 3088)
        slice_12687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12686, 2, 0, 16);  slice_12686 = None
        
        # No stacktrace found for following nodes
        slice_tensor_769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1537, 1, 3072, 3088)
        slice_scatter_default_1538: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_769, slice_12687, 2, 0, 16);  slice_tensor_769 = slice_12687 = None
        slice_scatter_default_1539: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1537, slice_scatter_default_1538, 1, 3072, 3088);  slice_scatter_default_1537 = slice_scatter_default_1538 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12707: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12673, 2, 16, 32);  slice_12673 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_388: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12707, memory_format = torch.contiguous_format);  slice_12707 = None
        view_780: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_388, [32, 11]);  clone_388 = None
        mm_385: "f32[32, 8]" = torch.ops.aten.mm.default(view_780, slice_37)
        view_781: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_385, [2, 16, 8]);  mm_385 = None
        slice_12714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1539, 1, 3072, 3088)
        slice_12715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12714, 2, 0, 16);  slice_12714 = None
        add_387: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12715, view_781);  slice_12715 = view_781 = None
        
        # No stacktrace found for following nodes
        slice_tensor_770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1539, 1, 3072, 3088)
        slice_scatter_default_1540: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_770, add_387, 2, 0, 16);  slice_tensor_770 = add_387 = None
        slice_scatter_default_1541: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1539, slice_scatter_default_1540, 1, 3072, 3088);  slice_scatter_default_1539 = slice_scatter_default_1540 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1541, 1, 3072, 3088)
        slice_12720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12719, 2, 0, 16);  slice_12719 = None
        
        # No stacktrace found for following nodes
        slice_tensor_771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1541, 1, 3072, 3088)
        slice_scatter_default_1542: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_771, slice_12720, 2, 0, 16);  slice_tensor_771 = slice_12720 = None
        slice_scatter_default_1543: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1541, slice_scatter_default_1542, 1, 3072, 3088);  slice_scatter_default_1541 = slice_scatter_default_1542 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12739: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3088, 3104)
        slice_12740: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12739, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_389: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12740, memory_format = torch.contiguous_format);  slice_12740 = None
        view_782: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_389, [32, 16]);  clone_389 = None
        mm_386: "f32[32, 8]" = torch.ops.aten.mm.default(view_782, slice_7)
        view_783: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_386, [2, 16, 8]);  mm_386 = None
        slice_12747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1543, 1, 3088, 3104)
        slice_12748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12747, 2, 0, 16);  slice_12747 = None
        add_388: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12748, view_783);  slice_12748 = view_783 = None
        
        # No stacktrace found for following nodes
        slice_tensor_772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1543, 1, 3088, 3104)
        slice_scatter_default_1544: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_772, add_388, 2, 0, 16);  slice_tensor_772 = add_388 = None
        slice_scatter_default_1545: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1543, slice_scatter_default_1544, 1, 3088, 3104);  slice_scatter_default_1543 = slice_scatter_default_1544 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1545, 1, 3088, 3104)
        slice_12753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12752, 2, 0, 16);  slice_12752 = None
        
        # No stacktrace found for following nodes
        slice_tensor_773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1545, 1, 3088, 3104)
        slice_scatter_default_1546: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_773, slice_12753, 2, 0, 16);  slice_tensor_773 = slice_12753 = None
        slice_scatter_default_1547: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1545, slice_scatter_default_1546, 1, 3088, 3104);  slice_scatter_default_1545 = slice_scatter_default_1546 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12773: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12739, 2, 16, 32);  slice_12739 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_390: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12773, memory_format = torch.contiguous_format);  slice_12773 = None
        view_784: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_390, [32, 11]);  clone_390 = None
        mm_387: "f32[32, 8]" = torch.ops.aten.mm.default(view_784, slice_37)
        view_785: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_387, [2, 16, 8]);  mm_387 = None
        slice_12780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1547, 1, 3088, 3104)
        slice_12781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12780, 2, 0, 16);  slice_12780 = None
        add_389: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12781, view_785);  slice_12781 = view_785 = None
        
        # No stacktrace found for following nodes
        slice_tensor_774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1547, 1, 3088, 3104)
        slice_scatter_default_1548: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_774, add_389, 2, 0, 16);  slice_tensor_774 = add_389 = None
        slice_scatter_default_1549: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1547, slice_scatter_default_1548, 1, 3088, 3104);  slice_scatter_default_1547 = slice_scatter_default_1548 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1549, 1, 3088, 3104)
        slice_12786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12785, 2, 0, 16);  slice_12785 = None
        
        # No stacktrace found for following nodes
        slice_tensor_775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1549, 1, 3088, 3104)
        slice_scatter_default_1550: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_775, slice_12786, 2, 0, 16);  slice_tensor_775 = slice_12786 = None
        slice_scatter_default_1551: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1549, slice_scatter_default_1550, 1, 3088, 3104);  slice_scatter_default_1549 = slice_scatter_default_1550 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12805: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3104, 3120)
        slice_12806: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12805, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_391: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12806, memory_format = torch.contiguous_format);  slice_12806 = None
        view_786: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_391, [32, 16]);  clone_391 = None
        mm_388: "f32[32, 8]" = torch.ops.aten.mm.default(view_786, slice_7)
        view_787: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_388, [2, 16, 8]);  mm_388 = None
        slice_12813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1551, 1, 3104, 3120)
        slice_12814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12813, 2, 0, 16);  slice_12813 = None
        add_390: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12814, view_787);  slice_12814 = view_787 = None
        
        # No stacktrace found for following nodes
        slice_tensor_776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1551, 1, 3104, 3120)
        slice_scatter_default_1552: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_776, add_390, 2, 0, 16);  slice_tensor_776 = add_390 = None
        slice_scatter_default_1553: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1551, slice_scatter_default_1552, 1, 3104, 3120);  slice_scatter_default_1551 = slice_scatter_default_1552 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1553, 1, 3104, 3120)
        slice_12819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12818, 2, 0, 16);  slice_12818 = None
        
        # No stacktrace found for following nodes
        slice_tensor_777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1553, 1, 3104, 3120)
        slice_scatter_default_1554: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_777, slice_12819, 2, 0, 16);  slice_tensor_777 = slice_12819 = None
        slice_scatter_default_1555: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1553, slice_scatter_default_1554, 1, 3104, 3120);  slice_scatter_default_1553 = slice_scatter_default_1554 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12839: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12805, 2, 16, 32);  slice_12805 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_392: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12839, memory_format = torch.contiguous_format);  slice_12839 = None
        view_788: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_392, [32, 11]);  clone_392 = None
        mm_389: "f32[32, 8]" = torch.ops.aten.mm.default(view_788, slice_37)
        view_789: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_389, [2, 16, 8]);  mm_389 = None
        slice_12846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1555, 1, 3104, 3120)
        slice_12847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12846, 2, 0, 16);  slice_12846 = None
        add_391: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12847, view_789);  slice_12847 = view_789 = None
        
        # No stacktrace found for following nodes
        slice_tensor_778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1555, 1, 3104, 3120)
        slice_scatter_default_1556: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_778, add_391, 2, 0, 16);  slice_tensor_778 = add_391 = None
        slice_scatter_default_1557: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1555, slice_scatter_default_1556, 1, 3104, 3120);  slice_scatter_default_1555 = slice_scatter_default_1556 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1557, 1, 3104, 3120)
        slice_12852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12851, 2, 0, 16);  slice_12851 = None
        
        # No stacktrace found for following nodes
        slice_tensor_779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1557, 1, 3104, 3120)
        slice_scatter_default_1558: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_779, slice_12852, 2, 0, 16);  slice_tensor_779 = slice_12852 = None
        slice_scatter_default_1559: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1557, slice_scatter_default_1558, 1, 3104, 3120);  slice_scatter_default_1557 = slice_scatter_default_1558 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12871: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3120, 3136)
        slice_12872: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12871, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_393: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12872, memory_format = torch.contiguous_format);  slice_12872 = None
        view_790: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_393, [32, 16]);  clone_393 = None
        mm_390: "f32[32, 8]" = torch.ops.aten.mm.default(view_790, slice_7)
        view_791: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_390, [2, 16, 8]);  mm_390 = None
        slice_12879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1559, 1, 3120, 3136)
        slice_12880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12879, 2, 0, 16);  slice_12879 = None
        add_392: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12880, view_791);  slice_12880 = view_791 = None
        
        # No stacktrace found for following nodes
        slice_tensor_780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1559, 1, 3120, 3136)
        slice_scatter_default_1560: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_780, add_392, 2, 0, 16);  slice_tensor_780 = add_392 = None
        slice_scatter_default_1561: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1559, slice_scatter_default_1560, 1, 3120, 3136);  slice_scatter_default_1559 = slice_scatter_default_1560 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1561, 1, 3120, 3136)
        slice_12885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12884, 2, 0, 16);  slice_12884 = None
        
        # No stacktrace found for following nodes
        slice_tensor_781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1561, 1, 3120, 3136)
        slice_scatter_default_1562: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_781, slice_12885, 2, 0, 16);  slice_tensor_781 = slice_12885 = None
        slice_scatter_default_1563: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1561, slice_scatter_default_1562, 1, 3120, 3136);  slice_scatter_default_1561 = slice_scatter_default_1562 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12905: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12871, 2, 16, 32);  slice_12871 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_394: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12905, memory_format = torch.contiguous_format);  slice_12905 = None
        view_792: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_394, [32, 11]);  clone_394 = None
        mm_391: "f32[32, 8]" = torch.ops.aten.mm.default(view_792, slice_37)
        view_793: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_391, [2, 16, 8]);  mm_391 = None
        slice_12912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1563, 1, 3120, 3136)
        slice_12913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12912, 2, 0, 16);  slice_12912 = None
        add_393: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12913, view_793);  slice_12913 = view_793 = None
        
        # No stacktrace found for following nodes
        slice_tensor_782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1563, 1, 3120, 3136)
        slice_scatter_default_1564: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_782, add_393, 2, 0, 16);  slice_tensor_782 = add_393 = None
        slice_scatter_default_1565: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1563, slice_scatter_default_1564, 1, 3120, 3136);  slice_scatter_default_1563 = slice_scatter_default_1564 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1565, 1, 3120, 3136)
        slice_12918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12917, 2, 0, 16);  slice_12917 = None
        
        # No stacktrace found for following nodes
        slice_tensor_783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1565, 1, 3120, 3136)
        slice_scatter_default_1566: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_783, slice_12918, 2, 0, 16);  slice_tensor_783 = slice_12918 = None
        slice_scatter_default_1567: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1565, slice_scatter_default_1566, 1, 3120, 3136);  slice_scatter_default_1565 = slice_scatter_default_1566 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12937: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3136, 3152)
        slice_12938: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_12937, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_395: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_12938, memory_format = torch.contiguous_format);  slice_12938 = None
        view_794: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_395, [32, 16]);  clone_395 = None
        mm_392: "f32[32, 8]" = torch.ops.aten.mm.default(view_794, slice_7)
        view_795: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_392, [2, 16, 8]);  mm_392 = None
        slice_12945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1567, 1, 3136, 3152)
        slice_12946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12945, 2, 0, 16);  slice_12945 = None
        add_394: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12946, view_795);  slice_12946 = view_795 = None
        
        # No stacktrace found for following nodes
        slice_tensor_784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1567, 1, 3136, 3152)
        slice_scatter_default_1568: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_784, add_394, 2, 0, 16);  slice_tensor_784 = add_394 = None
        slice_scatter_default_1569: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1567, slice_scatter_default_1568, 1, 3136, 3152);  slice_scatter_default_1567 = slice_scatter_default_1568 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1569, 1, 3136, 3152)
        slice_12951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12950, 2, 0, 16);  slice_12950 = None
        
        # No stacktrace found for following nodes
        slice_tensor_785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1569, 1, 3136, 3152)
        slice_scatter_default_1570: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_785, slice_12951, 2, 0, 16);  slice_tensor_785 = slice_12951 = None
        slice_scatter_default_1571: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1569, slice_scatter_default_1570, 1, 3136, 3152);  slice_scatter_default_1569 = slice_scatter_default_1570 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_12971: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_12937, 2, 16, 32);  slice_12937 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_396: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_12971, memory_format = torch.contiguous_format);  slice_12971 = None
        view_796: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_396, [32, 11]);  clone_396 = None
        mm_393: "f32[32, 8]" = torch.ops.aten.mm.default(view_796, slice_37)
        view_797: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_393, [2, 16, 8]);  mm_393 = None
        slice_12978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1571, 1, 3136, 3152)
        slice_12979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12978, 2, 0, 16);  slice_12978 = None
        add_395: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_12979, view_797);  slice_12979 = view_797 = None
        
        # No stacktrace found for following nodes
        slice_tensor_786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1571, 1, 3136, 3152)
        slice_scatter_default_1572: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_786, add_395, 2, 0, 16);  slice_tensor_786 = add_395 = None
        slice_scatter_default_1573: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1571, slice_scatter_default_1572, 1, 3136, 3152);  slice_scatter_default_1571 = slice_scatter_default_1572 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_12983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1573, 1, 3136, 3152)
        slice_12984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_12983, 2, 0, 16);  slice_12983 = None
        
        # No stacktrace found for following nodes
        slice_tensor_787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1573, 1, 3136, 3152)
        slice_scatter_default_1574: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_787, slice_12984, 2, 0, 16);  slice_tensor_787 = slice_12984 = None
        slice_scatter_default_1575: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1573, slice_scatter_default_1574, 1, 3136, 3152);  slice_scatter_default_1573 = slice_scatter_default_1574 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13003: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3152, 3168)
        slice_13004: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13003, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_397: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13004, memory_format = torch.contiguous_format);  slice_13004 = None
        view_798: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_397, [32, 16]);  clone_397 = None
        mm_394: "f32[32, 8]" = torch.ops.aten.mm.default(view_798, slice_7)
        view_799: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_394, [2, 16, 8]);  mm_394 = None
        slice_13011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1575, 1, 3152, 3168)
        slice_13012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13011, 2, 0, 16);  slice_13011 = None
        add_396: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13012, view_799);  slice_13012 = view_799 = None
        
        # No stacktrace found for following nodes
        slice_tensor_788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1575, 1, 3152, 3168)
        slice_scatter_default_1576: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_788, add_396, 2, 0, 16);  slice_tensor_788 = add_396 = None
        slice_scatter_default_1577: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1575, slice_scatter_default_1576, 1, 3152, 3168);  slice_scatter_default_1575 = slice_scatter_default_1576 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1577, 1, 3152, 3168)
        slice_13017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13016, 2, 0, 16);  slice_13016 = None
        
        # No stacktrace found for following nodes
        slice_tensor_789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1577, 1, 3152, 3168)
        slice_scatter_default_1578: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_789, slice_13017, 2, 0, 16);  slice_tensor_789 = slice_13017 = None
        slice_scatter_default_1579: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1577, slice_scatter_default_1578, 1, 3152, 3168);  slice_scatter_default_1577 = slice_scatter_default_1578 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13037: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13003, 2, 16, 32);  slice_13003 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_398: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13037, memory_format = torch.contiguous_format);  slice_13037 = None
        view_800: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_398, [32, 11]);  clone_398 = None
        mm_395: "f32[32, 8]" = torch.ops.aten.mm.default(view_800, slice_37)
        view_801: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_395, [2, 16, 8]);  mm_395 = None
        slice_13044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1579, 1, 3152, 3168)
        slice_13045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13044, 2, 0, 16);  slice_13044 = None
        add_397: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13045, view_801);  slice_13045 = view_801 = None
        
        # No stacktrace found for following nodes
        slice_tensor_790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1579, 1, 3152, 3168)
        slice_scatter_default_1580: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_790, add_397, 2, 0, 16);  slice_tensor_790 = add_397 = None
        slice_scatter_default_1581: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1579, slice_scatter_default_1580, 1, 3152, 3168);  slice_scatter_default_1579 = slice_scatter_default_1580 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1581, 1, 3152, 3168)
        slice_13050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13049, 2, 0, 16);  slice_13049 = None
        
        # No stacktrace found for following nodes
        slice_tensor_791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1581, 1, 3152, 3168)
        slice_scatter_default_1582: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_791, slice_13050, 2, 0, 16);  slice_tensor_791 = slice_13050 = None
        slice_scatter_default_1583: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1581, slice_scatter_default_1582, 1, 3152, 3168);  slice_scatter_default_1581 = slice_scatter_default_1582 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13069: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3168, 3184)
        slice_13070: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13069, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_399: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13070, memory_format = torch.contiguous_format);  slice_13070 = None
        view_802: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_399, [32, 16]);  clone_399 = None
        mm_396: "f32[32, 8]" = torch.ops.aten.mm.default(view_802, slice_7)
        view_803: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_396, [2, 16, 8]);  mm_396 = None
        slice_13077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1583, 1, 3168, 3184)
        slice_13078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13077, 2, 0, 16);  slice_13077 = None
        add_398: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13078, view_803);  slice_13078 = view_803 = None
        
        # No stacktrace found for following nodes
        slice_tensor_792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1583, 1, 3168, 3184)
        slice_scatter_default_1584: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_792, add_398, 2, 0, 16);  slice_tensor_792 = add_398 = None
        slice_scatter_default_1585: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1583, slice_scatter_default_1584, 1, 3168, 3184);  slice_scatter_default_1583 = slice_scatter_default_1584 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1585, 1, 3168, 3184)
        slice_13083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13082, 2, 0, 16);  slice_13082 = None
        
        # No stacktrace found for following nodes
        slice_tensor_793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1585, 1, 3168, 3184)
        slice_scatter_default_1586: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_793, slice_13083, 2, 0, 16);  slice_tensor_793 = slice_13083 = None
        slice_scatter_default_1587: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1585, slice_scatter_default_1586, 1, 3168, 3184);  slice_scatter_default_1585 = slice_scatter_default_1586 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13103: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13069, 2, 16, 32);  slice_13069 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_400: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13103, memory_format = torch.contiguous_format);  slice_13103 = None
        view_804: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_400, [32, 11]);  clone_400 = None
        mm_397: "f32[32, 8]" = torch.ops.aten.mm.default(view_804, slice_37)
        view_805: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_397, [2, 16, 8]);  mm_397 = None
        slice_13110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1587, 1, 3168, 3184)
        slice_13111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13110, 2, 0, 16);  slice_13110 = None
        add_399: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13111, view_805);  slice_13111 = view_805 = None
        
        # No stacktrace found for following nodes
        slice_tensor_794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1587, 1, 3168, 3184)
        slice_scatter_default_1588: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_794, add_399, 2, 0, 16);  slice_tensor_794 = add_399 = None
        slice_scatter_default_1589: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1587, slice_scatter_default_1588, 1, 3168, 3184);  slice_scatter_default_1587 = slice_scatter_default_1588 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1589, 1, 3168, 3184)
        slice_13116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13115, 2, 0, 16);  slice_13115 = None
        
        # No stacktrace found for following nodes
        slice_tensor_795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1589, 1, 3168, 3184)
        slice_scatter_default_1590: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_795, slice_13116, 2, 0, 16);  slice_tensor_795 = slice_13116 = None
        slice_scatter_default_1591: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1589, slice_scatter_default_1590, 1, 3168, 3184);  slice_scatter_default_1589 = slice_scatter_default_1590 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13135: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3184, 3200)
        slice_13136: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13135, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_401: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13136, memory_format = torch.contiguous_format);  slice_13136 = None
        view_806: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_401, [32, 16]);  clone_401 = None
        mm_398: "f32[32, 8]" = torch.ops.aten.mm.default(view_806, slice_7)
        view_807: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_398, [2, 16, 8]);  mm_398 = None
        slice_13143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1591, 1, 3184, 3200)
        slice_13144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13143, 2, 0, 16);  slice_13143 = None
        add_400: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13144, view_807);  slice_13144 = view_807 = None
        
        # No stacktrace found for following nodes
        slice_tensor_796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1591, 1, 3184, 3200)
        slice_scatter_default_1592: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_796, add_400, 2, 0, 16);  slice_tensor_796 = add_400 = None
        slice_scatter_default_1593: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1591, slice_scatter_default_1592, 1, 3184, 3200);  slice_scatter_default_1591 = slice_scatter_default_1592 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1593, 1, 3184, 3200)
        slice_13149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13148, 2, 0, 16);  slice_13148 = None
        
        # No stacktrace found for following nodes
        slice_tensor_797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1593, 1, 3184, 3200)
        slice_scatter_default_1594: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_797, slice_13149, 2, 0, 16);  slice_tensor_797 = slice_13149 = None
        slice_scatter_default_1595: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1593, slice_scatter_default_1594, 1, 3184, 3200);  slice_scatter_default_1593 = slice_scatter_default_1594 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13169: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13135, 2, 16, 32);  slice_13135 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_402: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13169, memory_format = torch.contiguous_format);  slice_13169 = None
        view_808: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_402, [32, 11]);  clone_402 = None
        mm_399: "f32[32, 8]" = torch.ops.aten.mm.default(view_808, slice_37)
        view_809: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_399, [2, 16, 8]);  mm_399 = None
        slice_13176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1595, 1, 3184, 3200)
        slice_13177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13176, 2, 0, 16);  slice_13176 = None
        add_401: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13177, view_809);  slice_13177 = view_809 = None
        
        # No stacktrace found for following nodes
        slice_tensor_798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1595, 1, 3184, 3200)
        slice_scatter_default_1596: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_798, add_401, 2, 0, 16);  slice_tensor_798 = add_401 = None
        slice_scatter_default_1597: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1595, slice_scatter_default_1596, 1, 3184, 3200);  slice_scatter_default_1595 = slice_scatter_default_1596 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1597, 1, 3184, 3200)
        slice_13182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13181, 2, 0, 16);  slice_13181 = None
        
        # No stacktrace found for following nodes
        slice_tensor_799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1597, 1, 3184, 3200)
        slice_scatter_default_1598: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_799, slice_13182, 2, 0, 16);  slice_tensor_799 = slice_13182 = None
        slice_scatter_default_1599: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1597, slice_scatter_default_1598, 1, 3184, 3200);  slice_scatter_default_1597 = slice_scatter_default_1598 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13201: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3200, 3216)
        slice_13202: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13201, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_403: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13202, memory_format = torch.contiguous_format);  slice_13202 = None
        view_810: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_403, [32, 16]);  clone_403 = None
        mm_400: "f32[32, 8]" = torch.ops.aten.mm.default(view_810, slice_7)
        view_811: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_400, [2, 16, 8]);  mm_400 = None
        slice_13209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1599, 1, 3200, 3216)
        slice_13210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13209, 2, 0, 16);  slice_13209 = None
        add_402: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13210, view_811);  slice_13210 = view_811 = None
        
        # No stacktrace found for following nodes
        slice_tensor_800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1599, 1, 3200, 3216)
        slice_scatter_default_1600: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_800, add_402, 2, 0, 16);  slice_tensor_800 = add_402 = None
        slice_scatter_default_1601: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1599, slice_scatter_default_1600, 1, 3200, 3216);  slice_scatter_default_1599 = slice_scatter_default_1600 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1601, 1, 3200, 3216)
        slice_13215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13214, 2, 0, 16);  slice_13214 = None
        
        # No stacktrace found for following nodes
        slice_tensor_801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1601, 1, 3200, 3216)
        slice_scatter_default_1602: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_801, slice_13215, 2, 0, 16);  slice_tensor_801 = slice_13215 = None
        slice_scatter_default_1603: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1601, slice_scatter_default_1602, 1, 3200, 3216);  slice_scatter_default_1601 = slice_scatter_default_1602 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13235: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13201, 2, 16, 32);  slice_13201 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_404: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13235, memory_format = torch.contiguous_format);  slice_13235 = None
        view_812: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_404, [32, 11]);  clone_404 = None
        mm_401: "f32[32, 8]" = torch.ops.aten.mm.default(view_812, slice_37)
        view_813: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_401, [2, 16, 8]);  mm_401 = None
        slice_13242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1603, 1, 3200, 3216)
        slice_13243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13242, 2, 0, 16);  slice_13242 = None
        add_403: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13243, view_813);  slice_13243 = view_813 = None
        
        # No stacktrace found for following nodes
        slice_tensor_802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1603, 1, 3200, 3216)
        slice_scatter_default_1604: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_802, add_403, 2, 0, 16);  slice_tensor_802 = add_403 = None
        slice_scatter_default_1605: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1603, slice_scatter_default_1604, 1, 3200, 3216);  slice_scatter_default_1603 = slice_scatter_default_1604 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1605, 1, 3200, 3216)
        slice_13248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13247, 2, 0, 16);  slice_13247 = None
        
        # No stacktrace found for following nodes
        slice_tensor_803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1605, 1, 3200, 3216)
        slice_scatter_default_1606: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_803, slice_13248, 2, 0, 16);  slice_tensor_803 = slice_13248 = None
        slice_scatter_default_1607: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1605, slice_scatter_default_1606, 1, 3200, 3216);  slice_scatter_default_1605 = slice_scatter_default_1606 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13267: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3216, 3232)
        slice_13268: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13267, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_405: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13268, memory_format = torch.contiguous_format);  slice_13268 = None
        view_814: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_405, [32, 16]);  clone_405 = None
        mm_402: "f32[32, 8]" = torch.ops.aten.mm.default(view_814, slice_7)
        view_815: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_402, [2, 16, 8]);  mm_402 = None
        slice_13275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1607, 1, 3216, 3232)
        slice_13276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13275, 2, 0, 16);  slice_13275 = None
        add_404: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13276, view_815);  slice_13276 = view_815 = None
        
        # No stacktrace found for following nodes
        slice_tensor_804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1607, 1, 3216, 3232)
        slice_scatter_default_1608: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_804, add_404, 2, 0, 16);  slice_tensor_804 = add_404 = None
        slice_scatter_default_1609: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1607, slice_scatter_default_1608, 1, 3216, 3232);  slice_scatter_default_1607 = slice_scatter_default_1608 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1609, 1, 3216, 3232)
        slice_13281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13280, 2, 0, 16);  slice_13280 = None
        
        # No stacktrace found for following nodes
        slice_tensor_805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1609, 1, 3216, 3232)
        slice_scatter_default_1610: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_805, slice_13281, 2, 0, 16);  slice_tensor_805 = slice_13281 = None
        slice_scatter_default_1611: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1609, slice_scatter_default_1610, 1, 3216, 3232);  slice_scatter_default_1609 = slice_scatter_default_1610 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13301: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13267, 2, 16, 32);  slice_13267 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_406: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13301, memory_format = torch.contiguous_format);  slice_13301 = None
        view_816: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_406, [32, 11]);  clone_406 = None
        mm_403: "f32[32, 8]" = torch.ops.aten.mm.default(view_816, slice_37)
        view_817: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_403, [2, 16, 8]);  mm_403 = None
        slice_13308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1611, 1, 3216, 3232)
        slice_13309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13308, 2, 0, 16);  slice_13308 = None
        add_405: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13309, view_817);  slice_13309 = view_817 = None
        
        # No stacktrace found for following nodes
        slice_tensor_806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1611, 1, 3216, 3232)
        slice_scatter_default_1612: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_806, add_405, 2, 0, 16);  slice_tensor_806 = add_405 = None
        slice_scatter_default_1613: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1611, slice_scatter_default_1612, 1, 3216, 3232);  slice_scatter_default_1611 = slice_scatter_default_1612 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1613, 1, 3216, 3232)
        slice_13314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13313, 2, 0, 16);  slice_13313 = None
        
        # No stacktrace found for following nodes
        slice_tensor_807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1613, 1, 3216, 3232)
        slice_scatter_default_1614: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_807, slice_13314, 2, 0, 16);  slice_tensor_807 = slice_13314 = None
        slice_scatter_default_1615: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1613, slice_scatter_default_1614, 1, 3216, 3232);  slice_scatter_default_1613 = slice_scatter_default_1614 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13333: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3232, 3248)
        slice_13334: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13333, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_407: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13334, memory_format = torch.contiguous_format);  slice_13334 = None
        view_818: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_407, [32, 16]);  clone_407 = None
        mm_404: "f32[32, 8]" = torch.ops.aten.mm.default(view_818, slice_7)
        view_819: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_404, [2, 16, 8]);  mm_404 = None
        slice_13341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1615, 1, 3232, 3248)
        slice_13342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13341, 2, 0, 16);  slice_13341 = None
        add_406: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13342, view_819);  slice_13342 = view_819 = None
        
        # No stacktrace found for following nodes
        slice_tensor_808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1615, 1, 3232, 3248)
        slice_scatter_default_1616: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_808, add_406, 2, 0, 16);  slice_tensor_808 = add_406 = None
        slice_scatter_default_1617: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1615, slice_scatter_default_1616, 1, 3232, 3248);  slice_scatter_default_1615 = slice_scatter_default_1616 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1617, 1, 3232, 3248)
        slice_13347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13346, 2, 0, 16);  slice_13346 = None
        
        # No stacktrace found for following nodes
        slice_tensor_809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1617, 1, 3232, 3248)
        slice_scatter_default_1618: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_809, slice_13347, 2, 0, 16);  slice_tensor_809 = slice_13347 = None
        slice_scatter_default_1619: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1617, slice_scatter_default_1618, 1, 3232, 3248);  slice_scatter_default_1617 = slice_scatter_default_1618 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13367: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13333, 2, 16, 32);  slice_13333 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_408: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13367, memory_format = torch.contiguous_format);  slice_13367 = None
        view_820: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_408, [32, 11]);  clone_408 = None
        mm_405: "f32[32, 8]" = torch.ops.aten.mm.default(view_820, slice_37)
        view_821: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_405, [2, 16, 8]);  mm_405 = None
        slice_13374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1619, 1, 3232, 3248)
        slice_13375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13374, 2, 0, 16);  slice_13374 = None
        add_407: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13375, view_821);  slice_13375 = view_821 = None
        
        # No stacktrace found for following nodes
        slice_tensor_810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1619, 1, 3232, 3248)
        slice_scatter_default_1620: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_810, add_407, 2, 0, 16);  slice_tensor_810 = add_407 = None
        slice_scatter_default_1621: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1619, slice_scatter_default_1620, 1, 3232, 3248);  slice_scatter_default_1619 = slice_scatter_default_1620 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1621, 1, 3232, 3248)
        slice_13380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13379, 2, 0, 16);  slice_13379 = None
        
        # No stacktrace found for following nodes
        slice_tensor_811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1621, 1, 3232, 3248)
        slice_scatter_default_1622: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_811, slice_13380, 2, 0, 16);  slice_tensor_811 = slice_13380 = None
        slice_scatter_default_1623: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1621, slice_scatter_default_1622, 1, 3232, 3248);  slice_scatter_default_1621 = slice_scatter_default_1622 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13399: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3248, 3264)
        slice_13400: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13399, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_409: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13400, memory_format = torch.contiguous_format);  slice_13400 = None
        view_822: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_409, [32, 16]);  clone_409 = None
        mm_406: "f32[32, 8]" = torch.ops.aten.mm.default(view_822, slice_7)
        view_823: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_406, [2, 16, 8]);  mm_406 = None
        slice_13407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1623, 1, 3248, 3264)
        slice_13408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13407, 2, 0, 16);  slice_13407 = None
        add_408: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13408, view_823);  slice_13408 = view_823 = None
        
        # No stacktrace found for following nodes
        slice_tensor_812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1623, 1, 3248, 3264)
        slice_scatter_default_1624: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_812, add_408, 2, 0, 16);  slice_tensor_812 = add_408 = None
        slice_scatter_default_1625: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1623, slice_scatter_default_1624, 1, 3248, 3264);  slice_scatter_default_1623 = slice_scatter_default_1624 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1625, 1, 3248, 3264)
        slice_13413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13412, 2, 0, 16);  slice_13412 = None
        
        # No stacktrace found for following nodes
        slice_tensor_813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1625, 1, 3248, 3264)
        slice_scatter_default_1626: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_813, slice_13413, 2, 0, 16);  slice_tensor_813 = slice_13413 = None
        slice_scatter_default_1627: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1625, slice_scatter_default_1626, 1, 3248, 3264);  slice_scatter_default_1625 = slice_scatter_default_1626 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13433: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13399, 2, 16, 32);  slice_13399 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_410: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13433, memory_format = torch.contiguous_format);  slice_13433 = None
        view_824: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_410, [32, 11]);  clone_410 = None
        mm_407: "f32[32, 8]" = torch.ops.aten.mm.default(view_824, slice_37)
        view_825: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_407, [2, 16, 8]);  mm_407 = None
        slice_13440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1627, 1, 3248, 3264)
        slice_13441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13440, 2, 0, 16);  slice_13440 = None
        add_409: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13441, view_825);  slice_13441 = view_825 = None
        
        # No stacktrace found for following nodes
        slice_tensor_814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1627, 1, 3248, 3264)
        slice_scatter_default_1628: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_814, add_409, 2, 0, 16);  slice_tensor_814 = add_409 = None
        slice_scatter_default_1629: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1627, slice_scatter_default_1628, 1, 3248, 3264);  slice_scatter_default_1627 = slice_scatter_default_1628 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1629, 1, 3248, 3264)
        slice_13446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13445, 2, 0, 16);  slice_13445 = None
        
        # No stacktrace found for following nodes
        slice_tensor_815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1629, 1, 3248, 3264)
        slice_scatter_default_1630: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_815, slice_13446, 2, 0, 16);  slice_tensor_815 = slice_13446 = None
        slice_scatter_default_1631: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1629, slice_scatter_default_1630, 1, 3248, 3264);  slice_scatter_default_1629 = slice_scatter_default_1630 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13465: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3264, 3280)
        slice_13466: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13465, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_411: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13466, memory_format = torch.contiguous_format);  slice_13466 = None
        view_826: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_411, [32, 16]);  clone_411 = None
        mm_408: "f32[32, 8]" = torch.ops.aten.mm.default(view_826, slice_7)
        view_827: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_408, [2, 16, 8]);  mm_408 = None
        slice_13473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1631, 1, 3264, 3280)
        slice_13474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13473, 2, 0, 16);  slice_13473 = None
        add_410: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13474, view_827);  slice_13474 = view_827 = None
        
        # No stacktrace found for following nodes
        slice_tensor_816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1631, 1, 3264, 3280)
        slice_scatter_default_1632: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_816, add_410, 2, 0, 16);  slice_tensor_816 = add_410 = None
        slice_scatter_default_1633: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1631, slice_scatter_default_1632, 1, 3264, 3280);  slice_scatter_default_1631 = slice_scatter_default_1632 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1633, 1, 3264, 3280)
        slice_13479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13478, 2, 0, 16);  slice_13478 = None
        
        # No stacktrace found for following nodes
        slice_tensor_817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1633, 1, 3264, 3280)
        slice_scatter_default_1634: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_817, slice_13479, 2, 0, 16);  slice_tensor_817 = slice_13479 = None
        slice_scatter_default_1635: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1633, slice_scatter_default_1634, 1, 3264, 3280);  slice_scatter_default_1633 = slice_scatter_default_1634 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13499: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13465, 2, 16, 32);  slice_13465 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_412: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13499, memory_format = torch.contiguous_format);  slice_13499 = None
        view_828: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_412, [32, 11]);  clone_412 = None
        mm_409: "f32[32, 8]" = torch.ops.aten.mm.default(view_828, slice_37)
        view_829: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_409, [2, 16, 8]);  mm_409 = None
        slice_13506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1635, 1, 3264, 3280)
        slice_13507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13506, 2, 0, 16);  slice_13506 = None
        add_411: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13507, view_829);  slice_13507 = view_829 = None
        
        # No stacktrace found for following nodes
        slice_tensor_818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1635, 1, 3264, 3280)
        slice_scatter_default_1636: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_818, add_411, 2, 0, 16);  slice_tensor_818 = add_411 = None
        slice_scatter_default_1637: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1635, slice_scatter_default_1636, 1, 3264, 3280);  slice_scatter_default_1635 = slice_scatter_default_1636 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1637, 1, 3264, 3280)
        slice_13512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13511, 2, 0, 16);  slice_13511 = None
        
        # No stacktrace found for following nodes
        slice_tensor_819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1637, 1, 3264, 3280)
        slice_scatter_default_1638: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_819, slice_13512, 2, 0, 16);  slice_tensor_819 = slice_13512 = None
        slice_scatter_default_1639: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1637, slice_scatter_default_1638, 1, 3264, 3280);  slice_scatter_default_1637 = slice_scatter_default_1638 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13531: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3280, 3296)
        slice_13532: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13531, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_413: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13532, memory_format = torch.contiguous_format);  slice_13532 = None
        view_830: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_413, [32, 16]);  clone_413 = None
        mm_410: "f32[32, 8]" = torch.ops.aten.mm.default(view_830, slice_7)
        view_831: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_410, [2, 16, 8]);  mm_410 = None
        slice_13539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1639, 1, 3280, 3296)
        slice_13540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13539, 2, 0, 16);  slice_13539 = None
        add_412: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13540, view_831);  slice_13540 = view_831 = None
        
        # No stacktrace found for following nodes
        slice_tensor_820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1639, 1, 3280, 3296)
        slice_scatter_default_1640: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_820, add_412, 2, 0, 16);  slice_tensor_820 = add_412 = None
        slice_scatter_default_1641: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1639, slice_scatter_default_1640, 1, 3280, 3296);  slice_scatter_default_1639 = slice_scatter_default_1640 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1641, 1, 3280, 3296)
        slice_13545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13544, 2, 0, 16);  slice_13544 = None
        
        # No stacktrace found for following nodes
        slice_tensor_821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1641, 1, 3280, 3296)
        slice_scatter_default_1642: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_821, slice_13545, 2, 0, 16);  slice_tensor_821 = slice_13545 = None
        slice_scatter_default_1643: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1641, slice_scatter_default_1642, 1, 3280, 3296);  slice_scatter_default_1641 = slice_scatter_default_1642 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13565: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13531, 2, 16, 32);  slice_13531 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_414: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13565, memory_format = torch.contiguous_format);  slice_13565 = None
        view_832: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_414, [32, 11]);  clone_414 = None
        mm_411: "f32[32, 8]" = torch.ops.aten.mm.default(view_832, slice_37)
        view_833: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_411, [2, 16, 8]);  mm_411 = None
        slice_13572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1643, 1, 3280, 3296)
        slice_13573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13572, 2, 0, 16);  slice_13572 = None
        add_413: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13573, view_833);  slice_13573 = view_833 = None
        
        # No stacktrace found for following nodes
        slice_tensor_822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1643, 1, 3280, 3296)
        slice_scatter_default_1644: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_822, add_413, 2, 0, 16);  slice_tensor_822 = add_413 = None
        slice_scatter_default_1645: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1643, slice_scatter_default_1644, 1, 3280, 3296);  slice_scatter_default_1643 = slice_scatter_default_1644 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1645, 1, 3280, 3296)
        slice_13578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13577, 2, 0, 16);  slice_13577 = None
        
        # No stacktrace found for following nodes
        slice_tensor_823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1645, 1, 3280, 3296)
        slice_scatter_default_1646: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_823, slice_13578, 2, 0, 16);  slice_tensor_823 = slice_13578 = None
        slice_scatter_default_1647: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1645, slice_scatter_default_1646, 1, 3280, 3296);  slice_scatter_default_1645 = slice_scatter_default_1646 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13597: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3296, 3312)
        slice_13598: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13597, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_415: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13598, memory_format = torch.contiguous_format);  slice_13598 = None
        view_834: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_415, [32, 16]);  clone_415 = None
        mm_412: "f32[32, 8]" = torch.ops.aten.mm.default(view_834, slice_7)
        view_835: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_412, [2, 16, 8]);  mm_412 = None
        slice_13605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1647, 1, 3296, 3312)
        slice_13606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13605, 2, 0, 16);  slice_13605 = None
        add_414: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13606, view_835);  slice_13606 = view_835 = None
        
        # No stacktrace found for following nodes
        slice_tensor_824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1647, 1, 3296, 3312)
        slice_scatter_default_1648: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_824, add_414, 2, 0, 16);  slice_tensor_824 = add_414 = None
        slice_scatter_default_1649: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1647, slice_scatter_default_1648, 1, 3296, 3312);  slice_scatter_default_1647 = slice_scatter_default_1648 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1649, 1, 3296, 3312)
        slice_13611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13610, 2, 0, 16);  slice_13610 = None
        
        # No stacktrace found for following nodes
        slice_tensor_825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1649, 1, 3296, 3312)
        slice_scatter_default_1650: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_825, slice_13611, 2, 0, 16);  slice_tensor_825 = slice_13611 = None
        slice_scatter_default_1651: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1649, slice_scatter_default_1650, 1, 3296, 3312);  slice_scatter_default_1649 = slice_scatter_default_1650 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13631: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13597, 2, 16, 32);  slice_13597 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_416: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13631, memory_format = torch.contiguous_format);  slice_13631 = None
        view_836: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_416, [32, 11]);  clone_416 = None
        mm_413: "f32[32, 8]" = torch.ops.aten.mm.default(view_836, slice_37)
        view_837: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_413, [2, 16, 8]);  mm_413 = None
        slice_13638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1651, 1, 3296, 3312)
        slice_13639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13638, 2, 0, 16);  slice_13638 = None
        add_415: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13639, view_837);  slice_13639 = view_837 = None
        
        # No stacktrace found for following nodes
        slice_tensor_826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1651, 1, 3296, 3312)
        slice_scatter_default_1652: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_826, add_415, 2, 0, 16);  slice_tensor_826 = add_415 = None
        slice_scatter_default_1653: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1651, slice_scatter_default_1652, 1, 3296, 3312);  slice_scatter_default_1651 = slice_scatter_default_1652 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1653, 1, 3296, 3312)
        slice_13644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13643, 2, 0, 16);  slice_13643 = None
        
        # No stacktrace found for following nodes
        slice_tensor_827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1653, 1, 3296, 3312)
        slice_scatter_default_1654: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_827, slice_13644, 2, 0, 16);  slice_tensor_827 = slice_13644 = None
        slice_scatter_default_1655: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1653, slice_scatter_default_1654, 1, 3296, 3312);  slice_scatter_default_1653 = slice_scatter_default_1654 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13663: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3312, 3328)
        slice_13664: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13663, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_417: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13664, memory_format = torch.contiguous_format);  slice_13664 = None
        view_838: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_417, [32, 16]);  clone_417 = None
        mm_414: "f32[32, 8]" = torch.ops.aten.mm.default(view_838, slice_7)
        view_839: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_414, [2, 16, 8]);  mm_414 = None
        slice_13671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1655, 1, 3312, 3328)
        slice_13672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13671, 2, 0, 16);  slice_13671 = None
        add_416: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13672, view_839);  slice_13672 = view_839 = None
        
        # No stacktrace found for following nodes
        slice_tensor_828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1655, 1, 3312, 3328)
        slice_scatter_default_1656: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_828, add_416, 2, 0, 16);  slice_tensor_828 = add_416 = None
        slice_scatter_default_1657: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1655, slice_scatter_default_1656, 1, 3312, 3328);  slice_scatter_default_1655 = slice_scatter_default_1656 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1657, 1, 3312, 3328)
        slice_13677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13676, 2, 0, 16);  slice_13676 = None
        
        # No stacktrace found for following nodes
        slice_tensor_829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1657, 1, 3312, 3328)
        slice_scatter_default_1658: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_829, slice_13677, 2, 0, 16);  slice_tensor_829 = slice_13677 = None
        slice_scatter_default_1659: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1657, slice_scatter_default_1658, 1, 3312, 3328);  slice_scatter_default_1657 = slice_scatter_default_1658 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13697: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13663, 2, 16, 32);  slice_13663 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_418: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13697, memory_format = torch.contiguous_format);  slice_13697 = None
        view_840: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_418, [32, 11]);  clone_418 = None
        mm_415: "f32[32, 8]" = torch.ops.aten.mm.default(view_840, slice_37)
        view_841: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_415, [2, 16, 8]);  mm_415 = None
        slice_13704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1659, 1, 3312, 3328)
        slice_13705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13704, 2, 0, 16);  slice_13704 = None
        add_417: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13705, view_841);  slice_13705 = view_841 = None
        
        # No stacktrace found for following nodes
        slice_tensor_830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1659, 1, 3312, 3328)
        slice_scatter_default_1660: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_830, add_417, 2, 0, 16);  slice_tensor_830 = add_417 = None
        slice_scatter_default_1661: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1659, slice_scatter_default_1660, 1, 3312, 3328);  slice_scatter_default_1659 = slice_scatter_default_1660 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1661, 1, 3312, 3328)
        slice_13710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13709, 2, 0, 16);  slice_13709 = None
        
        # No stacktrace found for following nodes
        slice_tensor_831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1661, 1, 3312, 3328)
        slice_scatter_default_1662: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_831, slice_13710, 2, 0, 16);  slice_tensor_831 = slice_13710 = None
        slice_scatter_default_1663: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1661, slice_scatter_default_1662, 1, 3312, 3328);  slice_scatter_default_1661 = slice_scatter_default_1662 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13729: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3328, 3344)
        slice_13730: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13729, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_419: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13730, memory_format = torch.contiguous_format);  slice_13730 = None
        view_842: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_419, [32, 16]);  clone_419 = None
        mm_416: "f32[32, 8]" = torch.ops.aten.mm.default(view_842, slice_7)
        view_843: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_416, [2, 16, 8]);  mm_416 = None
        slice_13737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1663, 1, 3328, 3344)
        slice_13738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13737, 2, 0, 16);  slice_13737 = None
        add_418: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13738, view_843);  slice_13738 = view_843 = None
        
        # No stacktrace found for following nodes
        slice_tensor_832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1663, 1, 3328, 3344)
        slice_scatter_default_1664: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_832, add_418, 2, 0, 16);  slice_tensor_832 = add_418 = None
        slice_scatter_default_1665: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1663, slice_scatter_default_1664, 1, 3328, 3344);  slice_scatter_default_1663 = slice_scatter_default_1664 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1665, 1, 3328, 3344)
        slice_13743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13742, 2, 0, 16);  slice_13742 = None
        
        # No stacktrace found for following nodes
        slice_tensor_833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1665, 1, 3328, 3344)
        slice_scatter_default_1666: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_833, slice_13743, 2, 0, 16);  slice_tensor_833 = slice_13743 = None
        slice_scatter_default_1667: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1665, slice_scatter_default_1666, 1, 3328, 3344);  slice_scatter_default_1665 = slice_scatter_default_1666 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13763: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13729, 2, 16, 32);  slice_13729 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_420: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13763, memory_format = torch.contiguous_format);  slice_13763 = None
        view_844: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_420, [32, 11]);  clone_420 = None
        mm_417: "f32[32, 8]" = torch.ops.aten.mm.default(view_844, slice_37)
        view_845: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_417, [2, 16, 8]);  mm_417 = None
        slice_13770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1667, 1, 3328, 3344)
        slice_13771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13770, 2, 0, 16);  slice_13770 = None
        add_419: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13771, view_845);  slice_13771 = view_845 = None
        
        # No stacktrace found for following nodes
        slice_tensor_834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1667, 1, 3328, 3344)
        slice_scatter_default_1668: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_834, add_419, 2, 0, 16);  slice_tensor_834 = add_419 = None
        slice_scatter_default_1669: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1667, slice_scatter_default_1668, 1, 3328, 3344);  slice_scatter_default_1667 = slice_scatter_default_1668 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1669, 1, 3328, 3344)
        slice_13776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13775, 2, 0, 16);  slice_13775 = None
        
        # No stacktrace found for following nodes
        slice_tensor_835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1669, 1, 3328, 3344)
        slice_scatter_default_1670: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_835, slice_13776, 2, 0, 16);  slice_tensor_835 = slice_13776 = None
        slice_scatter_default_1671: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1669, slice_scatter_default_1670, 1, 3328, 3344);  slice_scatter_default_1669 = slice_scatter_default_1670 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13795: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3344, 3360)
        slice_13796: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13795, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_421: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13796, memory_format = torch.contiguous_format);  slice_13796 = None
        view_846: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_421, [32, 16]);  clone_421 = None
        mm_418: "f32[32, 8]" = torch.ops.aten.mm.default(view_846, slice_7)
        view_847: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_418, [2, 16, 8]);  mm_418 = None
        slice_13803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1671, 1, 3344, 3360)
        slice_13804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13803, 2, 0, 16);  slice_13803 = None
        add_420: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13804, view_847);  slice_13804 = view_847 = None
        
        # No stacktrace found for following nodes
        slice_tensor_836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1671, 1, 3344, 3360)
        slice_scatter_default_1672: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_836, add_420, 2, 0, 16);  slice_tensor_836 = add_420 = None
        slice_scatter_default_1673: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1671, slice_scatter_default_1672, 1, 3344, 3360);  slice_scatter_default_1671 = slice_scatter_default_1672 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1673, 1, 3344, 3360)
        slice_13809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13808, 2, 0, 16);  slice_13808 = None
        
        # No stacktrace found for following nodes
        slice_tensor_837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1673, 1, 3344, 3360)
        slice_scatter_default_1674: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_837, slice_13809, 2, 0, 16);  slice_tensor_837 = slice_13809 = None
        slice_scatter_default_1675: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1673, slice_scatter_default_1674, 1, 3344, 3360);  slice_scatter_default_1673 = slice_scatter_default_1674 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13829: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13795, 2, 16, 32);  slice_13795 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_422: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13829, memory_format = torch.contiguous_format);  slice_13829 = None
        view_848: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_422, [32, 11]);  clone_422 = None
        mm_419: "f32[32, 8]" = torch.ops.aten.mm.default(view_848, slice_37)
        view_849: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_419, [2, 16, 8]);  mm_419 = None
        slice_13836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1675, 1, 3344, 3360)
        slice_13837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13836, 2, 0, 16);  slice_13836 = None
        add_421: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13837, view_849);  slice_13837 = view_849 = None
        
        # No stacktrace found for following nodes
        slice_tensor_838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1675, 1, 3344, 3360)
        slice_scatter_default_1676: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_838, add_421, 2, 0, 16);  slice_tensor_838 = add_421 = None
        slice_scatter_default_1677: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1675, slice_scatter_default_1676, 1, 3344, 3360);  slice_scatter_default_1675 = slice_scatter_default_1676 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1677, 1, 3344, 3360)
        slice_13842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13841, 2, 0, 16);  slice_13841 = None
        
        # No stacktrace found for following nodes
        slice_tensor_839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1677, 1, 3344, 3360)
        slice_scatter_default_1678: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_839, slice_13842, 2, 0, 16);  slice_tensor_839 = slice_13842 = None
        slice_scatter_default_1679: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1677, slice_scatter_default_1678, 1, 3344, 3360);  slice_scatter_default_1677 = slice_scatter_default_1678 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13861: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3360, 3376)
        slice_13862: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13861, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_423: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13862, memory_format = torch.contiguous_format);  slice_13862 = None
        view_850: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_423, [32, 16]);  clone_423 = None
        mm_420: "f32[32, 8]" = torch.ops.aten.mm.default(view_850, slice_7)
        view_851: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_420, [2, 16, 8]);  mm_420 = None
        slice_13869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1679, 1, 3360, 3376)
        slice_13870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13869, 2, 0, 16);  slice_13869 = None
        add_422: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13870, view_851);  slice_13870 = view_851 = None
        
        # No stacktrace found for following nodes
        slice_tensor_840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1679, 1, 3360, 3376)
        slice_scatter_default_1680: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_840, add_422, 2, 0, 16);  slice_tensor_840 = add_422 = None
        slice_scatter_default_1681: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1679, slice_scatter_default_1680, 1, 3360, 3376);  slice_scatter_default_1679 = slice_scatter_default_1680 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1681, 1, 3360, 3376)
        slice_13875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13874, 2, 0, 16);  slice_13874 = None
        
        # No stacktrace found for following nodes
        slice_tensor_841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1681, 1, 3360, 3376)
        slice_scatter_default_1682: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_841, slice_13875, 2, 0, 16);  slice_tensor_841 = slice_13875 = None
        slice_scatter_default_1683: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1681, slice_scatter_default_1682, 1, 3360, 3376);  slice_scatter_default_1681 = slice_scatter_default_1682 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13895: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13861, 2, 16, 32);  slice_13861 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_424: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13895, memory_format = torch.contiguous_format);  slice_13895 = None
        view_852: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_424, [32, 11]);  clone_424 = None
        mm_421: "f32[32, 8]" = torch.ops.aten.mm.default(view_852, slice_37)
        view_853: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_421, [2, 16, 8]);  mm_421 = None
        slice_13902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1683, 1, 3360, 3376)
        slice_13903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13902, 2, 0, 16);  slice_13902 = None
        add_423: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13903, view_853);  slice_13903 = view_853 = None
        
        # No stacktrace found for following nodes
        slice_tensor_842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1683, 1, 3360, 3376)
        slice_scatter_default_1684: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_842, add_423, 2, 0, 16);  slice_tensor_842 = add_423 = None
        slice_scatter_default_1685: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1683, slice_scatter_default_1684, 1, 3360, 3376);  slice_scatter_default_1683 = slice_scatter_default_1684 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1685, 1, 3360, 3376)
        slice_13908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13907, 2, 0, 16);  slice_13907 = None
        
        # No stacktrace found for following nodes
        slice_tensor_843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1685, 1, 3360, 3376)
        slice_scatter_default_1686: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_843, slice_13908, 2, 0, 16);  slice_tensor_843 = slice_13908 = None
        slice_scatter_default_1687: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1685, slice_scatter_default_1686, 1, 3360, 3376);  slice_scatter_default_1685 = slice_scatter_default_1686 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13927: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3376, 3392)
        slice_13928: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13927, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_425: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13928, memory_format = torch.contiguous_format);  slice_13928 = None
        view_854: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_425, [32, 16]);  clone_425 = None
        mm_422: "f32[32, 8]" = torch.ops.aten.mm.default(view_854, slice_7)
        view_855: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_422, [2, 16, 8]);  mm_422 = None
        slice_13935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1687, 1, 3376, 3392)
        slice_13936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13935, 2, 0, 16);  slice_13935 = None
        add_424: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13936, view_855);  slice_13936 = view_855 = None
        
        # No stacktrace found for following nodes
        slice_tensor_844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1687, 1, 3376, 3392)
        slice_scatter_default_1688: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_844, add_424, 2, 0, 16);  slice_tensor_844 = add_424 = None
        slice_scatter_default_1689: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1687, slice_scatter_default_1688, 1, 3376, 3392);  slice_scatter_default_1687 = slice_scatter_default_1688 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1689, 1, 3376, 3392)
        slice_13941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13940, 2, 0, 16);  slice_13940 = None
        
        # No stacktrace found for following nodes
        slice_tensor_845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1689, 1, 3376, 3392)
        slice_scatter_default_1690: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_845, slice_13941, 2, 0, 16);  slice_tensor_845 = slice_13941 = None
        slice_scatter_default_1691: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1689, slice_scatter_default_1690, 1, 3376, 3392);  slice_scatter_default_1689 = slice_scatter_default_1690 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13961: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13927, 2, 16, 32);  slice_13927 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_426: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_13961, memory_format = torch.contiguous_format);  slice_13961 = None
        view_856: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_426, [32, 11]);  clone_426 = None
        mm_423: "f32[32, 8]" = torch.ops.aten.mm.default(view_856, slice_37)
        view_857: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_423, [2, 16, 8]);  mm_423 = None
        slice_13968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1691, 1, 3376, 3392)
        slice_13969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13968, 2, 0, 16);  slice_13968 = None
        add_425: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_13969, view_857);  slice_13969 = view_857 = None
        
        # No stacktrace found for following nodes
        slice_tensor_846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1691, 1, 3376, 3392)
        slice_scatter_default_1692: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_846, add_425, 2, 0, 16);  slice_tensor_846 = add_425 = None
        slice_scatter_default_1693: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1691, slice_scatter_default_1692, 1, 3376, 3392);  slice_scatter_default_1691 = slice_scatter_default_1692 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_13973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1693, 1, 3376, 3392)
        slice_13974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_13973, 2, 0, 16);  slice_13973 = None
        
        # No stacktrace found for following nodes
        slice_tensor_847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1693, 1, 3376, 3392)
        slice_scatter_default_1694: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_847, slice_13974, 2, 0, 16);  slice_tensor_847 = slice_13974 = None
        slice_scatter_default_1695: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1693, slice_scatter_default_1694, 1, 3376, 3392);  slice_scatter_default_1693 = slice_scatter_default_1694 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_13993: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3392, 3408)
        slice_13994: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_13993, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_427: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_13994, memory_format = torch.contiguous_format);  slice_13994 = None
        view_858: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_427, [32, 16]);  clone_427 = None
        mm_424: "f32[32, 8]" = torch.ops.aten.mm.default(view_858, slice_7)
        view_859: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_424, [2, 16, 8]);  mm_424 = None
        slice_14001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1695, 1, 3392, 3408)
        slice_14002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14001, 2, 0, 16);  slice_14001 = None
        add_426: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14002, view_859);  slice_14002 = view_859 = None
        
        # No stacktrace found for following nodes
        slice_tensor_848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1695, 1, 3392, 3408)
        slice_scatter_default_1696: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_848, add_426, 2, 0, 16);  slice_tensor_848 = add_426 = None
        slice_scatter_default_1697: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1695, slice_scatter_default_1696, 1, 3392, 3408);  slice_scatter_default_1695 = slice_scatter_default_1696 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1697, 1, 3392, 3408)
        slice_14007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14006, 2, 0, 16);  slice_14006 = None
        
        # No stacktrace found for following nodes
        slice_tensor_849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1697, 1, 3392, 3408)
        slice_scatter_default_1698: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_849, slice_14007, 2, 0, 16);  slice_tensor_849 = slice_14007 = None
        slice_scatter_default_1699: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1697, slice_scatter_default_1698, 1, 3392, 3408);  slice_scatter_default_1697 = slice_scatter_default_1698 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14027: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_13993, 2, 16, 32);  slice_13993 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_428: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14027, memory_format = torch.contiguous_format);  slice_14027 = None
        view_860: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_428, [32, 11]);  clone_428 = None
        mm_425: "f32[32, 8]" = torch.ops.aten.mm.default(view_860, slice_37)
        view_861: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_425, [2, 16, 8]);  mm_425 = None
        slice_14034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1699, 1, 3392, 3408)
        slice_14035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14034, 2, 0, 16);  slice_14034 = None
        add_427: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14035, view_861);  slice_14035 = view_861 = None
        
        # No stacktrace found for following nodes
        slice_tensor_850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1699, 1, 3392, 3408)
        slice_scatter_default_1700: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_850, add_427, 2, 0, 16);  slice_tensor_850 = add_427 = None
        slice_scatter_default_1701: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1699, slice_scatter_default_1700, 1, 3392, 3408);  slice_scatter_default_1699 = slice_scatter_default_1700 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1701, 1, 3392, 3408)
        slice_14040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14039, 2, 0, 16);  slice_14039 = None
        
        # No stacktrace found for following nodes
        slice_tensor_851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1701, 1, 3392, 3408)
        slice_scatter_default_1702: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_851, slice_14040, 2, 0, 16);  slice_tensor_851 = slice_14040 = None
        slice_scatter_default_1703: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1701, slice_scatter_default_1702, 1, 3392, 3408);  slice_scatter_default_1701 = slice_scatter_default_1702 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14059: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3408, 3424)
        slice_14060: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14059, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_429: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14060, memory_format = torch.contiguous_format);  slice_14060 = None
        view_862: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_429, [32, 16]);  clone_429 = None
        mm_426: "f32[32, 8]" = torch.ops.aten.mm.default(view_862, slice_7)
        view_863: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_426, [2, 16, 8]);  mm_426 = None
        slice_14067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1703, 1, 3408, 3424)
        slice_14068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14067, 2, 0, 16);  slice_14067 = None
        add_428: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14068, view_863);  slice_14068 = view_863 = None
        
        # No stacktrace found for following nodes
        slice_tensor_852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1703, 1, 3408, 3424)
        slice_scatter_default_1704: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_852, add_428, 2, 0, 16);  slice_tensor_852 = add_428 = None
        slice_scatter_default_1705: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1703, slice_scatter_default_1704, 1, 3408, 3424);  slice_scatter_default_1703 = slice_scatter_default_1704 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1705, 1, 3408, 3424)
        slice_14073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14072, 2, 0, 16);  slice_14072 = None
        
        # No stacktrace found for following nodes
        slice_tensor_853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1705, 1, 3408, 3424)
        slice_scatter_default_1706: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_853, slice_14073, 2, 0, 16);  slice_tensor_853 = slice_14073 = None
        slice_scatter_default_1707: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1705, slice_scatter_default_1706, 1, 3408, 3424);  slice_scatter_default_1705 = slice_scatter_default_1706 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14093: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14059, 2, 16, 32);  slice_14059 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_430: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14093, memory_format = torch.contiguous_format);  slice_14093 = None
        view_864: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_430, [32, 11]);  clone_430 = None
        mm_427: "f32[32, 8]" = torch.ops.aten.mm.default(view_864, slice_37)
        view_865: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_427, [2, 16, 8]);  mm_427 = None
        slice_14100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1707, 1, 3408, 3424)
        slice_14101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14100, 2, 0, 16);  slice_14100 = None
        add_429: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14101, view_865);  slice_14101 = view_865 = None
        
        # No stacktrace found for following nodes
        slice_tensor_854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1707, 1, 3408, 3424)
        slice_scatter_default_1708: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_854, add_429, 2, 0, 16);  slice_tensor_854 = add_429 = None
        slice_scatter_default_1709: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1707, slice_scatter_default_1708, 1, 3408, 3424);  slice_scatter_default_1707 = slice_scatter_default_1708 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1709, 1, 3408, 3424)
        slice_14106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14105, 2, 0, 16);  slice_14105 = None
        
        # No stacktrace found for following nodes
        slice_tensor_855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1709, 1, 3408, 3424)
        slice_scatter_default_1710: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_855, slice_14106, 2, 0, 16);  slice_tensor_855 = slice_14106 = None
        slice_scatter_default_1711: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1709, slice_scatter_default_1710, 1, 3408, 3424);  slice_scatter_default_1709 = slice_scatter_default_1710 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14125: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3424, 3440)
        slice_14126: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14125, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_431: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14126, memory_format = torch.contiguous_format);  slice_14126 = None
        view_866: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_431, [32, 16]);  clone_431 = None
        mm_428: "f32[32, 8]" = torch.ops.aten.mm.default(view_866, slice_7)
        view_867: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_428, [2, 16, 8]);  mm_428 = None
        slice_14133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1711, 1, 3424, 3440)
        slice_14134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14133, 2, 0, 16);  slice_14133 = None
        add_430: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14134, view_867);  slice_14134 = view_867 = None
        
        # No stacktrace found for following nodes
        slice_tensor_856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1711, 1, 3424, 3440)
        slice_scatter_default_1712: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_856, add_430, 2, 0, 16);  slice_tensor_856 = add_430 = None
        slice_scatter_default_1713: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1711, slice_scatter_default_1712, 1, 3424, 3440);  slice_scatter_default_1711 = slice_scatter_default_1712 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1713, 1, 3424, 3440)
        slice_14139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14138, 2, 0, 16);  slice_14138 = None
        
        # No stacktrace found for following nodes
        slice_tensor_857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1713, 1, 3424, 3440)
        slice_scatter_default_1714: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_857, slice_14139, 2, 0, 16);  slice_tensor_857 = slice_14139 = None
        slice_scatter_default_1715: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1713, slice_scatter_default_1714, 1, 3424, 3440);  slice_scatter_default_1713 = slice_scatter_default_1714 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14159: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14125, 2, 16, 32);  slice_14125 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_432: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14159, memory_format = torch.contiguous_format);  slice_14159 = None
        view_868: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_432, [32, 11]);  clone_432 = None
        mm_429: "f32[32, 8]" = torch.ops.aten.mm.default(view_868, slice_37)
        view_869: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_429, [2, 16, 8]);  mm_429 = None
        slice_14166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1715, 1, 3424, 3440)
        slice_14167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14166, 2, 0, 16);  slice_14166 = None
        add_431: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14167, view_869);  slice_14167 = view_869 = None
        
        # No stacktrace found for following nodes
        slice_tensor_858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1715, 1, 3424, 3440)
        slice_scatter_default_1716: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_858, add_431, 2, 0, 16);  slice_tensor_858 = add_431 = None
        slice_scatter_default_1717: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1715, slice_scatter_default_1716, 1, 3424, 3440);  slice_scatter_default_1715 = slice_scatter_default_1716 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1717, 1, 3424, 3440)
        slice_14172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14171, 2, 0, 16);  slice_14171 = None
        
        # No stacktrace found for following nodes
        slice_tensor_859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1717, 1, 3424, 3440)
        slice_scatter_default_1718: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_859, slice_14172, 2, 0, 16);  slice_tensor_859 = slice_14172 = None
        slice_scatter_default_1719: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1717, slice_scatter_default_1718, 1, 3424, 3440);  slice_scatter_default_1717 = slice_scatter_default_1718 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14191: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3440, 3456)
        slice_14192: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14191, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_433: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14192, memory_format = torch.contiguous_format);  slice_14192 = None
        view_870: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_433, [32, 16]);  clone_433 = None
        mm_430: "f32[32, 8]" = torch.ops.aten.mm.default(view_870, slice_7)
        view_871: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_430, [2, 16, 8]);  mm_430 = None
        slice_14199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1719, 1, 3440, 3456)
        slice_14200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14199, 2, 0, 16);  slice_14199 = None
        add_432: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14200, view_871);  slice_14200 = view_871 = None
        
        # No stacktrace found for following nodes
        slice_tensor_860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1719, 1, 3440, 3456)
        slice_scatter_default_1720: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_860, add_432, 2, 0, 16);  slice_tensor_860 = add_432 = None
        slice_scatter_default_1721: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1719, slice_scatter_default_1720, 1, 3440, 3456);  slice_scatter_default_1719 = slice_scatter_default_1720 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1721, 1, 3440, 3456)
        slice_14205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14204, 2, 0, 16);  slice_14204 = None
        
        # No stacktrace found for following nodes
        slice_tensor_861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1721, 1, 3440, 3456)
        slice_scatter_default_1722: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_861, slice_14205, 2, 0, 16);  slice_tensor_861 = slice_14205 = None
        slice_scatter_default_1723: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1721, slice_scatter_default_1722, 1, 3440, 3456);  slice_scatter_default_1721 = slice_scatter_default_1722 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14225: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14191, 2, 16, 32);  slice_14191 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_434: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14225, memory_format = torch.contiguous_format);  slice_14225 = None
        view_872: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_434, [32, 11]);  clone_434 = None
        mm_431: "f32[32, 8]" = torch.ops.aten.mm.default(view_872, slice_37)
        view_873: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_431, [2, 16, 8]);  mm_431 = None
        slice_14232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1723, 1, 3440, 3456)
        slice_14233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14232, 2, 0, 16);  slice_14232 = None
        add_433: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14233, view_873);  slice_14233 = view_873 = None
        
        # No stacktrace found for following nodes
        slice_tensor_862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1723, 1, 3440, 3456)
        slice_scatter_default_1724: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_862, add_433, 2, 0, 16);  slice_tensor_862 = add_433 = None
        slice_scatter_default_1725: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1723, slice_scatter_default_1724, 1, 3440, 3456);  slice_scatter_default_1723 = slice_scatter_default_1724 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1725, 1, 3440, 3456)
        slice_14238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14237, 2, 0, 16);  slice_14237 = None
        
        # No stacktrace found for following nodes
        slice_tensor_863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1725, 1, 3440, 3456)
        slice_scatter_default_1726: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_863, slice_14238, 2, 0, 16);  slice_tensor_863 = slice_14238 = None
        slice_scatter_default_1727: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1725, slice_scatter_default_1726, 1, 3440, 3456);  slice_scatter_default_1725 = slice_scatter_default_1726 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14257: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3456, 3472)
        slice_14258: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14257, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_435: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14258, memory_format = torch.contiguous_format);  slice_14258 = None
        view_874: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_435, [32, 16]);  clone_435 = None
        mm_432: "f32[32, 8]" = torch.ops.aten.mm.default(view_874, slice_7)
        view_875: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_432, [2, 16, 8]);  mm_432 = None
        slice_14265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1727, 1, 3456, 3472)
        slice_14266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14265, 2, 0, 16);  slice_14265 = None
        add_434: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14266, view_875);  slice_14266 = view_875 = None
        
        # No stacktrace found for following nodes
        slice_tensor_864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1727, 1, 3456, 3472)
        slice_scatter_default_1728: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_864, add_434, 2, 0, 16);  slice_tensor_864 = add_434 = None
        slice_scatter_default_1729: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1727, slice_scatter_default_1728, 1, 3456, 3472);  slice_scatter_default_1727 = slice_scatter_default_1728 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1729, 1, 3456, 3472)
        slice_14271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14270, 2, 0, 16);  slice_14270 = None
        
        # No stacktrace found for following nodes
        slice_tensor_865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1729, 1, 3456, 3472)
        slice_scatter_default_1730: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_865, slice_14271, 2, 0, 16);  slice_tensor_865 = slice_14271 = None
        slice_scatter_default_1731: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1729, slice_scatter_default_1730, 1, 3456, 3472);  slice_scatter_default_1729 = slice_scatter_default_1730 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14291: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14257, 2, 16, 32);  slice_14257 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_436: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14291, memory_format = torch.contiguous_format);  slice_14291 = None
        view_876: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_436, [32, 11]);  clone_436 = None
        mm_433: "f32[32, 8]" = torch.ops.aten.mm.default(view_876, slice_37)
        view_877: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_433, [2, 16, 8]);  mm_433 = None
        slice_14298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1731, 1, 3456, 3472)
        slice_14299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14298, 2, 0, 16);  slice_14298 = None
        add_435: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14299, view_877);  slice_14299 = view_877 = None
        
        # No stacktrace found for following nodes
        slice_tensor_866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1731, 1, 3456, 3472)
        slice_scatter_default_1732: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_866, add_435, 2, 0, 16);  slice_tensor_866 = add_435 = None
        slice_scatter_default_1733: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1731, slice_scatter_default_1732, 1, 3456, 3472);  slice_scatter_default_1731 = slice_scatter_default_1732 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1733, 1, 3456, 3472)
        slice_14304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14303, 2, 0, 16);  slice_14303 = None
        
        # No stacktrace found for following nodes
        slice_tensor_867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1733, 1, 3456, 3472)
        slice_scatter_default_1734: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_867, slice_14304, 2, 0, 16);  slice_tensor_867 = slice_14304 = None
        slice_scatter_default_1735: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1733, slice_scatter_default_1734, 1, 3456, 3472);  slice_scatter_default_1733 = slice_scatter_default_1734 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14323: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3472, 3488)
        slice_14324: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14323, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_437: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14324, memory_format = torch.contiguous_format);  slice_14324 = None
        view_878: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_437, [32, 16]);  clone_437 = None
        mm_434: "f32[32, 8]" = torch.ops.aten.mm.default(view_878, slice_7)
        view_879: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_434, [2, 16, 8]);  mm_434 = None
        slice_14331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1735, 1, 3472, 3488)
        slice_14332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14331, 2, 0, 16);  slice_14331 = None
        add_436: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14332, view_879);  slice_14332 = view_879 = None
        
        # No stacktrace found for following nodes
        slice_tensor_868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1735, 1, 3472, 3488)
        slice_scatter_default_1736: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_868, add_436, 2, 0, 16);  slice_tensor_868 = add_436 = None
        slice_scatter_default_1737: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1735, slice_scatter_default_1736, 1, 3472, 3488);  slice_scatter_default_1735 = slice_scatter_default_1736 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1737, 1, 3472, 3488)
        slice_14337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14336, 2, 0, 16);  slice_14336 = None
        
        # No stacktrace found for following nodes
        slice_tensor_869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1737, 1, 3472, 3488)
        slice_scatter_default_1738: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_869, slice_14337, 2, 0, 16);  slice_tensor_869 = slice_14337 = None
        slice_scatter_default_1739: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1737, slice_scatter_default_1738, 1, 3472, 3488);  slice_scatter_default_1737 = slice_scatter_default_1738 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14357: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14323, 2, 16, 32);  slice_14323 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_438: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14357, memory_format = torch.contiguous_format);  slice_14357 = None
        view_880: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_438, [32, 11]);  clone_438 = None
        mm_435: "f32[32, 8]" = torch.ops.aten.mm.default(view_880, slice_37)
        view_881: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_435, [2, 16, 8]);  mm_435 = None
        slice_14364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1739, 1, 3472, 3488)
        slice_14365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14364, 2, 0, 16);  slice_14364 = None
        add_437: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14365, view_881);  slice_14365 = view_881 = None
        
        # No stacktrace found for following nodes
        slice_tensor_870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1739, 1, 3472, 3488)
        slice_scatter_default_1740: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_870, add_437, 2, 0, 16);  slice_tensor_870 = add_437 = None
        slice_scatter_default_1741: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1739, slice_scatter_default_1740, 1, 3472, 3488);  slice_scatter_default_1739 = slice_scatter_default_1740 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1741, 1, 3472, 3488)
        slice_14370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14369, 2, 0, 16);  slice_14369 = None
        
        # No stacktrace found for following nodes
        slice_tensor_871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1741, 1, 3472, 3488)
        slice_scatter_default_1742: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_871, slice_14370, 2, 0, 16);  slice_tensor_871 = slice_14370 = None
        slice_scatter_default_1743: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1741, slice_scatter_default_1742, 1, 3472, 3488);  slice_scatter_default_1741 = slice_scatter_default_1742 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14389: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3488, 3504)
        slice_14390: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14389, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_439: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14390, memory_format = torch.contiguous_format);  slice_14390 = None
        view_882: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_439, [32, 16]);  clone_439 = None
        mm_436: "f32[32, 8]" = torch.ops.aten.mm.default(view_882, slice_7)
        view_883: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_436, [2, 16, 8]);  mm_436 = None
        slice_14397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1743, 1, 3488, 3504)
        slice_14398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14397, 2, 0, 16);  slice_14397 = None
        add_438: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14398, view_883);  slice_14398 = view_883 = None
        
        # No stacktrace found for following nodes
        slice_tensor_872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1743, 1, 3488, 3504)
        slice_scatter_default_1744: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_872, add_438, 2, 0, 16);  slice_tensor_872 = add_438 = None
        slice_scatter_default_1745: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1743, slice_scatter_default_1744, 1, 3488, 3504);  slice_scatter_default_1743 = slice_scatter_default_1744 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1745, 1, 3488, 3504)
        slice_14403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14402, 2, 0, 16);  slice_14402 = None
        
        # No stacktrace found for following nodes
        slice_tensor_873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1745, 1, 3488, 3504)
        slice_scatter_default_1746: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_873, slice_14403, 2, 0, 16);  slice_tensor_873 = slice_14403 = None
        slice_scatter_default_1747: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1745, slice_scatter_default_1746, 1, 3488, 3504);  slice_scatter_default_1745 = slice_scatter_default_1746 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14423: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14389, 2, 16, 32);  slice_14389 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_440: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14423, memory_format = torch.contiguous_format);  slice_14423 = None
        view_884: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_440, [32, 11]);  clone_440 = None
        mm_437: "f32[32, 8]" = torch.ops.aten.mm.default(view_884, slice_37)
        view_885: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_437, [2, 16, 8]);  mm_437 = None
        slice_14430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1747, 1, 3488, 3504)
        slice_14431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14430, 2, 0, 16);  slice_14430 = None
        add_439: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14431, view_885);  slice_14431 = view_885 = None
        
        # No stacktrace found for following nodes
        slice_tensor_874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1747, 1, 3488, 3504)
        slice_scatter_default_1748: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_874, add_439, 2, 0, 16);  slice_tensor_874 = add_439 = None
        slice_scatter_default_1749: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1747, slice_scatter_default_1748, 1, 3488, 3504);  slice_scatter_default_1747 = slice_scatter_default_1748 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1749, 1, 3488, 3504)
        slice_14436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14435, 2, 0, 16);  slice_14435 = None
        
        # No stacktrace found for following nodes
        slice_tensor_875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1749, 1, 3488, 3504)
        slice_scatter_default_1750: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_875, slice_14436, 2, 0, 16);  slice_tensor_875 = slice_14436 = None
        slice_scatter_default_1751: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1749, slice_scatter_default_1750, 1, 3488, 3504);  slice_scatter_default_1749 = slice_scatter_default_1750 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14455: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3504, 3520)
        slice_14456: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14455, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_441: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14456, memory_format = torch.contiguous_format);  slice_14456 = None
        view_886: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_441, [32, 16]);  clone_441 = None
        mm_438: "f32[32, 8]" = torch.ops.aten.mm.default(view_886, slice_7)
        view_887: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_438, [2, 16, 8]);  mm_438 = None
        slice_14463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1751, 1, 3504, 3520)
        slice_14464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14463, 2, 0, 16);  slice_14463 = None
        add_440: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14464, view_887);  slice_14464 = view_887 = None
        
        # No stacktrace found for following nodes
        slice_tensor_876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1751, 1, 3504, 3520)
        slice_scatter_default_1752: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_876, add_440, 2, 0, 16);  slice_tensor_876 = add_440 = None
        slice_scatter_default_1753: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1751, slice_scatter_default_1752, 1, 3504, 3520);  slice_scatter_default_1751 = slice_scatter_default_1752 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1753, 1, 3504, 3520)
        slice_14469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14468, 2, 0, 16);  slice_14468 = None
        
        # No stacktrace found for following nodes
        slice_tensor_877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1753, 1, 3504, 3520)
        slice_scatter_default_1754: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_877, slice_14469, 2, 0, 16);  slice_tensor_877 = slice_14469 = None
        slice_scatter_default_1755: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1753, slice_scatter_default_1754, 1, 3504, 3520);  slice_scatter_default_1753 = slice_scatter_default_1754 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14489: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14455, 2, 16, 32);  slice_14455 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_442: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14489, memory_format = torch.contiguous_format);  slice_14489 = None
        view_888: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_442, [32, 11]);  clone_442 = None
        mm_439: "f32[32, 8]" = torch.ops.aten.mm.default(view_888, slice_37)
        view_889: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_439, [2, 16, 8]);  mm_439 = None
        slice_14496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1755, 1, 3504, 3520)
        slice_14497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14496, 2, 0, 16);  slice_14496 = None
        add_441: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14497, view_889);  slice_14497 = view_889 = None
        
        # No stacktrace found for following nodes
        slice_tensor_878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1755, 1, 3504, 3520)
        slice_scatter_default_1756: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_878, add_441, 2, 0, 16);  slice_tensor_878 = add_441 = None
        slice_scatter_default_1757: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1755, slice_scatter_default_1756, 1, 3504, 3520);  slice_scatter_default_1755 = slice_scatter_default_1756 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1757, 1, 3504, 3520)
        slice_14502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14501, 2, 0, 16);  slice_14501 = None
        
        # No stacktrace found for following nodes
        slice_tensor_879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1757, 1, 3504, 3520)
        slice_scatter_default_1758: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_879, slice_14502, 2, 0, 16);  slice_tensor_879 = slice_14502 = None
        slice_scatter_default_1759: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1757, slice_scatter_default_1758, 1, 3504, 3520);  slice_scatter_default_1757 = slice_scatter_default_1758 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14521: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3520, 3536)
        slice_14522: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14521, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_443: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14522, memory_format = torch.contiguous_format);  slice_14522 = None
        view_890: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_443, [32, 16]);  clone_443 = None
        mm_440: "f32[32, 8]" = torch.ops.aten.mm.default(view_890, slice_7)
        view_891: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_440, [2, 16, 8]);  mm_440 = None
        slice_14529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1759, 1, 3520, 3536)
        slice_14530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14529, 2, 0, 16);  slice_14529 = None
        add_442: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14530, view_891);  slice_14530 = view_891 = None
        
        # No stacktrace found for following nodes
        slice_tensor_880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1759, 1, 3520, 3536)
        slice_scatter_default_1760: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_880, add_442, 2, 0, 16);  slice_tensor_880 = add_442 = None
        slice_scatter_default_1761: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1759, slice_scatter_default_1760, 1, 3520, 3536);  slice_scatter_default_1759 = slice_scatter_default_1760 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1761, 1, 3520, 3536)
        slice_14535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14534, 2, 0, 16);  slice_14534 = None
        
        # No stacktrace found for following nodes
        slice_tensor_881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1761, 1, 3520, 3536)
        slice_scatter_default_1762: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_881, slice_14535, 2, 0, 16);  slice_tensor_881 = slice_14535 = None
        slice_scatter_default_1763: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1761, slice_scatter_default_1762, 1, 3520, 3536);  slice_scatter_default_1761 = slice_scatter_default_1762 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14555: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14521, 2, 16, 32);  slice_14521 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_444: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14555, memory_format = torch.contiguous_format);  slice_14555 = None
        view_892: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_444, [32, 11]);  clone_444 = None
        mm_441: "f32[32, 8]" = torch.ops.aten.mm.default(view_892, slice_37)
        view_893: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_441, [2, 16, 8]);  mm_441 = None
        slice_14562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1763, 1, 3520, 3536)
        slice_14563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14562, 2, 0, 16);  slice_14562 = None
        add_443: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14563, view_893);  slice_14563 = view_893 = None
        
        # No stacktrace found for following nodes
        slice_tensor_882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1763, 1, 3520, 3536)
        slice_scatter_default_1764: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_882, add_443, 2, 0, 16);  slice_tensor_882 = add_443 = None
        slice_scatter_default_1765: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1763, slice_scatter_default_1764, 1, 3520, 3536);  slice_scatter_default_1763 = slice_scatter_default_1764 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1765, 1, 3520, 3536)
        slice_14568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14567, 2, 0, 16);  slice_14567 = None
        
        # No stacktrace found for following nodes
        slice_tensor_883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1765, 1, 3520, 3536)
        slice_scatter_default_1766: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_883, slice_14568, 2, 0, 16);  slice_tensor_883 = slice_14568 = None
        slice_scatter_default_1767: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1765, slice_scatter_default_1766, 1, 3520, 3536);  slice_scatter_default_1765 = slice_scatter_default_1766 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14587: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3536, 3552)
        slice_14588: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14587, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_445: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14588, memory_format = torch.contiguous_format);  slice_14588 = None
        view_894: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_445, [32, 16]);  clone_445 = None
        mm_442: "f32[32, 8]" = torch.ops.aten.mm.default(view_894, slice_7)
        view_895: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_442, [2, 16, 8]);  mm_442 = None
        slice_14595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1767, 1, 3536, 3552)
        slice_14596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14595, 2, 0, 16);  slice_14595 = None
        add_444: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14596, view_895);  slice_14596 = view_895 = None
        
        # No stacktrace found for following nodes
        slice_tensor_884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1767, 1, 3536, 3552)
        slice_scatter_default_1768: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_884, add_444, 2, 0, 16);  slice_tensor_884 = add_444 = None
        slice_scatter_default_1769: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1767, slice_scatter_default_1768, 1, 3536, 3552);  slice_scatter_default_1767 = slice_scatter_default_1768 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1769, 1, 3536, 3552)
        slice_14601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14600, 2, 0, 16);  slice_14600 = None
        
        # No stacktrace found for following nodes
        slice_tensor_885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1769, 1, 3536, 3552)
        slice_scatter_default_1770: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_885, slice_14601, 2, 0, 16);  slice_tensor_885 = slice_14601 = None
        slice_scatter_default_1771: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1769, slice_scatter_default_1770, 1, 3536, 3552);  slice_scatter_default_1769 = slice_scatter_default_1770 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14621: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14587, 2, 16, 32);  slice_14587 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_446: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14621, memory_format = torch.contiguous_format);  slice_14621 = None
        view_896: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_446, [32, 11]);  clone_446 = None
        mm_443: "f32[32, 8]" = torch.ops.aten.mm.default(view_896, slice_37)
        view_897: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_443, [2, 16, 8]);  mm_443 = None
        slice_14628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1771, 1, 3536, 3552)
        slice_14629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14628, 2, 0, 16);  slice_14628 = None
        add_445: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14629, view_897);  slice_14629 = view_897 = None
        
        # No stacktrace found for following nodes
        slice_tensor_886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1771, 1, 3536, 3552)
        slice_scatter_default_1772: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_886, add_445, 2, 0, 16);  slice_tensor_886 = add_445 = None
        slice_scatter_default_1773: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1771, slice_scatter_default_1772, 1, 3536, 3552);  slice_scatter_default_1771 = slice_scatter_default_1772 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1773, 1, 3536, 3552)
        slice_14634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14633, 2, 0, 16);  slice_14633 = None
        
        # No stacktrace found for following nodes
        slice_tensor_887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1773, 1, 3536, 3552)
        slice_scatter_default_1774: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_887, slice_14634, 2, 0, 16);  slice_tensor_887 = slice_14634 = None
        slice_scatter_default_1775: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1773, slice_scatter_default_1774, 1, 3536, 3552);  slice_scatter_default_1773 = slice_scatter_default_1774 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14653: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3552, 3568)
        slice_14654: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14653, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_447: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14654, memory_format = torch.contiguous_format);  slice_14654 = None
        view_898: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_447, [32, 16]);  clone_447 = None
        mm_444: "f32[32, 8]" = torch.ops.aten.mm.default(view_898, slice_7)
        view_899: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_444, [2, 16, 8]);  mm_444 = None
        slice_14661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1775, 1, 3552, 3568)
        slice_14662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14661, 2, 0, 16);  slice_14661 = None
        add_446: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14662, view_899);  slice_14662 = view_899 = None
        
        # No stacktrace found for following nodes
        slice_tensor_888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1775, 1, 3552, 3568)
        slice_scatter_default_1776: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_888, add_446, 2, 0, 16);  slice_tensor_888 = add_446 = None
        slice_scatter_default_1777: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1775, slice_scatter_default_1776, 1, 3552, 3568);  slice_scatter_default_1775 = slice_scatter_default_1776 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1777, 1, 3552, 3568)
        slice_14667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14666, 2, 0, 16);  slice_14666 = None
        
        # No stacktrace found for following nodes
        slice_tensor_889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1777, 1, 3552, 3568)
        slice_scatter_default_1778: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_889, slice_14667, 2, 0, 16);  slice_tensor_889 = slice_14667 = None
        slice_scatter_default_1779: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1777, slice_scatter_default_1778, 1, 3552, 3568);  slice_scatter_default_1777 = slice_scatter_default_1778 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14687: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14653, 2, 16, 32);  slice_14653 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_448: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14687, memory_format = torch.contiguous_format);  slice_14687 = None
        view_900: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_448, [32, 11]);  clone_448 = None
        mm_445: "f32[32, 8]" = torch.ops.aten.mm.default(view_900, slice_37)
        view_901: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_445, [2, 16, 8]);  mm_445 = None
        slice_14694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1779, 1, 3552, 3568)
        slice_14695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14694, 2, 0, 16);  slice_14694 = None
        add_447: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14695, view_901);  slice_14695 = view_901 = None
        
        # No stacktrace found for following nodes
        slice_tensor_890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1779, 1, 3552, 3568)
        slice_scatter_default_1780: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_890, add_447, 2, 0, 16);  slice_tensor_890 = add_447 = None
        slice_scatter_default_1781: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1779, slice_scatter_default_1780, 1, 3552, 3568);  slice_scatter_default_1779 = slice_scatter_default_1780 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1781, 1, 3552, 3568)
        slice_14700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14699, 2, 0, 16);  slice_14699 = None
        
        # No stacktrace found for following nodes
        slice_tensor_891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1781, 1, 3552, 3568)
        slice_scatter_default_1782: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_891, slice_14700, 2, 0, 16);  slice_tensor_891 = slice_14700 = None
        slice_scatter_default_1783: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1781, slice_scatter_default_1782, 1, 3552, 3568);  slice_scatter_default_1781 = slice_scatter_default_1782 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14719: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3568, 3584)
        slice_14720: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14719, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_449: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14720, memory_format = torch.contiguous_format);  slice_14720 = None
        view_902: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_449, [32, 16]);  clone_449 = None
        mm_446: "f32[32, 8]" = torch.ops.aten.mm.default(view_902, slice_7)
        view_903: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_446, [2, 16, 8]);  mm_446 = None
        slice_14727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1783, 1, 3568, 3584)
        slice_14728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14727, 2, 0, 16);  slice_14727 = None
        add_448: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14728, view_903);  slice_14728 = view_903 = None
        
        # No stacktrace found for following nodes
        slice_tensor_892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1783, 1, 3568, 3584)
        slice_scatter_default_1784: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_892, add_448, 2, 0, 16);  slice_tensor_892 = add_448 = None
        slice_scatter_default_1785: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1783, slice_scatter_default_1784, 1, 3568, 3584);  slice_scatter_default_1783 = slice_scatter_default_1784 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1785, 1, 3568, 3584)
        slice_14733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14732, 2, 0, 16);  slice_14732 = None
        
        # No stacktrace found for following nodes
        slice_tensor_893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1785, 1, 3568, 3584)
        slice_scatter_default_1786: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_893, slice_14733, 2, 0, 16);  slice_tensor_893 = slice_14733 = None
        slice_scatter_default_1787: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1785, slice_scatter_default_1786, 1, 3568, 3584);  slice_scatter_default_1785 = slice_scatter_default_1786 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14753: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14719, 2, 16, 32);  slice_14719 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_450: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14753, memory_format = torch.contiguous_format);  slice_14753 = None
        view_904: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_450, [32, 11]);  clone_450 = None
        mm_447: "f32[32, 8]" = torch.ops.aten.mm.default(view_904, slice_37)
        view_905: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_447, [2, 16, 8]);  mm_447 = None
        slice_14760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1787, 1, 3568, 3584)
        slice_14761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14760, 2, 0, 16);  slice_14760 = None
        add_449: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14761, view_905);  slice_14761 = view_905 = None
        
        # No stacktrace found for following nodes
        slice_tensor_894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1787, 1, 3568, 3584)
        slice_scatter_default_1788: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_894, add_449, 2, 0, 16);  slice_tensor_894 = add_449 = None
        slice_scatter_default_1789: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1787, slice_scatter_default_1788, 1, 3568, 3584);  slice_scatter_default_1787 = slice_scatter_default_1788 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1789, 1, 3568, 3584)
        slice_14766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14765, 2, 0, 16);  slice_14765 = None
        
        # No stacktrace found for following nodes
        slice_tensor_895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1789, 1, 3568, 3584)
        slice_scatter_default_1790: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_895, slice_14766, 2, 0, 16);  slice_tensor_895 = slice_14766 = None
        slice_scatter_default_1791: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1789, slice_scatter_default_1790, 1, 3568, 3584);  slice_scatter_default_1789 = slice_scatter_default_1790 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14785: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3584, 3600)
        slice_14786: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14785, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_451: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14786, memory_format = torch.contiguous_format);  slice_14786 = None
        view_906: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_451, [32, 16]);  clone_451 = None
        mm_448: "f32[32, 8]" = torch.ops.aten.mm.default(view_906, slice_7)
        view_907: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_448, [2, 16, 8]);  mm_448 = None
        slice_14793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1791, 1, 3584, 3600)
        slice_14794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14793, 2, 0, 16);  slice_14793 = None
        add_450: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14794, view_907);  slice_14794 = view_907 = None
        
        # No stacktrace found for following nodes
        slice_tensor_896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1791, 1, 3584, 3600)
        slice_scatter_default_1792: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_896, add_450, 2, 0, 16);  slice_tensor_896 = add_450 = None
        slice_scatter_default_1793: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1791, slice_scatter_default_1792, 1, 3584, 3600);  slice_scatter_default_1791 = slice_scatter_default_1792 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1793, 1, 3584, 3600)
        slice_14799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14798, 2, 0, 16);  slice_14798 = None
        
        # No stacktrace found for following nodes
        slice_tensor_897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1793, 1, 3584, 3600)
        slice_scatter_default_1794: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_897, slice_14799, 2, 0, 16);  slice_tensor_897 = slice_14799 = None
        slice_scatter_default_1795: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1793, slice_scatter_default_1794, 1, 3584, 3600);  slice_scatter_default_1793 = slice_scatter_default_1794 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14819: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14785, 2, 16, 32);  slice_14785 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_452: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14819, memory_format = torch.contiguous_format);  slice_14819 = None
        view_908: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_452, [32, 11]);  clone_452 = None
        mm_449: "f32[32, 8]" = torch.ops.aten.mm.default(view_908, slice_37)
        view_909: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_449, [2, 16, 8]);  mm_449 = None
        slice_14826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1795, 1, 3584, 3600)
        slice_14827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14826, 2, 0, 16);  slice_14826 = None
        add_451: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14827, view_909);  slice_14827 = view_909 = None
        
        # No stacktrace found for following nodes
        slice_tensor_898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1795, 1, 3584, 3600)
        slice_scatter_default_1796: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_898, add_451, 2, 0, 16);  slice_tensor_898 = add_451 = None
        slice_scatter_default_1797: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1795, slice_scatter_default_1796, 1, 3584, 3600);  slice_scatter_default_1795 = slice_scatter_default_1796 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1797, 1, 3584, 3600)
        slice_14832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14831, 2, 0, 16);  slice_14831 = None
        
        # No stacktrace found for following nodes
        slice_tensor_899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1797, 1, 3584, 3600)
        slice_scatter_default_1798: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_899, slice_14832, 2, 0, 16);  slice_tensor_899 = slice_14832 = None
        slice_scatter_default_1799: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1797, slice_scatter_default_1798, 1, 3584, 3600);  slice_scatter_default_1797 = slice_scatter_default_1798 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14851: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3600, 3616)
        slice_14852: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14851, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_453: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14852, memory_format = torch.contiguous_format);  slice_14852 = None
        view_910: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_453, [32, 16]);  clone_453 = None
        mm_450: "f32[32, 8]" = torch.ops.aten.mm.default(view_910, slice_7)
        view_911: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_450, [2, 16, 8]);  mm_450 = None
        slice_14859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1799, 1, 3600, 3616)
        slice_14860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14859, 2, 0, 16);  slice_14859 = None
        add_452: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14860, view_911);  slice_14860 = view_911 = None
        
        # No stacktrace found for following nodes
        slice_tensor_900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1799, 1, 3600, 3616)
        slice_scatter_default_1800: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_900, add_452, 2, 0, 16);  slice_tensor_900 = add_452 = None
        slice_scatter_default_1801: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1799, slice_scatter_default_1800, 1, 3600, 3616);  slice_scatter_default_1799 = slice_scatter_default_1800 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1801, 1, 3600, 3616)
        slice_14865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14864, 2, 0, 16);  slice_14864 = None
        
        # No stacktrace found for following nodes
        slice_tensor_901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1801, 1, 3600, 3616)
        slice_scatter_default_1802: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_901, slice_14865, 2, 0, 16);  slice_tensor_901 = slice_14865 = None
        slice_scatter_default_1803: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1801, slice_scatter_default_1802, 1, 3600, 3616);  slice_scatter_default_1801 = slice_scatter_default_1802 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14885: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14851, 2, 16, 32);  slice_14851 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_454: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14885, memory_format = torch.contiguous_format);  slice_14885 = None
        view_912: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_454, [32, 11]);  clone_454 = None
        mm_451: "f32[32, 8]" = torch.ops.aten.mm.default(view_912, slice_37)
        view_913: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_451, [2, 16, 8]);  mm_451 = None
        slice_14892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1803, 1, 3600, 3616)
        slice_14893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14892, 2, 0, 16);  slice_14892 = None
        add_453: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14893, view_913);  slice_14893 = view_913 = None
        
        # No stacktrace found for following nodes
        slice_tensor_902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1803, 1, 3600, 3616)
        slice_scatter_default_1804: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_902, add_453, 2, 0, 16);  slice_tensor_902 = add_453 = None
        slice_scatter_default_1805: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1803, slice_scatter_default_1804, 1, 3600, 3616);  slice_scatter_default_1803 = slice_scatter_default_1804 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1805, 1, 3600, 3616)
        slice_14898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14897, 2, 0, 16);  slice_14897 = None
        
        # No stacktrace found for following nodes
        slice_tensor_903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1805, 1, 3600, 3616)
        slice_scatter_default_1806: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_903, slice_14898, 2, 0, 16);  slice_tensor_903 = slice_14898 = None
        slice_scatter_default_1807: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1805, slice_scatter_default_1806, 1, 3600, 3616);  slice_scatter_default_1805 = slice_scatter_default_1806 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14917: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3616, 3632)
        slice_14918: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14917, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_455: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14918, memory_format = torch.contiguous_format);  slice_14918 = None
        view_914: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_455, [32, 16]);  clone_455 = None
        mm_452: "f32[32, 8]" = torch.ops.aten.mm.default(view_914, slice_7)
        view_915: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_452, [2, 16, 8]);  mm_452 = None
        slice_14925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1807, 1, 3616, 3632)
        slice_14926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14925, 2, 0, 16);  slice_14925 = None
        add_454: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14926, view_915);  slice_14926 = view_915 = None
        
        # No stacktrace found for following nodes
        slice_tensor_904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1807, 1, 3616, 3632)
        slice_scatter_default_1808: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_904, add_454, 2, 0, 16);  slice_tensor_904 = add_454 = None
        slice_scatter_default_1809: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1807, slice_scatter_default_1808, 1, 3616, 3632);  slice_scatter_default_1807 = slice_scatter_default_1808 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1809, 1, 3616, 3632)
        slice_14931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14930, 2, 0, 16);  slice_14930 = None
        
        # No stacktrace found for following nodes
        slice_tensor_905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1809, 1, 3616, 3632)
        slice_scatter_default_1810: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_905, slice_14931, 2, 0, 16);  slice_tensor_905 = slice_14931 = None
        slice_scatter_default_1811: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1809, slice_scatter_default_1810, 1, 3616, 3632);  slice_scatter_default_1809 = slice_scatter_default_1810 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14951: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14917, 2, 16, 32);  slice_14917 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_456: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_14951, memory_format = torch.contiguous_format);  slice_14951 = None
        view_916: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_456, [32, 11]);  clone_456 = None
        mm_453: "f32[32, 8]" = torch.ops.aten.mm.default(view_916, slice_37)
        view_917: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_453, [2, 16, 8]);  mm_453 = None
        slice_14958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1811, 1, 3616, 3632)
        slice_14959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14958, 2, 0, 16);  slice_14958 = None
        add_455: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14959, view_917);  slice_14959 = view_917 = None
        
        # No stacktrace found for following nodes
        slice_tensor_906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1811, 1, 3616, 3632)
        slice_scatter_default_1812: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_906, add_455, 2, 0, 16);  slice_tensor_906 = add_455 = None
        slice_scatter_default_1813: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1811, slice_scatter_default_1812, 1, 3616, 3632);  slice_scatter_default_1811 = slice_scatter_default_1812 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1813, 1, 3616, 3632)
        slice_14964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14963, 2, 0, 16);  slice_14963 = None
        
        # No stacktrace found for following nodes
        slice_tensor_907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1813, 1, 3616, 3632)
        slice_scatter_default_1814: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_907, slice_14964, 2, 0, 16);  slice_tensor_907 = slice_14964 = None
        slice_scatter_default_1815: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1813, slice_scatter_default_1814, 1, 3616, 3632);  slice_scatter_default_1813 = slice_scatter_default_1814 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_14983: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3632, 3648)
        slice_14984: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_14983, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_457: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_14984, memory_format = torch.contiguous_format);  slice_14984 = None
        view_918: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_457, [32, 16]);  clone_457 = None
        mm_454: "f32[32, 8]" = torch.ops.aten.mm.default(view_918, slice_7)
        view_919: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_454, [2, 16, 8]);  mm_454 = None
        slice_14991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1815, 1, 3632, 3648)
        slice_14992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14991, 2, 0, 16);  slice_14991 = None
        add_456: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_14992, view_919);  slice_14992 = view_919 = None
        
        # No stacktrace found for following nodes
        slice_tensor_908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1815, 1, 3632, 3648)
        slice_scatter_default_1816: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_908, add_456, 2, 0, 16);  slice_tensor_908 = add_456 = None
        slice_scatter_default_1817: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1815, slice_scatter_default_1816, 1, 3632, 3648);  slice_scatter_default_1815 = slice_scatter_default_1816 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_14996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1817, 1, 3632, 3648)
        slice_14997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_14996, 2, 0, 16);  slice_14996 = None
        
        # No stacktrace found for following nodes
        slice_tensor_909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1817, 1, 3632, 3648)
        slice_scatter_default_1818: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_909, slice_14997, 2, 0, 16);  slice_tensor_909 = slice_14997 = None
        slice_scatter_default_1819: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1817, slice_scatter_default_1818, 1, 3632, 3648);  slice_scatter_default_1817 = slice_scatter_default_1818 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15017: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_14983, 2, 16, 32);  slice_14983 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_458: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15017, memory_format = torch.contiguous_format);  slice_15017 = None
        view_920: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_458, [32, 11]);  clone_458 = None
        mm_455: "f32[32, 8]" = torch.ops.aten.mm.default(view_920, slice_37)
        view_921: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_455, [2, 16, 8]);  mm_455 = None
        slice_15024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1819, 1, 3632, 3648)
        slice_15025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15024, 2, 0, 16);  slice_15024 = None
        add_457: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15025, view_921);  slice_15025 = view_921 = None
        
        # No stacktrace found for following nodes
        slice_tensor_910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1819, 1, 3632, 3648)
        slice_scatter_default_1820: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_910, add_457, 2, 0, 16);  slice_tensor_910 = add_457 = None
        slice_scatter_default_1821: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1819, slice_scatter_default_1820, 1, 3632, 3648);  slice_scatter_default_1819 = slice_scatter_default_1820 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1821, 1, 3632, 3648)
        slice_15030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15029, 2, 0, 16);  slice_15029 = None
        
        # No stacktrace found for following nodes
        slice_tensor_911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1821, 1, 3632, 3648)
        slice_scatter_default_1822: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_911, slice_15030, 2, 0, 16);  slice_tensor_911 = slice_15030 = None
        slice_scatter_default_1823: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1821, slice_scatter_default_1822, 1, 3632, 3648);  slice_scatter_default_1821 = slice_scatter_default_1822 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15049: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3648, 3664)
        slice_15050: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15049, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_459: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15050, memory_format = torch.contiguous_format);  slice_15050 = None
        view_922: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_459, [32, 16]);  clone_459 = None
        mm_456: "f32[32, 8]" = torch.ops.aten.mm.default(view_922, slice_7)
        view_923: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_456, [2, 16, 8]);  mm_456 = None
        slice_15057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1823, 1, 3648, 3664)
        slice_15058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15057, 2, 0, 16);  slice_15057 = None
        add_458: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15058, view_923);  slice_15058 = view_923 = None
        
        # No stacktrace found for following nodes
        slice_tensor_912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1823, 1, 3648, 3664)
        slice_scatter_default_1824: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_912, add_458, 2, 0, 16);  slice_tensor_912 = add_458 = None
        slice_scatter_default_1825: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1823, slice_scatter_default_1824, 1, 3648, 3664);  slice_scatter_default_1823 = slice_scatter_default_1824 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1825, 1, 3648, 3664)
        slice_15063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15062, 2, 0, 16);  slice_15062 = None
        
        # No stacktrace found for following nodes
        slice_tensor_913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1825, 1, 3648, 3664)
        slice_scatter_default_1826: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_913, slice_15063, 2, 0, 16);  slice_tensor_913 = slice_15063 = None
        slice_scatter_default_1827: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1825, slice_scatter_default_1826, 1, 3648, 3664);  slice_scatter_default_1825 = slice_scatter_default_1826 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15083: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15049, 2, 16, 32);  slice_15049 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_460: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15083, memory_format = torch.contiguous_format);  slice_15083 = None
        view_924: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_460, [32, 11]);  clone_460 = None
        mm_457: "f32[32, 8]" = torch.ops.aten.mm.default(view_924, slice_37)
        view_925: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_457, [2, 16, 8]);  mm_457 = None
        slice_15090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1827, 1, 3648, 3664)
        slice_15091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15090, 2, 0, 16);  slice_15090 = None
        add_459: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15091, view_925);  slice_15091 = view_925 = None
        
        # No stacktrace found for following nodes
        slice_tensor_914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1827, 1, 3648, 3664)
        slice_scatter_default_1828: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_914, add_459, 2, 0, 16);  slice_tensor_914 = add_459 = None
        slice_scatter_default_1829: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1827, slice_scatter_default_1828, 1, 3648, 3664);  slice_scatter_default_1827 = slice_scatter_default_1828 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1829, 1, 3648, 3664)
        slice_15096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15095, 2, 0, 16);  slice_15095 = None
        
        # No stacktrace found for following nodes
        slice_tensor_915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1829, 1, 3648, 3664)
        slice_scatter_default_1830: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_915, slice_15096, 2, 0, 16);  slice_tensor_915 = slice_15096 = None
        slice_scatter_default_1831: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1829, slice_scatter_default_1830, 1, 3648, 3664);  slice_scatter_default_1829 = slice_scatter_default_1830 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15115: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3664, 3680)
        slice_15116: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15115, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_461: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15116, memory_format = torch.contiguous_format);  slice_15116 = None
        view_926: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_461, [32, 16]);  clone_461 = None
        mm_458: "f32[32, 8]" = torch.ops.aten.mm.default(view_926, slice_7)
        view_927: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_458, [2, 16, 8]);  mm_458 = None
        slice_15123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1831, 1, 3664, 3680)
        slice_15124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15123, 2, 0, 16);  slice_15123 = None
        add_460: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15124, view_927);  slice_15124 = view_927 = None
        
        # No stacktrace found for following nodes
        slice_tensor_916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1831, 1, 3664, 3680)
        slice_scatter_default_1832: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_916, add_460, 2, 0, 16);  slice_tensor_916 = add_460 = None
        slice_scatter_default_1833: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1831, slice_scatter_default_1832, 1, 3664, 3680);  slice_scatter_default_1831 = slice_scatter_default_1832 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1833, 1, 3664, 3680)
        slice_15129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15128, 2, 0, 16);  slice_15128 = None
        
        # No stacktrace found for following nodes
        slice_tensor_917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1833, 1, 3664, 3680)
        slice_scatter_default_1834: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_917, slice_15129, 2, 0, 16);  slice_tensor_917 = slice_15129 = None
        slice_scatter_default_1835: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1833, slice_scatter_default_1834, 1, 3664, 3680);  slice_scatter_default_1833 = slice_scatter_default_1834 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15149: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15115, 2, 16, 32);  slice_15115 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_462: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15149, memory_format = torch.contiguous_format);  slice_15149 = None
        view_928: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_462, [32, 11]);  clone_462 = None
        mm_459: "f32[32, 8]" = torch.ops.aten.mm.default(view_928, slice_37)
        view_929: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_459, [2, 16, 8]);  mm_459 = None
        slice_15156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1835, 1, 3664, 3680)
        slice_15157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15156, 2, 0, 16);  slice_15156 = None
        add_461: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15157, view_929);  slice_15157 = view_929 = None
        
        # No stacktrace found for following nodes
        slice_tensor_918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1835, 1, 3664, 3680)
        slice_scatter_default_1836: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_918, add_461, 2, 0, 16);  slice_tensor_918 = add_461 = None
        slice_scatter_default_1837: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1835, slice_scatter_default_1836, 1, 3664, 3680);  slice_scatter_default_1835 = slice_scatter_default_1836 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1837, 1, 3664, 3680)
        slice_15162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15161, 2, 0, 16);  slice_15161 = None
        
        # No stacktrace found for following nodes
        slice_tensor_919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1837, 1, 3664, 3680)
        slice_scatter_default_1838: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_919, slice_15162, 2, 0, 16);  slice_tensor_919 = slice_15162 = None
        slice_scatter_default_1839: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1837, slice_scatter_default_1838, 1, 3664, 3680);  slice_scatter_default_1837 = slice_scatter_default_1838 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15181: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3680, 3696)
        slice_15182: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15181, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_463: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15182, memory_format = torch.contiguous_format);  slice_15182 = None
        view_930: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_463, [32, 16]);  clone_463 = None
        mm_460: "f32[32, 8]" = torch.ops.aten.mm.default(view_930, slice_7)
        view_931: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_460, [2, 16, 8]);  mm_460 = None
        slice_15189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1839, 1, 3680, 3696)
        slice_15190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15189, 2, 0, 16);  slice_15189 = None
        add_462: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15190, view_931);  slice_15190 = view_931 = None
        
        # No stacktrace found for following nodes
        slice_tensor_920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1839, 1, 3680, 3696)
        slice_scatter_default_1840: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_920, add_462, 2, 0, 16);  slice_tensor_920 = add_462 = None
        slice_scatter_default_1841: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1839, slice_scatter_default_1840, 1, 3680, 3696);  slice_scatter_default_1839 = slice_scatter_default_1840 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1841, 1, 3680, 3696)
        slice_15195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15194, 2, 0, 16);  slice_15194 = None
        
        # No stacktrace found for following nodes
        slice_tensor_921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1841, 1, 3680, 3696)
        slice_scatter_default_1842: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_921, slice_15195, 2, 0, 16);  slice_tensor_921 = slice_15195 = None
        slice_scatter_default_1843: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1841, slice_scatter_default_1842, 1, 3680, 3696);  slice_scatter_default_1841 = slice_scatter_default_1842 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15215: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15181, 2, 16, 32);  slice_15181 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_464: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15215, memory_format = torch.contiguous_format);  slice_15215 = None
        view_932: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_464, [32, 11]);  clone_464 = None
        mm_461: "f32[32, 8]" = torch.ops.aten.mm.default(view_932, slice_37)
        view_933: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_461, [2, 16, 8]);  mm_461 = None
        slice_15222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1843, 1, 3680, 3696)
        slice_15223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15222, 2, 0, 16);  slice_15222 = None
        add_463: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15223, view_933);  slice_15223 = view_933 = None
        
        # No stacktrace found for following nodes
        slice_tensor_922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1843, 1, 3680, 3696)
        slice_scatter_default_1844: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_922, add_463, 2, 0, 16);  slice_tensor_922 = add_463 = None
        slice_scatter_default_1845: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1843, slice_scatter_default_1844, 1, 3680, 3696);  slice_scatter_default_1843 = slice_scatter_default_1844 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1845, 1, 3680, 3696)
        slice_15228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15227, 2, 0, 16);  slice_15227 = None
        
        # No stacktrace found for following nodes
        slice_tensor_923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1845, 1, 3680, 3696)
        slice_scatter_default_1846: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_923, slice_15228, 2, 0, 16);  slice_tensor_923 = slice_15228 = None
        slice_scatter_default_1847: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1845, slice_scatter_default_1846, 1, 3680, 3696);  slice_scatter_default_1845 = slice_scatter_default_1846 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15247: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3696, 3712)
        slice_15248: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15247, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_465: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15248, memory_format = torch.contiguous_format);  slice_15248 = None
        view_934: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_465, [32, 16]);  clone_465 = None
        mm_462: "f32[32, 8]" = torch.ops.aten.mm.default(view_934, slice_7)
        view_935: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_462, [2, 16, 8]);  mm_462 = None
        slice_15255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1847, 1, 3696, 3712)
        slice_15256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15255, 2, 0, 16);  slice_15255 = None
        add_464: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15256, view_935);  slice_15256 = view_935 = None
        
        # No stacktrace found for following nodes
        slice_tensor_924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1847, 1, 3696, 3712)
        slice_scatter_default_1848: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_924, add_464, 2, 0, 16);  slice_tensor_924 = add_464 = None
        slice_scatter_default_1849: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1847, slice_scatter_default_1848, 1, 3696, 3712);  slice_scatter_default_1847 = slice_scatter_default_1848 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1849, 1, 3696, 3712)
        slice_15261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15260, 2, 0, 16);  slice_15260 = None
        
        # No stacktrace found for following nodes
        slice_tensor_925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1849, 1, 3696, 3712)
        slice_scatter_default_1850: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_925, slice_15261, 2, 0, 16);  slice_tensor_925 = slice_15261 = None
        slice_scatter_default_1851: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1849, slice_scatter_default_1850, 1, 3696, 3712);  slice_scatter_default_1849 = slice_scatter_default_1850 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15281: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15247, 2, 16, 32);  slice_15247 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_466: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15281, memory_format = torch.contiguous_format);  slice_15281 = None
        view_936: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_466, [32, 11]);  clone_466 = None
        mm_463: "f32[32, 8]" = torch.ops.aten.mm.default(view_936, slice_37)
        view_937: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_463, [2, 16, 8]);  mm_463 = None
        slice_15288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1851, 1, 3696, 3712)
        slice_15289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15288, 2, 0, 16);  slice_15288 = None
        add_465: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15289, view_937);  slice_15289 = view_937 = None
        
        # No stacktrace found for following nodes
        slice_tensor_926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1851, 1, 3696, 3712)
        slice_scatter_default_1852: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_926, add_465, 2, 0, 16);  slice_tensor_926 = add_465 = None
        slice_scatter_default_1853: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1851, slice_scatter_default_1852, 1, 3696, 3712);  slice_scatter_default_1851 = slice_scatter_default_1852 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1853, 1, 3696, 3712)
        slice_15294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15293, 2, 0, 16);  slice_15293 = None
        
        # No stacktrace found for following nodes
        slice_tensor_927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1853, 1, 3696, 3712)
        slice_scatter_default_1854: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_927, slice_15294, 2, 0, 16);  slice_tensor_927 = slice_15294 = None
        slice_scatter_default_1855: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1853, slice_scatter_default_1854, 1, 3696, 3712);  slice_scatter_default_1853 = slice_scatter_default_1854 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15313: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3712, 3728)
        slice_15314: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15313, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_467: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15314, memory_format = torch.contiguous_format);  slice_15314 = None
        view_938: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_467, [32, 16]);  clone_467 = None
        mm_464: "f32[32, 8]" = torch.ops.aten.mm.default(view_938, slice_7)
        view_939: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_464, [2, 16, 8]);  mm_464 = None
        slice_15321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1855, 1, 3712, 3728)
        slice_15322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15321, 2, 0, 16);  slice_15321 = None
        add_466: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15322, view_939);  slice_15322 = view_939 = None
        
        # No stacktrace found for following nodes
        slice_tensor_928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1855, 1, 3712, 3728)
        slice_scatter_default_1856: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_928, add_466, 2, 0, 16);  slice_tensor_928 = add_466 = None
        slice_scatter_default_1857: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1855, slice_scatter_default_1856, 1, 3712, 3728);  slice_scatter_default_1855 = slice_scatter_default_1856 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1857, 1, 3712, 3728)
        slice_15327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15326, 2, 0, 16);  slice_15326 = None
        
        # No stacktrace found for following nodes
        slice_tensor_929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1857, 1, 3712, 3728)
        slice_scatter_default_1858: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_929, slice_15327, 2, 0, 16);  slice_tensor_929 = slice_15327 = None
        slice_scatter_default_1859: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1857, slice_scatter_default_1858, 1, 3712, 3728);  slice_scatter_default_1857 = slice_scatter_default_1858 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15347: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15313, 2, 16, 32);  slice_15313 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_468: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15347, memory_format = torch.contiguous_format);  slice_15347 = None
        view_940: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_468, [32, 11]);  clone_468 = None
        mm_465: "f32[32, 8]" = torch.ops.aten.mm.default(view_940, slice_37)
        view_941: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_465, [2, 16, 8]);  mm_465 = None
        slice_15354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1859, 1, 3712, 3728)
        slice_15355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15354, 2, 0, 16);  slice_15354 = None
        add_467: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15355, view_941);  slice_15355 = view_941 = None
        
        # No stacktrace found for following nodes
        slice_tensor_930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1859, 1, 3712, 3728)
        slice_scatter_default_1860: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_930, add_467, 2, 0, 16);  slice_tensor_930 = add_467 = None
        slice_scatter_default_1861: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1859, slice_scatter_default_1860, 1, 3712, 3728);  slice_scatter_default_1859 = slice_scatter_default_1860 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1861, 1, 3712, 3728)
        slice_15360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15359, 2, 0, 16);  slice_15359 = None
        
        # No stacktrace found for following nodes
        slice_tensor_931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1861, 1, 3712, 3728)
        slice_scatter_default_1862: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_931, slice_15360, 2, 0, 16);  slice_tensor_931 = slice_15360 = None
        slice_scatter_default_1863: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1861, slice_scatter_default_1862, 1, 3712, 3728);  slice_scatter_default_1861 = slice_scatter_default_1862 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15379: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3728, 3744)
        slice_15380: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15379, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_469: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15380, memory_format = torch.contiguous_format);  slice_15380 = None
        view_942: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_469, [32, 16]);  clone_469 = None
        mm_466: "f32[32, 8]" = torch.ops.aten.mm.default(view_942, slice_7)
        view_943: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_466, [2, 16, 8]);  mm_466 = None
        slice_15387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1863, 1, 3728, 3744)
        slice_15388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15387, 2, 0, 16);  slice_15387 = None
        add_468: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15388, view_943);  slice_15388 = view_943 = None
        
        # No stacktrace found for following nodes
        slice_tensor_932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1863, 1, 3728, 3744)
        slice_scatter_default_1864: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_932, add_468, 2, 0, 16);  slice_tensor_932 = add_468 = None
        slice_scatter_default_1865: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1863, slice_scatter_default_1864, 1, 3728, 3744);  slice_scatter_default_1863 = slice_scatter_default_1864 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1865, 1, 3728, 3744)
        slice_15393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15392, 2, 0, 16);  slice_15392 = None
        
        # No stacktrace found for following nodes
        slice_tensor_933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1865, 1, 3728, 3744)
        slice_scatter_default_1866: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_933, slice_15393, 2, 0, 16);  slice_tensor_933 = slice_15393 = None
        slice_scatter_default_1867: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1865, slice_scatter_default_1866, 1, 3728, 3744);  slice_scatter_default_1865 = slice_scatter_default_1866 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15413: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15379, 2, 16, 32);  slice_15379 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_470: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15413, memory_format = torch.contiguous_format);  slice_15413 = None
        view_944: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_470, [32, 11]);  clone_470 = None
        mm_467: "f32[32, 8]" = torch.ops.aten.mm.default(view_944, slice_37)
        view_945: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_467, [2, 16, 8]);  mm_467 = None
        slice_15420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1867, 1, 3728, 3744)
        slice_15421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15420, 2, 0, 16);  slice_15420 = None
        add_469: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15421, view_945);  slice_15421 = view_945 = None
        
        # No stacktrace found for following nodes
        slice_tensor_934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1867, 1, 3728, 3744)
        slice_scatter_default_1868: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_934, add_469, 2, 0, 16);  slice_tensor_934 = add_469 = None
        slice_scatter_default_1869: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1867, slice_scatter_default_1868, 1, 3728, 3744);  slice_scatter_default_1867 = slice_scatter_default_1868 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1869, 1, 3728, 3744)
        slice_15426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15425, 2, 0, 16);  slice_15425 = None
        
        # No stacktrace found for following nodes
        slice_tensor_935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1869, 1, 3728, 3744)
        slice_scatter_default_1870: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_935, slice_15426, 2, 0, 16);  slice_tensor_935 = slice_15426 = None
        slice_scatter_default_1871: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1869, slice_scatter_default_1870, 1, 3728, 3744);  slice_scatter_default_1869 = slice_scatter_default_1870 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15445: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3744, 3760)
        slice_15446: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15445, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_471: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15446, memory_format = torch.contiguous_format);  slice_15446 = None
        view_946: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_471, [32, 16]);  clone_471 = None
        mm_468: "f32[32, 8]" = torch.ops.aten.mm.default(view_946, slice_7)
        view_947: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_468, [2, 16, 8]);  mm_468 = None
        slice_15453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1871, 1, 3744, 3760)
        slice_15454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15453, 2, 0, 16);  slice_15453 = None
        add_470: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15454, view_947);  slice_15454 = view_947 = None
        
        # No stacktrace found for following nodes
        slice_tensor_936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1871, 1, 3744, 3760)
        slice_scatter_default_1872: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_936, add_470, 2, 0, 16);  slice_tensor_936 = add_470 = None
        slice_scatter_default_1873: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1871, slice_scatter_default_1872, 1, 3744, 3760);  slice_scatter_default_1871 = slice_scatter_default_1872 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1873, 1, 3744, 3760)
        slice_15459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15458, 2, 0, 16);  slice_15458 = None
        
        # No stacktrace found for following nodes
        slice_tensor_937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1873, 1, 3744, 3760)
        slice_scatter_default_1874: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_937, slice_15459, 2, 0, 16);  slice_tensor_937 = slice_15459 = None
        slice_scatter_default_1875: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1873, slice_scatter_default_1874, 1, 3744, 3760);  slice_scatter_default_1873 = slice_scatter_default_1874 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15479: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15445, 2, 16, 32);  slice_15445 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_472: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15479, memory_format = torch.contiguous_format);  slice_15479 = None
        view_948: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_472, [32, 11]);  clone_472 = None
        mm_469: "f32[32, 8]" = torch.ops.aten.mm.default(view_948, slice_37)
        view_949: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_469, [2, 16, 8]);  mm_469 = None
        slice_15486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1875, 1, 3744, 3760)
        slice_15487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15486, 2, 0, 16);  slice_15486 = None
        add_471: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15487, view_949);  slice_15487 = view_949 = None
        
        # No stacktrace found for following nodes
        slice_tensor_938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1875, 1, 3744, 3760)
        slice_scatter_default_1876: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_938, add_471, 2, 0, 16);  slice_tensor_938 = add_471 = None
        slice_scatter_default_1877: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1875, slice_scatter_default_1876, 1, 3744, 3760);  slice_scatter_default_1875 = slice_scatter_default_1876 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1877, 1, 3744, 3760)
        slice_15492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15491, 2, 0, 16);  slice_15491 = None
        
        # No stacktrace found for following nodes
        slice_tensor_939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1877, 1, 3744, 3760)
        slice_scatter_default_1878: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_939, slice_15492, 2, 0, 16);  slice_tensor_939 = slice_15492 = None
        slice_scatter_default_1879: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1877, slice_scatter_default_1878, 1, 3744, 3760);  slice_scatter_default_1877 = slice_scatter_default_1878 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15511: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3760, 3776)
        slice_15512: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15511, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_473: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15512, memory_format = torch.contiguous_format);  slice_15512 = None
        view_950: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_473, [32, 16]);  clone_473 = None
        mm_470: "f32[32, 8]" = torch.ops.aten.mm.default(view_950, slice_7)
        view_951: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_470, [2, 16, 8]);  mm_470 = None
        slice_15519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1879, 1, 3760, 3776)
        slice_15520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15519, 2, 0, 16);  slice_15519 = None
        add_472: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15520, view_951);  slice_15520 = view_951 = None
        
        # No stacktrace found for following nodes
        slice_tensor_940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1879, 1, 3760, 3776)
        slice_scatter_default_1880: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_940, add_472, 2, 0, 16);  slice_tensor_940 = add_472 = None
        slice_scatter_default_1881: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1879, slice_scatter_default_1880, 1, 3760, 3776);  slice_scatter_default_1879 = slice_scatter_default_1880 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1881, 1, 3760, 3776)
        slice_15525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15524, 2, 0, 16);  slice_15524 = None
        
        # No stacktrace found for following nodes
        slice_tensor_941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1881, 1, 3760, 3776)
        slice_scatter_default_1882: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_941, slice_15525, 2, 0, 16);  slice_tensor_941 = slice_15525 = None
        slice_scatter_default_1883: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1881, slice_scatter_default_1882, 1, 3760, 3776);  slice_scatter_default_1881 = slice_scatter_default_1882 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15545: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15511, 2, 16, 32);  slice_15511 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_474: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15545, memory_format = torch.contiguous_format);  slice_15545 = None
        view_952: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_474, [32, 11]);  clone_474 = None
        mm_471: "f32[32, 8]" = torch.ops.aten.mm.default(view_952, slice_37)
        view_953: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_471, [2, 16, 8]);  mm_471 = None
        slice_15552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1883, 1, 3760, 3776)
        slice_15553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15552, 2, 0, 16);  slice_15552 = None
        add_473: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15553, view_953);  slice_15553 = view_953 = None
        
        # No stacktrace found for following nodes
        slice_tensor_942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1883, 1, 3760, 3776)
        slice_scatter_default_1884: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_942, add_473, 2, 0, 16);  slice_tensor_942 = add_473 = None
        slice_scatter_default_1885: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1883, slice_scatter_default_1884, 1, 3760, 3776);  slice_scatter_default_1883 = slice_scatter_default_1884 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1885, 1, 3760, 3776)
        slice_15558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15557, 2, 0, 16);  slice_15557 = None
        
        # No stacktrace found for following nodes
        slice_tensor_943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1885, 1, 3760, 3776)
        slice_scatter_default_1886: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_943, slice_15558, 2, 0, 16);  slice_tensor_943 = slice_15558 = None
        slice_scatter_default_1887: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1885, slice_scatter_default_1886, 1, 3760, 3776);  slice_scatter_default_1885 = slice_scatter_default_1886 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15577: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3776, 3792)
        slice_15578: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15577, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_475: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15578, memory_format = torch.contiguous_format);  slice_15578 = None
        view_954: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_475, [32, 16]);  clone_475 = None
        mm_472: "f32[32, 8]" = torch.ops.aten.mm.default(view_954, slice_7)
        view_955: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_472, [2, 16, 8]);  mm_472 = None
        slice_15585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1887, 1, 3776, 3792)
        slice_15586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15585, 2, 0, 16);  slice_15585 = None
        add_474: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15586, view_955);  slice_15586 = view_955 = None
        
        # No stacktrace found for following nodes
        slice_tensor_944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1887, 1, 3776, 3792)
        slice_scatter_default_1888: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_944, add_474, 2, 0, 16);  slice_tensor_944 = add_474 = None
        slice_scatter_default_1889: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1887, slice_scatter_default_1888, 1, 3776, 3792);  slice_scatter_default_1887 = slice_scatter_default_1888 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1889, 1, 3776, 3792)
        slice_15591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15590, 2, 0, 16);  slice_15590 = None
        
        # No stacktrace found for following nodes
        slice_tensor_945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1889, 1, 3776, 3792)
        slice_scatter_default_1890: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_945, slice_15591, 2, 0, 16);  slice_tensor_945 = slice_15591 = None
        slice_scatter_default_1891: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1889, slice_scatter_default_1890, 1, 3776, 3792);  slice_scatter_default_1889 = slice_scatter_default_1890 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15611: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15577, 2, 16, 32);  slice_15577 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_476: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15611, memory_format = torch.contiguous_format);  slice_15611 = None
        view_956: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_476, [32, 11]);  clone_476 = None
        mm_473: "f32[32, 8]" = torch.ops.aten.mm.default(view_956, slice_37)
        view_957: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_473, [2, 16, 8]);  mm_473 = None
        slice_15618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1891, 1, 3776, 3792)
        slice_15619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15618, 2, 0, 16);  slice_15618 = None
        add_475: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15619, view_957);  slice_15619 = view_957 = None
        
        # No stacktrace found for following nodes
        slice_tensor_946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1891, 1, 3776, 3792)
        slice_scatter_default_1892: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_946, add_475, 2, 0, 16);  slice_tensor_946 = add_475 = None
        slice_scatter_default_1893: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1891, slice_scatter_default_1892, 1, 3776, 3792);  slice_scatter_default_1891 = slice_scatter_default_1892 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1893, 1, 3776, 3792)
        slice_15624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15623, 2, 0, 16);  slice_15623 = None
        
        # No stacktrace found for following nodes
        slice_tensor_947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1893, 1, 3776, 3792)
        slice_scatter_default_1894: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_947, slice_15624, 2, 0, 16);  slice_tensor_947 = slice_15624 = None
        slice_scatter_default_1895: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1893, slice_scatter_default_1894, 1, 3776, 3792);  slice_scatter_default_1893 = slice_scatter_default_1894 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15643: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3792, 3808)
        slice_15644: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15643, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_477: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15644, memory_format = torch.contiguous_format);  slice_15644 = None
        view_958: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_477, [32, 16]);  clone_477 = None
        mm_474: "f32[32, 8]" = torch.ops.aten.mm.default(view_958, slice_7)
        view_959: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_474, [2, 16, 8]);  mm_474 = None
        slice_15651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1895, 1, 3792, 3808)
        slice_15652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15651, 2, 0, 16);  slice_15651 = None
        add_476: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15652, view_959);  slice_15652 = view_959 = None
        
        # No stacktrace found for following nodes
        slice_tensor_948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1895, 1, 3792, 3808)
        slice_scatter_default_1896: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_948, add_476, 2, 0, 16);  slice_tensor_948 = add_476 = None
        slice_scatter_default_1897: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1895, slice_scatter_default_1896, 1, 3792, 3808);  slice_scatter_default_1895 = slice_scatter_default_1896 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1897, 1, 3792, 3808)
        slice_15657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15656, 2, 0, 16);  slice_15656 = None
        
        # No stacktrace found for following nodes
        slice_tensor_949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1897, 1, 3792, 3808)
        slice_scatter_default_1898: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_949, slice_15657, 2, 0, 16);  slice_tensor_949 = slice_15657 = None
        slice_scatter_default_1899: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1897, slice_scatter_default_1898, 1, 3792, 3808);  slice_scatter_default_1897 = slice_scatter_default_1898 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15677: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15643, 2, 16, 32);  slice_15643 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_478: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15677, memory_format = torch.contiguous_format);  slice_15677 = None
        view_960: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_478, [32, 11]);  clone_478 = None
        mm_475: "f32[32, 8]" = torch.ops.aten.mm.default(view_960, slice_37)
        view_961: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_475, [2, 16, 8]);  mm_475 = None
        slice_15684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1899, 1, 3792, 3808)
        slice_15685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15684, 2, 0, 16);  slice_15684 = None
        add_477: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15685, view_961);  slice_15685 = view_961 = None
        
        # No stacktrace found for following nodes
        slice_tensor_950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1899, 1, 3792, 3808)
        slice_scatter_default_1900: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_950, add_477, 2, 0, 16);  slice_tensor_950 = add_477 = None
        slice_scatter_default_1901: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1899, slice_scatter_default_1900, 1, 3792, 3808);  slice_scatter_default_1899 = slice_scatter_default_1900 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1901, 1, 3792, 3808)
        slice_15690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15689, 2, 0, 16);  slice_15689 = None
        
        # No stacktrace found for following nodes
        slice_tensor_951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1901, 1, 3792, 3808)
        slice_scatter_default_1902: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_951, slice_15690, 2, 0, 16);  slice_tensor_951 = slice_15690 = None
        slice_scatter_default_1903: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1901, slice_scatter_default_1902, 1, 3792, 3808);  slice_scatter_default_1901 = slice_scatter_default_1902 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15709: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3808, 3824)
        slice_15710: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15709, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_479: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15710, memory_format = torch.contiguous_format);  slice_15710 = None
        view_962: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_479, [32, 16]);  clone_479 = None
        mm_476: "f32[32, 8]" = torch.ops.aten.mm.default(view_962, slice_7)
        view_963: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_476, [2, 16, 8]);  mm_476 = None
        slice_15717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1903, 1, 3808, 3824)
        slice_15718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15717, 2, 0, 16);  slice_15717 = None
        add_478: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15718, view_963);  slice_15718 = view_963 = None
        
        # No stacktrace found for following nodes
        slice_tensor_952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1903, 1, 3808, 3824)
        slice_scatter_default_1904: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_952, add_478, 2, 0, 16);  slice_tensor_952 = add_478 = None
        slice_scatter_default_1905: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1903, slice_scatter_default_1904, 1, 3808, 3824);  slice_scatter_default_1903 = slice_scatter_default_1904 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1905, 1, 3808, 3824)
        slice_15723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15722, 2, 0, 16);  slice_15722 = None
        
        # No stacktrace found for following nodes
        slice_tensor_953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1905, 1, 3808, 3824)
        slice_scatter_default_1906: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_953, slice_15723, 2, 0, 16);  slice_tensor_953 = slice_15723 = None
        slice_scatter_default_1907: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1905, slice_scatter_default_1906, 1, 3808, 3824);  slice_scatter_default_1905 = slice_scatter_default_1906 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15743: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15709, 2, 16, 32);  slice_15709 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_480: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15743, memory_format = torch.contiguous_format);  slice_15743 = None
        view_964: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_480, [32, 11]);  clone_480 = None
        mm_477: "f32[32, 8]" = torch.ops.aten.mm.default(view_964, slice_37)
        view_965: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_477, [2, 16, 8]);  mm_477 = None
        slice_15750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1907, 1, 3808, 3824)
        slice_15751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15750, 2, 0, 16);  slice_15750 = None
        add_479: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15751, view_965);  slice_15751 = view_965 = None
        
        # No stacktrace found for following nodes
        slice_tensor_954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1907, 1, 3808, 3824)
        slice_scatter_default_1908: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_954, add_479, 2, 0, 16);  slice_tensor_954 = add_479 = None
        slice_scatter_default_1909: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1907, slice_scatter_default_1908, 1, 3808, 3824);  slice_scatter_default_1907 = slice_scatter_default_1908 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1909, 1, 3808, 3824)
        slice_15756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15755, 2, 0, 16);  slice_15755 = None
        
        # No stacktrace found for following nodes
        slice_tensor_955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1909, 1, 3808, 3824)
        slice_scatter_default_1910: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_955, slice_15756, 2, 0, 16);  slice_tensor_955 = slice_15756 = None
        slice_scatter_default_1911: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1909, slice_scatter_default_1910, 1, 3808, 3824);  slice_scatter_default_1909 = slice_scatter_default_1910 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15775: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3824, 3840)
        slice_15776: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15775, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_481: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15776, memory_format = torch.contiguous_format);  slice_15776 = None
        view_966: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_481, [32, 16]);  clone_481 = None
        mm_478: "f32[32, 8]" = torch.ops.aten.mm.default(view_966, slice_7)
        view_967: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_478, [2, 16, 8]);  mm_478 = None
        slice_15783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1911, 1, 3824, 3840)
        slice_15784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15783, 2, 0, 16);  slice_15783 = None
        add_480: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15784, view_967);  slice_15784 = view_967 = None
        
        # No stacktrace found for following nodes
        slice_tensor_956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1911, 1, 3824, 3840)
        slice_scatter_default_1912: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_956, add_480, 2, 0, 16);  slice_tensor_956 = add_480 = None
        slice_scatter_default_1913: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1911, slice_scatter_default_1912, 1, 3824, 3840);  slice_scatter_default_1911 = slice_scatter_default_1912 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1913, 1, 3824, 3840)
        slice_15789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15788, 2, 0, 16);  slice_15788 = None
        
        # No stacktrace found for following nodes
        slice_tensor_957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1913, 1, 3824, 3840)
        slice_scatter_default_1914: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_957, slice_15789, 2, 0, 16);  slice_tensor_957 = slice_15789 = None
        slice_scatter_default_1915: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1913, slice_scatter_default_1914, 1, 3824, 3840);  slice_scatter_default_1913 = slice_scatter_default_1914 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15809: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15775, 2, 16, 32);  slice_15775 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_482: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15809, memory_format = torch.contiguous_format);  slice_15809 = None
        view_968: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_482, [32, 11]);  clone_482 = None
        mm_479: "f32[32, 8]" = torch.ops.aten.mm.default(view_968, slice_37)
        view_969: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_479, [2, 16, 8]);  mm_479 = None
        slice_15816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1915, 1, 3824, 3840)
        slice_15817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15816, 2, 0, 16);  slice_15816 = None
        add_481: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15817, view_969);  slice_15817 = view_969 = None
        
        # No stacktrace found for following nodes
        slice_tensor_958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1915, 1, 3824, 3840)
        slice_scatter_default_1916: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_958, add_481, 2, 0, 16);  slice_tensor_958 = add_481 = None
        slice_scatter_default_1917: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1915, slice_scatter_default_1916, 1, 3824, 3840);  slice_scatter_default_1915 = slice_scatter_default_1916 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1917, 1, 3824, 3840)
        slice_15822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15821, 2, 0, 16);  slice_15821 = None
        
        # No stacktrace found for following nodes
        slice_tensor_959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1917, 1, 3824, 3840)
        slice_scatter_default_1918: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_959, slice_15822, 2, 0, 16);  slice_tensor_959 = slice_15822 = None
        slice_scatter_default_1919: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1917, slice_scatter_default_1918, 1, 3824, 3840);  slice_scatter_default_1917 = slice_scatter_default_1918 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15841: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3840, 3856)
        slice_15842: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15841, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_483: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15842, memory_format = torch.contiguous_format);  slice_15842 = None
        view_970: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_483, [32, 16]);  clone_483 = None
        mm_480: "f32[32, 8]" = torch.ops.aten.mm.default(view_970, slice_7)
        view_971: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_480, [2, 16, 8]);  mm_480 = None
        slice_15849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1919, 1, 3840, 3856)
        slice_15850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15849, 2, 0, 16);  slice_15849 = None
        add_482: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15850, view_971);  slice_15850 = view_971 = None
        
        # No stacktrace found for following nodes
        slice_tensor_960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1919, 1, 3840, 3856)
        slice_scatter_default_1920: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_960, add_482, 2, 0, 16);  slice_tensor_960 = add_482 = None
        slice_scatter_default_1921: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1919, slice_scatter_default_1920, 1, 3840, 3856);  slice_scatter_default_1919 = slice_scatter_default_1920 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1921, 1, 3840, 3856)
        slice_15855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15854, 2, 0, 16);  slice_15854 = None
        
        # No stacktrace found for following nodes
        slice_tensor_961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1921, 1, 3840, 3856)
        slice_scatter_default_1922: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_961, slice_15855, 2, 0, 16);  slice_tensor_961 = slice_15855 = None
        slice_scatter_default_1923: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1921, slice_scatter_default_1922, 1, 3840, 3856);  slice_scatter_default_1921 = slice_scatter_default_1922 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15875: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15841, 2, 16, 32);  slice_15841 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_484: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15875, memory_format = torch.contiguous_format);  slice_15875 = None
        view_972: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_484, [32, 11]);  clone_484 = None
        mm_481: "f32[32, 8]" = torch.ops.aten.mm.default(view_972, slice_37)
        view_973: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_481, [2, 16, 8]);  mm_481 = None
        slice_15882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1923, 1, 3840, 3856)
        slice_15883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15882, 2, 0, 16);  slice_15882 = None
        add_483: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15883, view_973);  slice_15883 = view_973 = None
        
        # No stacktrace found for following nodes
        slice_tensor_962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1923, 1, 3840, 3856)
        slice_scatter_default_1924: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_962, add_483, 2, 0, 16);  slice_tensor_962 = add_483 = None
        slice_scatter_default_1925: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1923, slice_scatter_default_1924, 1, 3840, 3856);  slice_scatter_default_1923 = slice_scatter_default_1924 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1925, 1, 3840, 3856)
        slice_15888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15887, 2, 0, 16);  slice_15887 = None
        
        # No stacktrace found for following nodes
        slice_tensor_963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1925, 1, 3840, 3856)
        slice_scatter_default_1926: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_963, slice_15888, 2, 0, 16);  slice_tensor_963 = slice_15888 = None
        slice_scatter_default_1927: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1925, slice_scatter_default_1926, 1, 3840, 3856);  slice_scatter_default_1925 = slice_scatter_default_1926 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15907: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3856, 3872)
        slice_15908: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15907, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_485: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15908, memory_format = torch.contiguous_format);  slice_15908 = None
        view_974: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_485, [32, 16]);  clone_485 = None
        mm_482: "f32[32, 8]" = torch.ops.aten.mm.default(view_974, slice_7)
        view_975: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_482, [2, 16, 8]);  mm_482 = None
        slice_15915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1927, 1, 3856, 3872)
        slice_15916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15915, 2, 0, 16);  slice_15915 = None
        add_484: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15916, view_975);  slice_15916 = view_975 = None
        
        # No stacktrace found for following nodes
        slice_tensor_964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1927, 1, 3856, 3872)
        slice_scatter_default_1928: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_964, add_484, 2, 0, 16);  slice_tensor_964 = add_484 = None
        slice_scatter_default_1929: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1927, slice_scatter_default_1928, 1, 3856, 3872);  slice_scatter_default_1927 = slice_scatter_default_1928 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1929, 1, 3856, 3872)
        slice_15921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15920, 2, 0, 16);  slice_15920 = None
        
        # No stacktrace found for following nodes
        slice_tensor_965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1929, 1, 3856, 3872)
        slice_scatter_default_1930: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_965, slice_15921, 2, 0, 16);  slice_tensor_965 = slice_15921 = None
        slice_scatter_default_1931: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1929, slice_scatter_default_1930, 1, 3856, 3872);  slice_scatter_default_1929 = slice_scatter_default_1930 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15941: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15907, 2, 16, 32);  slice_15907 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_486: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_15941, memory_format = torch.contiguous_format);  slice_15941 = None
        view_976: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_486, [32, 11]);  clone_486 = None
        mm_483: "f32[32, 8]" = torch.ops.aten.mm.default(view_976, slice_37)
        view_977: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_483, [2, 16, 8]);  mm_483 = None
        slice_15948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1931, 1, 3856, 3872)
        slice_15949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15948, 2, 0, 16);  slice_15948 = None
        add_485: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15949, view_977);  slice_15949 = view_977 = None
        
        # No stacktrace found for following nodes
        slice_tensor_966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1931, 1, 3856, 3872)
        slice_scatter_default_1932: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_966, add_485, 2, 0, 16);  slice_tensor_966 = add_485 = None
        slice_scatter_default_1933: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1931, slice_scatter_default_1932, 1, 3856, 3872);  slice_scatter_default_1931 = slice_scatter_default_1932 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1933, 1, 3856, 3872)
        slice_15954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15953, 2, 0, 16);  slice_15953 = None
        
        # No stacktrace found for following nodes
        slice_tensor_967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1933, 1, 3856, 3872)
        slice_scatter_default_1934: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_967, slice_15954, 2, 0, 16);  slice_tensor_967 = slice_15954 = None
        slice_scatter_default_1935: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1933, slice_scatter_default_1934, 1, 3856, 3872);  slice_scatter_default_1933 = slice_scatter_default_1934 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_15973: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3872, 3888)
        slice_15974: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_15973, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_487: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_15974, memory_format = torch.contiguous_format);  slice_15974 = None
        view_978: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_487, [32, 16]);  clone_487 = None
        mm_484: "f32[32, 8]" = torch.ops.aten.mm.default(view_978, slice_7)
        view_979: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_484, [2, 16, 8]);  mm_484 = None
        slice_15981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1935, 1, 3872, 3888)
        slice_15982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15981, 2, 0, 16);  slice_15981 = None
        add_486: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_15982, view_979);  slice_15982 = view_979 = None
        
        # No stacktrace found for following nodes
        slice_tensor_968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1935, 1, 3872, 3888)
        slice_scatter_default_1936: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_968, add_486, 2, 0, 16);  slice_tensor_968 = add_486 = None
        slice_scatter_default_1937: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1935, slice_scatter_default_1936, 1, 3872, 3888);  slice_scatter_default_1935 = slice_scatter_default_1936 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_15986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1937, 1, 3872, 3888)
        slice_15987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_15986, 2, 0, 16);  slice_15986 = None
        
        # No stacktrace found for following nodes
        slice_tensor_969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1937, 1, 3872, 3888)
        slice_scatter_default_1938: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_969, slice_15987, 2, 0, 16);  slice_tensor_969 = slice_15987 = None
        slice_scatter_default_1939: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1937, slice_scatter_default_1938, 1, 3872, 3888);  slice_scatter_default_1937 = slice_scatter_default_1938 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16007: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_15973, 2, 16, 32);  slice_15973 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_488: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16007, memory_format = torch.contiguous_format);  slice_16007 = None
        view_980: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_488, [32, 11]);  clone_488 = None
        mm_485: "f32[32, 8]" = torch.ops.aten.mm.default(view_980, slice_37)
        view_981: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_485, [2, 16, 8]);  mm_485 = None
        slice_16014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1939, 1, 3872, 3888)
        slice_16015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16014, 2, 0, 16);  slice_16014 = None
        add_487: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16015, view_981);  slice_16015 = view_981 = None
        
        # No stacktrace found for following nodes
        slice_tensor_970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1939, 1, 3872, 3888)
        slice_scatter_default_1940: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_970, add_487, 2, 0, 16);  slice_tensor_970 = add_487 = None
        slice_scatter_default_1941: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1939, slice_scatter_default_1940, 1, 3872, 3888);  slice_scatter_default_1939 = slice_scatter_default_1940 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1941, 1, 3872, 3888)
        slice_16020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16019, 2, 0, 16);  slice_16019 = None
        
        # No stacktrace found for following nodes
        slice_tensor_971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1941, 1, 3872, 3888)
        slice_scatter_default_1942: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_971, slice_16020, 2, 0, 16);  slice_tensor_971 = slice_16020 = None
        slice_scatter_default_1943: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1941, slice_scatter_default_1942, 1, 3872, 3888);  slice_scatter_default_1941 = slice_scatter_default_1942 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16039: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3888, 3904)
        slice_16040: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16039, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_489: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16040, memory_format = torch.contiguous_format);  slice_16040 = None
        view_982: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_489, [32, 16]);  clone_489 = None
        mm_486: "f32[32, 8]" = torch.ops.aten.mm.default(view_982, slice_7)
        view_983: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_486, [2, 16, 8]);  mm_486 = None
        slice_16047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1943, 1, 3888, 3904)
        slice_16048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16047, 2, 0, 16);  slice_16047 = None
        add_488: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16048, view_983);  slice_16048 = view_983 = None
        
        # No stacktrace found for following nodes
        slice_tensor_972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1943, 1, 3888, 3904)
        slice_scatter_default_1944: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_972, add_488, 2, 0, 16);  slice_tensor_972 = add_488 = None
        slice_scatter_default_1945: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1943, slice_scatter_default_1944, 1, 3888, 3904);  slice_scatter_default_1943 = slice_scatter_default_1944 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1945, 1, 3888, 3904)
        slice_16053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16052, 2, 0, 16);  slice_16052 = None
        
        # No stacktrace found for following nodes
        slice_tensor_973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1945, 1, 3888, 3904)
        slice_scatter_default_1946: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_973, slice_16053, 2, 0, 16);  slice_tensor_973 = slice_16053 = None
        slice_scatter_default_1947: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1945, slice_scatter_default_1946, 1, 3888, 3904);  slice_scatter_default_1945 = slice_scatter_default_1946 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16073: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16039, 2, 16, 32);  slice_16039 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_490: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16073, memory_format = torch.contiguous_format);  slice_16073 = None
        view_984: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_490, [32, 11]);  clone_490 = None
        mm_487: "f32[32, 8]" = torch.ops.aten.mm.default(view_984, slice_37)
        view_985: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_487, [2, 16, 8]);  mm_487 = None
        slice_16080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1947, 1, 3888, 3904)
        slice_16081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16080, 2, 0, 16);  slice_16080 = None
        add_489: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16081, view_985);  slice_16081 = view_985 = None
        
        # No stacktrace found for following nodes
        slice_tensor_974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1947, 1, 3888, 3904)
        slice_scatter_default_1948: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_974, add_489, 2, 0, 16);  slice_tensor_974 = add_489 = None
        slice_scatter_default_1949: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1947, slice_scatter_default_1948, 1, 3888, 3904);  slice_scatter_default_1947 = slice_scatter_default_1948 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1949, 1, 3888, 3904)
        slice_16086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16085, 2, 0, 16);  slice_16085 = None
        
        # No stacktrace found for following nodes
        slice_tensor_975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1949, 1, 3888, 3904)
        slice_scatter_default_1950: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_975, slice_16086, 2, 0, 16);  slice_tensor_975 = slice_16086 = None
        slice_scatter_default_1951: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1949, slice_scatter_default_1950, 1, 3888, 3904);  slice_scatter_default_1949 = slice_scatter_default_1950 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16105: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3904, 3920)
        slice_16106: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16105, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_491: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16106, memory_format = torch.contiguous_format);  slice_16106 = None
        view_986: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_491, [32, 16]);  clone_491 = None
        mm_488: "f32[32, 8]" = torch.ops.aten.mm.default(view_986, slice_7)
        view_987: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_488, [2, 16, 8]);  mm_488 = None
        slice_16113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1951, 1, 3904, 3920)
        slice_16114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16113, 2, 0, 16);  slice_16113 = None
        add_490: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16114, view_987);  slice_16114 = view_987 = None
        
        # No stacktrace found for following nodes
        slice_tensor_976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1951, 1, 3904, 3920)
        slice_scatter_default_1952: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_976, add_490, 2, 0, 16);  slice_tensor_976 = add_490 = None
        slice_scatter_default_1953: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1951, slice_scatter_default_1952, 1, 3904, 3920);  slice_scatter_default_1951 = slice_scatter_default_1952 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1953, 1, 3904, 3920)
        slice_16119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16118, 2, 0, 16);  slice_16118 = None
        
        # No stacktrace found for following nodes
        slice_tensor_977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1953, 1, 3904, 3920)
        slice_scatter_default_1954: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_977, slice_16119, 2, 0, 16);  slice_tensor_977 = slice_16119 = None
        slice_scatter_default_1955: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1953, slice_scatter_default_1954, 1, 3904, 3920);  slice_scatter_default_1953 = slice_scatter_default_1954 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16139: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16105, 2, 16, 32);  slice_16105 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_492: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16139, memory_format = torch.contiguous_format);  slice_16139 = None
        view_988: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_492, [32, 11]);  clone_492 = None
        mm_489: "f32[32, 8]" = torch.ops.aten.mm.default(view_988, slice_37)
        view_989: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_489, [2, 16, 8]);  mm_489 = None
        slice_16146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1955, 1, 3904, 3920)
        slice_16147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16146, 2, 0, 16);  slice_16146 = None
        add_491: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16147, view_989);  slice_16147 = view_989 = None
        
        # No stacktrace found for following nodes
        slice_tensor_978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1955, 1, 3904, 3920)
        slice_scatter_default_1956: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_978, add_491, 2, 0, 16);  slice_tensor_978 = add_491 = None
        slice_scatter_default_1957: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1955, slice_scatter_default_1956, 1, 3904, 3920);  slice_scatter_default_1955 = slice_scatter_default_1956 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1957, 1, 3904, 3920)
        slice_16152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16151, 2, 0, 16);  slice_16151 = None
        
        # No stacktrace found for following nodes
        slice_tensor_979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1957, 1, 3904, 3920)
        slice_scatter_default_1958: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_979, slice_16152, 2, 0, 16);  slice_tensor_979 = slice_16152 = None
        slice_scatter_default_1959: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1957, slice_scatter_default_1958, 1, 3904, 3920);  slice_scatter_default_1957 = slice_scatter_default_1958 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16171: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3920, 3936)
        slice_16172: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16171, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_493: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16172, memory_format = torch.contiguous_format);  slice_16172 = None
        view_990: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_493, [32, 16]);  clone_493 = None
        mm_490: "f32[32, 8]" = torch.ops.aten.mm.default(view_990, slice_7)
        view_991: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_490, [2, 16, 8]);  mm_490 = None
        slice_16179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1959, 1, 3920, 3936)
        slice_16180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16179, 2, 0, 16);  slice_16179 = None
        add_492: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16180, view_991);  slice_16180 = view_991 = None
        
        # No stacktrace found for following nodes
        slice_tensor_980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1959, 1, 3920, 3936)
        slice_scatter_default_1960: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_980, add_492, 2, 0, 16);  slice_tensor_980 = add_492 = None
        slice_scatter_default_1961: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1959, slice_scatter_default_1960, 1, 3920, 3936);  slice_scatter_default_1959 = slice_scatter_default_1960 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1961, 1, 3920, 3936)
        slice_16185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16184, 2, 0, 16);  slice_16184 = None
        
        # No stacktrace found for following nodes
        slice_tensor_981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1961, 1, 3920, 3936)
        slice_scatter_default_1962: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_981, slice_16185, 2, 0, 16);  slice_tensor_981 = slice_16185 = None
        slice_scatter_default_1963: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1961, slice_scatter_default_1962, 1, 3920, 3936);  slice_scatter_default_1961 = slice_scatter_default_1962 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16205: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16171, 2, 16, 32);  slice_16171 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_494: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16205, memory_format = torch.contiguous_format);  slice_16205 = None
        view_992: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_494, [32, 11]);  clone_494 = None
        mm_491: "f32[32, 8]" = torch.ops.aten.mm.default(view_992, slice_37)
        view_993: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_491, [2, 16, 8]);  mm_491 = None
        slice_16212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1963, 1, 3920, 3936)
        slice_16213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16212, 2, 0, 16);  slice_16212 = None
        add_493: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16213, view_993);  slice_16213 = view_993 = None
        
        # No stacktrace found for following nodes
        slice_tensor_982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1963, 1, 3920, 3936)
        slice_scatter_default_1964: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_982, add_493, 2, 0, 16);  slice_tensor_982 = add_493 = None
        slice_scatter_default_1965: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1963, slice_scatter_default_1964, 1, 3920, 3936);  slice_scatter_default_1963 = slice_scatter_default_1964 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1965, 1, 3920, 3936)
        slice_16218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16217, 2, 0, 16);  slice_16217 = None
        
        # No stacktrace found for following nodes
        slice_tensor_983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1965, 1, 3920, 3936)
        slice_scatter_default_1966: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_983, slice_16218, 2, 0, 16);  slice_tensor_983 = slice_16218 = None
        slice_scatter_default_1967: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1965, slice_scatter_default_1966, 1, 3920, 3936);  slice_scatter_default_1965 = slice_scatter_default_1966 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16237: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3936, 3952)
        slice_16238: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16237, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_495: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16238, memory_format = torch.contiguous_format);  slice_16238 = None
        view_994: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_495, [32, 16]);  clone_495 = None
        mm_492: "f32[32, 8]" = torch.ops.aten.mm.default(view_994, slice_7)
        view_995: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_492, [2, 16, 8]);  mm_492 = None
        slice_16245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1967, 1, 3936, 3952)
        slice_16246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16245, 2, 0, 16);  slice_16245 = None
        add_494: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16246, view_995);  slice_16246 = view_995 = None
        
        # No stacktrace found for following nodes
        slice_tensor_984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1967, 1, 3936, 3952)
        slice_scatter_default_1968: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_984, add_494, 2, 0, 16);  slice_tensor_984 = add_494 = None
        slice_scatter_default_1969: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1967, slice_scatter_default_1968, 1, 3936, 3952);  slice_scatter_default_1967 = slice_scatter_default_1968 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1969, 1, 3936, 3952)
        slice_16251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16250, 2, 0, 16);  slice_16250 = None
        
        # No stacktrace found for following nodes
        slice_tensor_985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1969, 1, 3936, 3952)
        slice_scatter_default_1970: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_985, slice_16251, 2, 0, 16);  slice_tensor_985 = slice_16251 = None
        slice_scatter_default_1971: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1969, slice_scatter_default_1970, 1, 3936, 3952);  slice_scatter_default_1969 = slice_scatter_default_1970 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16271: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16237, 2, 16, 32);  slice_16237 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_496: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16271, memory_format = torch.contiguous_format);  slice_16271 = None
        view_996: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_496, [32, 11]);  clone_496 = None
        mm_493: "f32[32, 8]" = torch.ops.aten.mm.default(view_996, slice_37)
        view_997: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_493, [2, 16, 8]);  mm_493 = None
        slice_16278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1971, 1, 3936, 3952)
        slice_16279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16278, 2, 0, 16);  slice_16278 = None
        add_495: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16279, view_997);  slice_16279 = view_997 = None
        
        # No stacktrace found for following nodes
        slice_tensor_986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1971, 1, 3936, 3952)
        slice_scatter_default_1972: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_986, add_495, 2, 0, 16);  slice_tensor_986 = add_495 = None
        slice_scatter_default_1973: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1971, slice_scatter_default_1972, 1, 3936, 3952);  slice_scatter_default_1971 = slice_scatter_default_1972 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1973, 1, 3936, 3952)
        slice_16284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16283, 2, 0, 16);  slice_16283 = None
        
        # No stacktrace found for following nodes
        slice_tensor_987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1973, 1, 3936, 3952)
        slice_scatter_default_1974: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_987, slice_16284, 2, 0, 16);  slice_tensor_987 = slice_16284 = None
        slice_scatter_default_1975: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1973, slice_scatter_default_1974, 1, 3936, 3952);  slice_scatter_default_1973 = slice_scatter_default_1974 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16303: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3952, 3968)
        slice_16304: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16303, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_497: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16304, memory_format = torch.contiguous_format);  slice_16304 = None
        view_998: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_497, [32, 16]);  clone_497 = None
        mm_494: "f32[32, 8]" = torch.ops.aten.mm.default(view_998, slice_7)
        view_999: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_494, [2, 16, 8]);  mm_494 = None
        slice_16311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1975, 1, 3952, 3968)
        slice_16312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16311, 2, 0, 16);  slice_16311 = None
        add_496: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16312, view_999);  slice_16312 = view_999 = None
        
        # No stacktrace found for following nodes
        slice_tensor_988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1975, 1, 3952, 3968)
        slice_scatter_default_1976: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_988, add_496, 2, 0, 16);  slice_tensor_988 = add_496 = None
        slice_scatter_default_1977: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1975, slice_scatter_default_1976, 1, 3952, 3968);  slice_scatter_default_1975 = slice_scatter_default_1976 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1977, 1, 3952, 3968)
        slice_16317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16316, 2, 0, 16);  slice_16316 = None
        
        # No stacktrace found for following nodes
        slice_tensor_989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1977, 1, 3952, 3968)
        slice_scatter_default_1978: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_989, slice_16317, 2, 0, 16);  slice_tensor_989 = slice_16317 = None
        slice_scatter_default_1979: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1977, slice_scatter_default_1978, 1, 3952, 3968);  slice_scatter_default_1977 = slice_scatter_default_1978 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16337: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16303, 2, 16, 32);  slice_16303 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_498: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16337, memory_format = torch.contiguous_format);  slice_16337 = None
        view_1000: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_498, [32, 11]);  clone_498 = None
        mm_495: "f32[32, 8]" = torch.ops.aten.mm.default(view_1000, slice_37)
        view_1001: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_495, [2, 16, 8]);  mm_495 = None
        slice_16344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1979, 1, 3952, 3968)
        slice_16345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16344, 2, 0, 16);  slice_16344 = None
        add_497: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16345, view_1001);  slice_16345 = view_1001 = None
        
        # No stacktrace found for following nodes
        slice_tensor_990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1979, 1, 3952, 3968)
        slice_scatter_default_1980: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_990, add_497, 2, 0, 16);  slice_tensor_990 = add_497 = None
        slice_scatter_default_1981: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1979, slice_scatter_default_1980, 1, 3952, 3968);  slice_scatter_default_1979 = slice_scatter_default_1980 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1981, 1, 3952, 3968)
        slice_16350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16349, 2, 0, 16);  slice_16349 = None
        
        # No stacktrace found for following nodes
        slice_tensor_991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1981, 1, 3952, 3968)
        slice_scatter_default_1982: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_991, slice_16350, 2, 0, 16);  slice_tensor_991 = slice_16350 = None
        slice_scatter_default_1983: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1981, slice_scatter_default_1982, 1, 3952, 3968);  slice_scatter_default_1981 = slice_scatter_default_1982 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16369: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3968, 3984)
        slice_16370: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16369, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_499: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16370, memory_format = torch.contiguous_format);  slice_16370 = None
        view_1002: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_499, [32, 16]);  clone_499 = None
        mm_496: "f32[32, 8]" = torch.ops.aten.mm.default(view_1002, slice_7)
        view_1003: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_496, [2, 16, 8]);  mm_496 = None
        slice_16377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1983, 1, 3968, 3984)
        slice_16378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16377, 2, 0, 16);  slice_16377 = None
        add_498: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16378, view_1003);  slice_16378 = view_1003 = None
        
        # No stacktrace found for following nodes
        slice_tensor_992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1983, 1, 3968, 3984)
        slice_scatter_default_1984: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_992, add_498, 2, 0, 16);  slice_tensor_992 = add_498 = None
        slice_scatter_default_1985: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1983, slice_scatter_default_1984, 1, 3968, 3984);  slice_scatter_default_1983 = slice_scatter_default_1984 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1985, 1, 3968, 3984)
        slice_16383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16382, 2, 0, 16);  slice_16382 = None
        
        # No stacktrace found for following nodes
        slice_tensor_993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1985, 1, 3968, 3984)
        slice_scatter_default_1986: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_993, slice_16383, 2, 0, 16);  slice_tensor_993 = slice_16383 = None
        slice_scatter_default_1987: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1985, slice_scatter_default_1986, 1, 3968, 3984);  slice_scatter_default_1985 = slice_scatter_default_1986 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16403: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16369, 2, 16, 32);  slice_16369 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_500: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16403, memory_format = torch.contiguous_format);  slice_16403 = None
        view_1004: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_500, [32, 11]);  clone_500 = None
        mm_497: "f32[32, 8]" = torch.ops.aten.mm.default(view_1004, slice_37)
        view_1005: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_497, [2, 16, 8]);  mm_497 = None
        slice_16410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1987, 1, 3968, 3984)
        slice_16411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16410, 2, 0, 16);  slice_16410 = None
        add_499: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16411, view_1005);  slice_16411 = view_1005 = None
        
        # No stacktrace found for following nodes
        slice_tensor_994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1987, 1, 3968, 3984)
        slice_scatter_default_1988: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_994, add_499, 2, 0, 16);  slice_tensor_994 = add_499 = None
        slice_scatter_default_1989: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1987, slice_scatter_default_1988, 1, 3968, 3984);  slice_scatter_default_1987 = slice_scatter_default_1988 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1989, 1, 3968, 3984)
        slice_16416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16415, 2, 0, 16);  slice_16415 = None
        
        # No stacktrace found for following nodes
        slice_tensor_995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1989, 1, 3968, 3984)
        slice_scatter_default_1990: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_995, slice_16416, 2, 0, 16);  slice_tensor_995 = slice_16416 = None
        slice_scatter_default_1991: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1989, slice_scatter_default_1990, 1, 3968, 3984);  slice_scatter_default_1989 = slice_scatter_default_1990 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16435: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 3984, 4000)
        slice_16436: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16435, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_501: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16436, memory_format = torch.contiguous_format);  slice_16436 = None
        view_1006: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_501, [32, 16]);  clone_501 = None
        mm_498: "f32[32, 8]" = torch.ops.aten.mm.default(view_1006, slice_7)
        view_1007: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_498, [2, 16, 8]);  mm_498 = None
        slice_16443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1991, 1, 3984, 4000)
        slice_16444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16443, 2, 0, 16);  slice_16443 = None
        add_500: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16444, view_1007);  slice_16444 = view_1007 = None
        
        # No stacktrace found for following nodes
        slice_tensor_996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1991, 1, 3984, 4000)
        slice_scatter_default_1992: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_996, add_500, 2, 0, 16);  slice_tensor_996 = add_500 = None
        slice_scatter_default_1993: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1991, slice_scatter_default_1992, 1, 3984, 4000);  slice_scatter_default_1991 = slice_scatter_default_1992 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1993, 1, 3984, 4000)
        slice_16449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16448, 2, 0, 16);  slice_16448 = None
        
        # No stacktrace found for following nodes
        slice_tensor_997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1993, 1, 3984, 4000)
        slice_scatter_default_1994: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_997, slice_16449, 2, 0, 16);  slice_tensor_997 = slice_16449 = None
        slice_scatter_default_1995: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1993, slice_scatter_default_1994, 1, 3984, 4000);  slice_scatter_default_1993 = slice_scatter_default_1994 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16469: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16435, 2, 16, 32);  slice_16435 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_502: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16469, memory_format = torch.contiguous_format);  slice_16469 = None
        view_1008: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_502, [32, 11]);  clone_502 = None
        mm_499: "f32[32, 8]" = torch.ops.aten.mm.default(view_1008, slice_37)
        view_1009: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_499, [2, 16, 8]);  mm_499 = None
        slice_16476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1995, 1, 3984, 4000)
        slice_16477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16476, 2, 0, 16);  slice_16476 = None
        add_501: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16477, view_1009);  slice_16477 = view_1009 = None
        
        # No stacktrace found for following nodes
        slice_tensor_998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1995, 1, 3984, 4000)
        slice_scatter_default_1996: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_998, add_501, 2, 0, 16);  slice_tensor_998 = add_501 = None
        slice_scatter_default_1997: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1995, slice_scatter_default_1996, 1, 3984, 4000);  slice_scatter_default_1995 = slice_scatter_default_1996 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1997, 1, 3984, 4000)
        slice_16482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16481, 2, 0, 16);  slice_16481 = None
        
        # No stacktrace found for following nodes
        slice_tensor_999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1997, 1, 3984, 4000)
        slice_scatter_default_1998: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_999, slice_16482, 2, 0, 16);  slice_tensor_999 = slice_16482 = None
        slice_scatter_default_1999: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1997, slice_scatter_default_1998, 1, 3984, 4000);  slice_scatter_default_1997 = slice_scatter_default_1998 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16501: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4000, 4016)
        slice_16502: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16501, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_503: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16502, memory_format = torch.contiguous_format);  slice_16502 = None
        view_1010: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_503, [32, 16]);  clone_503 = None
        mm_500: "f32[32, 8]" = torch.ops.aten.mm.default(view_1010, slice_7)
        view_1011: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_500, [2, 16, 8]);  mm_500 = None
        slice_16509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1999, 1, 4000, 4016)
        slice_16510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16509, 2, 0, 16);  slice_16509 = None
        add_502: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16510, view_1011);  slice_16510 = view_1011 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_1999, 1, 4000, 4016)
        slice_scatter_default_2000: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1000, add_502, 2, 0, 16);  slice_tensor_1000 = add_502 = None
        slice_scatter_default_2001: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_1999, slice_scatter_default_2000, 1, 4000, 4016);  slice_scatter_default_1999 = slice_scatter_default_2000 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2001, 1, 4000, 4016)
        slice_16515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16514, 2, 0, 16);  slice_16514 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2001, 1, 4000, 4016)
        slice_scatter_default_2002: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1001, slice_16515, 2, 0, 16);  slice_tensor_1001 = slice_16515 = None
        slice_scatter_default_2003: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2001, slice_scatter_default_2002, 1, 4000, 4016);  slice_scatter_default_2001 = slice_scatter_default_2002 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16535: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16501, 2, 16, 32);  slice_16501 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_504: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16535, memory_format = torch.contiguous_format);  slice_16535 = None
        view_1012: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_504, [32, 11]);  clone_504 = None
        mm_501: "f32[32, 8]" = torch.ops.aten.mm.default(view_1012, slice_37)
        view_1013: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_501, [2, 16, 8]);  mm_501 = None
        slice_16542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2003, 1, 4000, 4016)
        slice_16543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16542, 2, 0, 16);  slice_16542 = None
        add_503: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16543, view_1013);  slice_16543 = view_1013 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2003, 1, 4000, 4016)
        slice_scatter_default_2004: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1002, add_503, 2, 0, 16);  slice_tensor_1002 = add_503 = None
        slice_scatter_default_2005: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2003, slice_scatter_default_2004, 1, 4000, 4016);  slice_scatter_default_2003 = slice_scatter_default_2004 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2005, 1, 4000, 4016)
        slice_16548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16547, 2, 0, 16);  slice_16547 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2005, 1, 4000, 4016)
        slice_scatter_default_2006: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1003, slice_16548, 2, 0, 16);  slice_tensor_1003 = slice_16548 = None
        slice_scatter_default_2007: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2005, slice_scatter_default_2006, 1, 4000, 4016);  slice_scatter_default_2005 = slice_scatter_default_2006 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16567: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4016, 4032)
        slice_16568: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16567, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_505: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16568, memory_format = torch.contiguous_format);  slice_16568 = None
        view_1014: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_505, [32, 16]);  clone_505 = None
        mm_502: "f32[32, 8]" = torch.ops.aten.mm.default(view_1014, slice_7)
        view_1015: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_502, [2, 16, 8]);  mm_502 = None
        slice_16575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2007, 1, 4016, 4032)
        slice_16576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16575, 2, 0, 16);  slice_16575 = None
        add_504: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16576, view_1015);  slice_16576 = view_1015 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2007, 1, 4016, 4032)
        slice_scatter_default_2008: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1004, add_504, 2, 0, 16);  slice_tensor_1004 = add_504 = None
        slice_scatter_default_2009: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2007, slice_scatter_default_2008, 1, 4016, 4032);  slice_scatter_default_2007 = slice_scatter_default_2008 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2009, 1, 4016, 4032)
        slice_16581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16580, 2, 0, 16);  slice_16580 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2009, 1, 4016, 4032)
        slice_scatter_default_2010: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1005, slice_16581, 2, 0, 16);  slice_tensor_1005 = slice_16581 = None
        slice_scatter_default_2011: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2009, slice_scatter_default_2010, 1, 4016, 4032);  slice_scatter_default_2009 = slice_scatter_default_2010 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16601: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16567, 2, 16, 32);  slice_16567 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_506: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16601, memory_format = torch.contiguous_format);  slice_16601 = None
        view_1016: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_506, [32, 11]);  clone_506 = None
        mm_503: "f32[32, 8]" = torch.ops.aten.mm.default(view_1016, slice_37)
        view_1017: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_503, [2, 16, 8]);  mm_503 = None
        slice_16608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2011, 1, 4016, 4032)
        slice_16609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16608, 2, 0, 16);  slice_16608 = None
        add_505: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16609, view_1017);  slice_16609 = view_1017 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2011, 1, 4016, 4032)
        slice_scatter_default_2012: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1006, add_505, 2, 0, 16);  slice_tensor_1006 = add_505 = None
        slice_scatter_default_2013: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2011, slice_scatter_default_2012, 1, 4016, 4032);  slice_scatter_default_2011 = slice_scatter_default_2012 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2013, 1, 4016, 4032)
        slice_16614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16613, 2, 0, 16);  slice_16613 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2013, 1, 4016, 4032)
        slice_scatter_default_2014: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1007, slice_16614, 2, 0, 16);  slice_tensor_1007 = slice_16614 = None
        slice_scatter_default_2015: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2013, slice_scatter_default_2014, 1, 4016, 4032);  slice_scatter_default_2013 = slice_scatter_default_2014 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16633: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4032, 4048)
        slice_16634: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16633, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_507: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16634, memory_format = torch.contiguous_format);  slice_16634 = None
        view_1018: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_507, [32, 16]);  clone_507 = None
        mm_504: "f32[32, 8]" = torch.ops.aten.mm.default(view_1018, slice_7)
        view_1019: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_504, [2, 16, 8]);  mm_504 = None
        slice_16641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2015, 1, 4032, 4048)
        slice_16642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16641, 2, 0, 16);  slice_16641 = None
        add_506: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16642, view_1019);  slice_16642 = view_1019 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2015, 1, 4032, 4048)
        slice_scatter_default_2016: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1008, add_506, 2, 0, 16);  slice_tensor_1008 = add_506 = None
        slice_scatter_default_2017: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2015, slice_scatter_default_2016, 1, 4032, 4048);  slice_scatter_default_2015 = slice_scatter_default_2016 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2017, 1, 4032, 4048)
        slice_16647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16646, 2, 0, 16);  slice_16646 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2017, 1, 4032, 4048)
        slice_scatter_default_2018: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1009, slice_16647, 2, 0, 16);  slice_tensor_1009 = slice_16647 = None
        slice_scatter_default_2019: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2017, slice_scatter_default_2018, 1, 4032, 4048);  slice_scatter_default_2017 = slice_scatter_default_2018 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16667: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16633, 2, 16, 32);  slice_16633 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_508: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16667, memory_format = torch.contiguous_format);  slice_16667 = None
        view_1020: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_508, [32, 11]);  clone_508 = None
        mm_505: "f32[32, 8]" = torch.ops.aten.mm.default(view_1020, slice_37)
        view_1021: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_505, [2, 16, 8]);  mm_505 = None
        slice_16674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2019, 1, 4032, 4048)
        slice_16675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16674, 2, 0, 16);  slice_16674 = None
        add_507: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16675, view_1021);  slice_16675 = view_1021 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2019, 1, 4032, 4048)
        slice_scatter_default_2020: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1010, add_507, 2, 0, 16);  slice_tensor_1010 = add_507 = None
        slice_scatter_default_2021: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2019, slice_scatter_default_2020, 1, 4032, 4048);  slice_scatter_default_2019 = slice_scatter_default_2020 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2021, 1, 4032, 4048)
        slice_16680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16679, 2, 0, 16);  slice_16679 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2021, 1, 4032, 4048)
        slice_scatter_default_2022: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1011, slice_16680, 2, 0, 16);  slice_tensor_1011 = slice_16680 = None
        slice_scatter_default_2023: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2021, slice_scatter_default_2022, 1, 4032, 4048);  slice_scatter_default_2021 = slice_scatter_default_2022 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16699: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4048, 4064)
        slice_16700: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16699, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_509: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16700, memory_format = torch.contiguous_format);  slice_16700 = None
        view_1022: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_509, [32, 16]);  clone_509 = None
        mm_506: "f32[32, 8]" = torch.ops.aten.mm.default(view_1022, slice_7)
        view_1023: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_506, [2, 16, 8]);  mm_506 = None
        slice_16707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2023, 1, 4048, 4064)
        slice_16708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16707, 2, 0, 16);  slice_16707 = None
        add_508: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16708, view_1023);  slice_16708 = view_1023 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2023, 1, 4048, 4064)
        slice_scatter_default_2024: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1012, add_508, 2, 0, 16);  slice_tensor_1012 = add_508 = None
        slice_scatter_default_2025: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2023, slice_scatter_default_2024, 1, 4048, 4064);  slice_scatter_default_2023 = slice_scatter_default_2024 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2025, 1, 4048, 4064)
        slice_16713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16712, 2, 0, 16);  slice_16712 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2025, 1, 4048, 4064)
        slice_scatter_default_2026: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1013, slice_16713, 2, 0, 16);  slice_tensor_1013 = slice_16713 = None
        slice_scatter_default_2027: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2025, slice_scatter_default_2026, 1, 4048, 4064);  slice_scatter_default_2025 = slice_scatter_default_2026 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16733: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16699, 2, 16, 32);  slice_16699 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_510: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16733, memory_format = torch.contiguous_format);  slice_16733 = None
        view_1024: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_510, [32, 11]);  clone_510 = None
        mm_507: "f32[32, 8]" = torch.ops.aten.mm.default(view_1024, slice_37)
        view_1025: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_507, [2, 16, 8]);  mm_507 = None
        slice_16740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2027, 1, 4048, 4064)
        slice_16741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16740, 2, 0, 16);  slice_16740 = None
        add_509: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16741, view_1025);  slice_16741 = view_1025 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2027, 1, 4048, 4064)
        slice_scatter_default_2028: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1014, add_509, 2, 0, 16);  slice_tensor_1014 = add_509 = None
        slice_scatter_default_2029: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2027, slice_scatter_default_2028, 1, 4048, 4064);  slice_scatter_default_2027 = slice_scatter_default_2028 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2029, 1, 4048, 4064)
        slice_16746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16745, 2, 0, 16);  slice_16745 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2029, 1, 4048, 4064)
        slice_scatter_default_2030: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1015, slice_16746, 2, 0, 16);  slice_tensor_1015 = slice_16746 = None
        slice_scatter_default_2031: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2029, slice_scatter_default_2030, 1, 4048, 4064);  slice_scatter_default_2029 = slice_scatter_default_2030 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16765: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4064, 4080)
        slice_16766: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16765, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_511: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16766, memory_format = torch.contiguous_format);  slice_16766 = None
        view_1026: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_511, [32, 16]);  clone_511 = None
        mm_508: "f32[32, 8]" = torch.ops.aten.mm.default(view_1026, slice_7)
        view_1027: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_508, [2, 16, 8]);  mm_508 = None
        slice_16773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2031, 1, 4064, 4080)
        slice_16774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16773, 2, 0, 16);  slice_16773 = None
        add_510: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16774, view_1027);  slice_16774 = view_1027 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2031, 1, 4064, 4080)
        slice_scatter_default_2032: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1016, add_510, 2, 0, 16);  slice_tensor_1016 = add_510 = None
        slice_scatter_default_2033: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2031, slice_scatter_default_2032, 1, 4064, 4080);  slice_scatter_default_2031 = slice_scatter_default_2032 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2033, 1, 4064, 4080)
        slice_16779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16778, 2, 0, 16);  slice_16778 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2033, 1, 4064, 4080)
        slice_scatter_default_2034: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1017, slice_16779, 2, 0, 16);  slice_tensor_1017 = slice_16779 = None
        slice_scatter_default_2035: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2033, slice_scatter_default_2034, 1, 4064, 4080);  slice_scatter_default_2033 = slice_scatter_default_2034 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16799: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16765, 2, 16, 32);  slice_16765 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_512: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16799, memory_format = torch.contiguous_format);  slice_16799 = None
        view_1028: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_512, [32, 11]);  clone_512 = None
        mm_509: "f32[32, 8]" = torch.ops.aten.mm.default(view_1028, slice_37)
        view_1029: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_509, [2, 16, 8]);  mm_509 = None
        slice_16806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2035, 1, 4064, 4080)
        slice_16807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16806, 2, 0, 16);  slice_16806 = None
        add_511: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16807, view_1029);  slice_16807 = view_1029 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2035, 1, 4064, 4080)
        slice_scatter_default_2036: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1018, add_511, 2, 0, 16);  slice_tensor_1018 = add_511 = None
        slice_scatter_default_2037: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2035, slice_scatter_default_2036, 1, 4064, 4080);  slice_scatter_default_2035 = slice_scatter_default_2036 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2037, 1, 4064, 4080)
        slice_16812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16811, 2, 0, 16);  slice_16811 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2037, 1, 4064, 4080)
        slice_scatter_default_2038: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1019, slice_16812, 2, 0, 16);  slice_tensor_1019 = slice_16812 = None
        slice_scatter_default_2039: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2037, slice_scatter_default_2038, 1, 4064, 4080);  slice_scatter_default_2037 = slice_scatter_default_2038 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16831: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4080, 4096)
        slice_16832: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16831, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_513: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16832, memory_format = torch.contiguous_format);  slice_16832 = None
        view_1030: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_513, [32, 16]);  clone_513 = None
        mm_510: "f32[32, 8]" = torch.ops.aten.mm.default(view_1030, slice_7)
        view_1031: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_510, [2, 16, 8]);  mm_510 = None
        slice_16839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2039, 1, 4080, 4096)
        slice_16840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16839, 2, 0, 16);  slice_16839 = None
        add_512: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16840, view_1031);  slice_16840 = view_1031 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2039, 1, 4080, 4096)
        slice_scatter_default_2040: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1020, add_512, 2, 0, 16);  slice_tensor_1020 = add_512 = None
        slice_scatter_default_2041: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2039, slice_scatter_default_2040, 1, 4080, 4096);  slice_scatter_default_2039 = slice_scatter_default_2040 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2041, 1, 4080, 4096)
        slice_16845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16844, 2, 0, 16);  slice_16844 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2041, 1, 4080, 4096)
        slice_scatter_default_2042: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1021, slice_16845, 2, 0, 16);  slice_tensor_1021 = slice_16845 = None
        slice_scatter_default_2043: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2041, slice_scatter_default_2042, 1, 4080, 4096);  slice_scatter_default_2041 = slice_scatter_default_2042 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16865: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16831, 2, 16, 32);  slice_16831 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_514: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16865, memory_format = torch.contiguous_format);  slice_16865 = None
        view_1032: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_514, [32, 11]);  clone_514 = None
        mm_511: "f32[32, 8]" = torch.ops.aten.mm.default(view_1032, slice_37)
        view_1033: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_511, [2, 16, 8]);  mm_511 = None
        slice_16872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2043, 1, 4080, 4096)
        slice_16873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16872, 2, 0, 16);  slice_16872 = None
        add_513: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16873, view_1033);  slice_16873 = view_1033 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2043, 1, 4080, 4096)
        slice_scatter_default_2044: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1022, add_513, 2, 0, 16);  slice_tensor_1022 = add_513 = None
        slice_scatter_default_2045: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2043, slice_scatter_default_2044, 1, 4080, 4096);  slice_scatter_default_2043 = slice_scatter_default_2044 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2045, 1, 4080, 4096)
        slice_16878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16877, 2, 0, 16);  slice_16877 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2045, 1, 4080, 4096)
        slice_scatter_default_2046: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1023, slice_16878, 2, 0, 16);  slice_tensor_1023 = slice_16878 = None
        slice_scatter_default_2047: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2045, slice_scatter_default_2046, 1, 4080, 4096);  slice_scatter_default_2045 = slice_scatter_default_2046 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16897: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4096, 4112)
        slice_16898: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16897, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_515: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16898, memory_format = torch.contiguous_format);  slice_16898 = None
        view_1034: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_515, [32, 16]);  clone_515 = None
        mm_512: "f32[32, 8]" = torch.ops.aten.mm.default(view_1034, slice_7)
        view_1035: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_512, [2, 16, 8]);  mm_512 = None
        slice_16905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2047, 1, 4096, 4112)
        slice_16906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16905, 2, 0, 16);  slice_16905 = None
        add_514: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16906, view_1035);  slice_16906 = view_1035 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2047, 1, 4096, 4112)
        slice_scatter_default_2048: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1024, add_514, 2, 0, 16);  slice_tensor_1024 = add_514 = None
        slice_scatter_default_2049: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2047, slice_scatter_default_2048, 1, 4096, 4112);  slice_scatter_default_2047 = slice_scatter_default_2048 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2049, 1, 4096, 4112)
        slice_16911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16910, 2, 0, 16);  slice_16910 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2049, 1, 4096, 4112)
        slice_scatter_default_2050: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1025, slice_16911, 2, 0, 16);  slice_tensor_1025 = slice_16911 = None
        slice_scatter_default_2051: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2049, slice_scatter_default_2050, 1, 4096, 4112);  slice_scatter_default_2049 = slice_scatter_default_2050 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16931: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16897, 2, 16, 32);  slice_16897 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_516: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16931, memory_format = torch.contiguous_format);  slice_16931 = None
        view_1036: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_516, [32, 11]);  clone_516 = None
        mm_513: "f32[32, 8]" = torch.ops.aten.mm.default(view_1036, slice_37)
        view_1037: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_513, [2, 16, 8]);  mm_513 = None
        slice_16938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2051, 1, 4096, 4112)
        slice_16939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16938, 2, 0, 16);  slice_16938 = None
        add_515: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16939, view_1037);  slice_16939 = view_1037 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2051, 1, 4096, 4112)
        slice_scatter_default_2052: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1026, add_515, 2, 0, 16);  slice_tensor_1026 = add_515 = None
        slice_scatter_default_2053: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2051, slice_scatter_default_2052, 1, 4096, 4112);  slice_scatter_default_2051 = slice_scatter_default_2052 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2053, 1, 4096, 4112)
        slice_16944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16943, 2, 0, 16);  slice_16943 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2053, 1, 4096, 4112)
        slice_scatter_default_2054: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1027, slice_16944, 2, 0, 16);  slice_tensor_1027 = slice_16944 = None
        slice_scatter_default_2055: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2053, slice_scatter_default_2054, 1, 4096, 4112);  slice_scatter_default_2053 = slice_scatter_default_2054 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16963: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4112, 4128)
        slice_16964: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_16963, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_517: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_16964, memory_format = torch.contiguous_format);  slice_16964 = None
        view_1038: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_517, [32, 16]);  clone_517 = None
        mm_514: "f32[32, 8]" = torch.ops.aten.mm.default(view_1038, slice_7)
        view_1039: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_514, [2, 16, 8]);  mm_514 = None
        slice_16971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2055, 1, 4112, 4128)
        slice_16972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16971, 2, 0, 16);  slice_16971 = None
        add_516: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_16972, view_1039);  slice_16972 = view_1039 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2055, 1, 4112, 4128)
        slice_scatter_default_2056: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1028, add_516, 2, 0, 16);  slice_tensor_1028 = add_516 = None
        slice_scatter_default_2057: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2055, slice_scatter_default_2056, 1, 4112, 4128);  slice_scatter_default_2055 = slice_scatter_default_2056 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_16976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2057, 1, 4112, 4128)
        slice_16977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_16976, 2, 0, 16);  slice_16976 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2057, 1, 4112, 4128)
        slice_scatter_default_2058: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1029, slice_16977, 2, 0, 16);  slice_tensor_1029 = slice_16977 = None
        slice_scatter_default_2059: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2057, slice_scatter_default_2058, 1, 4112, 4128);  slice_scatter_default_2057 = slice_scatter_default_2058 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_16997: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_16963, 2, 16, 32);  slice_16963 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_518: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_16997, memory_format = torch.contiguous_format);  slice_16997 = None
        view_1040: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_518, [32, 11]);  clone_518 = None
        mm_515: "f32[32, 8]" = torch.ops.aten.mm.default(view_1040, slice_37)
        view_1041: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_515, [2, 16, 8]);  mm_515 = None
        slice_17004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2059, 1, 4112, 4128)
        slice_17005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17004, 2, 0, 16);  slice_17004 = None
        add_517: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17005, view_1041);  slice_17005 = view_1041 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2059, 1, 4112, 4128)
        slice_scatter_default_2060: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1030, add_517, 2, 0, 16);  slice_tensor_1030 = add_517 = None
        slice_scatter_default_2061: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2059, slice_scatter_default_2060, 1, 4112, 4128);  slice_scatter_default_2059 = slice_scatter_default_2060 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2061, 1, 4112, 4128)
        slice_17010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17009, 2, 0, 16);  slice_17009 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2061, 1, 4112, 4128)
        slice_scatter_default_2062: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1031, slice_17010, 2, 0, 16);  slice_tensor_1031 = slice_17010 = None
        slice_scatter_default_2063: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2061, slice_scatter_default_2062, 1, 4112, 4128);  slice_scatter_default_2061 = slice_scatter_default_2062 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17029: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4128, 4144)
        slice_17030: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17029, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_519: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17030, memory_format = torch.contiguous_format);  slice_17030 = None
        view_1042: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_519, [32, 16]);  clone_519 = None
        mm_516: "f32[32, 8]" = torch.ops.aten.mm.default(view_1042, slice_7)
        view_1043: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_516, [2, 16, 8]);  mm_516 = None
        slice_17037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2063, 1, 4128, 4144)
        slice_17038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17037, 2, 0, 16);  slice_17037 = None
        add_518: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17038, view_1043);  slice_17038 = view_1043 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2063, 1, 4128, 4144)
        slice_scatter_default_2064: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1032, add_518, 2, 0, 16);  slice_tensor_1032 = add_518 = None
        slice_scatter_default_2065: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2063, slice_scatter_default_2064, 1, 4128, 4144);  slice_scatter_default_2063 = slice_scatter_default_2064 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2065, 1, 4128, 4144)
        slice_17043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17042, 2, 0, 16);  slice_17042 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2065, 1, 4128, 4144)
        slice_scatter_default_2066: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1033, slice_17043, 2, 0, 16);  slice_tensor_1033 = slice_17043 = None
        slice_scatter_default_2067: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2065, slice_scatter_default_2066, 1, 4128, 4144);  slice_scatter_default_2065 = slice_scatter_default_2066 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17063: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17029, 2, 16, 32);  slice_17029 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_520: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17063, memory_format = torch.contiguous_format);  slice_17063 = None
        view_1044: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_520, [32, 11]);  clone_520 = None
        mm_517: "f32[32, 8]" = torch.ops.aten.mm.default(view_1044, slice_37)
        view_1045: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_517, [2, 16, 8]);  mm_517 = None
        slice_17070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2067, 1, 4128, 4144)
        slice_17071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17070, 2, 0, 16);  slice_17070 = None
        add_519: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17071, view_1045);  slice_17071 = view_1045 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2067, 1, 4128, 4144)
        slice_scatter_default_2068: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1034, add_519, 2, 0, 16);  slice_tensor_1034 = add_519 = None
        slice_scatter_default_2069: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2067, slice_scatter_default_2068, 1, 4128, 4144);  slice_scatter_default_2067 = slice_scatter_default_2068 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2069, 1, 4128, 4144)
        slice_17076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17075, 2, 0, 16);  slice_17075 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2069, 1, 4128, 4144)
        slice_scatter_default_2070: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1035, slice_17076, 2, 0, 16);  slice_tensor_1035 = slice_17076 = None
        slice_scatter_default_2071: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2069, slice_scatter_default_2070, 1, 4128, 4144);  slice_scatter_default_2069 = slice_scatter_default_2070 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17095: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4144, 4160)
        slice_17096: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17095, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_521: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17096, memory_format = torch.contiguous_format);  slice_17096 = None
        view_1046: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_521, [32, 16]);  clone_521 = None
        mm_518: "f32[32, 8]" = torch.ops.aten.mm.default(view_1046, slice_7)
        view_1047: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_518, [2, 16, 8]);  mm_518 = None
        slice_17103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2071, 1, 4144, 4160)
        slice_17104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17103, 2, 0, 16);  slice_17103 = None
        add_520: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17104, view_1047);  slice_17104 = view_1047 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2071, 1, 4144, 4160)
        slice_scatter_default_2072: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1036, add_520, 2, 0, 16);  slice_tensor_1036 = add_520 = None
        slice_scatter_default_2073: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2071, slice_scatter_default_2072, 1, 4144, 4160);  slice_scatter_default_2071 = slice_scatter_default_2072 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2073, 1, 4144, 4160)
        slice_17109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17108, 2, 0, 16);  slice_17108 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2073, 1, 4144, 4160)
        slice_scatter_default_2074: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1037, slice_17109, 2, 0, 16);  slice_tensor_1037 = slice_17109 = None
        slice_scatter_default_2075: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2073, slice_scatter_default_2074, 1, 4144, 4160);  slice_scatter_default_2073 = slice_scatter_default_2074 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17129: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17095, 2, 16, 32);  slice_17095 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_522: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17129, memory_format = torch.contiguous_format);  slice_17129 = None
        view_1048: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_522, [32, 11]);  clone_522 = None
        mm_519: "f32[32, 8]" = torch.ops.aten.mm.default(view_1048, slice_37)
        view_1049: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_519, [2, 16, 8]);  mm_519 = None
        slice_17136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2075, 1, 4144, 4160)
        slice_17137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17136, 2, 0, 16);  slice_17136 = None
        add_521: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17137, view_1049);  slice_17137 = view_1049 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2075, 1, 4144, 4160)
        slice_scatter_default_2076: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1038, add_521, 2, 0, 16);  slice_tensor_1038 = add_521 = None
        slice_scatter_default_2077: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2075, slice_scatter_default_2076, 1, 4144, 4160);  slice_scatter_default_2075 = slice_scatter_default_2076 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2077, 1, 4144, 4160)
        slice_17142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17141, 2, 0, 16);  slice_17141 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2077, 1, 4144, 4160)
        slice_scatter_default_2078: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1039, slice_17142, 2, 0, 16);  slice_tensor_1039 = slice_17142 = None
        slice_scatter_default_2079: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2077, slice_scatter_default_2078, 1, 4144, 4160);  slice_scatter_default_2077 = slice_scatter_default_2078 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17161: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4160, 4176)
        slice_17162: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17161, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_523: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17162, memory_format = torch.contiguous_format);  slice_17162 = None
        view_1050: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_523, [32, 16]);  clone_523 = None
        mm_520: "f32[32, 8]" = torch.ops.aten.mm.default(view_1050, slice_7)
        view_1051: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_520, [2, 16, 8]);  mm_520 = None
        slice_17169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2079, 1, 4160, 4176)
        slice_17170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17169, 2, 0, 16);  slice_17169 = None
        add_522: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17170, view_1051);  slice_17170 = view_1051 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2079, 1, 4160, 4176)
        slice_scatter_default_2080: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1040, add_522, 2, 0, 16);  slice_tensor_1040 = add_522 = None
        slice_scatter_default_2081: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2079, slice_scatter_default_2080, 1, 4160, 4176);  slice_scatter_default_2079 = slice_scatter_default_2080 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2081, 1, 4160, 4176)
        slice_17175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17174, 2, 0, 16);  slice_17174 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2081, 1, 4160, 4176)
        slice_scatter_default_2082: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1041, slice_17175, 2, 0, 16);  slice_tensor_1041 = slice_17175 = None
        slice_scatter_default_2083: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2081, slice_scatter_default_2082, 1, 4160, 4176);  slice_scatter_default_2081 = slice_scatter_default_2082 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17195: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17161, 2, 16, 32);  slice_17161 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_524: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17195, memory_format = torch.contiguous_format);  slice_17195 = None
        view_1052: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_524, [32, 11]);  clone_524 = None
        mm_521: "f32[32, 8]" = torch.ops.aten.mm.default(view_1052, slice_37)
        view_1053: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_521, [2, 16, 8]);  mm_521 = None
        slice_17202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2083, 1, 4160, 4176)
        slice_17203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17202, 2, 0, 16);  slice_17202 = None
        add_523: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17203, view_1053);  slice_17203 = view_1053 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2083, 1, 4160, 4176)
        slice_scatter_default_2084: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1042, add_523, 2, 0, 16);  slice_tensor_1042 = add_523 = None
        slice_scatter_default_2085: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2083, slice_scatter_default_2084, 1, 4160, 4176);  slice_scatter_default_2083 = slice_scatter_default_2084 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2085, 1, 4160, 4176)
        slice_17208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17207, 2, 0, 16);  slice_17207 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2085, 1, 4160, 4176)
        slice_scatter_default_2086: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1043, slice_17208, 2, 0, 16);  slice_tensor_1043 = slice_17208 = None
        slice_scatter_default_2087: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2085, slice_scatter_default_2086, 1, 4160, 4176);  slice_scatter_default_2085 = slice_scatter_default_2086 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17227: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4176, 4192)
        slice_17228: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17227, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_525: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17228, memory_format = torch.contiguous_format);  slice_17228 = None
        view_1054: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_525, [32, 16]);  clone_525 = None
        mm_522: "f32[32, 8]" = torch.ops.aten.mm.default(view_1054, slice_7)
        view_1055: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_522, [2, 16, 8]);  mm_522 = None
        slice_17235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2087, 1, 4176, 4192)
        slice_17236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17235, 2, 0, 16);  slice_17235 = None
        add_524: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17236, view_1055);  slice_17236 = view_1055 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2087, 1, 4176, 4192)
        slice_scatter_default_2088: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1044, add_524, 2, 0, 16);  slice_tensor_1044 = add_524 = None
        slice_scatter_default_2089: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2087, slice_scatter_default_2088, 1, 4176, 4192);  slice_scatter_default_2087 = slice_scatter_default_2088 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2089, 1, 4176, 4192)
        slice_17241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17240, 2, 0, 16);  slice_17240 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2089, 1, 4176, 4192)
        slice_scatter_default_2090: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1045, slice_17241, 2, 0, 16);  slice_tensor_1045 = slice_17241 = None
        slice_scatter_default_2091: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2089, slice_scatter_default_2090, 1, 4176, 4192);  slice_scatter_default_2089 = slice_scatter_default_2090 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17261: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17227, 2, 16, 32);  slice_17227 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_526: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17261, memory_format = torch.contiguous_format);  slice_17261 = None
        view_1056: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_526, [32, 11]);  clone_526 = None
        mm_523: "f32[32, 8]" = torch.ops.aten.mm.default(view_1056, slice_37)
        view_1057: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_523, [2, 16, 8]);  mm_523 = None
        slice_17268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2091, 1, 4176, 4192)
        slice_17269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17268, 2, 0, 16);  slice_17268 = None
        add_525: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17269, view_1057);  slice_17269 = view_1057 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2091, 1, 4176, 4192)
        slice_scatter_default_2092: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1046, add_525, 2, 0, 16);  slice_tensor_1046 = add_525 = None
        slice_scatter_default_2093: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2091, slice_scatter_default_2092, 1, 4176, 4192);  slice_scatter_default_2091 = slice_scatter_default_2092 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2093, 1, 4176, 4192)
        slice_17274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17273, 2, 0, 16);  slice_17273 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2093, 1, 4176, 4192)
        slice_scatter_default_2094: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1047, slice_17274, 2, 0, 16);  slice_tensor_1047 = slice_17274 = None
        slice_scatter_default_2095: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2093, slice_scatter_default_2094, 1, 4176, 4192);  slice_scatter_default_2093 = slice_scatter_default_2094 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17293: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4192, 4208)
        slice_17294: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17293, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_527: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17294, memory_format = torch.contiguous_format);  slice_17294 = None
        view_1058: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_527, [32, 16]);  clone_527 = None
        mm_524: "f32[32, 8]" = torch.ops.aten.mm.default(view_1058, slice_7)
        view_1059: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_524, [2, 16, 8]);  mm_524 = None
        slice_17301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2095, 1, 4192, 4208)
        slice_17302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17301, 2, 0, 16);  slice_17301 = None
        add_526: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17302, view_1059);  slice_17302 = view_1059 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2095, 1, 4192, 4208)
        slice_scatter_default_2096: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1048, add_526, 2, 0, 16);  slice_tensor_1048 = add_526 = None
        slice_scatter_default_2097: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2095, slice_scatter_default_2096, 1, 4192, 4208);  slice_scatter_default_2095 = slice_scatter_default_2096 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2097, 1, 4192, 4208)
        slice_17307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17306, 2, 0, 16);  slice_17306 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2097, 1, 4192, 4208)
        slice_scatter_default_2098: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1049, slice_17307, 2, 0, 16);  slice_tensor_1049 = slice_17307 = None
        slice_scatter_default_2099: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2097, slice_scatter_default_2098, 1, 4192, 4208);  slice_scatter_default_2097 = slice_scatter_default_2098 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17327: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17293, 2, 16, 32);  slice_17293 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_528: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17327, memory_format = torch.contiguous_format);  slice_17327 = None
        view_1060: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_528, [32, 11]);  clone_528 = None
        mm_525: "f32[32, 8]" = torch.ops.aten.mm.default(view_1060, slice_37)
        view_1061: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_525, [2, 16, 8]);  mm_525 = None
        slice_17334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2099, 1, 4192, 4208)
        slice_17335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17334, 2, 0, 16);  slice_17334 = None
        add_527: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17335, view_1061);  slice_17335 = view_1061 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2099, 1, 4192, 4208)
        slice_scatter_default_2100: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1050, add_527, 2, 0, 16);  slice_tensor_1050 = add_527 = None
        slice_scatter_default_2101: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2099, slice_scatter_default_2100, 1, 4192, 4208);  slice_scatter_default_2099 = slice_scatter_default_2100 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2101, 1, 4192, 4208)
        slice_17340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17339, 2, 0, 16);  slice_17339 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2101, 1, 4192, 4208)
        slice_scatter_default_2102: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1051, slice_17340, 2, 0, 16);  slice_tensor_1051 = slice_17340 = None
        slice_scatter_default_2103: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2101, slice_scatter_default_2102, 1, 4192, 4208);  slice_scatter_default_2101 = slice_scatter_default_2102 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17359: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4208, 4224)
        slice_17360: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17359, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_529: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17360, memory_format = torch.contiguous_format);  slice_17360 = None
        view_1062: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_529, [32, 16]);  clone_529 = None
        mm_526: "f32[32, 8]" = torch.ops.aten.mm.default(view_1062, slice_7)
        view_1063: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_526, [2, 16, 8]);  mm_526 = None
        slice_17367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2103, 1, 4208, 4224)
        slice_17368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17367, 2, 0, 16);  slice_17367 = None
        add_528: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17368, view_1063);  slice_17368 = view_1063 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2103, 1, 4208, 4224)
        slice_scatter_default_2104: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1052, add_528, 2, 0, 16);  slice_tensor_1052 = add_528 = None
        slice_scatter_default_2105: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2103, slice_scatter_default_2104, 1, 4208, 4224);  slice_scatter_default_2103 = slice_scatter_default_2104 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2105, 1, 4208, 4224)
        slice_17373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17372, 2, 0, 16);  slice_17372 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2105, 1, 4208, 4224)
        slice_scatter_default_2106: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1053, slice_17373, 2, 0, 16);  slice_tensor_1053 = slice_17373 = None
        slice_scatter_default_2107: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2105, slice_scatter_default_2106, 1, 4208, 4224);  slice_scatter_default_2105 = slice_scatter_default_2106 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17393: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17359, 2, 16, 32);  slice_17359 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_530: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17393, memory_format = torch.contiguous_format);  slice_17393 = None
        view_1064: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_530, [32, 11]);  clone_530 = None
        mm_527: "f32[32, 8]" = torch.ops.aten.mm.default(view_1064, slice_37)
        view_1065: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_527, [2, 16, 8]);  mm_527 = None
        slice_17400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2107, 1, 4208, 4224)
        slice_17401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17400, 2, 0, 16);  slice_17400 = None
        add_529: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17401, view_1065);  slice_17401 = view_1065 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2107, 1, 4208, 4224)
        slice_scatter_default_2108: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1054, add_529, 2, 0, 16);  slice_tensor_1054 = add_529 = None
        slice_scatter_default_2109: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2107, slice_scatter_default_2108, 1, 4208, 4224);  slice_scatter_default_2107 = slice_scatter_default_2108 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2109, 1, 4208, 4224)
        slice_17406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17405, 2, 0, 16);  slice_17405 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2109, 1, 4208, 4224)
        slice_scatter_default_2110: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1055, slice_17406, 2, 0, 16);  slice_tensor_1055 = slice_17406 = None
        slice_scatter_default_2111: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2109, slice_scatter_default_2110, 1, 4208, 4224);  slice_scatter_default_2109 = slice_scatter_default_2110 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17425: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4224, 4240)
        slice_17426: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17425, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_531: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17426, memory_format = torch.contiguous_format);  slice_17426 = None
        view_1066: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_531, [32, 16]);  clone_531 = None
        mm_528: "f32[32, 8]" = torch.ops.aten.mm.default(view_1066, slice_7)
        view_1067: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_528, [2, 16, 8]);  mm_528 = None
        slice_17433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2111, 1, 4224, 4240)
        slice_17434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17433, 2, 0, 16);  slice_17433 = None
        add_530: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17434, view_1067);  slice_17434 = view_1067 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2111, 1, 4224, 4240)
        slice_scatter_default_2112: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1056, add_530, 2, 0, 16);  slice_tensor_1056 = add_530 = None
        slice_scatter_default_2113: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2111, slice_scatter_default_2112, 1, 4224, 4240);  slice_scatter_default_2111 = slice_scatter_default_2112 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2113, 1, 4224, 4240)
        slice_17439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17438, 2, 0, 16);  slice_17438 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2113, 1, 4224, 4240)
        slice_scatter_default_2114: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1057, slice_17439, 2, 0, 16);  slice_tensor_1057 = slice_17439 = None
        slice_scatter_default_2115: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2113, slice_scatter_default_2114, 1, 4224, 4240);  slice_scatter_default_2113 = slice_scatter_default_2114 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17459: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17425, 2, 16, 32);  slice_17425 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_532: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17459, memory_format = torch.contiguous_format);  slice_17459 = None
        view_1068: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_532, [32, 11]);  clone_532 = None
        mm_529: "f32[32, 8]" = torch.ops.aten.mm.default(view_1068, slice_37)
        view_1069: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_529, [2, 16, 8]);  mm_529 = None
        slice_17466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2115, 1, 4224, 4240)
        slice_17467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17466, 2, 0, 16);  slice_17466 = None
        add_531: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17467, view_1069);  slice_17467 = view_1069 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2115, 1, 4224, 4240)
        slice_scatter_default_2116: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1058, add_531, 2, 0, 16);  slice_tensor_1058 = add_531 = None
        slice_scatter_default_2117: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2115, slice_scatter_default_2116, 1, 4224, 4240);  slice_scatter_default_2115 = slice_scatter_default_2116 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2117, 1, 4224, 4240)
        slice_17472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17471, 2, 0, 16);  slice_17471 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2117, 1, 4224, 4240)
        slice_scatter_default_2118: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1059, slice_17472, 2, 0, 16);  slice_tensor_1059 = slice_17472 = None
        slice_scatter_default_2119: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2117, slice_scatter_default_2118, 1, 4224, 4240);  slice_scatter_default_2117 = slice_scatter_default_2118 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17491: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4240, 4256)
        slice_17492: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17491, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_533: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17492, memory_format = torch.contiguous_format);  slice_17492 = None
        view_1070: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_533, [32, 16]);  clone_533 = None
        mm_530: "f32[32, 8]" = torch.ops.aten.mm.default(view_1070, slice_7)
        view_1071: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_530, [2, 16, 8]);  mm_530 = None
        slice_17499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2119, 1, 4240, 4256)
        slice_17500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17499, 2, 0, 16);  slice_17499 = None
        add_532: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17500, view_1071);  slice_17500 = view_1071 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2119, 1, 4240, 4256)
        slice_scatter_default_2120: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1060, add_532, 2, 0, 16);  slice_tensor_1060 = add_532 = None
        slice_scatter_default_2121: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2119, slice_scatter_default_2120, 1, 4240, 4256);  slice_scatter_default_2119 = slice_scatter_default_2120 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2121, 1, 4240, 4256)
        slice_17505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17504, 2, 0, 16);  slice_17504 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2121, 1, 4240, 4256)
        slice_scatter_default_2122: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1061, slice_17505, 2, 0, 16);  slice_tensor_1061 = slice_17505 = None
        slice_scatter_default_2123: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2121, slice_scatter_default_2122, 1, 4240, 4256);  slice_scatter_default_2121 = slice_scatter_default_2122 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17525: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17491, 2, 16, 32);  slice_17491 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_534: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17525, memory_format = torch.contiguous_format);  slice_17525 = None
        view_1072: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_534, [32, 11]);  clone_534 = None
        mm_531: "f32[32, 8]" = torch.ops.aten.mm.default(view_1072, slice_37)
        view_1073: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_531, [2, 16, 8]);  mm_531 = None
        slice_17532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2123, 1, 4240, 4256)
        slice_17533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17532, 2, 0, 16);  slice_17532 = None
        add_533: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17533, view_1073);  slice_17533 = view_1073 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2123, 1, 4240, 4256)
        slice_scatter_default_2124: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1062, add_533, 2, 0, 16);  slice_tensor_1062 = add_533 = None
        slice_scatter_default_2125: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2123, slice_scatter_default_2124, 1, 4240, 4256);  slice_scatter_default_2123 = slice_scatter_default_2124 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2125, 1, 4240, 4256)
        slice_17538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17537, 2, 0, 16);  slice_17537 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2125, 1, 4240, 4256)
        slice_scatter_default_2126: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1063, slice_17538, 2, 0, 16);  slice_tensor_1063 = slice_17538 = None
        slice_scatter_default_2127: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2125, slice_scatter_default_2126, 1, 4240, 4256);  slice_scatter_default_2125 = slice_scatter_default_2126 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17557: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4256, 4272)
        slice_17558: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17557, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_535: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17558, memory_format = torch.contiguous_format);  slice_17558 = None
        view_1074: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_535, [32, 16]);  clone_535 = None
        mm_532: "f32[32, 8]" = torch.ops.aten.mm.default(view_1074, slice_7)
        view_1075: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_532, [2, 16, 8]);  mm_532 = None
        slice_17565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2127, 1, 4256, 4272)
        slice_17566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17565, 2, 0, 16);  slice_17565 = None
        add_534: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17566, view_1075);  slice_17566 = view_1075 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2127, 1, 4256, 4272)
        slice_scatter_default_2128: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1064, add_534, 2, 0, 16);  slice_tensor_1064 = add_534 = None
        slice_scatter_default_2129: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2127, slice_scatter_default_2128, 1, 4256, 4272);  slice_scatter_default_2127 = slice_scatter_default_2128 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2129, 1, 4256, 4272)
        slice_17571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17570, 2, 0, 16);  slice_17570 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2129, 1, 4256, 4272)
        slice_scatter_default_2130: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1065, slice_17571, 2, 0, 16);  slice_tensor_1065 = slice_17571 = None
        slice_scatter_default_2131: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2129, slice_scatter_default_2130, 1, 4256, 4272);  slice_scatter_default_2129 = slice_scatter_default_2130 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17591: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17557, 2, 16, 32);  slice_17557 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_536: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17591, memory_format = torch.contiguous_format);  slice_17591 = None
        view_1076: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_536, [32, 11]);  clone_536 = None
        mm_533: "f32[32, 8]" = torch.ops.aten.mm.default(view_1076, slice_37)
        view_1077: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_533, [2, 16, 8]);  mm_533 = None
        slice_17598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2131, 1, 4256, 4272)
        slice_17599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17598, 2, 0, 16);  slice_17598 = None
        add_535: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17599, view_1077);  slice_17599 = view_1077 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2131, 1, 4256, 4272)
        slice_scatter_default_2132: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1066, add_535, 2, 0, 16);  slice_tensor_1066 = add_535 = None
        slice_scatter_default_2133: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2131, slice_scatter_default_2132, 1, 4256, 4272);  slice_scatter_default_2131 = slice_scatter_default_2132 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2133, 1, 4256, 4272)
        slice_17604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17603, 2, 0, 16);  slice_17603 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2133, 1, 4256, 4272)
        slice_scatter_default_2134: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1067, slice_17604, 2, 0, 16);  slice_tensor_1067 = slice_17604 = None
        slice_scatter_default_2135: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2133, slice_scatter_default_2134, 1, 4256, 4272);  slice_scatter_default_2133 = slice_scatter_default_2134 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17623: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4272, 4288)
        slice_17624: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17623, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_537: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17624, memory_format = torch.contiguous_format);  slice_17624 = None
        view_1078: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_537, [32, 16]);  clone_537 = None
        mm_534: "f32[32, 8]" = torch.ops.aten.mm.default(view_1078, slice_7)
        view_1079: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_534, [2, 16, 8]);  mm_534 = None
        slice_17631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2135, 1, 4272, 4288)
        slice_17632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17631, 2, 0, 16);  slice_17631 = None
        add_536: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17632, view_1079);  slice_17632 = view_1079 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2135, 1, 4272, 4288)
        slice_scatter_default_2136: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1068, add_536, 2, 0, 16);  slice_tensor_1068 = add_536 = None
        slice_scatter_default_2137: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2135, slice_scatter_default_2136, 1, 4272, 4288);  slice_scatter_default_2135 = slice_scatter_default_2136 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2137, 1, 4272, 4288)
        slice_17637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17636, 2, 0, 16);  slice_17636 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2137, 1, 4272, 4288)
        slice_scatter_default_2138: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1069, slice_17637, 2, 0, 16);  slice_tensor_1069 = slice_17637 = None
        slice_scatter_default_2139: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2137, slice_scatter_default_2138, 1, 4272, 4288);  slice_scatter_default_2137 = slice_scatter_default_2138 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17657: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17623, 2, 16, 32);  slice_17623 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_538: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17657, memory_format = torch.contiguous_format);  slice_17657 = None
        view_1080: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_538, [32, 11]);  clone_538 = None
        mm_535: "f32[32, 8]" = torch.ops.aten.mm.default(view_1080, slice_37)
        view_1081: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_535, [2, 16, 8]);  mm_535 = None
        slice_17664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2139, 1, 4272, 4288)
        slice_17665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17664, 2, 0, 16);  slice_17664 = None
        add_537: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17665, view_1081);  slice_17665 = view_1081 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2139, 1, 4272, 4288)
        slice_scatter_default_2140: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1070, add_537, 2, 0, 16);  slice_tensor_1070 = add_537 = None
        slice_scatter_default_2141: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2139, slice_scatter_default_2140, 1, 4272, 4288);  slice_scatter_default_2139 = slice_scatter_default_2140 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2141, 1, 4272, 4288)
        slice_17670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17669, 2, 0, 16);  slice_17669 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2141, 1, 4272, 4288)
        slice_scatter_default_2142: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1071, slice_17670, 2, 0, 16);  slice_tensor_1071 = slice_17670 = None
        slice_scatter_default_2143: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2141, slice_scatter_default_2142, 1, 4272, 4288);  slice_scatter_default_2141 = slice_scatter_default_2142 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17689: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4288, 4304)
        slice_17690: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17689, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_539: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17690, memory_format = torch.contiguous_format);  slice_17690 = None
        view_1082: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_539, [32, 16]);  clone_539 = None
        mm_536: "f32[32, 8]" = torch.ops.aten.mm.default(view_1082, slice_7)
        view_1083: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_536, [2, 16, 8]);  mm_536 = None
        slice_17697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2143, 1, 4288, 4304)
        slice_17698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17697, 2, 0, 16);  slice_17697 = None
        add_538: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17698, view_1083);  slice_17698 = view_1083 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2143, 1, 4288, 4304)
        slice_scatter_default_2144: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1072, add_538, 2, 0, 16);  slice_tensor_1072 = add_538 = None
        slice_scatter_default_2145: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2143, slice_scatter_default_2144, 1, 4288, 4304);  slice_scatter_default_2143 = slice_scatter_default_2144 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2145, 1, 4288, 4304)
        slice_17703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17702, 2, 0, 16);  slice_17702 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2145, 1, 4288, 4304)
        slice_scatter_default_2146: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1073, slice_17703, 2, 0, 16);  slice_tensor_1073 = slice_17703 = None
        slice_scatter_default_2147: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2145, slice_scatter_default_2146, 1, 4288, 4304);  slice_scatter_default_2145 = slice_scatter_default_2146 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17723: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17689, 2, 16, 32);  slice_17689 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_540: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17723, memory_format = torch.contiguous_format);  slice_17723 = None
        view_1084: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_540, [32, 11]);  clone_540 = None
        mm_537: "f32[32, 8]" = torch.ops.aten.mm.default(view_1084, slice_37)
        view_1085: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_537, [2, 16, 8]);  mm_537 = None
        slice_17730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2147, 1, 4288, 4304)
        slice_17731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17730, 2, 0, 16);  slice_17730 = None
        add_539: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17731, view_1085);  slice_17731 = view_1085 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2147, 1, 4288, 4304)
        slice_scatter_default_2148: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1074, add_539, 2, 0, 16);  slice_tensor_1074 = add_539 = None
        slice_scatter_default_2149: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2147, slice_scatter_default_2148, 1, 4288, 4304);  slice_scatter_default_2147 = slice_scatter_default_2148 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2149, 1, 4288, 4304)
        slice_17736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17735, 2, 0, 16);  slice_17735 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2149, 1, 4288, 4304)
        slice_scatter_default_2150: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1075, slice_17736, 2, 0, 16);  slice_tensor_1075 = slice_17736 = None
        slice_scatter_default_2151: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2149, slice_scatter_default_2150, 1, 4288, 4304);  slice_scatter_default_2149 = slice_scatter_default_2150 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17755: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4304, 4320)
        slice_17756: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17755, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_541: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17756, memory_format = torch.contiguous_format);  slice_17756 = None
        view_1086: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_541, [32, 16]);  clone_541 = None
        mm_538: "f32[32, 8]" = torch.ops.aten.mm.default(view_1086, slice_7)
        view_1087: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_538, [2, 16, 8]);  mm_538 = None
        slice_17763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2151, 1, 4304, 4320)
        slice_17764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17763, 2, 0, 16);  slice_17763 = None
        add_540: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17764, view_1087);  slice_17764 = view_1087 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2151, 1, 4304, 4320)
        slice_scatter_default_2152: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1076, add_540, 2, 0, 16);  slice_tensor_1076 = add_540 = None
        slice_scatter_default_2153: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2151, slice_scatter_default_2152, 1, 4304, 4320);  slice_scatter_default_2151 = slice_scatter_default_2152 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2153, 1, 4304, 4320)
        slice_17769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17768, 2, 0, 16);  slice_17768 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2153, 1, 4304, 4320)
        slice_scatter_default_2154: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1077, slice_17769, 2, 0, 16);  slice_tensor_1077 = slice_17769 = None
        slice_scatter_default_2155: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2153, slice_scatter_default_2154, 1, 4304, 4320);  slice_scatter_default_2153 = slice_scatter_default_2154 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17789: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17755, 2, 16, 32);  slice_17755 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_542: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17789, memory_format = torch.contiguous_format);  slice_17789 = None
        view_1088: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_542, [32, 11]);  clone_542 = None
        mm_539: "f32[32, 8]" = torch.ops.aten.mm.default(view_1088, slice_37)
        view_1089: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_539, [2, 16, 8]);  mm_539 = None
        slice_17796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2155, 1, 4304, 4320)
        slice_17797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17796, 2, 0, 16);  slice_17796 = None
        add_541: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17797, view_1089);  slice_17797 = view_1089 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2155, 1, 4304, 4320)
        slice_scatter_default_2156: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1078, add_541, 2, 0, 16);  slice_tensor_1078 = add_541 = None
        slice_scatter_default_2157: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2155, slice_scatter_default_2156, 1, 4304, 4320);  slice_scatter_default_2155 = slice_scatter_default_2156 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2157, 1, 4304, 4320)
        slice_17802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17801, 2, 0, 16);  slice_17801 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2157, 1, 4304, 4320)
        slice_scatter_default_2158: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1079, slice_17802, 2, 0, 16);  slice_tensor_1079 = slice_17802 = None
        slice_scatter_default_2159: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2157, slice_scatter_default_2158, 1, 4304, 4320);  slice_scatter_default_2157 = slice_scatter_default_2158 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17821: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4320, 4336)
        slice_17822: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17821, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_543: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17822, memory_format = torch.contiguous_format);  slice_17822 = None
        view_1090: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_543, [32, 16]);  clone_543 = None
        mm_540: "f32[32, 8]" = torch.ops.aten.mm.default(view_1090, slice_7)
        view_1091: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_540, [2, 16, 8]);  mm_540 = None
        slice_17829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2159, 1, 4320, 4336)
        slice_17830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17829, 2, 0, 16);  slice_17829 = None
        add_542: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17830, view_1091);  slice_17830 = view_1091 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2159, 1, 4320, 4336)
        slice_scatter_default_2160: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1080, add_542, 2, 0, 16);  slice_tensor_1080 = add_542 = None
        slice_scatter_default_2161: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2159, slice_scatter_default_2160, 1, 4320, 4336);  slice_scatter_default_2159 = slice_scatter_default_2160 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2161, 1, 4320, 4336)
        slice_17835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17834, 2, 0, 16);  slice_17834 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2161, 1, 4320, 4336)
        slice_scatter_default_2162: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1081, slice_17835, 2, 0, 16);  slice_tensor_1081 = slice_17835 = None
        slice_scatter_default_2163: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2161, slice_scatter_default_2162, 1, 4320, 4336);  slice_scatter_default_2161 = slice_scatter_default_2162 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17855: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17821, 2, 16, 32);  slice_17821 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_544: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17855, memory_format = torch.contiguous_format);  slice_17855 = None
        view_1092: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_544, [32, 11]);  clone_544 = None
        mm_541: "f32[32, 8]" = torch.ops.aten.mm.default(view_1092, slice_37)
        view_1093: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_541, [2, 16, 8]);  mm_541 = None
        slice_17862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2163, 1, 4320, 4336)
        slice_17863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17862, 2, 0, 16);  slice_17862 = None
        add_543: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17863, view_1093);  slice_17863 = view_1093 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2163, 1, 4320, 4336)
        slice_scatter_default_2164: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1082, add_543, 2, 0, 16);  slice_tensor_1082 = add_543 = None
        slice_scatter_default_2165: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2163, slice_scatter_default_2164, 1, 4320, 4336);  slice_scatter_default_2163 = slice_scatter_default_2164 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2165, 1, 4320, 4336)
        slice_17868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17867, 2, 0, 16);  slice_17867 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2165, 1, 4320, 4336)
        slice_scatter_default_2166: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1083, slice_17868, 2, 0, 16);  slice_tensor_1083 = slice_17868 = None
        slice_scatter_default_2167: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2165, slice_scatter_default_2166, 1, 4320, 4336);  slice_scatter_default_2165 = slice_scatter_default_2166 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17887: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4336, 4352)
        slice_17888: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17887, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_545: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17888, memory_format = torch.contiguous_format);  slice_17888 = None
        view_1094: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_545, [32, 16]);  clone_545 = None
        mm_542: "f32[32, 8]" = torch.ops.aten.mm.default(view_1094, slice_7)
        view_1095: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_542, [2, 16, 8]);  mm_542 = None
        slice_17895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2167, 1, 4336, 4352)
        slice_17896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17895, 2, 0, 16);  slice_17895 = None
        add_544: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17896, view_1095);  slice_17896 = view_1095 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2167, 1, 4336, 4352)
        slice_scatter_default_2168: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1084, add_544, 2, 0, 16);  slice_tensor_1084 = add_544 = None
        slice_scatter_default_2169: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2167, slice_scatter_default_2168, 1, 4336, 4352);  slice_scatter_default_2167 = slice_scatter_default_2168 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2169, 1, 4336, 4352)
        slice_17901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17900, 2, 0, 16);  slice_17900 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2169, 1, 4336, 4352)
        slice_scatter_default_2170: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1085, slice_17901, 2, 0, 16);  slice_tensor_1085 = slice_17901 = None
        slice_scatter_default_2171: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2169, slice_scatter_default_2170, 1, 4336, 4352);  slice_scatter_default_2169 = slice_scatter_default_2170 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17921: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17887, 2, 16, 32);  slice_17887 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_546: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17921, memory_format = torch.contiguous_format);  slice_17921 = None
        view_1096: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_546, [32, 11]);  clone_546 = None
        mm_543: "f32[32, 8]" = torch.ops.aten.mm.default(view_1096, slice_37)
        view_1097: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_543, [2, 16, 8]);  mm_543 = None
        slice_17928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2171, 1, 4336, 4352)
        slice_17929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17928, 2, 0, 16);  slice_17928 = None
        add_545: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17929, view_1097);  slice_17929 = view_1097 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2171, 1, 4336, 4352)
        slice_scatter_default_2172: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1086, add_545, 2, 0, 16);  slice_tensor_1086 = add_545 = None
        slice_scatter_default_2173: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2171, slice_scatter_default_2172, 1, 4336, 4352);  slice_scatter_default_2171 = slice_scatter_default_2172 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2173, 1, 4336, 4352)
        slice_17934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17933, 2, 0, 16);  slice_17933 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2173, 1, 4336, 4352)
        slice_scatter_default_2174: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1087, slice_17934, 2, 0, 16);  slice_tensor_1087 = slice_17934 = None
        slice_scatter_default_2175: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2173, slice_scatter_default_2174, 1, 4336, 4352);  slice_scatter_default_2173 = slice_scatter_default_2174 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17953: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4352, 4368)
        slice_17954: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_17953, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_547: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_17954, memory_format = torch.contiguous_format);  slice_17954 = None
        view_1098: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_547, [32, 16]);  clone_547 = None
        mm_544: "f32[32, 8]" = torch.ops.aten.mm.default(view_1098, slice_7)
        view_1099: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_544, [2, 16, 8]);  mm_544 = None
        slice_17961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2175, 1, 4352, 4368)
        slice_17962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17961, 2, 0, 16);  slice_17961 = None
        add_546: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17962, view_1099);  slice_17962 = view_1099 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2175, 1, 4352, 4368)
        slice_scatter_default_2176: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1088, add_546, 2, 0, 16);  slice_tensor_1088 = add_546 = None
        slice_scatter_default_2177: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2175, slice_scatter_default_2176, 1, 4352, 4368);  slice_scatter_default_2175 = slice_scatter_default_2176 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2177, 1, 4352, 4368)
        slice_17967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17966, 2, 0, 16);  slice_17966 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2177, 1, 4352, 4368)
        slice_scatter_default_2178: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1089, slice_17967, 2, 0, 16);  slice_tensor_1089 = slice_17967 = None
        slice_scatter_default_2179: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2177, slice_scatter_default_2178, 1, 4352, 4368);  slice_scatter_default_2177 = slice_scatter_default_2178 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_17987: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_17953, 2, 16, 32);  slice_17953 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_548: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_17987, memory_format = torch.contiguous_format);  slice_17987 = None
        view_1100: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_548, [32, 11]);  clone_548 = None
        mm_545: "f32[32, 8]" = torch.ops.aten.mm.default(view_1100, slice_37)
        view_1101: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_545, [2, 16, 8]);  mm_545 = None
        slice_17994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2179, 1, 4352, 4368)
        slice_17995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17994, 2, 0, 16);  slice_17994 = None
        add_547: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_17995, view_1101);  slice_17995 = view_1101 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2179, 1, 4352, 4368)
        slice_scatter_default_2180: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1090, add_547, 2, 0, 16);  slice_tensor_1090 = add_547 = None
        slice_scatter_default_2181: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2179, slice_scatter_default_2180, 1, 4352, 4368);  slice_scatter_default_2179 = slice_scatter_default_2180 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_17999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2181, 1, 4352, 4368)
        slice_18000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_17999, 2, 0, 16);  slice_17999 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2181, 1, 4352, 4368)
        slice_scatter_default_2182: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1091, slice_18000, 2, 0, 16);  slice_tensor_1091 = slice_18000 = None
        slice_scatter_default_2183: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2181, slice_scatter_default_2182, 1, 4352, 4368);  slice_scatter_default_2181 = slice_scatter_default_2182 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18019: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4368, 4384)
        slice_18020: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18019, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_549: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18020, memory_format = torch.contiguous_format);  slice_18020 = None
        view_1102: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_549, [32, 16]);  clone_549 = None
        mm_546: "f32[32, 8]" = torch.ops.aten.mm.default(view_1102, slice_7)
        view_1103: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_546, [2, 16, 8]);  mm_546 = None
        slice_18027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2183, 1, 4368, 4384)
        slice_18028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18027, 2, 0, 16);  slice_18027 = None
        add_548: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18028, view_1103);  slice_18028 = view_1103 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2183, 1, 4368, 4384)
        slice_scatter_default_2184: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1092, add_548, 2, 0, 16);  slice_tensor_1092 = add_548 = None
        slice_scatter_default_2185: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2183, slice_scatter_default_2184, 1, 4368, 4384);  slice_scatter_default_2183 = slice_scatter_default_2184 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2185, 1, 4368, 4384)
        slice_18033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18032, 2, 0, 16);  slice_18032 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2185, 1, 4368, 4384)
        slice_scatter_default_2186: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1093, slice_18033, 2, 0, 16);  slice_tensor_1093 = slice_18033 = None
        slice_scatter_default_2187: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2185, slice_scatter_default_2186, 1, 4368, 4384);  slice_scatter_default_2185 = slice_scatter_default_2186 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18053: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18019, 2, 16, 32);  slice_18019 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_550: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18053, memory_format = torch.contiguous_format);  slice_18053 = None
        view_1104: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_550, [32, 11]);  clone_550 = None
        mm_547: "f32[32, 8]" = torch.ops.aten.mm.default(view_1104, slice_37)
        view_1105: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_547, [2, 16, 8]);  mm_547 = None
        slice_18060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2187, 1, 4368, 4384)
        slice_18061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18060, 2, 0, 16);  slice_18060 = None
        add_549: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18061, view_1105);  slice_18061 = view_1105 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2187, 1, 4368, 4384)
        slice_scatter_default_2188: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1094, add_549, 2, 0, 16);  slice_tensor_1094 = add_549 = None
        slice_scatter_default_2189: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2187, slice_scatter_default_2188, 1, 4368, 4384);  slice_scatter_default_2187 = slice_scatter_default_2188 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2189, 1, 4368, 4384)
        slice_18066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18065, 2, 0, 16);  slice_18065 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2189, 1, 4368, 4384)
        slice_scatter_default_2190: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1095, slice_18066, 2, 0, 16);  slice_tensor_1095 = slice_18066 = None
        slice_scatter_default_2191: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2189, slice_scatter_default_2190, 1, 4368, 4384);  slice_scatter_default_2189 = slice_scatter_default_2190 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18085: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4384, 4400)
        slice_18086: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18085, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_551: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18086, memory_format = torch.contiguous_format);  slice_18086 = None
        view_1106: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_551, [32, 16]);  clone_551 = None
        mm_548: "f32[32, 8]" = torch.ops.aten.mm.default(view_1106, slice_7)
        view_1107: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_548, [2, 16, 8]);  mm_548 = None
        slice_18093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2191, 1, 4384, 4400)
        slice_18094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18093, 2, 0, 16);  slice_18093 = None
        add_550: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18094, view_1107);  slice_18094 = view_1107 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2191, 1, 4384, 4400)
        slice_scatter_default_2192: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1096, add_550, 2, 0, 16);  slice_tensor_1096 = add_550 = None
        slice_scatter_default_2193: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2191, slice_scatter_default_2192, 1, 4384, 4400);  slice_scatter_default_2191 = slice_scatter_default_2192 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2193, 1, 4384, 4400)
        slice_18099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18098, 2, 0, 16);  slice_18098 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2193, 1, 4384, 4400)
        slice_scatter_default_2194: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1097, slice_18099, 2, 0, 16);  slice_tensor_1097 = slice_18099 = None
        slice_scatter_default_2195: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2193, slice_scatter_default_2194, 1, 4384, 4400);  slice_scatter_default_2193 = slice_scatter_default_2194 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18119: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18085, 2, 16, 32);  slice_18085 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_552: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18119, memory_format = torch.contiguous_format);  slice_18119 = None
        view_1108: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_552, [32, 11]);  clone_552 = None
        mm_549: "f32[32, 8]" = torch.ops.aten.mm.default(view_1108, slice_37)
        view_1109: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_549, [2, 16, 8]);  mm_549 = None
        slice_18126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2195, 1, 4384, 4400)
        slice_18127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18126, 2, 0, 16);  slice_18126 = None
        add_551: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18127, view_1109);  slice_18127 = view_1109 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2195, 1, 4384, 4400)
        slice_scatter_default_2196: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1098, add_551, 2, 0, 16);  slice_tensor_1098 = add_551 = None
        slice_scatter_default_2197: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2195, slice_scatter_default_2196, 1, 4384, 4400);  slice_scatter_default_2195 = slice_scatter_default_2196 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2197, 1, 4384, 4400)
        slice_18132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18131, 2, 0, 16);  slice_18131 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2197, 1, 4384, 4400)
        slice_scatter_default_2198: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1099, slice_18132, 2, 0, 16);  slice_tensor_1099 = slice_18132 = None
        slice_scatter_default_2199: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2197, slice_scatter_default_2198, 1, 4384, 4400);  slice_scatter_default_2197 = slice_scatter_default_2198 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18151: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4400, 4416)
        slice_18152: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18151, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_553: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18152, memory_format = torch.contiguous_format);  slice_18152 = None
        view_1110: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_553, [32, 16]);  clone_553 = None
        mm_550: "f32[32, 8]" = torch.ops.aten.mm.default(view_1110, slice_7)
        view_1111: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_550, [2, 16, 8]);  mm_550 = None
        slice_18159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2199, 1, 4400, 4416)
        slice_18160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18159, 2, 0, 16);  slice_18159 = None
        add_552: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18160, view_1111);  slice_18160 = view_1111 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2199, 1, 4400, 4416)
        slice_scatter_default_2200: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1100, add_552, 2, 0, 16);  slice_tensor_1100 = add_552 = None
        slice_scatter_default_2201: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2199, slice_scatter_default_2200, 1, 4400, 4416);  slice_scatter_default_2199 = slice_scatter_default_2200 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2201, 1, 4400, 4416)
        slice_18165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18164, 2, 0, 16);  slice_18164 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2201, 1, 4400, 4416)
        slice_scatter_default_2202: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1101, slice_18165, 2, 0, 16);  slice_tensor_1101 = slice_18165 = None
        slice_scatter_default_2203: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2201, slice_scatter_default_2202, 1, 4400, 4416);  slice_scatter_default_2201 = slice_scatter_default_2202 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18185: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18151, 2, 16, 32);  slice_18151 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_554: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18185, memory_format = torch.contiguous_format);  slice_18185 = None
        view_1112: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_554, [32, 11]);  clone_554 = None
        mm_551: "f32[32, 8]" = torch.ops.aten.mm.default(view_1112, slice_37)
        view_1113: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_551, [2, 16, 8]);  mm_551 = None
        slice_18192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2203, 1, 4400, 4416)
        slice_18193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18192, 2, 0, 16);  slice_18192 = None
        add_553: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18193, view_1113);  slice_18193 = view_1113 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2203, 1, 4400, 4416)
        slice_scatter_default_2204: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1102, add_553, 2, 0, 16);  slice_tensor_1102 = add_553 = None
        slice_scatter_default_2205: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2203, slice_scatter_default_2204, 1, 4400, 4416);  slice_scatter_default_2203 = slice_scatter_default_2204 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2205, 1, 4400, 4416)
        slice_18198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18197, 2, 0, 16);  slice_18197 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2205, 1, 4400, 4416)
        slice_scatter_default_2206: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1103, slice_18198, 2, 0, 16);  slice_tensor_1103 = slice_18198 = None
        slice_scatter_default_2207: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2205, slice_scatter_default_2206, 1, 4400, 4416);  slice_scatter_default_2205 = slice_scatter_default_2206 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18217: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4416, 4432)
        slice_18218: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18217, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_555: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18218, memory_format = torch.contiguous_format);  slice_18218 = None
        view_1114: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_555, [32, 16]);  clone_555 = None
        mm_552: "f32[32, 8]" = torch.ops.aten.mm.default(view_1114, slice_7)
        view_1115: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_552, [2, 16, 8]);  mm_552 = None
        slice_18225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2207, 1, 4416, 4432)
        slice_18226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18225, 2, 0, 16);  slice_18225 = None
        add_554: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18226, view_1115);  slice_18226 = view_1115 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2207, 1, 4416, 4432)
        slice_scatter_default_2208: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1104, add_554, 2, 0, 16);  slice_tensor_1104 = add_554 = None
        slice_scatter_default_2209: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2207, slice_scatter_default_2208, 1, 4416, 4432);  slice_scatter_default_2207 = slice_scatter_default_2208 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2209, 1, 4416, 4432)
        slice_18231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18230, 2, 0, 16);  slice_18230 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2209, 1, 4416, 4432)
        slice_scatter_default_2210: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1105, slice_18231, 2, 0, 16);  slice_tensor_1105 = slice_18231 = None
        slice_scatter_default_2211: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2209, slice_scatter_default_2210, 1, 4416, 4432);  slice_scatter_default_2209 = slice_scatter_default_2210 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18251: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18217, 2, 16, 32);  slice_18217 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_556: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18251, memory_format = torch.contiguous_format);  slice_18251 = None
        view_1116: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_556, [32, 11]);  clone_556 = None
        mm_553: "f32[32, 8]" = torch.ops.aten.mm.default(view_1116, slice_37)
        view_1117: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_553, [2, 16, 8]);  mm_553 = None
        slice_18258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2211, 1, 4416, 4432)
        slice_18259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18258, 2, 0, 16);  slice_18258 = None
        add_555: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18259, view_1117);  slice_18259 = view_1117 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2211, 1, 4416, 4432)
        slice_scatter_default_2212: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1106, add_555, 2, 0, 16);  slice_tensor_1106 = add_555 = None
        slice_scatter_default_2213: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2211, slice_scatter_default_2212, 1, 4416, 4432);  slice_scatter_default_2211 = slice_scatter_default_2212 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2213, 1, 4416, 4432)
        slice_18264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18263, 2, 0, 16);  slice_18263 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2213, 1, 4416, 4432)
        slice_scatter_default_2214: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1107, slice_18264, 2, 0, 16);  slice_tensor_1107 = slice_18264 = None
        slice_scatter_default_2215: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2213, slice_scatter_default_2214, 1, 4416, 4432);  slice_scatter_default_2213 = slice_scatter_default_2214 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18283: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4432, 4448)
        slice_18284: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18283, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_557: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18284, memory_format = torch.contiguous_format);  slice_18284 = None
        view_1118: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_557, [32, 16]);  clone_557 = None
        mm_554: "f32[32, 8]" = torch.ops.aten.mm.default(view_1118, slice_7)
        view_1119: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_554, [2, 16, 8]);  mm_554 = None
        slice_18291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2215, 1, 4432, 4448)
        slice_18292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18291, 2, 0, 16);  slice_18291 = None
        add_556: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18292, view_1119);  slice_18292 = view_1119 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2215, 1, 4432, 4448)
        slice_scatter_default_2216: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1108, add_556, 2, 0, 16);  slice_tensor_1108 = add_556 = None
        slice_scatter_default_2217: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2215, slice_scatter_default_2216, 1, 4432, 4448);  slice_scatter_default_2215 = slice_scatter_default_2216 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2217, 1, 4432, 4448)
        slice_18297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18296, 2, 0, 16);  slice_18296 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2217, 1, 4432, 4448)
        slice_scatter_default_2218: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1109, slice_18297, 2, 0, 16);  slice_tensor_1109 = slice_18297 = None
        slice_scatter_default_2219: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2217, slice_scatter_default_2218, 1, 4432, 4448);  slice_scatter_default_2217 = slice_scatter_default_2218 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18317: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18283, 2, 16, 32);  slice_18283 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_558: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18317, memory_format = torch.contiguous_format);  slice_18317 = None
        view_1120: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_558, [32, 11]);  clone_558 = None
        mm_555: "f32[32, 8]" = torch.ops.aten.mm.default(view_1120, slice_37)
        view_1121: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_555, [2, 16, 8]);  mm_555 = None
        slice_18324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2219, 1, 4432, 4448)
        slice_18325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18324, 2, 0, 16);  slice_18324 = None
        add_557: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18325, view_1121);  slice_18325 = view_1121 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2219, 1, 4432, 4448)
        slice_scatter_default_2220: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1110, add_557, 2, 0, 16);  slice_tensor_1110 = add_557 = None
        slice_scatter_default_2221: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2219, slice_scatter_default_2220, 1, 4432, 4448);  slice_scatter_default_2219 = slice_scatter_default_2220 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2221, 1, 4432, 4448)
        slice_18330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18329, 2, 0, 16);  slice_18329 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2221, 1, 4432, 4448)
        slice_scatter_default_2222: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1111, slice_18330, 2, 0, 16);  slice_tensor_1111 = slice_18330 = None
        slice_scatter_default_2223: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2221, slice_scatter_default_2222, 1, 4432, 4448);  slice_scatter_default_2221 = slice_scatter_default_2222 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18349: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4448, 4464)
        slice_18350: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18349, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_559: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18350, memory_format = torch.contiguous_format);  slice_18350 = None
        view_1122: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_559, [32, 16]);  clone_559 = None
        mm_556: "f32[32, 8]" = torch.ops.aten.mm.default(view_1122, slice_7)
        view_1123: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_556, [2, 16, 8]);  mm_556 = None
        slice_18357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2223, 1, 4448, 4464)
        slice_18358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18357, 2, 0, 16);  slice_18357 = None
        add_558: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18358, view_1123);  slice_18358 = view_1123 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2223, 1, 4448, 4464)
        slice_scatter_default_2224: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1112, add_558, 2, 0, 16);  slice_tensor_1112 = add_558 = None
        slice_scatter_default_2225: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2223, slice_scatter_default_2224, 1, 4448, 4464);  slice_scatter_default_2223 = slice_scatter_default_2224 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2225, 1, 4448, 4464)
        slice_18363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18362, 2, 0, 16);  slice_18362 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2225, 1, 4448, 4464)
        slice_scatter_default_2226: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1113, slice_18363, 2, 0, 16);  slice_tensor_1113 = slice_18363 = None
        slice_scatter_default_2227: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2225, slice_scatter_default_2226, 1, 4448, 4464);  slice_scatter_default_2225 = slice_scatter_default_2226 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18383: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18349, 2, 16, 32);  slice_18349 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_560: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18383, memory_format = torch.contiguous_format);  slice_18383 = None
        view_1124: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_560, [32, 11]);  clone_560 = None
        mm_557: "f32[32, 8]" = torch.ops.aten.mm.default(view_1124, slice_37)
        view_1125: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_557, [2, 16, 8]);  mm_557 = None
        slice_18390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2227, 1, 4448, 4464)
        slice_18391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18390, 2, 0, 16);  slice_18390 = None
        add_559: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18391, view_1125);  slice_18391 = view_1125 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2227, 1, 4448, 4464)
        slice_scatter_default_2228: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1114, add_559, 2, 0, 16);  slice_tensor_1114 = add_559 = None
        slice_scatter_default_2229: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2227, slice_scatter_default_2228, 1, 4448, 4464);  slice_scatter_default_2227 = slice_scatter_default_2228 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2229, 1, 4448, 4464)
        slice_18396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18395, 2, 0, 16);  slice_18395 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2229, 1, 4448, 4464)
        slice_scatter_default_2230: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1115, slice_18396, 2, 0, 16);  slice_tensor_1115 = slice_18396 = None
        slice_scatter_default_2231: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2229, slice_scatter_default_2230, 1, 4448, 4464);  slice_scatter_default_2229 = slice_scatter_default_2230 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18415: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4464, 4480)
        slice_18416: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18415, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_561: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18416, memory_format = torch.contiguous_format);  slice_18416 = None
        view_1126: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_561, [32, 16]);  clone_561 = None
        mm_558: "f32[32, 8]" = torch.ops.aten.mm.default(view_1126, slice_7)
        view_1127: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_558, [2, 16, 8]);  mm_558 = None
        slice_18423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2231, 1, 4464, 4480)
        slice_18424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18423, 2, 0, 16);  slice_18423 = None
        add_560: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18424, view_1127);  slice_18424 = view_1127 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2231, 1, 4464, 4480)
        slice_scatter_default_2232: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1116, add_560, 2, 0, 16);  slice_tensor_1116 = add_560 = None
        slice_scatter_default_2233: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2231, slice_scatter_default_2232, 1, 4464, 4480);  slice_scatter_default_2231 = slice_scatter_default_2232 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2233, 1, 4464, 4480)
        slice_18429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18428, 2, 0, 16);  slice_18428 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2233, 1, 4464, 4480)
        slice_scatter_default_2234: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1117, slice_18429, 2, 0, 16);  slice_tensor_1117 = slice_18429 = None
        slice_scatter_default_2235: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2233, slice_scatter_default_2234, 1, 4464, 4480);  slice_scatter_default_2233 = slice_scatter_default_2234 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18449: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18415, 2, 16, 32);  slice_18415 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_562: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18449, memory_format = torch.contiguous_format);  slice_18449 = None
        view_1128: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_562, [32, 11]);  clone_562 = None
        mm_559: "f32[32, 8]" = torch.ops.aten.mm.default(view_1128, slice_37)
        view_1129: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_559, [2, 16, 8]);  mm_559 = None
        slice_18456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2235, 1, 4464, 4480)
        slice_18457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18456, 2, 0, 16);  slice_18456 = None
        add_561: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18457, view_1129);  slice_18457 = view_1129 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2235, 1, 4464, 4480)
        slice_scatter_default_2236: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1118, add_561, 2, 0, 16);  slice_tensor_1118 = add_561 = None
        slice_scatter_default_2237: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2235, slice_scatter_default_2236, 1, 4464, 4480);  slice_scatter_default_2235 = slice_scatter_default_2236 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2237, 1, 4464, 4480)
        slice_18462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18461, 2, 0, 16);  slice_18461 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2237, 1, 4464, 4480)
        slice_scatter_default_2238: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1119, slice_18462, 2, 0, 16);  slice_tensor_1119 = slice_18462 = None
        slice_scatter_default_2239: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2237, slice_scatter_default_2238, 1, 4464, 4480);  slice_scatter_default_2237 = slice_scatter_default_2238 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18481: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4480, 4496)
        slice_18482: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18481, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_563: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18482, memory_format = torch.contiguous_format);  slice_18482 = None
        view_1130: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_563, [32, 16]);  clone_563 = None
        mm_560: "f32[32, 8]" = torch.ops.aten.mm.default(view_1130, slice_7)
        view_1131: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_560, [2, 16, 8]);  mm_560 = None
        slice_18489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2239, 1, 4480, 4496)
        slice_18490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18489, 2, 0, 16);  slice_18489 = None
        add_562: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18490, view_1131);  slice_18490 = view_1131 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2239, 1, 4480, 4496)
        slice_scatter_default_2240: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1120, add_562, 2, 0, 16);  slice_tensor_1120 = add_562 = None
        slice_scatter_default_2241: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2239, slice_scatter_default_2240, 1, 4480, 4496);  slice_scatter_default_2239 = slice_scatter_default_2240 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2241, 1, 4480, 4496)
        slice_18495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18494, 2, 0, 16);  slice_18494 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2241, 1, 4480, 4496)
        slice_scatter_default_2242: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1121, slice_18495, 2, 0, 16);  slice_tensor_1121 = slice_18495 = None
        slice_scatter_default_2243: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2241, slice_scatter_default_2242, 1, 4480, 4496);  slice_scatter_default_2241 = slice_scatter_default_2242 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18515: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18481, 2, 16, 32);  slice_18481 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_564: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18515, memory_format = torch.contiguous_format);  slice_18515 = None
        view_1132: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_564, [32, 11]);  clone_564 = None
        mm_561: "f32[32, 8]" = torch.ops.aten.mm.default(view_1132, slice_37)
        view_1133: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_561, [2, 16, 8]);  mm_561 = None
        slice_18522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2243, 1, 4480, 4496)
        slice_18523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18522, 2, 0, 16);  slice_18522 = None
        add_563: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18523, view_1133);  slice_18523 = view_1133 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2243, 1, 4480, 4496)
        slice_scatter_default_2244: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1122, add_563, 2, 0, 16);  slice_tensor_1122 = add_563 = None
        slice_scatter_default_2245: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2243, slice_scatter_default_2244, 1, 4480, 4496);  slice_scatter_default_2243 = slice_scatter_default_2244 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2245, 1, 4480, 4496)
        slice_18528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18527, 2, 0, 16);  slice_18527 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2245, 1, 4480, 4496)
        slice_scatter_default_2246: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1123, slice_18528, 2, 0, 16);  slice_tensor_1123 = slice_18528 = None
        slice_scatter_default_2247: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2245, slice_scatter_default_2246, 1, 4480, 4496);  slice_scatter_default_2245 = slice_scatter_default_2246 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18547: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4496, 4512)
        slice_18548: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18547, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_565: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18548, memory_format = torch.contiguous_format);  slice_18548 = None
        view_1134: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_565, [32, 16]);  clone_565 = None
        mm_562: "f32[32, 8]" = torch.ops.aten.mm.default(view_1134, slice_7)
        view_1135: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_562, [2, 16, 8]);  mm_562 = None
        slice_18555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2247, 1, 4496, 4512)
        slice_18556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18555, 2, 0, 16);  slice_18555 = None
        add_564: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18556, view_1135);  slice_18556 = view_1135 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2247, 1, 4496, 4512)
        slice_scatter_default_2248: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1124, add_564, 2, 0, 16);  slice_tensor_1124 = add_564 = None
        slice_scatter_default_2249: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2247, slice_scatter_default_2248, 1, 4496, 4512);  slice_scatter_default_2247 = slice_scatter_default_2248 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2249, 1, 4496, 4512)
        slice_18561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18560, 2, 0, 16);  slice_18560 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2249, 1, 4496, 4512)
        slice_scatter_default_2250: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1125, slice_18561, 2, 0, 16);  slice_tensor_1125 = slice_18561 = None
        slice_scatter_default_2251: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2249, slice_scatter_default_2250, 1, 4496, 4512);  slice_scatter_default_2249 = slice_scatter_default_2250 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18581: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18547, 2, 16, 32);  slice_18547 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_566: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18581, memory_format = torch.contiguous_format);  slice_18581 = None
        view_1136: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_566, [32, 11]);  clone_566 = None
        mm_563: "f32[32, 8]" = torch.ops.aten.mm.default(view_1136, slice_37)
        view_1137: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_563, [2, 16, 8]);  mm_563 = None
        slice_18588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2251, 1, 4496, 4512)
        slice_18589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18588, 2, 0, 16);  slice_18588 = None
        add_565: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18589, view_1137);  slice_18589 = view_1137 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2251, 1, 4496, 4512)
        slice_scatter_default_2252: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1126, add_565, 2, 0, 16);  slice_tensor_1126 = add_565 = None
        slice_scatter_default_2253: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2251, slice_scatter_default_2252, 1, 4496, 4512);  slice_scatter_default_2251 = slice_scatter_default_2252 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2253, 1, 4496, 4512)
        slice_18594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18593, 2, 0, 16);  slice_18593 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2253, 1, 4496, 4512)
        slice_scatter_default_2254: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1127, slice_18594, 2, 0, 16);  slice_tensor_1127 = slice_18594 = None
        slice_scatter_default_2255: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2253, slice_scatter_default_2254, 1, 4496, 4512);  slice_scatter_default_2253 = slice_scatter_default_2254 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18613: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4512, 4528)
        slice_18614: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18613, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_567: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18614, memory_format = torch.contiguous_format);  slice_18614 = None
        view_1138: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_567, [32, 16]);  clone_567 = None
        mm_564: "f32[32, 8]" = torch.ops.aten.mm.default(view_1138, slice_7)
        view_1139: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_564, [2, 16, 8]);  mm_564 = None
        slice_18621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2255, 1, 4512, 4528)
        slice_18622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18621, 2, 0, 16);  slice_18621 = None
        add_566: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18622, view_1139);  slice_18622 = view_1139 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2255, 1, 4512, 4528)
        slice_scatter_default_2256: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1128, add_566, 2, 0, 16);  slice_tensor_1128 = add_566 = None
        slice_scatter_default_2257: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2255, slice_scatter_default_2256, 1, 4512, 4528);  slice_scatter_default_2255 = slice_scatter_default_2256 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2257, 1, 4512, 4528)
        slice_18627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18626, 2, 0, 16);  slice_18626 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2257, 1, 4512, 4528)
        slice_scatter_default_2258: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1129, slice_18627, 2, 0, 16);  slice_tensor_1129 = slice_18627 = None
        slice_scatter_default_2259: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2257, slice_scatter_default_2258, 1, 4512, 4528);  slice_scatter_default_2257 = slice_scatter_default_2258 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18647: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18613, 2, 16, 32);  slice_18613 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_568: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18647, memory_format = torch.contiguous_format);  slice_18647 = None
        view_1140: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_568, [32, 11]);  clone_568 = None
        mm_565: "f32[32, 8]" = torch.ops.aten.mm.default(view_1140, slice_37)
        view_1141: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_565, [2, 16, 8]);  mm_565 = None
        slice_18654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2259, 1, 4512, 4528)
        slice_18655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18654, 2, 0, 16);  slice_18654 = None
        add_567: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18655, view_1141);  slice_18655 = view_1141 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2259, 1, 4512, 4528)
        slice_scatter_default_2260: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1130, add_567, 2, 0, 16);  slice_tensor_1130 = add_567 = None
        slice_scatter_default_2261: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2259, slice_scatter_default_2260, 1, 4512, 4528);  slice_scatter_default_2259 = slice_scatter_default_2260 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2261, 1, 4512, 4528)
        slice_18660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18659, 2, 0, 16);  slice_18659 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2261, 1, 4512, 4528)
        slice_scatter_default_2262: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1131, slice_18660, 2, 0, 16);  slice_tensor_1131 = slice_18660 = None
        slice_scatter_default_2263: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2261, slice_scatter_default_2262, 1, 4512, 4528);  slice_scatter_default_2261 = slice_scatter_default_2262 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18679: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4528, 4544)
        slice_18680: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18679, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_569: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18680, memory_format = torch.contiguous_format);  slice_18680 = None
        view_1142: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_569, [32, 16]);  clone_569 = None
        mm_566: "f32[32, 8]" = torch.ops.aten.mm.default(view_1142, slice_7)
        view_1143: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_566, [2, 16, 8]);  mm_566 = None
        slice_18687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2263, 1, 4528, 4544)
        slice_18688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18687, 2, 0, 16);  slice_18687 = None
        add_568: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18688, view_1143);  slice_18688 = view_1143 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2263, 1, 4528, 4544)
        slice_scatter_default_2264: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1132, add_568, 2, 0, 16);  slice_tensor_1132 = add_568 = None
        slice_scatter_default_2265: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2263, slice_scatter_default_2264, 1, 4528, 4544);  slice_scatter_default_2263 = slice_scatter_default_2264 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2265, 1, 4528, 4544)
        slice_18693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18692, 2, 0, 16);  slice_18692 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2265, 1, 4528, 4544)
        slice_scatter_default_2266: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1133, slice_18693, 2, 0, 16);  slice_tensor_1133 = slice_18693 = None
        slice_scatter_default_2267: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2265, slice_scatter_default_2266, 1, 4528, 4544);  slice_scatter_default_2265 = slice_scatter_default_2266 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18713: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18679, 2, 16, 32);  slice_18679 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_570: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18713, memory_format = torch.contiguous_format);  slice_18713 = None
        view_1144: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_570, [32, 11]);  clone_570 = None
        mm_567: "f32[32, 8]" = torch.ops.aten.mm.default(view_1144, slice_37)
        view_1145: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_567, [2, 16, 8]);  mm_567 = None
        slice_18720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2267, 1, 4528, 4544)
        slice_18721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18720, 2, 0, 16);  slice_18720 = None
        add_569: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18721, view_1145);  slice_18721 = view_1145 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2267, 1, 4528, 4544)
        slice_scatter_default_2268: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1134, add_569, 2, 0, 16);  slice_tensor_1134 = add_569 = None
        slice_scatter_default_2269: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2267, slice_scatter_default_2268, 1, 4528, 4544);  slice_scatter_default_2267 = slice_scatter_default_2268 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2269, 1, 4528, 4544)
        slice_18726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18725, 2, 0, 16);  slice_18725 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2269, 1, 4528, 4544)
        slice_scatter_default_2270: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1135, slice_18726, 2, 0, 16);  slice_tensor_1135 = slice_18726 = None
        slice_scatter_default_2271: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2269, slice_scatter_default_2270, 1, 4528, 4544);  slice_scatter_default_2269 = slice_scatter_default_2270 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18745: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4544, 4560)
        slice_18746: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18745, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_571: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18746, memory_format = torch.contiguous_format);  slice_18746 = None
        view_1146: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_571, [32, 16]);  clone_571 = None
        mm_568: "f32[32, 8]" = torch.ops.aten.mm.default(view_1146, slice_7)
        view_1147: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_568, [2, 16, 8]);  mm_568 = None
        slice_18753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2271, 1, 4544, 4560)
        slice_18754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18753, 2, 0, 16);  slice_18753 = None
        add_570: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18754, view_1147);  slice_18754 = view_1147 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2271, 1, 4544, 4560)
        slice_scatter_default_2272: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1136, add_570, 2, 0, 16);  slice_tensor_1136 = add_570 = None
        slice_scatter_default_2273: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2271, slice_scatter_default_2272, 1, 4544, 4560);  slice_scatter_default_2271 = slice_scatter_default_2272 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2273, 1, 4544, 4560)
        slice_18759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18758, 2, 0, 16);  slice_18758 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2273, 1, 4544, 4560)
        slice_scatter_default_2274: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1137, slice_18759, 2, 0, 16);  slice_tensor_1137 = slice_18759 = None
        slice_scatter_default_2275: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2273, slice_scatter_default_2274, 1, 4544, 4560);  slice_scatter_default_2273 = slice_scatter_default_2274 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18779: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18745, 2, 16, 32);  slice_18745 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_572: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18779, memory_format = torch.contiguous_format);  slice_18779 = None
        view_1148: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_572, [32, 11]);  clone_572 = None
        mm_569: "f32[32, 8]" = torch.ops.aten.mm.default(view_1148, slice_37)
        view_1149: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_569, [2, 16, 8]);  mm_569 = None
        slice_18786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2275, 1, 4544, 4560)
        slice_18787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18786, 2, 0, 16);  slice_18786 = None
        add_571: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18787, view_1149);  slice_18787 = view_1149 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2275, 1, 4544, 4560)
        slice_scatter_default_2276: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1138, add_571, 2, 0, 16);  slice_tensor_1138 = add_571 = None
        slice_scatter_default_2277: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2275, slice_scatter_default_2276, 1, 4544, 4560);  slice_scatter_default_2275 = slice_scatter_default_2276 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2277, 1, 4544, 4560)
        slice_18792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18791, 2, 0, 16);  slice_18791 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2277, 1, 4544, 4560)
        slice_scatter_default_2278: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1139, slice_18792, 2, 0, 16);  slice_tensor_1139 = slice_18792 = None
        slice_scatter_default_2279: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2277, slice_scatter_default_2278, 1, 4544, 4560);  slice_scatter_default_2277 = slice_scatter_default_2278 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18811: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4560, 4576)
        slice_18812: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18811, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_573: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18812, memory_format = torch.contiguous_format);  slice_18812 = None
        view_1150: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_573, [32, 16]);  clone_573 = None
        mm_570: "f32[32, 8]" = torch.ops.aten.mm.default(view_1150, slice_7)
        view_1151: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_570, [2, 16, 8]);  mm_570 = None
        slice_18819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2279, 1, 4560, 4576)
        slice_18820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18819, 2, 0, 16);  slice_18819 = None
        add_572: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18820, view_1151);  slice_18820 = view_1151 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2279, 1, 4560, 4576)
        slice_scatter_default_2280: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1140, add_572, 2, 0, 16);  slice_tensor_1140 = add_572 = None
        slice_scatter_default_2281: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2279, slice_scatter_default_2280, 1, 4560, 4576);  slice_scatter_default_2279 = slice_scatter_default_2280 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2281, 1, 4560, 4576)
        slice_18825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18824, 2, 0, 16);  slice_18824 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2281, 1, 4560, 4576)
        slice_scatter_default_2282: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1141, slice_18825, 2, 0, 16);  slice_tensor_1141 = slice_18825 = None
        slice_scatter_default_2283: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2281, slice_scatter_default_2282, 1, 4560, 4576);  slice_scatter_default_2281 = slice_scatter_default_2282 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18845: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18811, 2, 16, 32);  slice_18811 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_574: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18845, memory_format = torch.contiguous_format);  slice_18845 = None
        view_1152: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_574, [32, 11]);  clone_574 = None
        mm_571: "f32[32, 8]" = torch.ops.aten.mm.default(view_1152, slice_37)
        view_1153: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_571, [2, 16, 8]);  mm_571 = None
        slice_18852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2283, 1, 4560, 4576)
        slice_18853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18852, 2, 0, 16);  slice_18852 = None
        add_573: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18853, view_1153);  slice_18853 = view_1153 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2283, 1, 4560, 4576)
        slice_scatter_default_2284: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1142, add_573, 2, 0, 16);  slice_tensor_1142 = add_573 = None
        slice_scatter_default_2285: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2283, slice_scatter_default_2284, 1, 4560, 4576);  slice_scatter_default_2283 = slice_scatter_default_2284 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2285, 1, 4560, 4576)
        slice_18858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18857, 2, 0, 16);  slice_18857 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2285, 1, 4560, 4576)
        slice_scatter_default_2286: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1143, slice_18858, 2, 0, 16);  slice_tensor_1143 = slice_18858 = None
        slice_scatter_default_2287: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2285, slice_scatter_default_2286, 1, 4560, 4576);  slice_scatter_default_2285 = slice_scatter_default_2286 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18877: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4576, 4592)
        slice_18878: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18877, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_575: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18878, memory_format = torch.contiguous_format);  slice_18878 = None
        view_1154: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_575, [32, 16]);  clone_575 = None
        mm_572: "f32[32, 8]" = torch.ops.aten.mm.default(view_1154, slice_7)
        view_1155: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_572, [2, 16, 8]);  mm_572 = None
        slice_18885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2287, 1, 4576, 4592)
        slice_18886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18885, 2, 0, 16);  slice_18885 = None
        add_574: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18886, view_1155);  slice_18886 = view_1155 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2287, 1, 4576, 4592)
        slice_scatter_default_2288: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1144, add_574, 2, 0, 16);  slice_tensor_1144 = add_574 = None
        slice_scatter_default_2289: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2287, slice_scatter_default_2288, 1, 4576, 4592);  slice_scatter_default_2287 = slice_scatter_default_2288 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2289, 1, 4576, 4592)
        slice_18891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18890, 2, 0, 16);  slice_18890 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2289, 1, 4576, 4592)
        slice_scatter_default_2290: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1145, slice_18891, 2, 0, 16);  slice_tensor_1145 = slice_18891 = None
        slice_scatter_default_2291: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2289, slice_scatter_default_2290, 1, 4576, 4592);  slice_scatter_default_2289 = slice_scatter_default_2290 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18911: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18877, 2, 16, 32);  slice_18877 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_576: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18911, memory_format = torch.contiguous_format);  slice_18911 = None
        view_1156: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_576, [32, 11]);  clone_576 = None
        mm_573: "f32[32, 8]" = torch.ops.aten.mm.default(view_1156, slice_37)
        view_1157: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_573, [2, 16, 8]);  mm_573 = None
        slice_18918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2291, 1, 4576, 4592)
        slice_18919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18918, 2, 0, 16);  slice_18918 = None
        add_575: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18919, view_1157);  slice_18919 = view_1157 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2291, 1, 4576, 4592)
        slice_scatter_default_2292: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1146, add_575, 2, 0, 16);  slice_tensor_1146 = add_575 = None
        slice_scatter_default_2293: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2291, slice_scatter_default_2292, 1, 4576, 4592);  slice_scatter_default_2291 = slice_scatter_default_2292 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2293, 1, 4576, 4592)
        slice_18924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18923, 2, 0, 16);  slice_18923 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2293, 1, 4576, 4592)
        slice_scatter_default_2294: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1147, slice_18924, 2, 0, 16);  slice_tensor_1147 = slice_18924 = None
        slice_scatter_default_2295: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2293, slice_scatter_default_2294, 1, 4576, 4592);  slice_scatter_default_2293 = slice_scatter_default_2294 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18943: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4592, 4608)
        slice_18944: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_18943, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_577: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_18944, memory_format = torch.contiguous_format);  slice_18944 = None
        view_1158: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_577, [32, 16]);  clone_577 = None
        mm_574: "f32[32, 8]" = torch.ops.aten.mm.default(view_1158, slice_7)
        view_1159: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_574, [2, 16, 8]);  mm_574 = None
        slice_18951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2295, 1, 4592, 4608)
        slice_18952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18951, 2, 0, 16);  slice_18951 = None
        add_576: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18952, view_1159);  slice_18952 = view_1159 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2295, 1, 4592, 4608)
        slice_scatter_default_2296: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1148, add_576, 2, 0, 16);  slice_tensor_1148 = add_576 = None
        slice_scatter_default_2297: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2295, slice_scatter_default_2296, 1, 4592, 4608);  slice_scatter_default_2295 = slice_scatter_default_2296 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2297, 1, 4592, 4608)
        slice_18957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18956, 2, 0, 16);  slice_18956 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2297, 1, 4592, 4608)
        slice_scatter_default_2298: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1149, slice_18957, 2, 0, 16);  slice_tensor_1149 = slice_18957 = None
        slice_scatter_default_2299: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2297, slice_scatter_default_2298, 1, 4592, 4608);  slice_scatter_default_2297 = slice_scatter_default_2298 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_18977: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_18943, 2, 16, 32);  slice_18943 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_578: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_18977, memory_format = torch.contiguous_format);  slice_18977 = None
        view_1160: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_578, [32, 11]);  clone_578 = None
        mm_575: "f32[32, 8]" = torch.ops.aten.mm.default(view_1160, slice_37)
        view_1161: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_575, [2, 16, 8]);  mm_575 = None
        slice_18984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2299, 1, 4592, 4608)
        slice_18985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18984, 2, 0, 16);  slice_18984 = None
        add_577: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_18985, view_1161);  slice_18985 = view_1161 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2299, 1, 4592, 4608)
        slice_scatter_default_2300: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1150, add_577, 2, 0, 16);  slice_tensor_1150 = add_577 = None
        slice_scatter_default_2301: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2299, slice_scatter_default_2300, 1, 4592, 4608);  slice_scatter_default_2299 = slice_scatter_default_2300 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_18989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2301, 1, 4592, 4608)
        slice_18990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_18989, 2, 0, 16);  slice_18989 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2301, 1, 4592, 4608)
        slice_scatter_default_2302: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1151, slice_18990, 2, 0, 16);  slice_tensor_1151 = slice_18990 = None
        slice_scatter_default_2303: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2301, slice_scatter_default_2302, 1, 4592, 4608);  slice_scatter_default_2301 = slice_scatter_default_2302 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19009: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4608, 4624)
        slice_19010: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19009, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_579: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19010, memory_format = torch.contiguous_format);  slice_19010 = None
        view_1162: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_579, [32, 16]);  clone_579 = None
        mm_576: "f32[32, 8]" = torch.ops.aten.mm.default(view_1162, slice_7)
        view_1163: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_576, [2, 16, 8]);  mm_576 = None
        slice_19017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2303, 1, 4608, 4624)
        slice_19018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19017, 2, 0, 16);  slice_19017 = None
        add_578: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19018, view_1163);  slice_19018 = view_1163 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2303, 1, 4608, 4624)
        slice_scatter_default_2304: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1152, add_578, 2, 0, 16);  slice_tensor_1152 = add_578 = None
        slice_scatter_default_2305: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2303, slice_scatter_default_2304, 1, 4608, 4624);  slice_scatter_default_2303 = slice_scatter_default_2304 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2305, 1, 4608, 4624)
        slice_19023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19022, 2, 0, 16);  slice_19022 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2305, 1, 4608, 4624)
        slice_scatter_default_2306: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1153, slice_19023, 2, 0, 16);  slice_tensor_1153 = slice_19023 = None
        slice_scatter_default_2307: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2305, slice_scatter_default_2306, 1, 4608, 4624);  slice_scatter_default_2305 = slice_scatter_default_2306 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19043: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19009, 2, 16, 32);  slice_19009 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_580: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19043, memory_format = torch.contiguous_format);  slice_19043 = None
        view_1164: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_580, [32, 11]);  clone_580 = None
        mm_577: "f32[32, 8]" = torch.ops.aten.mm.default(view_1164, slice_37)
        view_1165: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_577, [2, 16, 8]);  mm_577 = None
        slice_19050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2307, 1, 4608, 4624)
        slice_19051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19050, 2, 0, 16);  slice_19050 = None
        add_579: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19051, view_1165);  slice_19051 = view_1165 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2307, 1, 4608, 4624)
        slice_scatter_default_2308: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1154, add_579, 2, 0, 16);  slice_tensor_1154 = add_579 = None
        slice_scatter_default_2309: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2307, slice_scatter_default_2308, 1, 4608, 4624);  slice_scatter_default_2307 = slice_scatter_default_2308 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2309, 1, 4608, 4624)
        slice_19056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19055, 2, 0, 16);  slice_19055 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2309, 1, 4608, 4624)
        slice_scatter_default_2310: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1155, slice_19056, 2, 0, 16);  slice_tensor_1155 = slice_19056 = None
        slice_scatter_default_2311: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2309, slice_scatter_default_2310, 1, 4608, 4624);  slice_scatter_default_2309 = slice_scatter_default_2310 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19075: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4624, 4640)
        slice_19076: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19075, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_581: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19076, memory_format = torch.contiguous_format);  slice_19076 = None
        view_1166: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_581, [32, 16]);  clone_581 = None
        mm_578: "f32[32, 8]" = torch.ops.aten.mm.default(view_1166, slice_7)
        view_1167: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_578, [2, 16, 8]);  mm_578 = None
        slice_19083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2311, 1, 4624, 4640)
        slice_19084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19083, 2, 0, 16);  slice_19083 = None
        add_580: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19084, view_1167);  slice_19084 = view_1167 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2311, 1, 4624, 4640)
        slice_scatter_default_2312: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1156, add_580, 2, 0, 16);  slice_tensor_1156 = add_580 = None
        slice_scatter_default_2313: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2311, slice_scatter_default_2312, 1, 4624, 4640);  slice_scatter_default_2311 = slice_scatter_default_2312 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2313, 1, 4624, 4640)
        slice_19089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19088, 2, 0, 16);  slice_19088 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2313, 1, 4624, 4640)
        slice_scatter_default_2314: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1157, slice_19089, 2, 0, 16);  slice_tensor_1157 = slice_19089 = None
        slice_scatter_default_2315: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2313, slice_scatter_default_2314, 1, 4624, 4640);  slice_scatter_default_2313 = slice_scatter_default_2314 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19109: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19075, 2, 16, 32);  slice_19075 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_582: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19109, memory_format = torch.contiguous_format);  slice_19109 = None
        view_1168: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_582, [32, 11]);  clone_582 = None
        mm_579: "f32[32, 8]" = torch.ops.aten.mm.default(view_1168, slice_37)
        view_1169: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_579, [2, 16, 8]);  mm_579 = None
        slice_19116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2315, 1, 4624, 4640)
        slice_19117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19116, 2, 0, 16);  slice_19116 = None
        add_581: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19117, view_1169);  slice_19117 = view_1169 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2315, 1, 4624, 4640)
        slice_scatter_default_2316: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1158, add_581, 2, 0, 16);  slice_tensor_1158 = add_581 = None
        slice_scatter_default_2317: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2315, slice_scatter_default_2316, 1, 4624, 4640);  slice_scatter_default_2315 = slice_scatter_default_2316 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2317, 1, 4624, 4640)
        slice_19122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19121, 2, 0, 16);  slice_19121 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2317, 1, 4624, 4640)
        slice_scatter_default_2318: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1159, slice_19122, 2, 0, 16);  slice_tensor_1159 = slice_19122 = None
        slice_scatter_default_2319: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2317, slice_scatter_default_2318, 1, 4624, 4640);  slice_scatter_default_2317 = slice_scatter_default_2318 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19141: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4640, 4656)
        slice_19142: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19141, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_583: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19142, memory_format = torch.contiguous_format);  slice_19142 = None
        view_1170: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_583, [32, 16]);  clone_583 = None
        mm_580: "f32[32, 8]" = torch.ops.aten.mm.default(view_1170, slice_7)
        view_1171: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_580, [2, 16, 8]);  mm_580 = None
        slice_19149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2319, 1, 4640, 4656)
        slice_19150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19149, 2, 0, 16);  slice_19149 = None
        add_582: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19150, view_1171);  slice_19150 = view_1171 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2319, 1, 4640, 4656)
        slice_scatter_default_2320: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1160, add_582, 2, 0, 16);  slice_tensor_1160 = add_582 = None
        slice_scatter_default_2321: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2319, slice_scatter_default_2320, 1, 4640, 4656);  slice_scatter_default_2319 = slice_scatter_default_2320 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2321, 1, 4640, 4656)
        slice_19155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19154, 2, 0, 16);  slice_19154 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2321, 1, 4640, 4656)
        slice_scatter_default_2322: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1161, slice_19155, 2, 0, 16);  slice_tensor_1161 = slice_19155 = None
        slice_scatter_default_2323: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2321, slice_scatter_default_2322, 1, 4640, 4656);  slice_scatter_default_2321 = slice_scatter_default_2322 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19175: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19141, 2, 16, 32);  slice_19141 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_584: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19175, memory_format = torch.contiguous_format);  slice_19175 = None
        view_1172: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_584, [32, 11]);  clone_584 = None
        mm_581: "f32[32, 8]" = torch.ops.aten.mm.default(view_1172, slice_37)
        view_1173: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_581, [2, 16, 8]);  mm_581 = None
        slice_19182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2323, 1, 4640, 4656)
        slice_19183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19182, 2, 0, 16);  slice_19182 = None
        add_583: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19183, view_1173);  slice_19183 = view_1173 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2323, 1, 4640, 4656)
        slice_scatter_default_2324: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1162, add_583, 2, 0, 16);  slice_tensor_1162 = add_583 = None
        slice_scatter_default_2325: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2323, slice_scatter_default_2324, 1, 4640, 4656);  slice_scatter_default_2323 = slice_scatter_default_2324 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2325, 1, 4640, 4656)
        slice_19188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19187, 2, 0, 16);  slice_19187 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2325, 1, 4640, 4656)
        slice_scatter_default_2326: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1163, slice_19188, 2, 0, 16);  slice_tensor_1163 = slice_19188 = None
        slice_scatter_default_2327: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2325, slice_scatter_default_2326, 1, 4640, 4656);  slice_scatter_default_2325 = slice_scatter_default_2326 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19207: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4656, 4672)
        slice_19208: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19207, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_585: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19208, memory_format = torch.contiguous_format);  slice_19208 = None
        view_1174: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_585, [32, 16]);  clone_585 = None
        mm_582: "f32[32, 8]" = torch.ops.aten.mm.default(view_1174, slice_7)
        view_1175: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_582, [2, 16, 8]);  mm_582 = None
        slice_19215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2327, 1, 4656, 4672)
        slice_19216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19215, 2, 0, 16);  slice_19215 = None
        add_584: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19216, view_1175);  slice_19216 = view_1175 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2327, 1, 4656, 4672)
        slice_scatter_default_2328: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1164, add_584, 2, 0, 16);  slice_tensor_1164 = add_584 = None
        slice_scatter_default_2329: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2327, slice_scatter_default_2328, 1, 4656, 4672);  slice_scatter_default_2327 = slice_scatter_default_2328 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2329, 1, 4656, 4672)
        slice_19221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19220, 2, 0, 16);  slice_19220 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2329, 1, 4656, 4672)
        slice_scatter_default_2330: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1165, slice_19221, 2, 0, 16);  slice_tensor_1165 = slice_19221 = None
        slice_scatter_default_2331: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2329, slice_scatter_default_2330, 1, 4656, 4672);  slice_scatter_default_2329 = slice_scatter_default_2330 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19241: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19207, 2, 16, 32);  slice_19207 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_586: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19241, memory_format = torch.contiguous_format);  slice_19241 = None
        view_1176: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_586, [32, 11]);  clone_586 = None
        mm_583: "f32[32, 8]" = torch.ops.aten.mm.default(view_1176, slice_37)
        view_1177: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_583, [2, 16, 8]);  mm_583 = None
        slice_19248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2331, 1, 4656, 4672)
        slice_19249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19248, 2, 0, 16);  slice_19248 = None
        add_585: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19249, view_1177);  slice_19249 = view_1177 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2331, 1, 4656, 4672)
        slice_scatter_default_2332: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1166, add_585, 2, 0, 16);  slice_tensor_1166 = add_585 = None
        slice_scatter_default_2333: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2331, slice_scatter_default_2332, 1, 4656, 4672);  slice_scatter_default_2331 = slice_scatter_default_2332 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2333, 1, 4656, 4672)
        slice_19254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19253, 2, 0, 16);  slice_19253 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2333, 1, 4656, 4672)
        slice_scatter_default_2334: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1167, slice_19254, 2, 0, 16);  slice_tensor_1167 = slice_19254 = None
        slice_scatter_default_2335: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2333, slice_scatter_default_2334, 1, 4656, 4672);  slice_scatter_default_2333 = slice_scatter_default_2334 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19273: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4672, 4688)
        slice_19274: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19273, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_587: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19274, memory_format = torch.contiguous_format);  slice_19274 = None
        view_1178: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_587, [32, 16]);  clone_587 = None
        mm_584: "f32[32, 8]" = torch.ops.aten.mm.default(view_1178, slice_7)
        view_1179: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_584, [2, 16, 8]);  mm_584 = None
        slice_19281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2335, 1, 4672, 4688)
        slice_19282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19281, 2, 0, 16);  slice_19281 = None
        add_586: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19282, view_1179);  slice_19282 = view_1179 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2335, 1, 4672, 4688)
        slice_scatter_default_2336: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1168, add_586, 2, 0, 16);  slice_tensor_1168 = add_586 = None
        slice_scatter_default_2337: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2335, slice_scatter_default_2336, 1, 4672, 4688);  slice_scatter_default_2335 = slice_scatter_default_2336 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2337, 1, 4672, 4688)
        slice_19287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19286, 2, 0, 16);  slice_19286 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2337, 1, 4672, 4688)
        slice_scatter_default_2338: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1169, slice_19287, 2, 0, 16);  slice_tensor_1169 = slice_19287 = None
        slice_scatter_default_2339: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2337, slice_scatter_default_2338, 1, 4672, 4688);  slice_scatter_default_2337 = slice_scatter_default_2338 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19307: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19273, 2, 16, 32);  slice_19273 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_588: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19307, memory_format = torch.contiguous_format);  slice_19307 = None
        view_1180: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_588, [32, 11]);  clone_588 = None
        mm_585: "f32[32, 8]" = torch.ops.aten.mm.default(view_1180, slice_37)
        view_1181: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_585, [2, 16, 8]);  mm_585 = None
        slice_19314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2339, 1, 4672, 4688)
        slice_19315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19314, 2, 0, 16);  slice_19314 = None
        add_587: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19315, view_1181);  slice_19315 = view_1181 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2339, 1, 4672, 4688)
        slice_scatter_default_2340: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1170, add_587, 2, 0, 16);  slice_tensor_1170 = add_587 = None
        slice_scatter_default_2341: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2339, slice_scatter_default_2340, 1, 4672, 4688);  slice_scatter_default_2339 = slice_scatter_default_2340 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2341, 1, 4672, 4688)
        slice_19320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19319, 2, 0, 16);  slice_19319 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2341, 1, 4672, 4688)
        slice_scatter_default_2342: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1171, slice_19320, 2, 0, 16);  slice_tensor_1171 = slice_19320 = None
        slice_scatter_default_2343: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2341, slice_scatter_default_2342, 1, 4672, 4688);  slice_scatter_default_2341 = slice_scatter_default_2342 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19339: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4688, 4704)
        slice_19340: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19339, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_589: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19340, memory_format = torch.contiguous_format);  slice_19340 = None
        view_1182: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_589, [32, 16]);  clone_589 = None
        mm_586: "f32[32, 8]" = torch.ops.aten.mm.default(view_1182, slice_7)
        view_1183: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_586, [2, 16, 8]);  mm_586 = None
        slice_19347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2343, 1, 4688, 4704)
        slice_19348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19347, 2, 0, 16);  slice_19347 = None
        add_588: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19348, view_1183);  slice_19348 = view_1183 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2343, 1, 4688, 4704)
        slice_scatter_default_2344: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1172, add_588, 2, 0, 16);  slice_tensor_1172 = add_588 = None
        slice_scatter_default_2345: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2343, slice_scatter_default_2344, 1, 4688, 4704);  slice_scatter_default_2343 = slice_scatter_default_2344 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2345, 1, 4688, 4704)
        slice_19353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19352, 2, 0, 16);  slice_19352 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2345, 1, 4688, 4704)
        slice_scatter_default_2346: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1173, slice_19353, 2, 0, 16);  slice_tensor_1173 = slice_19353 = None
        slice_scatter_default_2347: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2345, slice_scatter_default_2346, 1, 4688, 4704);  slice_scatter_default_2345 = slice_scatter_default_2346 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19373: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19339, 2, 16, 32);  slice_19339 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_590: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19373, memory_format = torch.contiguous_format);  slice_19373 = None
        view_1184: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_590, [32, 11]);  clone_590 = None
        mm_587: "f32[32, 8]" = torch.ops.aten.mm.default(view_1184, slice_37)
        view_1185: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_587, [2, 16, 8]);  mm_587 = None
        slice_19380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2347, 1, 4688, 4704)
        slice_19381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19380, 2, 0, 16);  slice_19380 = None
        add_589: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19381, view_1185);  slice_19381 = view_1185 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2347, 1, 4688, 4704)
        slice_scatter_default_2348: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1174, add_589, 2, 0, 16);  slice_tensor_1174 = add_589 = None
        slice_scatter_default_2349: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2347, slice_scatter_default_2348, 1, 4688, 4704);  slice_scatter_default_2347 = slice_scatter_default_2348 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2349, 1, 4688, 4704)
        slice_19386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19385, 2, 0, 16);  slice_19385 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2349, 1, 4688, 4704)
        slice_scatter_default_2350: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1175, slice_19386, 2, 0, 16);  slice_tensor_1175 = slice_19386 = None
        slice_scatter_default_2351: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2349, slice_scatter_default_2350, 1, 4688, 4704);  slice_scatter_default_2349 = slice_scatter_default_2350 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19405: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4704, 4720)
        slice_19406: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19405, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_591: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19406, memory_format = torch.contiguous_format);  slice_19406 = None
        view_1186: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_591, [32, 16]);  clone_591 = None
        mm_588: "f32[32, 8]" = torch.ops.aten.mm.default(view_1186, slice_7)
        view_1187: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_588, [2, 16, 8]);  mm_588 = None
        slice_19413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2351, 1, 4704, 4720)
        slice_19414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19413, 2, 0, 16);  slice_19413 = None
        add_590: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19414, view_1187);  slice_19414 = view_1187 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2351, 1, 4704, 4720)
        slice_scatter_default_2352: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1176, add_590, 2, 0, 16);  slice_tensor_1176 = add_590 = None
        slice_scatter_default_2353: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2351, slice_scatter_default_2352, 1, 4704, 4720);  slice_scatter_default_2351 = slice_scatter_default_2352 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2353, 1, 4704, 4720)
        slice_19419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19418, 2, 0, 16);  slice_19418 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2353, 1, 4704, 4720)
        slice_scatter_default_2354: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1177, slice_19419, 2, 0, 16);  slice_tensor_1177 = slice_19419 = None
        slice_scatter_default_2355: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2353, slice_scatter_default_2354, 1, 4704, 4720);  slice_scatter_default_2353 = slice_scatter_default_2354 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19439: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19405, 2, 16, 32);  slice_19405 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_592: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19439, memory_format = torch.contiguous_format);  slice_19439 = None
        view_1188: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_592, [32, 11]);  clone_592 = None
        mm_589: "f32[32, 8]" = torch.ops.aten.mm.default(view_1188, slice_37)
        view_1189: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_589, [2, 16, 8]);  mm_589 = None
        slice_19446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2355, 1, 4704, 4720)
        slice_19447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19446, 2, 0, 16);  slice_19446 = None
        add_591: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19447, view_1189);  slice_19447 = view_1189 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2355, 1, 4704, 4720)
        slice_scatter_default_2356: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1178, add_591, 2, 0, 16);  slice_tensor_1178 = add_591 = None
        slice_scatter_default_2357: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2355, slice_scatter_default_2356, 1, 4704, 4720);  slice_scatter_default_2355 = slice_scatter_default_2356 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2357, 1, 4704, 4720)
        slice_19452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19451, 2, 0, 16);  slice_19451 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2357, 1, 4704, 4720)
        slice_scatter_default_2358: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1179, slice_19452, 2, 0, 16);  slice_tensor_1179 = slice_19452 = None
        slice_scatter_default_2359: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2357, slice_scatter_default_2358, 1, 4704, 4720);  slice_scatter_default_2357 = slice_scatter_default_2358 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19471: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4720, 4736)
        slice_19472: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19471, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_593: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19472, memory_format = torch.contiguous_format);  slice_19472 = None
        view_1190: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_593, [32, 16]);  clone_593 = None
        mm_590: "f32[32, 8]" = torch.ops.aten.mm.default(view_1190, slice_7)
        view_1191: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_590, [2, 16, 8]);  mm_590 = None
        slice_19479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2359, 1, 4720, 4736)
        slice_19480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19479, 2, 0, 16);  slice_19479 = None
        add_592: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19480, view_1191);  slice_19480 = view_1191 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2359, 1, 4720, 4736)
        slice_scatter_default_2360: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1180, add_592, 2, 0, 16);  slice_tensor_1180 = add_592 = None
        slice_scatter_default_2361: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2359, slice_scatter_default_2360, 1, 4720, 4736);  slice_scatter_default_2359 = slice_scatter_default_2360 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2361, 1, 4720, 4736)
        slice_19485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19484, 2, 0, 16);  slice_19484 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2361, 1, 4720, 4736)
        slice_scatter_default_2362: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1181, slice_19485, 2, 0, 16);  slice_tensor_1181 = slice_19485 = None
        slice_scatter_default_2363: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2361, slice_scatter_default_2362, 1, 4720, 4736);  slice_scatter_default_2361 = slice_scatter_default_2362 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19505: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19471, 2, 16, 32);  slice_19471 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_594: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19505, memory_format = torch.contiguous_format);  slice_19505 = None
        view_1192: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_594, [32, 11]);  clone_594 = None
        mm_591: "f32[32, 8]" = torch.ops.aten.mm.default(view_1192, slice_37)
        view_1193: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_591, [2, 16, 8]);  mm_591 = None
        slice_19512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2363, 1, 4720, 4736)
        slice_19513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19512, 2, 0, 16);  slice_19512 = None
        add_593: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19513, view_1193);  slice_19513 = view_1193 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2363, 1, 4720, 4736)
        slice_scatter_default_2364: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1182, add_593, 2, 0, 16);  slice_tensor_1182 = add_593 = None
        slice_scatter_default_2365: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2363, slice_scatter_default_2364, 1, 4720, 4736);  slice_scatter_default_2363 = slice_scatter_default_2364 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2365, 1, 4720, 4736)
        slice_19518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19517, 2, 0, 16);  slice_19517 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2365, 1, 4720, 4736)
        slice_scatter_default_2366: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1183, slice_19518, 2, 0, 16);  slice_tensor_1183 = slice_19518 = None
        slice_scatter_default_2367: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2365, slice_scatter_default_2366, 1, 4720, 4736);  slice_scatter_default_2365 = slice_scatter_default_2366 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19537: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4736, 4752)
        slice_19538: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19537, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_595: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19538, memory_format = torch.contiguous_format);  slice_19538 = None
        view_1194: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_595, [32, 16]);  clone_595 = None
        mm_592: "f32[32, 8]" = torch.ops.aten.mm.default(view_1194, slice_7)
        view_1195: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_592, [2, 16, 8]);  mm_592 = None
        slice_19545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2367, 1, 4736, 4752)
        slice_19546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19545, 2, 0, 16);  slice_19545 = None
        add_594: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19546, view_1195);  slice_19546 = view_1195 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2367, 1, 4736, 4752)
        slice_scatter_default_2368: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1184, add_594, 2, 0, 16);  slice_tensor_1184 = add_594 = None
        slice_scatter_default_2369: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2367, slice_scatter_default_2368, 1, 4736, 4752);  slice_scatter_default_2367 = slice_scatter_default_2368 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2369, 1, 4736, 4752)
        slice_19551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19550, 2, 0, 16);  slice_19550 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2369, 1, 4736, 4752)
        slice_scatter_default_2370: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1185, slice_19551, 2, 0, 16);  slice_tensor_1185 = slice_19551 = None
        slice_scatter_default_2371: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2369, slice_scatter_default_2370, 1, 4736, 4752);  slice_scatter_default_2369 = slice_scatter_default_2370 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19571: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19537, 2, 16, 32);  slice_19537 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_596: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19571, memory_format = torch.contiguous_format);  slice_19571 = None
        view_1196: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_596, [32, 11]);  clone_596 = None
        mm_593: "f32[32, 8]" = torch.ops.aten.mm.default(view_1196, slice_37)
        view_1197: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_593, [2, 16, 8]);  mm_593 = None
        slice_19578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2371, 1, 4736, 4752)
        slice_19579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19578, 2, 0, 16);  slice_19578 = None
        add_595: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19579, view_1197);  slice_19579 = view_1197 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2371, 1, 4736, 4752)
        slice_scatter_default_2372: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1186, add_595, 2, 0, 16);  slice_tensor_1186 = add_595 = None
        slice_scatter_default_2373: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2371, slice_scatter_default_2372, 1, 4736, 4752);  slice_scatter_default_2371 = slice_scatter_default_2372 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2373, 1, 4736, 4752)
        slice_19584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19583, 2, 0, 16);  slice_19583 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2373, 1, 4736, 4752)
        slice_scatter_default_2374: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1187, slice_19584, 2, 0, 16);  slice_tensor_1187 = slice_19584 = None
        slice_scatter_default_2375: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2373, slice_scatter_default_2374, 1, 4736, 4752);  slice_scatter_default_2373 = slice_scatter_default_2374 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19603: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4752, 4768)
        slice_19604: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19603, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_597: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19604, memory_format = torch.contiguous_format);  slice_19604 = None
        view_1198: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_597, [32, 16]);  clone_597 = None
        mm_594: "f32[32, 8]" = torch.ops.aten.mm.default(view_1198, slice_7)
        view_1199: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_594, [2, 16, 8]);  mm_594 = None
        slice_19611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2375, 1, 4752, 4768)
        slice_19612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19611, 2, 0, 16);  slice_19611 = None
        add_596: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19612, view_1199);  slice_19612 = view_1199 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2375, 1, 4752, 4768)
        slice_scatter_default_2376: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1188, add_596, 2, 0, 16);  slice_tensor_1188 = add_596 = None
        slice_scatter_default_2377: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2375, slice_scatter_default_2376, 1, 4752, 4768);  slice_scatter_default_2375 = slice_scatter_default_2376 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2377, 1, 4752, 4768)
        slice_19617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19616, 2, 0, 16);  slice_19616 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2377, 1, 4752, 4768)
        slice_scatter_default_2378: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1189, slice_19617, 2, 0, 16);  slice_tensor_1189 = slice_19617 = None
        slice_scatter_default_2379: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2377, slice_scatter_default_2378, 1, 4752, 4768);  slice_scatter_default_2377 = slice_scatter_default_2378 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19637: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19603, 2, 16, 32);  slice_19603 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_598: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19637, memory_format = torch.contiguous_format);  slice_19637 = None
        view_1200: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_598, [32, 11]);  clone_598 = None
        mm_595: "f32[32, 8]" = torch.ops.aten.mm.default(view_1200, slice_37)
        view_1201: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_595, [2, 16, 8]);  mm_595 = None
        slice_19644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2379, 1, 4752, 4768)
        slice_19645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19644, 2, 0, 16);  slice_19644 = None
        add_597: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19645, view_1201);  slice_19645 = view_1201 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2379, 1, 4752, 4768)
        slice_scatter_default_2380: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1190, add_597, 2, 0, 16);  slice_tensor_1190 = add_597 = None
        slice_scatter_default_2381: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2379, slice_scatter_default_2380, 1, 4752, 4768);  slice_scatter_default_2379 = slice_scatter_default_2380 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2381, 1, 4752, 4768)
        slice_19650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19649, 2, 0, 16);  slice_19649 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2381, 1, 4752, 4768)
        slice_scatter_default_2382: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1191, slice_19650, 2, 0, 16);  slice_tensor_1191 = slice_19650 = None
        slice_scatter_default_2383: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2381, slice_scatter_default_2382, 1, 4752, 4768);  slice_scatter_default_2381 = slice_scatter_default_2382 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19669: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4768, 4784)
        slice_19670: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19669, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_599: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19670, memory_format = torch.contiguous_format);  slice_19670 = None
        view_1202: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_599, [32, 16]);  clone_599 = None
        mm_596: "f32[32, 8]" = torch.ops.aten.mm.default(view_1202, slice_7)
        view_1203: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_596, [2, 16, 8]);  mm_596 = None
        slice_19677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2383, 1, 4768, 4784)
        slice_19678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19677, 2, 0, 16);  slice_19677 = None
        add_598: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19678, view_1203);  slice_19678 = view_1203 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2383, 1, 4768, 4784)
        slice_scatter_default_2384: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1192, add_598, 2, 0, 16);  slice_tensor_1192 = add_598 = None
        slice_scatter_default_2385: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2383, slice_scatter_default_2384, 1, 4768, 4784);  slice_scatter_default_2383 = slice_scatter_default_2384 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2385, 1, 4768, 4784)
        slice_19683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19682, 2, 0, 16);  slice_19682 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2385, 1, 4768, 4784)
        slice_scatter_default_2386: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1193, slice_19683, 2, 0, 16);  slice_tensor_1193 = slice_19683 = None
        slice_scatter_default_2387: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2385, slice_scatter_default_2386, 1, 4768, 4784);  slice_scatter_default_2385 = slice_scatter_default_2386 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19703: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19669, 2, 16, 32);  slice_19669 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_600: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19703, memory_format = torch.contiguous_format);  slice_19703 = None
        view_1204: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_600, [32, 11]);  clone_600 = None
        mm_597: "f32[32, 8]" = torch.ops.aten.mm.default(view_1204, slice_37)
        view_1205: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_597, [2, 16, 8]);  mm_597 = None
        slice_19710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2387, 1, 4768, 4784)
        slice_19711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19710, 2, 0, 16);  slice_19710 = None
        add_599: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19711, view_1205);  slice_19711 = view_1205 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2387, 1, 4768, 4784)
        slice_scatter_default_2388: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1194, add_599, 2, 0, 16);  slice_tensor_1194 = add_599 = None
        slice_scatter_default_2389: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2387, slice_scatter_default_2388, 1, 4768, 4784);  slice_scatter_default_2387 = slice_scatter_default_2388 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2389, 1, 4768, 4784)
        slice_19716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19715, 2, 0, 16);  slice_19715 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2389, 1, 4768, 4784)
        slice_scatter_default_2390: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1195, slice_19716, 2, 0, 16);  slice_tensor_1195 = slice_19716 = None
        slice_scatter_default_2391: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2389, slice_scatter_default_2390, 1, 4768, 4784);  slice_scatter_default_2389 = slice_scatter_default_2390 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19735: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4784, 4800)
        slice_19736: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19735, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_601: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19736, memory_format = torch.contiguous_format);  slice_19736 = None
        view_1206: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_601, [32, 16]);  clone_601 = None
        mm_598: "f32[32, 8]" = torch.ops.aten.mm.default(view_1206, slice_7)
        view_1207: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_598, [2, 16, 8]);  mm_598 = None
        slice_19743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2391, 1, 4784, 4800)
        slice_19744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19743, 2, 0, 16);  slice_19743 = None
        add_600: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19744, view_1207);  slice_19744 = view_1207 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2391, 1, 4784, 4800)
        slice_scatter_default_2392: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1196, add_600, 2, 0, 16);  slice_tensor_1196 = add_600 = None
        slice_scatter_default_2393: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2391, slice_scatter_default_2392, 1, 4784, 4800);  slice_scatter_default_2391 = slice_scatter_default_2392 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2393, 1, 4784, 4800)
        slice_19749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19748, 2, 0, 16);  slice_19748 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2393, 1, 4784, 4800)
        slice_scatter_default_2394: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1197, slice_19749, 2, 0, 16);  slice_tensor_1197 = slice_19749 = None
        slice_scatter_default_2395: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2393, slice_scatter_default_2394, 1, 4784, 4800);  slice_scatter_default_2393 = slice_scatter_default_2394 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19769: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19735, 2, 16, 32);  slice_19735 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_602: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19769, memory_format = torch.contiguous_format);  slice_19769 = None
        view_1208: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_602, [32, 11]);  clone_602 = None
        mm_599: "f32[32, 8]" = torch.ops.aten.mm.default(view_1208, slice_37)
        view_1209: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_599, [2, 16, 8]);  mm_599 = None
        slice_19776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2395, 1, 4784, 4800)
        slice_19777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19776, 2, 0, 16);  slice_19776 = None
        add_601: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19777, view_1209);  slice_19777 = view_1209 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2395, 1, 4784, 4800)
        slice_scatter_default_2396: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1198, add_601, 2, 0, 16);  slice_tensor_1198 = add_601 = None
        slice_scatter_default_2397: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2395, slice_scatter_default_2396, 1, 4784, 4800);  slice_scatter_default_2395 = slice_scatter_default_2396 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2397, 1, 4784, 4800)
        slice_19782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19781, 2, 0, 16);  slice_19781 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2397, 1, 4784, 4800)
        slice_scatter_default_2398: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1199, slice_19782, 2, 0, 16);  slice_tensor_1199 = slice_19782 = None
        slice_scatter_default_2399: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2397, slice_scatter_default_2398, 1, 4784, 4800);  slice_scatter_default_2397 = slice_scatter_default_2398 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19801: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4800, 4816)
        slice_19802: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19801, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_603: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19802, memory_format = torch.contiguous_format);  slice_19802 = None
        view_1210: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_603, [32, 16]);  clone_603 = None
        mm_600: "f32[32, 8]" = torch.ops.aten.mm.default(view_1210, slice_7)
        view_1211: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_600, [2, 16, 8]);  mm_600 = None
        slice_19809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2399, 1, 4800, 4816)
        slice_19810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19809, 2, 0, 16);  slice_19809 = None
        add_602: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19810, view_1211);  slice_19810 = view_1211 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2399, 1, 4800, 4816)
        slice_scatter_default_2400: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1200, add_602, 2, 0, 16);  slice_tensor_1200 = add_602 = None
        slice_scatter_default_2401: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2399, slice_scatter_default_2400, 1, 4800, 4816);  slice_scatter_default_2399 = slice_scatter_default_2400 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2401, 1, 4800, 4816)
        slice_19815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19814, 2, 0, 16);  slice_19814 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2401, 1, 4800, 4816)
        slice_scatter_default_2402: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1201, slice_19815, 2, 0, 16);  slice_tensor_1201 = slice_19815 = None
        slice_scatter_default_2403: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2401, slice_scatter_default_2402, 1, 4800, 4816);  slice_scatter_default_2401 = slice_scatter_default_2402 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19835: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19801, 2, 16, 32);  slice_19801 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_604: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19835, memory_format = torch.contiguous_format);  slice_19835 = None
        view_1212: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_604, [32, 11]);  clone_604 = None
        mm_601: "f32[32, 8]" = torch.ops.aten.mm.default(view_1212, slice_37)
        view_1213: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_601, [2, 16, 8]);  mm_601 = None
        slice_19842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2403, 1, 4800, 4816)
        slice_19843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19842, 2, 0, 16);  slice_19842 = None
        add_603: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19843, view_1213);  slice_19843 = view_1213 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2403, 1, 4800, 4816)
        slice_scatter_default_2404: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1202, add_603, 2, 0, 16);  slice_tensor_1202 = add_603 = None
        slice_scatter_default_2405: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2403, slice_scatter_default_2404, 1, 4800, 4816);  slice_scatter_default_2403 = slice_scatter_default_2404 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2405, 1, 4800, 4816)
        slice_19848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19847, 2, 0, 16);  slice_19847 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2405, 1, 4800, 4816)
        slice_scatter_default_2406: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1203, slice_19848, 2, 0, 16);  slice_tensor_1203 = slice_19848 = None
        slice_scatter_default_2407: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2405, slice_scatter_default_2406, 1, 4800, 4816);  slice_scatter_default_2405 = slice_scatter_default_2406 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19867: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4816, 4832)
        slice_19868: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19867, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_605: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19868, memory_format = torch.contiguous_format);  slice_19868 = None
        view_1214: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_605, [32, 16]);  clone_605 = None
        mm_602: "f32[32, 8]" = torch.ops.aten.mm.default(view_1214, slice_7)
        view_1215: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_602, [2, 16, 8]);  mm_602 = None
        slice_19875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2407, 1, 4816, 4832)
        slice_19876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19875, 2, 0, 16);  slice_19875 = None
        add_604: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19876, view_1215);  slice_19876 = view_1215 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2407, 1, 4816, 4832)
        slice_scatter_default_2408: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1204, add_604, 2, 0, 16);  slice_tensor_1204 = add_604 = None
        slice_scatter_default_2409: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2407, slice_scatter_default_2408, 1, 4816, 4832);  slice_scatter_default_2407 = slice_scatter_default_2408 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2409, 1, 4816, 4832)
        slice_19881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19880, 2, 0, 16);  slice_19880 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2409, 1, 4816, 4832)
        slice_scatter_default_2410: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1205, slice_19881, 2, 0, 16);  slice_tensor_1205 = slice_19881 = None
        slice_scatter_default_2411: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2409, slice_scatter_default_2410, 1, 4816, 4832);  slice_scatter_default_2409 = slice_scatter_default_2410 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19901: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19867, 2, 16, 32);  slice_19867 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_606: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19901, memory_format = torch.contiguous_format);  slice_19901 = None
        view_1216: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_606, [32, 11]);  clone_606 = None
        mm_603: "f32[32, 8]" = torch.ops.aten.mm.default(view_1216, slice_37)
        view_1217: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_603, [2, 16, 8]);  mm_603 = None
        slice_19908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2411, 1, 4816, 4832)
        slice_19909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19908, 2, 0, 16);  slice_19908 = None
        add_605: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19909, view_1217);  slice_19909 = view_1217 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2411, 1, 4816, 4832)
        slice_scatter_default_2412: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1206, add_605, 2, 0, 16);  slice_tensor_1206 = add_605 = None
        slice_scatter_default_2413: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2411, slice_scatter_default_2412, 1, 4816, 4832);  slice_scatter_default_2411 = slice_scatter_default_2412 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2413, 1, 4816, 4832)
        slice_19914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19913, 2, 0, 16);  slice_19913 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2413, 1, 4816, 4832)
        slice_scatter_default_2414: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1207, slice_19914, 2, 0, 16);  slice_tensor_1207 = slice_19914 = None
        slice_scatter_default_2415: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2413, slice_scatter_default_2414, 1, 4816, 4832);  slice_scatter_default_2413 = slice_scatter_default_2414 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19933: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4832, 4848)
        slice_19934: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19933, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_607: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_19934, memory_format = torch.contiguous_format);  slice_19934 = None
        view_1218: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_607, [32, 16]);  clone_607 = None
        mm_604: "f32[32, 8]" = torch.ops.aten.mm.default(view_1218, slice_7)
        view_1219: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_604, [2, 16, 8]);  mm_604 = None
        slice_19941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2415, 1, 4832, 4848)
        slice_19942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19941, 2, 0, 16);  slice_19941 = None
        add_606: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19942, view_1219);  slice_19942 = view_1219 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2415, 1, 4832, 4848)
        slice_scatter_default_2416: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1208, add_606, 2, 0, 16);  slice_tensor_1208 = add_606 = None
        slice_scatter_default_2417: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2415, slice_scatter_default_2416, 1, 4832, 4848);  slice_scatter_default_2415 = slice_scatter_default_2416 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2417, 1, 4832, 4848)
        slice_19947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19946, 2, 0, 16);  slice_19946 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2417, 1, 4832, 4848)
        slice_scatter_default_2418: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1209, slice_19947, 2, 0, 16);  slice_tensor_1209 = slice_19947 = None
        slice_scatter_default_2419: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2417, slice_scatter_default_2418, 1, 4832, 4848);  slice_scatter_default_2417 = slice_scatter_default_2418 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19967: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19933, 2, 16, 32);  slice_19933 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_608: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_19967, memory_format = torch.contiguous_format);  slice_19967 = None
        view_1220: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_608, [32, 11]);  clone_608 = None
        mm_605: "f32[32, 8]" = torch.ops.aten.mm.default(view_1220, slice_37)
        view_1221: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_605, [2, 16, 8]);  mm_605 = None
        slice_19974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2419, 1, 4832, 4848)
        slice_19975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19974, 2, 0, 16);  slice_19974 = None
        add_607: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_19975, view_1221);  slice_19975 = view_1221 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2419, 1, 4832, 4848)
        slice_scatter_default_2420: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1210, add_607, 2, 0, 16);  slice_tensor_1210 = add_607 = None
        slice_scatter_default_2421: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2419, slice_scatter_default_2420, 1, 4832, 4848);  slice_scatter_default_2419 = slice_scatter_default_2420 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_19979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2421, 1, 4832, 4848)
        slice_19980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_19979, 2, 0, 16);  slice_19979 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2421, 1, 4832, 4848)
        slice_scatter_default_2422: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1211, slice_19980, 2, 0, 16);  slice_tensor_1211 = slice_19980 = None
        slice_scatter_default_2423: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2421, slice_scatter_default_2422, 1, 4832, 4848);  slice_scatter_default_2421 = slice_scatter_default_2422 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_19999: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4848, 4864)
        slice_20000: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_19999, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_609: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20000, memory_format = torch.contiguous_format);  slice_20000 = None
        view_1222: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_609, [32, 16]);  clone_609 = None
        mm_606: "f32[32, 8]" = torch.ops.aten.mm.default(view_1222, slice_7)
        view_1223: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_606, [2, 16, 8]);  mm_606 = None
        slice_20007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2423, 1, 4848, 4864)
        slice_20008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20007, 2, 0, 16);  slice_20007 = None
        add_608: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20008, view_1223);  slice_20008 = view_1223 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2423, 1, 4848, 4864)
        slice_scatter_default_2424: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1212, add_608, 2, 0, 16);  slice_tensor_1212 = add_608 = None
        slice_scatter_default_2425: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2423, slice_scatter_default_2424, 1, 4848, 4864);  slice_scatter_default_2423 = slice_scatter_default_2424 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2425, 1, 4848, 4864)
        slice_20013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20012, 2, 0, 16);  slice_20012 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2425, 1, 4848, 4864)
        slice_scatter_default_2426: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1213, slice_20013, 2, 0, 16);  slice_tensor_1213 = slice_20013 = None
        slice_scatter_default_2427: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2425, slice_scatter_default_2426, 1, 4848, 4864);  slice_scatter_default_2425 = slice_scatter_default_2426 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20033: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_19999, 2, 16, 32);  slice_19999 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_610: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20033, memory_format = torch.contiguous_format);  slice_20033 = None
        view_1224: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_610, [32, 11]);  clone_610 = None
        mm_607: "f32[32, 8]" = torch.ops.aten.mm.default(view_1224, slice_37)
        view_1225: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_607, [2, 16, 8]);  mm_607 = None
        slice_20040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2427, 1, 4848, 4864)
        slice_20041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20040, 2, 0, 16);  slice_20040 = None
        add_609: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20041, view_1225);  slice_20041 = view_1225 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2427, 1, 4848, 4864)
        slice_scatter_default_2428: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1214, add_609, 2, 0, 16);  slice_tensor_1214 = add_609 = None
        slice_scatter_default_2429: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2427, slice_scatter_default_2428, 1, 4848, 4864);  slice_scatter_default_2427 = slice_scatter_default_2428 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2429, 1, 4848, 4864)
        slice_20046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20045, 2, 0, 16);  slice_20045 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2429, 1, 4848, 4864)
        slice_scatter_default_2430: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1215, slice_20046, 2, 0, 16);  slice_tensor_1215 = slice_20046 = None
        slice_scatter_default_2431: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2429, slice_scatter_default_2430, 1, 4848, 4864);  slice_scatter_default_2429 = slice_scatter_default_2430 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20065: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4864, 4880)
        slice_20066: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20065, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_611: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20066, memory_format = torch.contiguous_format);  slice_20066 = None
        view_1226: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_611, [32, 16]);  clone_611 = None
        mm_608: "f32[32, 8]" = torch.ops.aten.mm.default(view_1226, slice_7)
        view_1227: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_608, [2, 16, 8]);  mm_608 = None
        slice_20073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2431, 1, 4864, 4880)
        slice_20074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20073, 2, 0, 16);  slice_20073 = None
        add_610: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20074, view_1227);  slice_20074 = view_1227 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2431, 1, 4864, 4880)
        slice_scatter_default_2432: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1216, add_610, 2, 0, 16);  slice_tensor_1216 = add_610 = None
        slice_scatter_default_2433: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2431, slice_scatter_default_2432, 1, 4864, 4880);  slice_scatter_default_2431 = slice_scatter_default_2432 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2433, 1, 4864, 4880)
        slice_20079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20078, 2, 0, 16);  slice_20078 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2433, 1, 4864, 4880)
        slice_scatter_default_2434: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1217, slice_20079, 2, 0, 16);  slice_tensor_1217 = slice_20079 = None
        slice_scatter_default_2435: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2433, slice_scatter_default_2434, 1, 4864, 4880);  slice_scatter_default_2433 = slice_scatter_default_2434 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20099: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20065, 2, 16, 32);  slice_20065 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_612: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20099, memory_format = torch.contiguous_format);  slice_20099 = None
        view_1228: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_612, [32, 11]);  clone_612 = None
        mm_609: "f32[32, 8]" = torch.ops.aten.mm.default(view_1228, slice_37)
        view_1229: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_609, [2, 16, 8]);  mm_609 = None
        slice_20106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2435, 1, 4864, 4880)
        slice_20107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20106, 2, 0, 16);  slice_20106 = None
        add_611: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20107, view_1229);  slice_20107 = view_1229 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2435, 1, 4864, 4880)
        slice_scatter_default_2436: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1218, add_611, 2, 0, 16);  slice_tensor_1218 = add_611 = None
        slice_scatter_default_2437: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2435, slice_scatter_default_2436, 1, 4864, 4880);  slice_scatter_default_2435 = slice_scatter_default_2436 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2437, 1, 4864, 4880)
        slice_20112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20111, 2, 0, 16);  slice_20111 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2437, 1, 4864, 4880)
        slice_scatter_default_2438: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1219, slice_20112, 2, 0, 16);  slice_tensor_1219 = slice_20112 = None
        slice_scatter_default_2439: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2437, slice_scatter_default_2438, 1, 4864, 4880);  slice_scatter_default_2437 = slice_scatter_default_2438 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20131: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4880, 4896)
        slice_20132: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20131, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_613: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20132, memory_format = torch.contiguous_format);  slice_20132 = None
        view_1230: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_613, [32, 16]);  clone_613 = None
        mm_610: "f32[32, 8]" = torch.ops.aten.mm.default(view_1230, slice_7)
        view_1231: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_610, [2, 16, 8]);  mm_610 = None
        slice_20139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2439, 1, 4880, 4896)
        slice_20140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20139, 2, 0, 16);  slice_20139 = None
        add_612: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20140, view_1231);  slice_20140 = view_1231 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2439, 1, 4880, 4896)
        slice_scatter_default_2440: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1220, add_612, 2, 0, 16);  slice_tensor_1220 = add_612 = None
        slice_scatter_default_2441: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2439, slice_scatter_default_2440, 1, 4880, 4896);  slice_scatter_default_2439 = slice_scatter_default_2440 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2441, 1, 4880, 4896)
        slice_20145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20144, 2, 0, 16);  slice_20144 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2441, 1, 4880, 4896)
        slice_scatter_default_2442: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1221, slice_20145, 2, 0, 16);  slice_tensor_1221 = slice_20145 = None
        slice_scatter_default_2443: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2441, slice_scatter_default_2442, 1, 4880, 4896);  slice_scatter_default_2441 = slice_scatter_default_2442 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20165: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20131, 2, 16, 32);  slice_20131 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_614: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20165, memory_format = torch.contiguous_format);  slice_20165 = None
        view_1232: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_614, [32, 11]);  clone_614 = None
        mm_611: "f32[32, 8]" = torch.ops.aten.mm.default(view_1232, slice_37)
        view_1233: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_611, [2, 16, 8]);  mm_611 = None
        slice_20172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2443, 1, 4880, 4896)
        slice_20173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20172, 2, 0, 16);  slice_20172 = None
        add_613: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20173, view_1233);  slice_20173 = view_1233 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2443, 1, 4880, 4896)
        slice_scatter_default_2444: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1222, add_613, 2, 0, 16);  slice_tensor_1222 = add_613 = None
        slice_scatter_default_2445: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2443, slice_scatter_default_2444, 1, 4880, 4896);  slice_scatter_default_2443 = slice_scatter_default_2444 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2445, 1, 4880, 4896)
        slice_20178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20177, 2, 0, 16);  slice_20177 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2445, 1, 4880, 4896)
        slice_scatter_default_2446: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1223, slice_20178, 2, 0, 16);  slice_tensor_1223 = slice_20178 = None
        slice_scatter_default_2447: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2445, slice_scatter_default_2446, 1, 4880, 4896);  slice_scatter_default_2445 = slice_scatter_default_2446 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20197: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4896, 4912)
        slice_20198: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20197, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_615: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20198, memory_format = torch.contiguous_format);  slice_20198 = None
        view_1234: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_615, [32, 16]);  clone_615 = None
        mm_612: "f32[32, 8]" = torch.ops.aten.mm.default(view_1234, slice_7)
        view_1235: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_612, [2, 16, 8]);  mm_612 = None
        slice_20205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2447, 1, 4896, 4912)
        slice_20206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20205, 2, 0, 16);  slice_20205 = None
        add_614: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20206, view_1235);  slice_20206 = view_1235 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2447, 1, 4896, 4912)
        slice_scatter_default_2448: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1224, add_614, 2, 0, 16);  slice_tensor_1224 = add_614 = None
        slice_scatter_default_2449: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2447, slice_scatter_default_2448, 1, 4896, 4912);  slice_scatter_default_2447 = slice_scatter_default_2448 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2449, 1, 4896, 4912)
        slice_20211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20210, 2, 0, 16);  slice_20210 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2449, 1, 4896, 4912)
        slice_scatter_default_2450: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1225, slice_20211, 2, 0, 16);  slice_tensor_1225 = slice_20211 = None
        slice_scatter_default_2451: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2449, slice_scatter_default_2450, 1, 4896, 4912);  slice_scatter_default_2449 = slice_scatter_default_2450 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20231: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20197, 2, 16, 32);  slice_20197 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_616: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20231, memory_format = torch.contiguous_format);  slice_20231 = None
        view_1236: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_616, [32, 11]);  clone_616 = None
        mm_613: "f32[32, 8]" = torch.ops.aten.mm.default(view_1236, slice_37)
        view_1237: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_613, [2, 16, 8]);  mm_613 = None
        slice_20238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2451, 1, 4896, 4912)
        slice_20239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20238, 2, 0, 16);  slice_20238 = None
        add_615: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20239, view_1237);  slice_20239 = view_1237 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2451, 1, 4896, 4912)
        slice_scatter_default_2452: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1226, add_615, 2, 0, 16);  slice_tensor_1226 = add_615 = None
        slice_scatter_default_2453: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2451, slice_scatter_default_2452, 1, 4896, 4912);  slice_scatter_default_2451 = slice_scatter_default_2452 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2453, 1, 4896, 4912)
        slice_20244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20243, 2, 0, 16);  slice_20243 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2453, 1, 4896, 4912)
        slice_scatter_default_2454: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1227, slice_20244, 2, 0, 16);  slice_tensor_1227 = slice_20244 = None
        slice_scatter_default_2455: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2453, slice_scatter_default_2454, 1, 4896, 4912);  slice_scatter_default_2453 = slice_scatter_default_2454 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20263: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4912, 4928)
        slice_20264: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20263, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_617: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20264, memory_format = torch.contiguous_format);  slice_20264 = None
        view_1238: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_617, [32, 16]);  clone_617 = None
        mm_614: "f32[32, 8]" = torch.ops.aten.mm.default(view_1238, slice_7)
        view_1239: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_614, [2, 16, 8]);  mm_614 = None
        slice_20271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2455, 1, 4912, 4928)
        slice_20272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20271, 2, 0, 16);  slice_20271 = None
        add_616: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20272, view_1239);  slice_20272 = view_1239 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2455, 1, 4912, 4928)
        slice_scatter_default_2456: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1228, add_616, 2, 0, 16);  slice_tensor_1228 = add_616 = None
        slice_scatter_default_2457: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2455, slice_scatter_default_2456, 1, 4912, 4928);  slice_scatter_default_2455 = slice_scatter_default_2456 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2457, 1, 4912, 4928)
        slice_20277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20276, 2, 0, 16);  slice_20276 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2457, 1, 4912, 4928)
        slice_scatter_default_2458: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1229, slice_20277, 2, 0, 16);  slice_tensor_1229 = slice_20277 = None
        slice_scatter_default_2459: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2457, slice_scatter_default_2458, 1, 4912, 4928);  slice_scatter_default_2457 = slice_scatter_default_2458 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20297: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20263, 2, 16, 32);  slice_20263 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_618: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20297, memory_format = torch.contiguous_format);  slice_20297 = None
        view_1240: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_618, [32, 11]);  clone_618 = None
        mm_615: "f32[32, 8]" = torch.ops.aten.mm.default(view_1240, slice_37)
        view_1241: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_615, [2, 16, 8]);  mm_615 = None
        slice_20304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2459, 1, 4912, 4928)
        slice_20305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20304, 2, 0, 16);  slice_20304 = None
        add_617: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20305, view_1241);  slice_20305 = view_1241 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2459, 1, 4912, 4928)
        slice_scatter_default_2460: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1230, add_617, 2, 0, 16);  slice_tensor_1230 = add_617 = None
        slice_scatter_default_2461: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2459, slice_scatter_default_2460, 1, 4912, 4928);  slice_scatter_default_2459 = slice_scatter_default_2460 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2461, 1, 4912, 4928)
        slice_20310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20309, 2, 0, 16);  slice_20309 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2461, 1, 4912, 4928)
        slice_scatter_default_2462: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1231, slice_20310, 2, 0, 16);  slice_tensor_1231 = slice_20310 = None
        slice_scatter_default_2463: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2461, slice_scatter_default_2462, 1, 4912, 4928);  slice_scatter_default_2461 = slice_scatter_default_2462 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20329: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4928, 4944)
        slice_20330: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20329, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_619: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20330, memory_format = torch.contiguous_format);  slice_20330 = None
        view_1242: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_619, [32, 16]);  clone_619 = None
        mm_616: "f32[32, 8]" = torch.ops.aten.mm.default(view_1242, slice_7)
        view_1243: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_616, [2, 16, 8]);  mm_616 = None
        slice_20337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2463, 1, 4928, 4944)
        slice_20338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20337, 2, 0, 16);  slice_20337 = None
        add_618: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20338, view_1243);  slice_20338 = view_1243 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2463, 1, 4928, 4944)
        slice_scatter_default_2464: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1232, add_618, 2, 0, 16);  slice_tensor_1232 = add_618 = None
        slice_scatter_default_2465: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2463, slice_scatter_default_2464, 1, 4928, 4944);  slice_scatter_default_2463 = slice_scatter_default_2464 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2465, 1, 4928, 4944)
        slice_20343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20342, 2, 0, 16);  slice_20342 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2465, 1, 4928, 4944)
        slice_scatter_default_2466: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1233, slice_20343, 2, 0, 16);  slice_tensor_1233 = slice_20343 = None
        slice_scatter_default_2467: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2465, slice_scatter_default_2466, 1, 4928, 4944);  slice_scatter_default_2465 = slice_scatter_default_2466 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20363: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20329, 2, 16, 32);  slice_20329 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_620: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20363, memory_format = torch.contiguous_format);  slice_20363 = None
        view_1244: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_620, [32, 11]);  clone_620 = None
        mm_617: "f32[32, 8]" = torch.ops.aten.mm.default(view_1244, slice_37)
        view_1245: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_617, [2, 16, 8]);  mm_617 = None
        slice_20370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2467, 1, 4928, 4944)
        slice_20371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20370, 2, 0, 16);  slice_20370 = None
        add_619: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20371, view_1245);  slice_20371 = view_1245 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2467, 1, 4928, 4944)
        slice_scatter_default_2468: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1234, add_619, 2, 0, 16);  slice_tensor_1234 = add_619 = None
        slice_scatter_default_2469: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2467, slice_scatter_default_2468, 1, 4928, 4944);  slice_scatter_default_2467 = slice_scatter_default_2468 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2469, 1, 4928, 4944)
        slice_20376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20375, 2, 0, 16);  slice_20375 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2469, 1, 4928, 4944)
        slice_scatter_default_2470: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1235, slice_20376, 2, 0, 16);  slice_tensor_1235 = slice_20376 = None
        slice_scatter_default_2471: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2469, slice_scatter_default_2470, 1, 4928, 4944);  slice_scatter_default_2469 = slice_scatter_default_2470 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20395: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4944, 4960)
        slice_20396: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20395, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_621: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20396, memory_format = torch.contiguous_format);  slice_20396 = None
        view_1246: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_621, [32, 16]);  clone_621 = None
        mm_618: "f32[32, 8]" = torch.ops.aten.mm.default(view_1246, slice_7)
        view_1247: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_618, [2, 16, 8]);  mm_618 = None
        slice_20403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2471, 1, 4944, 4960)
        slice_20404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20403, 2, 0, 16);  slice_20403 = None
        add_620: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20404, view_1247);  slice_20404 = view_1247 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2471, 1, 4944, 4960)
        slice_scatter_default_2472: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1236, add_620, 2, 0, 16);  slice_tensor_1236 = add_620 = None
        slice_scatter_default_2473: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2471, slice_scatter_default_2472, 1, 4944, 4960);  slice_scatter_default_2471 = slice_scatter_default_2472 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2473, 1, 4944, 4960)
        slice_20409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20408, 2, 0, 16);  slice_20408 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2473, 1, 4944, 4960)
        slice_scatter_default_2474: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1237, slice_20409, 2, 0, 16);  slice_tensor_1237 = slice_20409 = None
        slice_scatter_default_2475: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2473, slice_scatter_default_2474, 1, 4944, 4960);  slice_scatter_default_2473 = slice_scatter_default_2474 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20429: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20395, 2, 16, 32);  slice_20395 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_622: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20429, memory_format = torch.contiguous_format);  slice_20429 = None
        view_1248: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_622, [32, 11]);  clone_622 = None
        mm_619: "f32[32, 8]" = torch.ops.aten.mm.default(view_1248, slice_37)
        view_1249: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_619, [2, 16, 8]);  mm_619 = None
        slice_20436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2475, 1, 4944, 4960)
        slice_20437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20436, 2, 0, 16);  slice_20436 = None
        add_621: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20437, view_1249);  slice_20437 = view_1249 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2475, 1, 4944, 4960)
        slice_scatter_default_2476: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1238, add_621, 2, 0, 16);  slice_tensor_1238 = add_621 = None
        slice_scatter_default_2477: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2475, slice_scatter_default_2476, 1, 4944, 4960);  slice_scatter_default_2475 = slice_scatter_default_2476 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2477, 1, 4944, 4960)
        slice_20442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20441, 2, 0, 16);  slice_20441 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2477, 1, 4944, 4960)
        slice_scatter_default_2478: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1239, slice_20442, 2, 0, 16);  slice_tensor_1239 = slice_20442 = None
        slice_scatter_default_2479: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2477, slice_scatter_default_2478, 1, 4944, 4960);  slice_scatter_default_2477 = slice_scatter_default_2478 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20461: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4960, 4976)
        slice_20462: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20461, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_623: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20462, memory_format = torch.contiguous_format);  slice_20462 = None
        view_1250: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_623, [32, 16]);  clone_623 = None
        mm_620: "f32[32, 8]" = torch.ops.aten.mm.default(view_1250, slice_7)
        view_1251: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_620, [2, 16, 8]);  mm_620 = None
        slice_20469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2479, 1, 4960, 4976)
        slice_20470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20469, 2, 0, 16);  slice_20469 = None
        add_622: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20470, view_1251);  slice_20470 = view_1251 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2479, 1, 4960, 4976)
        slice_scatter_default_2480: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1240, add_622, 2, 0, 16);  slice_tensor_1240 = add_622 = None
        slice_scatter_default_2481: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2479, slice_scatter_default_2480, 1, 4960, 4976);  slice_scatter_default_2479 = slice_scatter_default_2480 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2481, 1, 4960, 4976)
        slice_20475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20474, 2, 0, 16);  slice_20474 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2481, 1, 4960, 4976)
        slice_scatter_default_2482: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1241, slice_20475, 2, 0, 16);  slice_tensor_1241 = slice_20475 = None
        slice_scatter_default_2483: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2481, slice_scatter_default_2482, 1, 4960, 4976);  slice_scatter_default_2481 = slice_scatter_default_2482 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20495: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20461, 2, 16, 32);  slice_20461 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_624: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20495, memory_format = torch.contiguous_format);  slice_20495 = None
        view_1252: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_624, [32, 11]);  clone_624 = None
        mm_621: "f32[32, 8]" = torch.ops.aten.mm.default(view_1252, slice_37)
        view_1253: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_621, [2, 16, 8]);  mm_621 = None
        slice_20502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2483, 1, 4960, 4976)
        slice_20503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20502, 2, 0, 16);  slice_20502 = None
        add_623: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20503, view_1253);  slice_20503 = view_1253 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2483, 1, 4960, 4976)
        slice_scatter_default_2484: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1242, add_623, 2, 0, 16);  slice_tensor_1242 = add_623 = None
        slice_scatter_default_2485: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2483, slice_scatter_default_2484, 1, 4960, 4976);  slice_scatter_default_2483 = slice_scatter_default_2484 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2485, 1, 4960, 4976)
        slice_20508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20507, 2, 0, 16);  slice_20507 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2485, 1, 4960, 4976)
        slice_scatter_default_2486: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1243, slice_20508, 2, 0, 16);  slice_tensor_1243 = slice_20508 = None
        slice_scatter_default_2487: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2485, slice_scatter_default_2486, 1, 4960, 4976);  slice_scatter_default_2485 = slice_scatter_default_2486 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20527: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4976, 4992)
        slice_20528: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20527, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_625: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20528, memory_format = torch.contiguous_format);  slice_20528 = None
        view_1254: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_625, [32, 16]);  clone_625 = None
        mm_622: "f32[32, 8]" = torch.ops.aten.mm.default(view_1254, slice_7)
        view_1255: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_622, [2, 16, 8]);  mm_622 = None
        slice_20535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2487, 1, 4976, 4992)
        slice_20536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20535, 2, 0, 16);  slice_20535 = None
        add_624: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20536, view_1255);  slice_20536 = view_1255 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2487, 1, 4976, 4992)
        slice_scatter_default_2488: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1244, add_624, 2, 0, 16);  slice_tensor_1244 = add_624 = None
        slice_scatter_default_2489: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2487, slice_scatter_default_2488, 1, 4976, 4992);  slice_scatter_default_2487 = slice_scatter_default_2488 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2489, 1, 4976, 4992)
        slice_20541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20540, 2, 0, 16);  slice_20540 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2489, 1, 4976, 4992)
        slice_scatter_default_2490: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1245, slice_20541, 2, 0, 16);  slice_tensor_1245 = slice_20541 = None
        slice_scatter_default_2491: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2489, slice_scatter_default_2490, 1, 4976, 4992);  slice_scatter_default_2489 = slice_scatter_default_2490 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20561: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20527, 2, 16, 32);  slice_20527 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_626: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20561, memory_format = torch.contiguous_format);  slice_20561 = None
        view_1256: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_626, [32, 11]);  clone_626 = None
        mm_623: "f32[32, 8]" = torch.ops.aten.mm.default(view_1256, slice_37)
        view_1257: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_623, [2, 16, 8]);  mm_623 = None
        slice_20568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2491, 1, 4976, 4992)
        slice_20569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20568, 2, 0, 16);  slice_20568 = None
        add_625: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20569, view_1257);  slice_20569 = view_1257 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2491, 1, 4976, 4992)
        slice_scatter_default_2492: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1246, add_625, 2, 0, 16);  slice_tensor_1246 = add_625 = None
        slice_scatter_default_2493: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2491, slice_scatter_default_2492, 1, 4976, 4992);  slice_scatter_default_2491 = slice_scatter_default_2492 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2493, 1, 4976, 4992)
        slice_20574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20573, 2, 0, 16);  slice_20573 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2493, 1, 4976, 4992)
        slice_scatter_default_2494: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1247, slice_20574, 2, 0, 16);  slice_tensor_1247 = slice_20574 = None
        slice_scatter_default_2495: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2493, slice_scatter_default_2494, 1, 4976, 4992);  slice_scatter_default_2493 = slice_scatter_default_2494 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20593: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 4992, 5008)
        slice_20594: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20593, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_627: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20594, memory_format = torch.contiguous_format);  slice_20594 = None
        view_1258: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_627, [32, 16]);  clone_627 = None
        mm_624: "f32[32, 8]" = torch.ops.aten.mm.default(view_1258, slice_7)
        view_1259: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_624, [2, 16, 8]);  mm_624 = None
        slice_20601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2495, 1, 4992, 5008)
        slice_20602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20601, 2, 0, 16);  slice_20601 = None
        add_626: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20602, view_1259);  slice_20602 = view_1259 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2495, 1, 4992, 5008)
        slice_scatter_default_2496: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1248, add_626, 2, 0, 16);  slice_tensor_1248 = add_626 = None
        slice_scatter_default_2497: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2495, slice_scatter_default_2496, 1, 4992, 5008);  slice_scatter_default_2495 = slice_scatter_default_2496 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2497, 1, 4992, 5008)
        slice_20607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20606, 2, 0, 16);  slice_20606 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2497, 1, 4992, 5008)
        slice_scatter_default_2498: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1249, slice_20607, 2, 0, 16);  slice_tensor_1249 = slice_20607 = None
        slice_scatter_default_2499: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2497, slice_scatter_default_2498, 1, 4992, 5008);  slice_scatter_default_2497 = slice_scatter_default_2498 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20627: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20593, 2, 16, 32);  slice_20593 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_628: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20627, memory_format = torch.contiguous_format);  slice_20627 = None
        view_1260: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_628, [32, 11]);  clone_628 = None
        mm_625: "f32[32, 8]" = torch.ops.aten.mm.default(view_1260, slice_37)
        view_1261: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_625, [2, 16, 8]);  mm_625 = None
        slice_20634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2499, 1, 4992, 5008)
        slice_20635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20634, 2, 0, 16);  slice_20634 = None
        add_627: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20635, view_1261);  slice_20635 = view_1261 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2499, 1, 4992, 5008)
        slice_scatter_default_2500: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1250, add_627, 2, 0, 16);  slice_tensor_1250 = add_627 = None
        slice_scatter_default_2501: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2499, slice_scatter_default_2500, 1, 4992, 5008);  slice_scatter_default_2499 = slice_scatter_default_2500 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2501, 1, 4992, 5008)
        slice_20640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20639, 2, 0, 16);  slice_20639 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2501, 1, 4992, 5008)
        slice_scatter_default_2502: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1251, slice_20640, 2, 0, 16);  slice_tensor_1251 = slice_20640 = None
        slice_scatter_default_2503: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2501, slice_scatter_default_2502, 1, 4992, 5008);  slice_scatter_default_2501 = slice_scatter_default_2502 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20659: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5008, 5024)
        slice_20660: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20659, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_629: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20660, memory_format = torch.contiguous_format);  slice_20660 = None
        view_1262: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_629, [32, 16]);  clone_629 = None
        mm_626: "f32[32, 8]" = torch.ops.aten.mm.default(view_1262, slice_7)
        view_1263: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_626, [2, 16, 8]);  mm_626 = None
        slice_20667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2503, 1, 5008, 5024)
        slice_20668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20667, 2, 0, 16);  slice_20667 = None
        add_628: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20668, view_1263);  slice_20668 = view_1263 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2503, 1, 5008, 5024)
        slice_scatter_default_2504: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1252, add_628, 2, 0, 16);  slice_tensor_1252 = add_628 = None
        slice_scatter_default_2505: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2503, slice_scatter_default_2504, 1, 5008, 5024);  slice_scatter_default_2503 = slice_scatter_default_2504 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2505, 1, 5008, 5024)
        slice_20673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20672, 2, 0, 16);  slice_20672 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2505, 1, 5008, 5024)
        slice_scatter_default_2506: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1253, slice_20673, 2, 0, 16);  slice_tensor_1253 = slice_20673 = None
        slice_scatter_default_2507: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2505, slice_scatter_default_2506, 1, 5008, 5024);  slice_scatter_default_2505 = slice_scatter_default_2506 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20693: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20659, 2, 16, 32);  slice_20659 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_630: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20693, memory_format = torch.contiguous_format);  slice_20693 = None
        view_1264: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_630, [32, 11]);  clone_630 = None
        mm_627: "f32[32, 8]" = torch.ops.aten.mm.default(view_1264, slice_37)
        view_1265: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_627, [2, 16, 8]);  mm_627 = None
        slice_20700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2507, 1, 5008, 5024)
        slice_20701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20700, 2, 0, 16);  slice_20700 = None
        add_629: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20701, view_1265);  slice_20701 = view_1265 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2507, 1, 5008, 5024)
        slice_scatter_default_2508: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1254, add_629, 2, 0, 16);  slice_tensor_1254 = add_629 = None
        slice_scatter_default_2509: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2507, slice_scatter_default_2508, 1, 5008, 5024);  slice_scatter_default_2507 = slice_scatter_default_2508 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2509, 1, 5008, 5024)
        slice_20706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20705, 2, 0, 16);  slice_20705 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2509, 1, 5008, 5024)
        slice_scatter_default_2510: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1255, slice_20706, 2, 0, 16);  slice_tensor_1255 = slice_20706 = None
        slice_scatter_default_2511: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2509, slice_scatter_default_2510, 1, 5008, 5024);  slice_scatter_default_2509 = slice_scatter_default_2510 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20725: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5024, 5040)
        slice_20726: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20725, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_631: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20726, memory_format = torch.contiguous_format);  slice_20726 = None
        view_1266: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_631, [32, 16]);  clone_631 = None
        mm_628: "f32[32, 8]" = torch.ops.aten.mm.default(view_1266, slice_7)
        view_1267: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_628, [2, 16, 8]);  mm_628 = None
        slice_20733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2511, 1, 5024, 5040)
        slice_20734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20733, 2, 0, 16);  slice_20733 = None
        add_630: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20734, view_1267);  slice_20734 = view_1267 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2511, 1, 5024, 5040)
        slice_scatter_default_2512: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1256, add_630, 2, 0, 16);  slice_tensor_1256 = add_630 = None
        slice_scatter_default_2513: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2511, slice_scatter_default_2512, 1, 5024, 5040);  slice_scatter_default_2511 = slice_scatter_default_2512 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2513, 1, 5024, 5040)
        slice_20739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20738, 2, 0, 16);  slice_20738 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2513, 1, 5024, 5040)
        slice_scatter_default_2514: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1257, slice_20739, 2, 0, 16);  slice_tensor_1257 = slice_20739 = None
        slice_scatter_default_2515: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2513, slice_scatter_default_2514, 1, 5024, 5040);  slice_scatter_default_2513 = slice_scatter_default_2514 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20759: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20725, 2, 16, 32);  slice_20725 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_632: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20759, memory_format = torch.contiguous_format);  slice_20759 = None
        view_1268: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_632, [32, 11]);  clone_632 = None
        mm_629: "f32[32, 8]" = torch.ops.aten.mm.default(view_1268, slice_37)
        view_1269: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_629, [2, 16, 8]);  mm_629 = None
        slice_20766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2515, 1, 5024, 5040)
        slice_20767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20766, 2, 0, 16);  slice_20766 = None
        add_631: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20767, view_1269);  slice_20767 = view_1269 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2515, 1, 5024, 5040)
        slice_scatter_default_2516: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1258, add_631, 2, 0, 16);  slice_tensor_1258 = add_631 = None
        slice_scatter_default_2517: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2515, slice_scatter_default_2516, 1, 5024, 5040);  slice_scatter_default_2515 = slice_scatter_default_2516 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2517, 1, 5024, 5040)
        slice_20772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20771, 2, 0, 16);  slice_20771 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2517, 1, 5024, 5040)
        slice_scatter_default_2518: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1259, slice_20772, 2, 0, 16);  slice_tensor_1259 = slice_20772 = None
        slice_scatter_default_2519: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2517, slice_scatter_default_2518, 1, 5024, 5040);  slice_scatter_default_2517 = slice_scatter_default_2518 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20791: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5040, 5056)
        slice_20792: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20791, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_633: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20792, memory_format = torch.contiguous_format);  slice_20792 = None
        view_1270: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_633, [32, 16]);  clone_633 = None
        mm_630: "f32[32, 8]" = torch.ops.aten.mm.default(view_1270, slice_7)
        view_1271: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_630, [2, 16, 8]);  mm_630 = None
        slice_20799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2519, 1, 5040, 5056)
        slice_20800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20799, 2, 0, 16);  slice_20799 = None
        add_632: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20800, view_1271);  slice_20800 = view_1271 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2519, 1, 5040, 5056)
        slice_scatter_default_2520: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1260, add_632, 2, 0, 16);  slice_tensor_1260 = add_632 = None
        slice_scatter_default_2521: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2519, slice_scatter_default_2520, 1, 5040, 5056);  slice_scatter_default_2519 = slice_scatter_default_2520 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2521, 1, 5040, 5056)
        slice_20805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20804, 2, 0, 16);  slice_20804 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2521, 1, 5040, 5056)
        slice_scatter_default_2522: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1261, slice_20805, 2, 0, 16);  slice_tensor_1261 = slice_20805 = None
        slice_scatter_default_2523: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2521, slice_scatter_default_2522, 1, 5040, 5056);  slice_scatter_default_2521 = slice_scatter_default_2522 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20825: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20791, 2, 16, 32);  slice_20791 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_634: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20825, memory_format = torch.contiguous_format);  slice_20825 = None
        view_1272: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_634, [32, 11]);  clone_634 = None
        mm_631: "f32[32, 8]" = torch.ops.aten.mm.default(view_1272, slice_37)
        view_1273: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_631, [2, 16, 8]);  mm_631 = None
        slice_20832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2523, 1, 5040, 5056)
        slice_20833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20832, 2, 0, 16);  slice_20832 = None
        add_633: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20833, view_1273);  slice_20833 = view_1273 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2523, 1, 5040, 5056)
        slice_scatter_default_2524: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1262, add_633, 2, 0, 16);  slice_tensor_1262 = add_633 = None
        slice_scatter_default_2525: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2523, slice_scatter_default_2524, 1, 5040, 5056);  slice_scatter_default_2523 = slice_scatter_default_2524 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2525, 1, 5040, 5056)
        slice_20838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20837, 2, 0, 16);  slice_20837 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2525, 1, 5040, 5056)
        slice_scatter_default_2526: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1263, slice_20838, 2, 0, 16);  slice_tensor_1263 = slice_20838 = None
        slice_scatter_default_2527: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2525, slice_scatter_default_2526, 1, 5040, 5056);  slice_scatter_default_2525 = slice_scatter_default_2526 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20857: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5056, 5072)
        slice_20858: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20857, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_635: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20858, memory_format = torch.contiguous_format);  slice_20858 = None
        view_1274: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_635, [32, 16]);  clone_635 = None
        mm_632: "f32[32, 8]" = torch.ops.aten.mm.default(view_1274, slice_7)
        view_1275: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_632, [2, 16, 8]);  mm_632 = None
        slice_20865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2527, 1, 5056, 5072)
        slice_20866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20865, 2, 0, 16);  slice_20865 = None
        add_634: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20866, view_1275);  slice_20866 = view_1275 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2527, 1, 5056, 5072)
        slice_scatter_default_2528: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1264, add_634, 2, 0, 16);  slice_tensor_1264 = add_634 = None
        slice_scatter_default_2529: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2527, slice_scatter_default_2528, 1, 5056, 5072);  slice_scatter_default_2527 = slice_scatter_default_2528 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2529, 1, 5056, 5072)
        slice_20871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20870, 2, 0, 16);  slice_20870 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2529, 1, 5056, 5072)
        slice_scatter_default_2530: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1265, slice_20871, 2, 0, 16);  slice_tensor_1265 = slice_20871 = None
        slice_scatter_default_2531: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2529, slice_scatter_default_2530, 1, 5056, 5072);  slice_scatter_default_2529 = slice_scatter_default_2530 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20891: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20857, 2, 16, 32);  slice_20857 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_636: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20891, memory_format = torch.contiguous_format);  slice_20891 = None
        view_1276: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_636, [32, 11]);  clone_636 = None
        mm_633: "f32[32, 8]" = torch.ops.aten.mm.default(view_1276, slice_37)
        view_1277: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_633, [2, 16, 8]);  mm_633 = None
        slice_20898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2531, 1, 5056, 5072)
        slice_20899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20898, 2, 0, 16);  slice_20898 = None
        add_635: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20899, view_1277);  slice_20899 = view_1277 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2531, 1, 5056, 5072)
        slice_scatter_default_2532: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1266, add_635, 2, 0, 16);  slice_tensor_1266 = add_635 = None
        slice_scatter_default_2533: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2531, slice_scatter_default_2532, 1, 5056, 5072);  slice_scatter_default_2531 = slice_scatter_default_2532 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2533, 1, 5056, 5072)
        slice_20904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20903, 2, 0, 16);  slice_20903 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2533, 1, 5056, 5072)
        slice_scatter_default_2534: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1267, slice_20904, 2, 0, 16);  slice_tensor_1267 = slice_20904 = None
        slice_scatter_default_2535: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2533, slice_scatter_default_2534, 1, 5056, 5072);  slice_scatter_default_2533 = slice_scatter_default_2534 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20923: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5072, 5088)
        slice_20924: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20923, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_637: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20924, memory_format = torch.contiguous_format);  slice_20924 = None
        view_1278: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_637, [32, 16]);  clone_637 = None
        mm_634: "f32[32, 8]" = torch.ops.aten.mm.default(view_1278, slice_7)
        view_1279: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_634, [2, 16, 8]);  mm_634 = None
        slice_20931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2535, 1, 5072, 5088)
        slice_20932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20931, 2, 0, 16);  slice_20931 = None
        add_636: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20932, view_1279);  slice_20932 = view_1279 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2535, 1, 5072, 5088)
        slice_scatter_default_2536: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1268, add_636, 2, 0, 16);  slice_tensor_1268 = add_636 = None
        slice_scatter_default_2537: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2535, slice_scatter_default_2536, 1, 5072, 5088);  slice_scatter_default_2535 = slice_scatter_default_2536 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2537, 1, 5072, 5088)
        slice_20937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20936, 2, 0, 16);  slice_20936 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2537, 1, 5072, 5088)
        slice_scatter_default_2538: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1269, slice_20937, 2, 0, 16);  slice_tensor_1269 = slice_20937 = None
        slice_scatter_default_2539: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2537, slice_scatter_default_2538, 1, 5072, 5088);  slice_scatter_default_2537 = slice_scatter_default_2538 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20957: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20923, 2, 16, 32);  slice_20923 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_638: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_20957, memory_format = torch.contiguous_format);  slice_20957 = None
        view_1280: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_638, [32, 11]);  clone_638 = None
        mm_635: "f32[32, 8]" = torch.ops.aten.mm.default(view_1280, slice_37)
        view_1281: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_635, [2, 16, 8]);  mm_635 = None
        slice_20964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2539, 1, 5072, 5088)
        slice_20965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20964, 2, 0, 16);  slice_20964 = None
        add_637: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20965, view_1281);  slice_20965 = view_1281 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2539, 1, 5072, 5088)
        slice_scatter_default_2540: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1270, add_637, 2, 0, 16);  slice_tensor_1270 = add_637 = None
        slice_scatter_default_2541: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2539, slice_scatter_default_2540, 1, 5072, 5088);  slice_scatter_default_2539 = slice_scatter_default_2540 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_20969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2541, 1, 5072, 5088)
        slice_20970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20969, 2, 0, 16);  slice_20969 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2541, 1, 5072, 5088)
        slice_scatter_default_2542: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1271, slice_20970, 2, 0, 16);  slice_tensor_1271 = slice_20970 = None
        slice_scatter_default_2543: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2541, slice_scatter_default_2542, 1, 5072, 5088);  slice_scatter_default_2541 = slice_scatter_default_2542 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_20989: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5088, 5104)
        slice_20990: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_20989, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_639: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_20990, memory_format = torch.contiguous_format);  slice_20990 = None
        view_1282: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_639, [32, 16]);  clone_639 = None
        mm_636: "f32[32, 8]" = torch.ops.aten.mm.default(view_1282, slice_7)
        view_1283: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_636, [2, 16, 8]);  mm_636 = None
        slice_20997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2543, 1, 5088, 5104)
        slice_20998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_20997, 2, 0, 16);  slice_20997 = None
        add_638: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_20998, view_1283);  slice_20998 = view_1283 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2543, 1, 5088, 5104)
        slice_scatter_default_2544: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1272, add_638, 2, 0, 16);  slice_tensor_1272 = add_638 = None
        slice_scatter_default_2545: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2543, slice_scatter_default_2544, 1, 5088, 5104);  slice_scatter_default_2543 = slice_scatter_default_2544 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2545, 1, 5088, 5104)
        slice_21003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21002, 2, 0, 16);  slice_21002 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2545, 1, 5088, 5104)
        slice_scatter_default_2546: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1273, slice_21003, 2, 0, 16);  slice_tensor_1273 = slice_21003 = None
        slice_scatter_default_2547: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2545, slice_scatter_default_2546, 1, 5088, 5104);  slice_scatter_default_2545 = slice_scatter_default_2546 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21023: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_20989, 2, 16, 32);  slice_20989 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_640: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21023, memory_format = torch.contiguous_format);  slice_21023 = None
        view_1284: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_640, [32, 11]);  clone_640 = None
        mm_637: "f32[32, 8]" = torch.ops.aten.mm.default(view_1284, slice_37)
        view_1285: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_637, [2, 16, 8]);  mm_637 = None
        slice_21030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2547, 1, 5088, 5104)
        slice_21031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21030, 2, 0, 16);  slice_21030 = None
        add_639: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21031, view_1285);  slice_21031 = view_1285 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2547, 1, 5088, 5104)
        slice_scatter_default_2548: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1274, add_639, 2, 0, 16);  slice_tensor_1274 = add_639 = None
        slice_scatter_default_2549: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2547, slice_scatter_default_2548, 1, 5088, 5104);  slice_scatter_default_2547 = slice_scatter_default_2548 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2549, 1, 5088, 5104)
        slice_21036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21035, 2, 0, 16);  slice_21035 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2549, 1, 5088, 5104)
        slice_scatter_default_2550: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1275, slice_21036, 2, 0, 16);  slice_tensor_1275 = slice_21036 = None
        slice_scatter_default_2551: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2549, slice_scatter_default_2550, 1, 5088, 5104);  slice_scatter_default_2549 = slice_scatter_default_2550 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21055: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5104, 5120)
        slice_21056: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21055, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_641: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21056, memory_format = torch.contiguous_format);  slice_21056 = None
        view_1286: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_641, [32, 16]);  clone_641 = None
        mm_638: "f32[32, 8]" = torch.ops.aten.mm.default(view_1286, slice_7)
        view_1287: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_638, [2, 16, 8]);  mm_638 = None
        slice_21063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2551, 1, 5104, 5120)
        slice_21064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21063, 2, 0, 16);  slice_21063 = None
        add_640: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21064, view_1287);  slice_21064 = view_1287 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2551, 1, 5104, 5120)
        slice_scatter_default_2552: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1276, add_640, 2, 0, 16);  slice_tensor_1276 = add_640 = None
        slice_scatter_default_2553: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2551, slice_scatter_default_2552, 1, 5104, 5120);  slice_scatter_default_2551 = slice_scatter_default_2552 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2553, 1, 5104, 5120)
        slice_21069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21068, 2, 0, 16);  slice_21068 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2553, 1, 5104, 5120)
        slice_scatter_default_2554: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1277, slice_21069, 2, 0, 16);  slice_tensor_1277 = slice_21069 = None
        slice_scatter_default_2555: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2553, slice_scatter_default_2554, 1, 5104, 5120);  slice_scatter_default_2553 = slice_scatter_default_2554 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21089: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21055, 2, 16, 32);  slice_21055 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_642: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21089, memory_format = torch.contiguous_format);  slice_21089 = None
        view_1288: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_642, [32, 11]);  clone_642 = None
        mm_639: "f32[32, 8]" = torch.ops.aten.mm.default(view_1288, slice_37)
        view_1289: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_639, [2, 16, 8]);  mm_639 = None
        slice_21096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2555, 1, 5104, 5120)
        slice_21097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21096, 2, 0, 16);  slice_21096 = None
        add_641: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21097, view_1289);  slice_21097 = view_1289 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2555, 1, 5104, 5120)
        slice_scatter_default_2556: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1278, add_641, 2, 0, 16);  slice_tensor_1278 = add_641 = None
        slice_scatter_default_2557: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2555, slice_scatter_default_2556, 1, 5104, 5120);  slice_scatter_default_2555 = slice_scatter_default_2556 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2557, 1, 5104, 5120)
        slice_21102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21101, 2, 0, 16);  slice_21101 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2557, 1, 5104, 5120)
        slice_scatter_default_2558: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1279, slice_21102, 2, 0, 16);  slice_tensor_1279 = slice_21102 = None
        slice_scatter_default_2559: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2557, slice_scatter_default_2558, 1, 5104, 5120);  slice_scatter_default_2557 = slice_scatter_default_2558 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21121: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5120, 5136)
        slice_21122: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21121, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_643: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21122, memory_format = torch.contiguous_format);  slice_21122 = None
        view_1290: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_643, [32, 16]);  clone_643 = None
        mm_640: "f32[32, 8]" = torch.ops.aten.mm.default(view_1290, slice_7)
        view_1291: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_640, [2, 16, 8]);  mm_640 = None
        slice_21129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2559, 1, 5120, 5136)
        slice_21130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21129, 2, 0, 16);  slice_21129 = None
        add_642: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21130, view_1291);  slice_21130 = view_1291 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2559, 1, 5120, 5136)
        slice_scatter_default_2560: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1280, add_642, 2, 0, 16);  slice_tensor_1280 = add_642 = None
        slice_scatter_default_2561: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2559, slice_scatter_default_2560, 1, 5120, 5136);  slice_scatter_default_2559 = slice_scatter_default_2560 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2561, 1, 5120, 5136)
        slice_21135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21134, 2, 0, 16);  slice_21134 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2561, 1, 5120, 5136)
        slice_scatter_default_2562: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1281, slice_21135, 2, 0, 16);  slice_tensor_1281 = slice_21135 = None
        slice_scatter_default_2563: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2561, slice_scatter_default_2562, 1, 5120, 5136);  slice_scatter_default_2561 = slice_scatter_default_2562 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21155: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21121, 2, 16, 32);  slice_21121 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_644: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21155, memory_format = torch.contiguous_format);  slice_21155 = None
        view_1292: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_644, [32, 11]);  clone_644 = None
        mm_641: "f32[32, 8]" = torch.ops.aten.mm.default(view_1292, slice_37)
        view_1293: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_641, [2, 16, 8]);  mm_641 = None
        slice_21162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2563, 1, 5120, 5136)
        slice_21163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21162, 2, 0, 16);  slice_21162 = None
        add_643: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21163, view_1293);  slice_21163 = view_1293 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2563, 1, 5120, 5136)
        slice_scatter_default_2564: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1282, add_643, 2, 0, 16);  slice_tensor_1282 = add_643 = None
        slice_scatter_default_2565: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2563, slice_scatter_default_2564, 1, 5120, 5136);  slice_scatter_default_2563 = slice_scatter_default_2564 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2565, 1, 5120, 5136)
        slice_21168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21167, 2, 0, 16);  slice_21167 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2565, 1, 5120, 5136)
        slice_scatter_default_2566: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1283, slice_21168, 2, 0, 16);  slice_tensor_1283 = slice_21168 = None
        slice_scatter_default_2567: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2565, slice_scatter_default_2566, 1, 5120, 5136);  slice_scatter_default_2565 = slice_scatter_default_2566 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21187: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5136, 5152)
        slice_21188: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21187, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_645: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21188, memory_format = torch.contiguous_format);  slice_21188 = None
        view_1294: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_645, [32, 16]);  clone_645 = None
        mm_642: "f32[32, 8]" = torch.ops.aten.mm.default(view_1294, slice_7)
        view_1295: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_642, [2, 16, 8]);  mm_642 = None
        slice_21195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2567, 1, 5136, 5152)
        slice_21196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21195, 2, 0, 16);  slice_21195 = None
        add_644: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21196, view_1295);  slice_21196 = view_1295 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2567, 1, 5136, 5152)
        slice_scatter_default_2568: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1284, add_644, 2, 0, 16);  slice_tensor_1284 = add_644 = None
        slice_scatter_default_2569: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2567, slice_scatter_default_2568, 1, 5136, 5152);  slice_scatter_default_2567 = slice_scatter_default_2568 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2569, 1, 5136, 5152)
        slice_21201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21200, 2, 0, 16);  slice_21200 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2569, 1, 5136, 5152)
        slice_scatter_default_2570: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1285, slice_21201, 2, 0, 16);  slice_tensor_1285 = slice_21201 = None
        slice_scatter_default_2571: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2569, slice_scatter_default_2570, 1, 5136, 5152);  slice_scatter_default_2569 = slice_scatter_default_2570 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21221: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21187, 2, 16, 32);  slice_21187 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_646: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21221, memory_format = torch.contiguous_format);  slice_21221 = None
        view_1296: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_646, [32, 11]);  clone_646 = None
        mm_643: "f32[32, 8]" = torch.ops.aten.mm.default(view_1296, slice_37)
        view_1297: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_643, [2, 16, 8]);  mm_643 = None
        slice_21228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2571, 1, 5136, 5152)
        slice_21229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21228, 2, 0, 16);  slice_21228 = None
        add_645: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21229, view_1297);  slice_21229 = view_1297 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2571, 1, 5136, 5152)
        slice_scatter_default_2572: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1286, add_645, 2, 0, 16);  slice_tensor_1286 = add_645 = None
        slice_scatter_default_2573: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2571, slice_scatter_default_2572, 1, 5136, 5152);  slice_scatter_default_2571 = slice_scatter_default_2572 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2573, 1, 5136, 5152)
        slice_21234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21233, 2, 0, 16);  slice_21233 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2573, 1, 5136, 5152)
        slice_scatter_default_2574: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1287, slice_21234, 2, 0, 16);  slice_tensor_1287 = slice_21234 = None
        slice_scatter_default_2575: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2573, slice_scatter_default_2574, 1, 5136, 5152);  slice_scatter_default_2573 = slice_scatter_default_2574 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21253: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5152, 5168)
        slice_21254: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21253, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_647: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21254, memory_format = torch.contiguous_format);  slice_21254 = None
        view_1298: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_647, [32, 16]);  clone_647 = None
        mm_644: "f32[32, 8]" = torch.ops.aten.mm.default(view_1298, slice_7)
        view_1299: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_644, [2, 16, 8]);  mm_644 = None
        slice_21261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2575, 1, 5152, 5168)
        slice_21262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21261, 2, 0, 16);  slice_21261 = None
        add_646: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21262, view_1299);  slice_21262 = view_1299 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2575, 1, 5152, 5168)
        slice_scatter_default_2576: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1288, add_646, 2, 0, 16);  slice_tensor_1288 = add_646 = None
        slice_scatter_default_2577: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2575, slice_scatter_default_2576, 1, 5152, 5168);  slice_scatter_default_2575 = slice_scatter_default_2576 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2577, 1, 5152, 5168)
        slice_21267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21266, 2, 0, 16);  slice_21266 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2577, 1, 5152, 5168)
        slice_scatter_default_2578: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1289, slice_21267, 2, 0, 16);  slice_tensor_1289 = slice_21267 = None
        slice_scatter_default_2579: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2577, slice_scatter_default_2578, 1, 5152, 5168);  slice_scatter_default_2577 = slice_scatter_default_2578 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21287: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21253, 2, 16, 32);  slice_21253 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_648: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21287, memory_format = torch.contiguous_format);  slice_21287 = None
        view_1300: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_648, [32, 11]);  clone_648 = None
        mm_645: "f32[32, 8]" = torch.ops.aten.mm.default(view_1300, slice_37)
        view_1301: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_645, [2, 16, 8]);  mm_645 = None
        slice_21294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2579, 1, 5152, 5168)
        slice_21295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21294, 2, 0, 16);  slice_21294 = None
        add_647: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21295, view_1301);  slice_21295 = view_1301 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2579, 1, 5152, 5168)
        slice_scatter_default_2580: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1290, add_647, 2, 0, 16);  slice_tensor_1290 = add_647 = None
        slice_scatter_default_2581: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2579, slice_scatter_default_2580, 1, 5152, 5168);  slice_scatter_default_2579 = slice_scatter_default_2580 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2581, 1, 5152, 5168)
        slice_21300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21299, 2, 0, 16);  slice_21299 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2581, 1, 5152, 5168)
        slice_scatter_default_2582: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1291, slice_21300, 2, 0, 16);  slice_tensor_1291 = slice_21300 = None
        slice_scatter_default_2583: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2581, slice_scatter_default_2582, 1, 5152, 5168);  slice_scatter_default_2581 = slice_scatter_default_2582 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21319: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5168, 5184)
        slice_21320: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21319, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_649: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21320, memory_format = torch.contiguous_format);  slice_21320 = None
        view_1302: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_649, [32, 16]);  clone_649 = None
        mm_646: "f32[32, 8]" = torch.ops.aten.mm.default(view_1302, slice_7)
        view_1303: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_646, [2, 16, 8]);  mm_646 = None
        slice_21327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2583, 1, 5168, 5184)
        slice_21328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21327, 2, 0, 16);  slice_21327 = None
        add_648: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21328, view_1303);  slice_21328 = view_1303 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2583, 1, 5168, 5184)
        slice_scatter_default_2584: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1292, add_648, 2, 0, 16);  slice_tensor_1292 = add_648 = None
        slice_scatter_default_2585: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2583, slice_scatter_default_2584, 1, 5168, 5184);  slice_scatter_default_2583 = slice_scatter_default_2584 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2585, 1, 5168, 5184)
        slice_21333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21332, 2, 0, 16);  slice_21332 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2585, 1, 5168, 5184)
        slice_scatter_default_2586: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1293, slice_21333, 2, 0, 16);  slice_tensor_1293 = slice_21333 = None
        slice_scatter_default_2587: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2585, slice_scatter_default_2586, 1, 5168, 5184);  slice_scatter_default_2585 = slice_scatter_default_2586 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21353: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21319, 2, 16, 32);  slice_21319 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_650: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21353, memory_format = torch.contiguous_format);  slice_21353 = None
        view_1304: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_650, [32, 11]);  clone_650 = None
        mm_647: "f32[32, 8]" = torch.ops.aten.mm.default(view_1304, slice_37)
        view_1305: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_647, [2, 16, 8]);  mm_647 = None
        slice_21360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2587, 1, 5168, 5184)
        slice_21361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21360, 2, 0, 16);  slice_21360 = None
        add_649: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21361, view_1305);  slice_21361 = view_1305 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2587, 1, 5168, 5184)
        slice_scatter_default_2588: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1294, add_649, 2, 0, 16);  slice_tensor_1294 = add_649 = None
        slice_scatter_default_2589: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2587, slice_scatter_default_2588, 1, 5168, 5184);  slice_scatter_default_2587 = slice_scatter_default_2588 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2589, 1, 5168, 5184)
        slice_21366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21365, 2, 0, 16);  slice_21365 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2589, 1, 5168, 5184)
        slice_scatter_default_2590: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1295, slice_21366, 2, 0, 16);  slice_tensor_1295 = slice_21366 = None
        slice_scatter_default_2591: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2589, slice_scatter_default_2590, 1, 5168, 5184);  slice_scatter_default_2589 = slice_scatter_default_2590 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21385: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5184, 5200)
        slice_21386: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21385, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_651: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21386, memory_format = torch.contiguous_format);  slice_21386 = None
        view_1306: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_651, [32, 16]);  clone_651 = None
        mm_648: "f32[32, 8]" = torch.ops.aten.mm.default(view_1306, slice_7)
        view_1307: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_648, [2, 16, 8]);  mm_648 = None
        slice_21393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2591, 1, 5184, 5200)
        slice_21394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21393, 2, 0, 16);  slice_21393 = None
        add_650: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21394, view_1307);  slice_21394 = view_1307 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2591, 1, 5184, 5200)
        slice_scatter_default_2592: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1296, add_650, 2, 0, 16);  slice_tensor_1296 = add_650 = None
        slice_scatter_default_2593: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2591, slice_scatter_default_2592, 1, 5184, 5200);  slice_scatter_default_2591 = slice_scatter_default_2592 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2593, 1, 5184, 5200)
        slice_21399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21398, 2, 0, 16);  slice_21398 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2593, 1, 5184, 5200)
        slice_scatter_default_2594: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1297, slice_21399, 2, 0, 16);  slice_tensor_1297 = slice_21399 = None
        slice_scatter_default_2595: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2593, slice_scatter_default_2594, 1, 5184, 5200);  slice_scatter_default_2593 = slice_scatter_default_2594 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21419: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21385, 2, 16, 32);  slice_21385 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_652: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21419, memory_format = torch.contiguous_format);  slice_21419 = None
        view_1308: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_652, [32, 11]);  clone_652 = None
        mm_649: "f32[32, 8]" = torch.ops.aten.mm.default(view_1308, slice_37)
        view_1309: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_649, [2, 16, 8]);  mm_649 = None
        slice_21426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2595, 1, 5184, 5200)
        slice_21427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21426, 2, 0, 16);  slice_21426 = None
        add_651: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21427, view_1309);  slice_21427 = view_1309 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2595, 1, 5184, 5200)
        slice_scatter_default_2596: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1298, add_651, 2, 0, 16);  slice_tensor_1298 = add_651 = None
        slice_scatter_default_2597: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2595, slice_scatter_default_2596, 1, 5184, 5200);  slice_scatter_default_2595 = slice_scatter_default_2596 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2597, 1, 5184, 5200)
        slice_21432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21431, 2, 0, 16);  slice_21431 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2597, 1, 5184, 5200)
        slice_scatter_default_2598: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1299, slice_21432, 2, 0, 16);  slice_tensor_1299 = slice_21432 = None
        slice_scatter_default_2599: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2597, slice_scatter_default_2598, 1, 5184, 5200);  slice_scatter_default_2597 = slice_scatter_default_2598 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21451: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5200, 5216)
        slice_21452: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21451, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_653: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21452, memory_format = torch.contiguous_format);  slice_21452 = None
        view_1310: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_653, [32, 16]);  clone_653 = None
        mm_650: "f32[32, 8]" = torch.ops.aten.mm.default(view_1310, slice_7)
        view_1311: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_650, [2, 16, 8]);  mm_650 = None
        slice_21459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2599, 1, 5200, 5216)
        slice_21460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21459, 2, 0, 16);  slice_21459 = None
        add_652: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21460, view_1311);  slice_21460 = view_1311 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2599, 1, 5200, 5216)
        slice_scatter_default_2600: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1300, add_652, 2, 0, 16);  slice_tensor_1300 = add_652 = None
        slice_scatter_default_2601: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2599, slice_scatter_default_2600, 1, 5200, 5216);  slice_scatter_default_2599 = slice_scatter_default_2600 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2601, 1, 5200, 5216)
        slice_21465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21464, 2, 0, 16);  slice_21464 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2601, 1, 5200, 5216)
        slice_scatter_default_2602: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1301, slice_21465, 2, 0, 16);  slice_tensor_1301 = slice_21465 = None
        slice_scatter_default_2603: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2601, slice_scatter_default_2602, 1, 5200, 5216);  slice_scatter_default_2601 = slice_scatter_default_2602 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21485: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21451, 2, 16, 32);  slice_21451 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_654: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21485, memory_format = torch.contiguous_format);  slice_21485 = None
        view_1312: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_654, [32, 11]);  clone_654 = None
        mm_651: "f32[32, 8]" = torch.ops.aten.mm.default(view_1312, slice_37)
        view_1313: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_651, [2, 16, 8]);  mm_651 = None
        slice_21492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2603, 1, 5200, 5216)
        slice_21493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21492, 2, 0, 16);  slice_21492 = None
        add_653: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21493, view_1313);  slice_21493 = view_1313 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2603, 1, 5200, 5216)
        slice_scatter_default_2604: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1302, add_653, 2, 0, 16);  slice_tensor_1302 = add_653 = None
        slice_scatter_default_2605: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2603, slice_scatter_default_2604, 1, 5200, 5216);  slice_scatter_default_2603 = slice_scatter_default_2604 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2605, 1, 5200, 5216)
        slice_21498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21497, 2, 0, 16);  slice_21497 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2605, 1, 5200, 5216)
        slice_scatter_default_2606: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1303, slice_21498, 2, 0, 16);  slice_tensor_1303 = slice_21498 = None
        slice_scatter_default_2607: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2605, slice_scatter_default_2606, 1, 5200, 5216);  slice_scatter_default_2605 = slice_scatter_default_2606 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21517: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5216, 5232)
        slice_21518: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21517, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_655: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21518, memory_format = torch.contiguous_format);  slice_21518 = None
        view_1314: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_655, [32, 16]);  clone_655 = None
        mm_652: "f32[32, 8]" = torch.ops.aten.mm.default(view_1314, slice_7)
        view_1315: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_652, [2, 16, 8]);  mm_652 = None
        slice_21525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2607, 1, 5216, 5232)
        slice_21526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21525, 2, 0, 16);  slice_21525 = None
        add_654: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21526, view_1315);  slice_21526 = view_1315 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2607, 1, 5216, 5232)
        slice_scatter_default_2608: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1304, add_654, 2, 0, 16);  slice_tensor_1304 = add_654 = None
        slice_scatter_default_2609: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2607, slice_scatter_default_2608, 1, 5216, 5232);  slice_scatter_default_2607 = slice_scatter_default_2608 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2609, 1, 5216, 5232)
        slice_21531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21530, 2, 0, 16);  slice_21530 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2609, 1, 5216, 5232)
        slice_scatter_default_2610: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1305, slice_21531, 2, 0, 16);  slice_tensor_1305 = slice_21531 = None
        slice_scatter_default_2611: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2609, slice_scatter_default_2610, 1, 5216, 5232);  slice_scatter_default_2609 = slice_scatter_default_2610 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21551: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21517, 2, 16, 32);  slice_21517 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_656: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21551, memory_format = torch.contiguous_format);  slice_21551 = None
        view_1316: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_656, [32, 11]);  clone_656 = None
        mm_653: "f32[32, 8]" = torch.ops.aten.mm.default(view_1316, slice_37)
        view_1317: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_653, [2, 16, 8]);  mm_653 = None
        slice_21558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2611, 1, 5216, 5232)
        slice_21559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21558, 2, 0, 16);  slice_21558 = None
        add_655: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21559, view_1317);  slice_21559 = view_1317 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2611, 1, 5216, 5232)
        slice_scatter_default_2612: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1306, add_655, 2, 0, 16);  slice_tensor_1306 = add_655 = None
        slice_scatter_default_2613: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2611, slice_scatter_default_2612, 1, 5216, 5232);  slice_scatter_default_2611 = slice_scatter_default_2612 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2613, 1, 5216, 5232)
        slice_21564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21563, 2, 0, 16);  slice_21563 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2613, 1, 5216, 5232)
        slice_scatter_default_2614: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1307, slice_21564, 2, 0, 16);  slice_tensor_1307 = slice_21564 = None
        slice_scatter_default_2615: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2613, slice_scatter_default_2614, 1, 5216, 5232);  slice_scatter_default_2613 = slice_scatter_default_2614 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21583: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5232, 5248)
        slice_21584: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21583, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_657: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21584, memory_format = torch.contiguous_format);  slice_21584 = None
        view_1318: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_657, [32, 16]);  clone_657 = None
        mm_654: "f32[32, 8]" = torch.ops.aten.mm.default(view_1318, slice_7)
        view_1319: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_654, [2, 16, 8]);  mm_654 = None
        slice_21591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2615, 1, 5232, 5248)
        slice_21592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21591, 2, 0, 16);  slice_21591 = None
        add_656: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21592, view_1319);  slice_21592 = view_1319 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2615, 1, 5232, 5248)
        slice_scatter_default_2616: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1308, add_656, 2, 0, 16);  slice_tensor_1308 = add_656 = None
        slice_scatter_default_2617: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2615, slice_scatter_default_2616, 1, 5232, 5248);  slice_scatter_default_2615 = slice_scatter_default_2616 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2617, 1, 5232, 5248)
        slice_21597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21596, 2, 0, 16);  slice_21596 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2617, 1, 5232, 5248)
        slice_scatter_default_2618: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1309, slice_21597, 2, 0, 16);  slice_tensor_1309 = slice_21597 = None
        slice_scatter_default_2619: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2617, slice_scatter_default_2618, 1, 5232, 5248);  slice_scatter_default_2617 = slice_scatter_default_2618 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21617: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21583, 2, 16, 32);  slice_21583 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_658: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21617, memory_format = torch.contiguous_format);  slice_21617 = None
        view_1320: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_658, [32, 11]);  clone_658 = None
        mm_655: "f32[32, 8]" = torch.ops.aten.mm.default(view_1320, slice_37)
        view_1321: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_655, [2, 16, 8]);  mm_655 = None
        slice_21624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2619, 1, 5232, 5248)
        slice_21625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21624, 2, 0, 16);  slice_21624 = None
        add_657: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21625, view_1321);  slice_21625 = view_1321 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2619, 1, 5232, 5248)
        slice_scatter_default_2620: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1310, add_657, 2, 0, 16);  slice_tensor_1310 = add_657 = None
        slice_scatter_default_2621: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2619, slice_scatter_default_2620, 1, 5232, 5248);  slice_scatter_default_2619 = slice_scatter_default_2620 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2621, 1, 5232, 5248)
        slice_21630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21629, 2, 0, 16);  slice_21629 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2621, 1, 5232, 5248)
        slice_scatter_default_2622: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1311, slice_21630, 2, 0, 16);  slice_tensor_1311 = slice_21630 = None
        slice_scatter_default_2623: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2621, slice_scatter_default_2622, 1, 5232, 5248);  slice_scatter_default_2621 = slice_scatter_default_2622 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21649: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5248, 5264)
        slice_21650: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21649, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_659: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21650, memory_format = torch.contiguous_format);  slice_21650 = None
        view_1322: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_659, [32, 16]);  clone_659 = None
        mm_656: "f32[32, 8]" = torch.ops.aten.mm.default(view_1322, slice_7)
        view_1323: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_656, [2, 16, 8]);  mm_656 = None
        slice_21657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2623, 1, 5248, 5264)
        slice_21658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21657, 2, 0, 16);  slice_21657 = None
        add_658: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21658, view_1323);  slice_21658 = view_1323 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2623, 1, 5248, 5264)
        slice_scatter_default_2624: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1312, add_658, 2, 0, 16);  slice_tensor_1312 = add_658 = None
        slice_scatter_default_2625: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2623, slice_scatter_default_2624, 1, 5248, 5264);  slice_scatter_default_2623 = slice_scatter_default_2624 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2625, 1, 5248, 5264)
        slice_21663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21662, 2, 0, 16);  slice_21662 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2625, 1, 5248, 5264)
        slice_scatter_default_2626: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1313, slice_21663, 2, 0, 16);  slice_tensor_1313 = slice_21663 = None
        slice_scatter_default_2627: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2625, slice_scatter_default_2626, 1, 5248, 5264);  slice_scatter_default_2625 = slice_scatter_default_2626 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21683: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21649, 2, 16, 32);  slice_21649 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_660: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21683, memory_format = torch.contiguous_format);  slice_21683 = None
        view_1324: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_660, [32, 11]);  clone_660 = None
        mm_657: "f32[32, 8]" = torch.ops.aten.mm.default(view_1324, slice_37)
        view_1325: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_657, [2, 16, 8]);  mm_657 = None
        slice_21690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2627, 1, 5248, 5264)
        slice_21691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21690, 2, 0, 16);  slice_21690 = None
        add_659: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21691, view_1325);  slice_21691 = view_1325 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2627, 1, 5248, 5264)
        slice_scatter_default_2628: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1314, add_659, 2, 0, 16);  slice_tensor_1314 = add_659 = None
        slice_scatter_default_2629: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2627, slice_scatter_default_2628, 1, 5248, 5264);  slice_scatter_default_2627 = slice_scatter_default_2628 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2629, 1, 5248, 5264)
        slice_21696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21695, 2, 0, 16);  slice_21695 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2629, 1, 5248, 5264)
        slice_scatter_default_2630: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1315, slice_21696, 2, 0, 16);  slice_tensor_1315 = slice_21696 = None
        slice_scatter_default_2631: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2629, slice_scatter_default_2630, 1, 5248, 5264);  slice_scatter_default_2629 = slice_scatter_default_2630 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21715: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5264, 5280)
        slice_21716: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21715, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_661: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21716, memory_format = torch.contiguous_format);  slice_21716 = None
        view_1326: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_661, [32, 16]);  clone_661 = None
        mm_658: "f32[32, 8]" = torch.ops.aten.mm.default(view_1326, slice_7)
        view_1327: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_658, [2, 16, 8]);  mm_658 = None
        slice_21723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2631, 1, 5264, 5280)
        slice_21724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21723, 2, 0, 16);  slice_21723 = None
        add_660: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21724, view_1327);  slice_21724 = view_1327 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2631, 1, 5264, 5280)
        slice_scatter_default_2632: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1316, add_660, 2, 0, 16);  slice_tensor_1316 = add_660 = None
        slice_scatter_default_2633: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2631, slice_scatter_default_2632, 1, 5264, 5280);  slice_scatter_default_2631 = slice_scatter_default_2632 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2633, 1, 5264, 5280)
        slice_21729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21728, 2, 0, 16);  slice_21728 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2633, 1, 5264, 5280)
        slice_scatter_default_2634: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1317, slice_21729, 2, 0, 16);  slice_tensor_1317 = slice_21729 = None
        slice_scatter_default_2635: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2633, slice_scatter_default_2634, 1, 5264, 5280);  slice_scatter_default_2633 = slice_scatter_default_2634 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21749: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21715, 2, 16, 32);  slice_21715 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_662: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21749, memory_format = torch.contiguous_format);  slice_21749 = None
        view_1328: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_662, [32, 11]);  clone_662 = None
        mm_659: "f32[32, 8]" = torch.ops.aten.mm.default(view_1328, slice_37)
        view_1329: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_659, [2, 16, 8]);  mm_659 = None
        slice_21756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2635, 1, 5264, 5280)
        slice_21757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21756, 2, 0, 16);  slice_21756 = None
        add_661: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21757, view_1329);  slice_21757 = view_1329 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2635, 1, 5264, 5280)
        slice_scatter_default_2636: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1318, add_661, 2, 0, 16);  slice_tensor_1318 = add_661 = None
        slice_scatter_default_2637: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2635, slice_scatter_default_2636, 1, 5264, 5280);  slice_scatter_default_2635 = slice_scatter_default_2636 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2637, 1, 5264, 5280)
        slice_21762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21761, 2, 0, 16);  slice_21761 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2637, 1, 5264, 5280)
        slice_scatter_default_2638: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1319, slice_21762, 2, 0, 16);  slice_tensor_1319 = slice_21762 = None
        slice_scatter_default_2639: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2637, slice_scatter_default_2638, 1, 5264, 5280);  slice_scatter_default_2637 = slice_scatter_default_2638 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21781: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5280, 5296)
        slice_21782: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21781, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_663: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21782, memory_format = torch.contiguous_format);  slice_21782 = None
        view_1330: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_663, [32, 16]);  clone_663 = None
        mm_660: "f32[32, 8]" = torch.ops.aten.mm.default(view_1330, slice_7)
        view_1331: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_660, [2, 16, 8]);  mm_660 = None
        slice_21789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2639, 1, 5280, 5296)
        slice_21790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21789, 2, 0, 16);  slice_21789 = None
        add_662: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21790, view_1331);  slice_21790 = view_1331 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2639, 1, 5280, 5296)
        slice_scatter_default_2640: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1320, add_662, 2, 0, 16);  slice_tensor_1320 = add_662 = None
        slice_scatter_default_2641: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2639, slice_scatter_default_2640, 1, 5280, 5296);  slice_scatter_default_2639 = slice_scatter_default_2640 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2641, 1, 5280, 5296)
        slice_21795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21794, 2, 0, 16);  slice_21794 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2641, 1, 5280, 5296)
        slice_scatter_default_2642: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1321, slice_21795, 2, 0, 16);  slice_tensor_1321 = slice_21795 = None
        slice_scatter_default_2643: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2641, slice_scatter_default_2642, 1, 5280, 5296);  slice_scatter_default_2641 = slice_scatter_default_2642 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21815: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21781, 2, 16, 32);  slice_21781 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_664: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21815, memory_format = torch.contiguous_format);  slice_21815 = None
        view_1332: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_664, [32, 11]);  clone_664 = None
        mm_661: "f32[32, 8]" = torch.ops.aten.mm.default(view_1332, slice_37)
        view_1333: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_661, [2, 16, 8]);  mm_661 = None
        slice_21822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2643, 1, 5280, 5296)
        slice_21823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21822, 2, 0, 16);  slice_21822 = None
        add_663: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21823, view_1333);  slice_21823 = view_1333 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2643, 1, 5280, 5296)
        slice_scatter_default_2644: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1322, add_663, 2, 0, 16);  slice_tensor_1322 = add_663 = None
        slice_scatter_default_2645: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2643, slice_scatter_default_2644, 1, 5280, 5296);  slice_scatter_default_2643 = slice_scatter_default_2644 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2645, 1, 5280, 5296)
        slice_21828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21827, 2, 0, 16);  slice_21827 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2645, 1, 5280, 5296)
        slice_scatter_default_2646: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1323, slice_21828, 2, 0, 16);  slice_tensor_1323 = slice_21828 = None
        slice_scatter_default_2647: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2645, slice_scatter_default_2646, 1, 5280, 5296);  slice_scatter_default_2645 = slice_scatter_default_2646 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21847: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5296, 5312)
        slice_21848: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21847, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_665: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21848, memory_format = torch.contiguous_format);  slice_21848 = None
        view_1334: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_665, [32, 16]);  clone_665 = None
        mm_662: "f32[32, 8]" = torch.ops.aten.mm.default(view_1334, slice_7)
        view_1335: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_662, [2, 16, 8]);  mm_662 = None
        slice_21855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2647, 1, 5296, 5312)
        slice_21856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21855, 2, 0, 16);  slice_21855 = None
        add_664: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21856, view_1335);  slice_21856 = view_1335 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2647, 1, 5296, 5312)
        slice_scatter_default_2648: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1324, add_664, 2, 0, 16);  slice_tensor_1324 = add_664 = None
        slice_scatter_default_2649: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2647, slice_scatter_default_2648, 1, 5296, 5312);  slice_scatter_default_2647 = slice_scatter_default_2648 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2649, 1, 5296, 5312)
        slice_21861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21860, 2, 0, 16);  slice_21860 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2649, 1, 5296, 5312)
        slice_scatter_default_2650: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1325, slice_21861, 2, 0, 16);  slice_tensor_1325 = slice_21861 = None
        slice_scatter_default_2651: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2649, slice_scatter_default_2650, 1, 5296, 5312);  slice_scatter_default_2649 = slice_scatter_default_2650 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21881: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21847, 2, 16, 32);  slice_21847 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_666: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21881, memory_format = torch.contiguous_format);  slice_21881 = None
        view_1336: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_666, [32, 11]);  clone_666 = None
        mm_663: "f32[32, 8]" = torch.ops.aten.mm.default(view_1336, slice_37)
        view_1337: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_663, [2, 16, 8]);  mm_663 = None
        slice_21888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2651, 1, 5296, 5312)
        slice_21889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21888, 2, 0, 16);  slice_21888 = None
        add_665: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21889, view_1337);  slice_21889 = view_1337 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2651, 1, 5296, 5312)
        slice_scatter_default_2652: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1326, add_665, 2, 0, 16);  slice_tensor_1326 = add_665 = None
        slice_scatter_default_2653: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2651, slice_scatter_default_2652, 1, 5296, 5312);  slice_scatter_default_2651 = slice_scatter_default_2652 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2653, 1, 5296, 5312)
        slice_21894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21893, 2, 0, 16);  slice_21893 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2653, 1, 5296, 5312)
        slice_scatter_default_2654: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1327, slice_21894, 2, 0, 16);  slice_tensor_1327 = slice_21894 = None
        slice_scatter_default_2655: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2653, slice_scatter_default_2654, 1, 5296, 5312);  slice_scatter_default_2653 = slice_scatter_default_2654 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21913: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5312, 5328)
        slice_21914: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21913, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_667: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21914, memory_format = torch.contiguous_format);  slice_21914 = None
        view_1338: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_667, [32, 16]);  clone_667 = None
        mm_664: "f32[32, 8]" = torch.ops.aten.mm.default(view_1338, slice_7)
        view_1339: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_664, [2, 16, 8]);  mm_664 = None
        slice_21921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2655, 1, 5312, 5328)
        slice_21922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21921, 2, 0, 16);  slice_21921 = None
        add_666: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21922, view_1339);  slice_21922 = view_1339 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2655, 1, 5312, 5328)
        slice_scatter_default_2656: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1328, add_666, 2, 0, 16);  slice_tensor_1328 = add_666 = None
        slice_scatter_default_2657: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2655, slice_scatter_default_2656, 1, 5312, 5328);  slice_scatter_default_2655 = slice_scatter_default_2656 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2657, 1, 5312, 5328)
        slice_21927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21926, 2, 0, 16);  slice_21926 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2657, 1, 5312, 5328)
        slice_scatter_default_2658: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1329, slice_21927, 2, 0, 16);  slice_tensor_1329 = slice_21927 = None
        slice_scatter_default_2659: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2657, slice_scatter_default_2658, 1, 5312, 5328);  slice_scatter_default_2657 = slice_scatter_default_2658 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21947: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21913, 2, 16, 32);  slice_21913 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_668: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_21947, memory_format = torch.contiguous_format);  slice_21947 = None
        view_1340: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_668, [32, 11]);  clone_668 = None
        mm_665: "f32[32, 8]" = torch.ops.aten.mm.default(view_1340, slice_37)
        view_1341: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_665, [2, 16, 8]);  mm_665 = None
        slice_21954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2659, 1, 5312, 5328)
        slice_21955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21954, 2, 0, 16);  slice_21954 = None
        add_667: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21955, view_1341);  slice_21955 = view_1341 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2659, 1, 5312, 5328)
        slice_scatter_default_2660: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1330, add_667, 2, 0, 16);  slice_tensor_1330 = add_667 = None
        slice_scatter_default_2661: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2659, slice_scatter_default_2660, 1, 5312, 5328);  slice_scatter_default_2659 = slice_scatter_default_2660 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2661, 1, 5312, 5328)
        slice_21960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21959, 2, 0, 16);  slice_21959 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2661, 1, 5312, 5328)
        slice_scatter_default_2662: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1331, slice_21960, 2, 0, 16);  slice_tensor_1331 = slice_21960 = None
        slice_scatter_default_2663: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2661, slice_scatter_default_2662, 1, 5312, 5328);  slice_scatter_default_2661 = slice_scatter_default_2662 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_21979: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5328, 5344)
        slice_21980: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_21979, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_669: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_21980, memory_format = torch.contiguous_format);  slice_21980 = None
        view_1342: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_669, [32, 16]);  clone_669 = None
        mm_666: "f32[32, 8]" = torch.ops.aten.mm.default(view_1342, slice_7)
        view_1343: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_666, [2, 16, 8]);  mm_666 = None
        slice_21987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2663, 1, 5328, 5344)
        slice_21988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21987, 2, 0, 16);  slice_21987 = None
        add_668: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_21988, view_1343);  slice_21988 = view_1343 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2663, 1, 5328, 5344)
        slice_scatter_default_2664: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1332, add_668, 2, 0, 16);  slice_tensor_1332 = add_668 = None
        slice_scatter_default_2665: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2663, slice_scatter_default_2664, 1, 5328, 5344);  slice_scatter_default_2663 = slice_scatter_default_2664 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_21992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2665, 1, 5328, 5344)
        slice_21993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_21992, 2, 0, 16);  slice_21992 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2665, 1, 5328, 5344)
        slice_scatter_default_2666: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1333, slice_21993, 2, 0, 16);  slice_tensor_1333 = slice_21993 = None
        slice_scatter_default_2667: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2665, slice_scatter_default_2666, 1, 5328, 5344);  slice_scatter_default_2665 = slice_scatter_default_2666 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22013: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_21979, 2, 16, 32);  slice_21979 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_670: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22013, memory_format = torch.contiguous_format);  slice_22013 = None
        view_1344: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_670, [32, 11]);  clone_670 = None
        mm_667: "f32[32, 8]" = torch.ops.aten.mm.default(view_1344, slice_37)
        view_1345: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_667, [2, 16, 8]);  mm_667 = None
        slice_22020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2667, 1, 5328, 5344)
        slice_22021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22020, 2, 0, 16);  slice_22020 = None
        add_669: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22021, view_1345);  slice_22021 = view_1345 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2667, 1, 5328, 5344)
        slice_scatter_default_2668: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1334, add_669, 2, 0, 16);  slice_tensor_1334 = add_669 = None
        slice_scatter_default_2669: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2667, slice_scatter_default_2668, 1, 5328, 5344);  slice_scatter_default_2667 = slice_scatter_default_2668 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2669, 1, 5328, 5344)
        slice_22026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22025, 2, 0, 16);  slice_22025 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2669, 1, 5328, 5344)
        slice_scatter_default_2670: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1335, slice_22026, 2, 0, 16);  slice_tensor_1335 = slice_22026 = None
        slice_scatter_default_2671: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2669, slice_scatter_default_2670, 1, 5328, 5344);  slice_scatter_default_2669 = slice_scatter_default_2670 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22045: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5344, 5360)
        slice_22046: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22045, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_671: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22046, memory_format = torch.contiguous_format);  slice_22046 = None
        view_1346: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_671, [32, 16]);  clone_671 = None
        mm_668: "f32[32, 8]" = torch.ops.aten.mm.default(view_1346, slice_7)
        view_1347: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_668, [2, 16, 8]);  mm_668 = None
        slice_22053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2671, 1, 5344, 5360)
        slice_22054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22053, 2, 0, 16);  slice_22053 = None
        add_670: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22054, view_1347);  slice_22054 = view_1347 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2671, 1, 5344, 5360)
        slice_scatter_default_2672: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1336, add_670, 2, 0, 16);  slice_tensor_1336 = add_670 = None
        slice_scatter_default_2673: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2671, slice_scatter_default_2672, 1, 5344, 5360);  slice_scatter_default_2671 = slice_scatter_default_2672 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2673, 1, 5344, 5360)
        slice_22059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22058, 2, 0, 16);  slice_22058 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2673, 1, 5344, 5360)
        slice_scatter_default_2674: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1337, slice_22059, 2, 0, 16);  slice_tensor_1337 = slice_22059 = None
        slice_scatter_default_2675: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2673, slice_scatter_default_2674, 1, 5344, 5360);  slice_scatter_default_2673 = slice_scatter_default_2674 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22079: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22045, 2, 16, 32);  slice_22045 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_672: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22079, memory_format = torch.contiguous_format);  slice_22079 = None
        view_1348: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_672, [32, 11]);  clone_672 = None
        mm_669: "f32[32, 8]" = torch.ops.aten.mm.default(view_1348, slice_37)
        view_1349: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_669, [2, 16, 8]);  mm_669 = None
        slice_22086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2675, 1, 5344, 5360)
        slice_22087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22086, 2, 0, 16);  slice_22086 = None
        add_671: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22087, view_1349);  slice_22087 = view_1349 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2675, 1, 5344, 5360)
        slice_scatter_default_2676: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1338, add_671, 2, 0, 16);  slice_tensor_1338 = add_671 = None
        slice_scatter_default_2677: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2675, slice_scatter_default_2676, 1, 5344, 5360);  slice_scatter_default_2675 = slice_scatter_default_2676 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2677, 1, 5344, 5360)
        slice_22092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22091, 2, 0, 16);  slice_22091 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2677, 1, 5344, 5360)
        slice_scatter_default_2678: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1339, slice_22092, 2, 0, 16);  slice_tensor_1339 = slice_22092 = None
        slice_scatter_default_2679: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2677, slice_scatter_default_2678, 1, 5344, 5360);  slice_scatter_default_2677 = slice_scatter_default_2678 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22111: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5360, 5376)
        slice_22112: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22111, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_673: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22112, memory_format = torch.contiguous_format);  slice_22112 = None
        view_1350: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_673, [32, 16]);  clone_673 = None
        mm_670: "f32[32, 8]" = torch.ops.aten.mm.default(view_1350, slice_7)
        view_1351: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_670, [2, 16, 8]);  mm_670 = None
        slice_22119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2679, 1, 5360, 5376)
        slice_22120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22119, 2, 0, 16);  slice_22119 = None
        add_672: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22120, view_1351);  slice_22120 = view_1351 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2679, 1, 5360, 5376)
        slice_scatter_default_2680: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1340, add_672, 2, 0, 16);  slice_tensor_1340 = add_672 = None
        slice_scatter_default_2681: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2679, slice_scatter_default_2680, 1, 5360, 5376);  slice_scatter_default_2679 = slice_scatter_default_2680 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2681, 1, 5360, 5376)
        slice_22125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22124, 2, 0, 16);  slice_22124 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2681, 1, 5360, 5376)
        slice_scatter_default_2682: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1341, slice_22125, 2, 0, 16);  slice_tensor_1341 = slice_22125 = None
        slice_scatter_default_2683: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2681, slice_scatter_default_2682, 1, 5360, 5376);  slice_scatter_default_2681 = slice_scatter_default_2682 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22145: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22111, 2, 16, 32);  slice_22111 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_674: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22145, memory_format = torch.contiguous_format);  slice_22145 = None
        view_1352: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_674, [32, 11]);  clone_674 = None
        mm_671: "f32[32, 8]" = torch.ops.aten.mm.default(view_1352, slice_37)
        view_1353: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_671, [2, 16, 8]);  mm_671 = None
        slice_22152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2683, 1, 5360, 5376)
        slice_22153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22152, 2, 0, 16);  slice_22152 = None
        add_673: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22153, view_1353);  slice_22153 = view_1353 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2683, 1, 5360, 5376)
        slice_scatter_default_2684: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1342, add_673, 2, 0, 16);  slice_tensor_1342 = add_673 = None
        slice_scatter_default_2685: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2683, slice_scatter_default_2684, 1, 5360, 5376);  slice_scatter_default_2683 = slice_scatter_default_2684 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2685, 1, 5360, 5376)
        slice_22158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22157, 2, 0, 16);  slice_22157 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2685, 1, 5360, 5376)
        slice_scatter_default_2686: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1343, slice_22158, 2, 0, 16);  slice_tensor_1343 = slice_22158 = None
        slice_scatter_default_2687: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2685, slice_scatter_default_2686, 1, 5360, 5376);  slice_scatter_default_2685 = slice_scatter_default_2686 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22177: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5376, 5392)
        slice_22178: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22177, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_675: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22178, memory_format = torch.contiguous_format);  slice_22178 = None
        view_1354: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_675, [32, 16]);  clone_675 = None
        mm_672: "f32[32, 8]" = torch.ops.aten.mm.default(view_1354, slice_7)
        view_1355: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_672, [2, 16, 8]);  mm_672 = None
        slice_22185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2687, 1, 5376, 5392)
        slice_22186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22185, 2, 0, 16);  slice_22185 = None
        add_674: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22186, view_1355);  slice_22186 = view_1355 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2687, 1, 5376, 5392)
        slice_scatter_default_2688: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1344, add_674, 2, 0, 16);  slice_tensor_1344 = add_674 = None
        slice_scatter_default_2689: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2687, slice_scatter_default_2688, 1, 5376, 5392);  slice_scatter_default_2687 = slice_scatter_default_2688 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2689, 1, 5376, 5392)
        slice_22191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22190, 2, 0, 16);  slice_22190 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2689, 1, 5376, 5392)
        slice_scatter_default_2690: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1345, slice_22191, 2, 0, 16);  slice_tensor_1345 = slice_22191 = None
        slice_scatter_default_2691: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2689, slice_scatter_default_2690, 1, 5376, 5392);  slice_scatter_default_2689 = slice_scatter_default_2690 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22211: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22177, 2, 16, 32);  slice_22177 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_676: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22211, memory_format = torch.contiguous_format);  slice_22211 = None
        view_1356: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_676, [32, 11]);  clone_676 = None
        mm_673: "f32[32, 8]" = torch.ops.aten.mm.default(view_1356, slice_37)
        view_1357: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_673, [2, 16, 8]);  mm_673 = None
        slice_22218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2691, 1, 5376, 5392)
        slice_22219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22218, 2, 0, 16);  slice_22218 = None
        add_675: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22219, view_1357);  slice_22219 = view_1357 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2691, 1, 5376, 5392)
        slice_scatter_default_2692: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1346, add_675, 2, 0, 16);  slice_tensor_1346 = add_675 = None
        slice_scatter_default_2693: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2691, slice_scatter_default_2692, 1, 5376, 5392);  slice_scatter_default_2691 = slice_scatter_default_2692 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2693, 1, 5376, 5392)
        slice_22224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22223, 2, 0, 16);  slice_22223 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2693, 1, 5376, 5392)
        slice_scatter_default_2694: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1347, slice_22224, 2, 0, 16);  slice_tensor_1347 = slice_22224 = None
        slice_scatter_default_2695: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2693, slice_scatter_default_2694, 1, 5376, 5392);  slice_scatter_default_2693 = slice_scatter_default_2694 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22243: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5392, 5408)
        slice_22244: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22243, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_677: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22244, memory_format = torch.contiguous_format);  slice_22244 = None
        view_1358: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_677, [32, 16]);  clone_677 = None
        mm_674: "f32[32, 8]" = torch.ops.aten.mm.default(view_1358, slice_7)
        view_1359: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_674, [2, 16, 8]);  mm_674 = None
        slice_22251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2695, 1, 5392, 5408)
        slice_22252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22251, 2, 0, 16);  slice_22251 = None
        add_676: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22252, view_1359);  slice_22252 = view_1359 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2695, 1, 5392, 5408)
        slice_scatter_default_2696: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1348, add_676, 2, 0, 16);  slice_tensor_1348 = add_676 = None
        slice_scatter_default_2697: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2695, slice_scatter_default_2696, 1, 5392, 5408);  slice_scatter_default_2695 = slice_scatter_default_2696 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2697, 1, 5392, 5408)
        slice_22257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22256, 2, 0, 16);  slice_22256 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2697, 1, 5392, 5408)
        slice_scatter_default_2698: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1349, slice_22257, 2, 0, 16);  slice_tensor_1349 = slice_22257 = None
        slice_scatter_default_2699: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2697, slice_scatter_default_2698, 1, 5392, 5408);  slice_scatter_default_2697 = slice_scatter_default_2698 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22277: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22243, 2, 16, 32);  slice_22243 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_678: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22277, memory_format = torch.contiguous_format);  slice_22277 = None
        view_1360: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_678, [32, 11]);  clone_678 = None
        mm_675: "f32[32, 8]" = torch.ops.aten.mm.default(view_1360, slice_37)
        view_1361: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_675, [2, 16, 8]);  mm_675 = None
        slice_22284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2699, 1, 5392, 5408)
        slice_22285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22284, 2, 0, 16);  slice_22284 = None
        add_677: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22285, view_1361);  slice_22285 = view_1361 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2699, 1, 5392, 5408)
        slice_scatter_default_2700: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1350, add_677, 2, 0, 16);  slice_tensor_1350 = add_677 = None
        slice_scatter_default_2701: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2699, slice_scatter_default_2700, 1, 5392, 5408);  slice_scatter_default_2699 = slice_scatter_default_2700 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2701, 1, 5392, 5408)
        slice_22290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22289, 2, 0, 16);  slice_22289 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2701, 1, 5392, 5408)
        slice_scatter_default_2702: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1351, slice_22290, 2, 0, 16);  slice_tensor_1351 = slice_22290 = None
        slice_scatter_default_2703: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2701, slice_scatter_default_2702, 1, 5392, 5408);  slice_scatter_default_2701 = slice_scatter_default_2702 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22309: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5408, 5424)
        slice_22310: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22309, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_679: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22310, memory_format = torch.contiguous_format);  slice_22310 = None
        view_1362: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_679, [32, 16]);  clone_679 = None
        mm_676: "f32[32, 8]" = torch.ops.aten.mm.default(view_1362, slice_7)
        view_1363: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_676, [2, 16, 8]);  mm_676 = None
        slice_22317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2703, 1, 5408, 5424)
        slice_22318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22317, 2, 0, 16);  slice_22317 = None
        add_678: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22318, view_1363);  slice_22318 = view_1363 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2703, 1, 5408, 5424)
        slice_scatter_default_2704: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1352, add_678, 2, 0, 16);  slice_tensor_1352 = add_678 = None
        slice_scatter_default_2705: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2703, slice_scatter_default_2704, 1, 5408, 5424);  slice_scatter_default_2703 = slice_scatter_default_2704 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2705, 1, 5408, 5424)
        slice_22323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22322, 2, 0, 16);  slice_22322 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2705, 1, 5408, 5424)
        slice_scatter_default_2706: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1353, slice_22323, 2, 0, 16);  slice_tensor_1353 = slice_22323 = None
        slice_scatter_default_2707: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2705, slice_scatter_default_2706, 1, 5408, 5424);  slice_scatter_default_2705 = slice_scatter_default_2706 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22343: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22309, 2, 16, 32);  slice_22309 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_680: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22343, memory_format = torch.contiguous_format);  slice_22343 = None
        view_1364: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_680, [32, 11]);  clone_680 = None
        mm_677: "f32[32, 8]" = torch.ops.aten.mm.default(view_1364, slice_37)
        view_1365: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_677, [2, 16, 8]);  mm_677 = None
        slice_22350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2707, 1, 5408, 5424)
        slice_22351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22350, 2, 0, 16);  slice_22350 = None
        add_679: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22351, view_1365);  slice_22351 = view_1365 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2707, 1, 5408, 5424)
        slice_scatter_default_2708: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1354, add_679, 2, 0, 16);  slice_tensor_1354 = add_679 = None
        slice_scatter_default_2709: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2707, slice_scatter_default_2708, 1, 5408, 5424);  slice_scatter_default_2707 = slice_scatter_default_2708 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2709, 1, 5408, 5424)
        slice_22356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22355, 2, 0, 16);  slice_22355 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2709, 1, 5408, 5424)
        slice_scatter_default_2710: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1355, slice_22356, 2, 0, 16);  slice_tensor_1355 = slice_22356 = None
        slice_scatter_default_2711: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2709, slice_scatter_default_2710, 1, 5408, 5424);  slice_scatter_default_2709 = slice_scatter_default_2710 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22375: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5424, 5440)
        slice_22376: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22375, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_681: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22376, memory_format = torch.contiguous_format);  slice_22376 = None
        view_1366: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_681, [32, 16]);  clone_681 = None
        mm_678: "f32[32, 8]" = torch.ops.aten.mm.default(view_1366, slice_7)
        view_1367: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_678, [2, 16, 8]);  mm_678 = None
        slice_22383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2711, 1, 5424, 5440)
        slice_22384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22383, 2, 0, 16);  slice_22383 = None
        add_680: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22384, view_1367);  slice_22384 = view_1367 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2711, 1, 5424, 5440)
        slice_scatter_default_2712: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1356, add_680, 2, 0, 16);  slice_tensor_1356 = add_680 = None
        slice_scatter_default_2713: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2711, slice_scatter_default_2712, 1, 5424, 5440);  slice_scatter_default_2711 = slice_scatter_default_2712 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2713, 1, 5424, 5440)
        slice_22389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22388, 2, 0, 16);  slice_22388 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2713, 1, 5424, 5440)
        slice_scatter_default_2714: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1357, slice_22389, 2, 0, 16);  slice_tensor_1357 = slice_22389 = None
        slice_scatter_default_2715: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2713, slice_scatter_default_2714, 1, 5424, 5440);  slice_scatter_default_2713 = slice_scatter_default_2714 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22409: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22375, 2, 16, 32);  slice_22375 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_682: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22409, memory_format = torch.contiguous_format);  slice_22409 = None
        view_1368: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_682, [32, 11]);  clone_682 = None
        mm_679: "f32[32, 8]" = torch.ops.aten.mm.default(view_1368, slice_37)
        view_1369: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_679, [2, 16, 8]);  mm_679 = None
        slice_22416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2715, 1, 5424, 5440)
        slice_22417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22416, 2, 0, 16);  slice_22416 = None
        add_681: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22417, view_1369);  slice_22417 = view_1369 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2715, 1, 5424, 5440)
        slice_scatter_default_2716: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1358, add_681, 2, 0, 16);  slice_tensor_1358 = add_681 = None
        slice_scatter_default_2717: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2715, slice_scatter_default_2716, 1, 5424, 5440);  slice_scatter_default_2715 = slice_scatter_default_2716 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2717, 1, 5424, 5440)
        slice_22422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22421, 2, 0, 16);  slice_22421 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2717, 1, 5424, 5440)
        slice_scatter_default_2718: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1359, slice_22422, 2, 0, 16);  slice_tensor_1359 = slice_22422 = None
        slice_scatter_default_2719: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2717, slice_scatter_default_2718, 1, 5424, 5440);  slice_scatter_default_2717 = slice_scatter_default_2718 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22441: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5440, 5456)
        slice_22442: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22441, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_683: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22442, memory_format = torch.contiguous_format);  slice_22442 = None
        view_1370: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_683, [32, 16]);  clone_683 = None
        mm_680: "f32[32, 8]" = torch.ops.aten.mm.default(view_1370, slice_7)
        view_1371: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_680, [2, 16, 8]);  mm_680 = None
        slice_22449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2719, 1, 5440, 5456)
        slice_22450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22449, 2, 0, 16);  slice_22449 = None
        add_682: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22450, view_1371);  slice_22450 = view_1371 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2719, 1, 5440, 5456)
        slice_scatter_default_2720: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1360, add_682, 2, 0, 16);  slice_tensor_1360 = add_682 = None
        slice_scatter_default_2721: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2719, slice_scatter_default_2720, 1, 5440, 5456);  slice_scatter_default_2719 = slice_scatter_default_2720 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2721, 1, 5440, 5456)
        slice_22455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22454, 2, 0, 16);  slice_22454 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2721, 1, 5440, 5456)
        slice_scatter_default_2722: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1361, slice_22455, 2, 0, 16);  slice_tensor_1361 = slice_22455 = None
        slice_scatter_default_2723: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2721, slice_scatter_default_2722, 1, 5440, 5456);  slice_scatter_default_2721 = slice_scatter_default_2722 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22475: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22441, 2, 16, 32);  slice_22441 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_684: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22475, memory_format = torch.contiguous_format);  slice_22475 = None
        view_1372: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_684, [32, 11]);  clone_684 = None
        mm_681: "f32[32, 8]" = torch.ops.aten.mm.default(view_1372, slice_37)
        view_1373: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_681, [2, 16, 8]);  mm_681 = None
        slice_22482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2723, 1, 5440, 5456)
        slice_22483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22482, 2, 0, 16);  slice_22482 = None
        add_683: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22483, view_1373);  slice_22483 = view_1373 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2723, 1, 5440, 5456)
        slice_scatter_default_2724: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1362, add_683, 2, 0, 16);  slice_tensor_1362 = add_683 = None
        slice_scatter_default_2725: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2723, slice_scatter_default_2724, 1, 5440, 5456);  slice_scatter_default_2723 = slice_scatter_default_2724 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2725, 1, 5440, 5456)
        slice_22488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22487, 2, 0, 16);  slice_22487 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2725, 1, 5440, 5456)
        slice_scatter_default_2726: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1363, slice_22488, 2, 0, 16);  slice_tensor_1363 = slice_22488 = None
        slice_scatter_default_2727: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2725, slice_scatter_default_2726, 1, 5440, 5456);  slice_scatter_default_2725 = slice_scatter_default_2726 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22507: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5456, 5472)
        slice_22508: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22507, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_685: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22508, memory_format = torch.contiguous_format);  slice_22508 = None
        view_1374: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_685, [32, 16]);  clone_685 = None
        mm_682: "f32[32, 8]" = torch.ops.aten.mm.default(view_1374, slice_7)
        view_1375: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_682, [2, 16, 8]);  mm_682 = None
        slice_22515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2727, 1, 5456, 5472)
        slice_22516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22515, 2, 0, 16);  slice_22515 = None
        add_684: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22516, view_1375);  slice_22516 = view_1375 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2727, 1, 5456, 5472)
        slice_scatter_default_2728: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1364, add_684, 2, 0, 16);  slice_tensor_1364 = add_684 = None
        slice_scatter_default_2729: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2727, slice_scatter_default_2728, 1, 5456, 5472);  slice_scatter_default_2727 = slice_scatter_default_2728 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2729, 1, 5456, 5472)
        slice_22521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22520, 2, 0, 16);  slice_22520 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2729, 1, 5456, 5472)
        slice_scatter_default_2730: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1365, slice_22521, 2, 0, 16);  slice_tensor_1365 = slice_22521 = None
        slice_scatter_default_2731: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2729, slice_scatter_default_2730, 1, 5456, 5472);  slice_scatter_default_2729 = slice_scatter_default_2730 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22541: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22507, 2, 16, 32);  slice_22507 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_686: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22541, memory_format = torch.contiguous_format);  slice_22541 = None
        view_1376: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_686, [32, 11]);  clone_686 = None
        mm_683: "f32[32, 8]" = torch.ops.aten.mm.default(view_1376, slice_37)
        view_1377: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_683, [2, 16, 8]);  mm_683 = None
        slice_22548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2731, 1, 5456, 5472)
        slice_22549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22548, 2, 0, 16);  slice_22548 = None
        add_685: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22549, view_1377);  slice_22549 = view_1377 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2731, 1, 5456, 5472)
        slice_scatter_default_2732: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1366, add_685, 2, 0, 16);  slice_tensor_1366 = add_685 = None
        slice_scatter_default_2733: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2731, slice_scatter_default_2732, 1, 5456, 5472);  slice_scatter_default_2731 = slice_scatter_default_2732 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2733, 1, 5456, 5472)
        slice_22554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22553, 2, 0, 16);  slice_22553 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2733, 1, 5456, 5472)
        slice_scatter_default_2734: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1367, slice_22554, 2, 0, 16);  slice_tensor_1367 = slice_22554 = None
        slice_scatter_default_2735: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2733, slice_scatter_default_2734, 1, 5456, 5472);  slice_scatter_default_2733 = slice_scatter_default_2734 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22573: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5472, 5488)
        slice_22574: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22573, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_687: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22574, memory_format = torch.contiguous_format);  slice_22574 = None
        view_1378: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_687, [32, 16]);  clone_687 = None
        mm_684: "f32[32, 8]" = torch.ops.aten.mm.default(view_1378, slice_7)
        view_1379: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_684, [2, 16, 8]);  mm_684 = None
        slice_22581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2735, 1, 5472, 5488)
        slice_22582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22581, 2, 0, 16);  slice_22581 = None
        add_686: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22582, view_1379);  slice_22582 = view_1379 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2735, 1, 5472, 5488)
        slice_scatter_default_2736: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1368, add_686, 2, 0, 16);  slice_tensor_1368 = add_686 = None
        slice_scatter_default_2737: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2735, slice_scatter_default_2736, 1, 5472, 5488);  slice_scatter_default_2735 = slice_scatter_default_2736 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2737, 1, 5472, 5488)
        slice_22587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22586, 2, 0, 16);  slice_22586 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2737, 1, 5472, 5488)
        slice_scatter_default_2738: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1369, slice_22587, 2, 0, 16);  slice_tensor_1369 = slice_22587 = None
        slice_scatter_default_2739: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2737, slice_scatter_default_2738, 1, 5472, 5488);  slice_scatter_default_2737 = slice_scatter_default_2738 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22607: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22573, 2, 16, 32);  slice_22573 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_688: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22607, memory_format = torch.contiguous_format);  slice_22607 = None
        view_1380: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_688, [32, 11]);  clone_688 = None
        mm_685: "f32[32, 8]" = torch.ops.aten.mm.default(view_1380, slice_37)
        view_1381: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_685, [2, 16, 8]);  mm_685 = None
        slice_22614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2739, 1, 5472, 5488)
        slice_22615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22614, 2, 0, 16);  slice_22614 = None
        add_687: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22615, view_1381);  slice_22615 = view_1381 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2739, 1, 5472, 5488)
        slice_scatter_default_2740: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1370, add_687, 2, 0, 16);  slice_tensor_1370 = add_687 = None
        slice_scatter_default_2741: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2739, slice_scatter_default_2740, 1, 5472, 5488);  slice_scatter_default_2739 = slice_scatter_default_2740 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2741, 1, 5472, 5488)
        slice_22620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22619, 2, 0, 16);  slice_22619 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2741, 1, 5472, 5488)
        slice_scatter_default_2742: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1371, slice_22620, 2, 0, 16);  slice_tensor_1371 = slice_22620 = None
        slice_scatter_default_2743: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2741, slice_scatter_default_2742, 1, 5472, 5488);  slice_scatter_default_2741 = slice_scatter_default_2742 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22639: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5488, 5504)
        slice_22640: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22639, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_689: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22640, memory_format = torch.contiguous_format);  slice_22640 = None
        view_1382: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_689, [32, 16]);  clone_689 = None
        mm_686: "f32[32, 8]" = torch.ops.aten.mm.default(view_1382, slice_7)
        view_1383: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_686, [2, 16, 8]);  mm_686 = None
        slice_22647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2743, 1, 5488, 5504)
        slice_22648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22647, 2, 0, 16);  slice_22647 = None
        add_688: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22648, view_1383);  slice_22648 = view_1383 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2743, 1, 5488, 5504)
        slice_scatter_default_2744: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1372, add_688, 2, 0, 16);  slice_tensor_1372 = add_688 = None
        slice_scatter_default_2745: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2743, slice_scatter_default_2744, 1, 5488, 5504);  slice_scatter_default_2743 = slice_scatter_default_2744 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2745, 1, 5488, 5504)
        slice_22653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22652, 2, 0, 16);  slice_22652 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2745, 1, 5488, 5504)
        slice_scatter_default_2746: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1373, slice_22653, 2, 0, 16);  slice_tensor_1373 = slice_22653 = None
        slice_scatter_default_2747: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2745, slice_scatter_default_2746, 1, 5488, 5504);  slice_scatter_default_2745 = slice_scatter_default_2746 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22673: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22639, 2, 16, 32);  slice_22639 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_690: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22673, memory_format = torch.contiguous_format);  slice_22673 = None
        view_1384: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_690, [32, 11]);  clone_690 = None
        mm_687: "f32[32, 8]" = torch.ops.aten.mm.default(view_1384, slice_37)
        view_1385: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_687, [2, 16, 8]);  mm_687 = None
        slice_22680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2747, 1, 5488, 5504)
        slice_22681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22680, 2, 0, 16);  slice_22680 = None
        add_689: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22681, view_1385);  slice_22681 = view_1385 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2747, 1, 5488, 5504)
        slice_scatter_default_2748: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1374, add_689, 2, 0, 16);  slice_tensor_1374 = add_689 = None
        slice_scatter_default_2749: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2747, slice_scatter_default_2748, 1, 5488, 5504);  slice_scatter_default_2747 = slice_scatter_default_2748 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2749, 1, 5488, 5504)
        slice_22686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22685, 2, 0, 16);  slice_22685 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2749, 1, 5488, 5504)
        slice_scatter_default_2750: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1375, slice_22686, 2, 0, 16);  slice_tensor_1375 = slice_22686 = None
        slice_scatter_default_2751: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2749, slice_scatter_default_2750, 1, 5488, 5504);  slice_scatter_default_2749 = slice_scatter_default_2750 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22705: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5504, 5520)
        slice_22706: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22705, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_691: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22706, memory_format = torch.contiguous_format);  slice_22706 = None
        view_1386: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_691, [32, 16]);  clone_691 = None
        mm_688: "f32[32, 8]" = torch.ops.aten.mm.default(view_1386, slice_7)
        view_1387: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_688, [2, 16, 8]);  mm_688 = None
        slice_22713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2751, 1, 5504, 5520)
        slice_22714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22713, 2, 0, 16);  slice_22713 = None
        add_690: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22714, view_1387);  slice_22714 = view_1387 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2751, 1, 5504, 5520)
        slice_scatter_default_2752: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1376, add_690, 2, 0, 16);  slice_tensor_1376 = add_690 = None
        slice_scatter_default_2753: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2751, slice_scatter_default_2752, 1, 5504, 5520);  slice_scatter_default_2751 = slice_scatter_default_2752 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2753, 1, 5504, 5520)
        slice_22719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22718, 2, 0, 16);  slice_22718 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2753, 1, 5504, 5520)
        slice_scatter_default_2754: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1377, slice_22719, 2, 0, 16);  slice_tensor_1377 = slice_22719 = None
        slice_scatter_default_2755: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2753, slice_scatter_default_2754, 1, 5504, 5520);  slice_scatter_default_2753 = slice_scatter_default_2754 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22739: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22705, 2, 16, 32);  slice_22705 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_692: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22739, memory_format = torch.contiguous_format);  slice_22739 = None
        view_1388: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_692, [32, 11]);  clone_692 = None
        mm_689: "f32[32, 8]" = torch.ops.aten.mm.default(view_1388, slice_37)
        view_1389: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_689, [2, 16, 8]);  mm_689 = None
        slice_22746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2755, 1, 5504, 5520)
        slice_22747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22746, 2, 0, 16);  slice_22746 = None
        add_691: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22747, view_1389);  slice_22747 = view_1389 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2755, 1, 5504, 5520)
        slice_scatter_default_2756: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1378, add_691, 2, 0, 16);  slice_tensor_1378 = add_691 = None
        slice_scatter_default_2757: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2755, slice_scatter_default_2756, 1, 5504, 5520);  slice_scatter_default_2755 = slice_scatter_default_2756 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2757, 1, 5504, 5520)
        slice_22752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22751, 2, 0, 16);  slice_22751 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2757, 1, 5504, 5520)
        slice_scatter_default_2758: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1379, slice_22752, 2, 0, 16);  slice_tensor_1379 = slice_22752 = None
        slice_scatter_default_2759: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2757, slice_scatter_default_2758, 1, 5504, 5520);  slice_scatter_default_2757 = slice_scatter_default_2758 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22771: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5520, 5536)
        slice_22772: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22771, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_693: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22772, memory_format = torch.contiguous_format);  slice_22772 = None
        view_1390: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_693, [32, 16]);  clone_693 = None
        mm_690: "f32[32, 8]" = torch.ops.aten.mm.default(view_1390, slice_7)
        view_1391: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_690, [2, 16, 8]);  mm_690 = None
        slice_22779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2759, 1, 5520, 5536)
        slice_22780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22779, 2, 0, 16);  slice_22779 = None
        add_692: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22780, view_1391);  slice_22780 = view_1391 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2759, 1, 5520, 5536)
        slice_scatter_default_2760: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1380, add_692, 2, 0, 16);  slice_tensor_1380 = add_692 = None
        slice_scatter_default_2761: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2759, slice_scatter_default_2760, 1, 5520, 5536);  slice_scatter_default_2759 = slice_scatter_default_2760 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2761, 1, 5520, 5536)
        slice_22785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22784, 2, 0, 16);  slice_22784 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2761, 1, 5520, 5536)
        slice_scatter_default_2762: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1381, slice_22785, 2, 0, 16);  slice_tensor_1381 = slice_22785 = None
        slice_scatter_default_2763: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2761, slice_scatter_default_2762, 1, 5520, 5536);  slice_scatter_default_2761 = slice_scatter_default_2762 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22805: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22771, 2, 16, 32);  slice_22771 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_694: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22805, memory_format = torch.contiguous_format);  slice_22805 = None
        view_1392: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_694, [32, 11]);  clone_694 = None
        mm_691: "f32[32, 8]" = torch.ops.aten.mm.default(view_1392, slice_37)
        view_1393: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_691, [2, 16, 8]);  mm_691 = None
        slice_22812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2763, 1, 5520, 5536)
        slice_22813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22812, 2, 0, 16);  slice_22812 = None
        add_693: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22813, view_1393);  slice_22813 = view_1393 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2763, 1, 5520, 5536)
        slice_scatter_default_2764: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1382, add_693, 2, 0, 16);  slice_tensor_1382 = add_693 = None
        slice_scatter_default_2765: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2763, slice_scatter_default_2764, 1, 5520, 5536);  slice_scatter_default_2763 = slice_scatter_default_2764 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2765, 1, 5520, 5536)
        slice_22818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22817, 2, 0, 16);  slice_22817 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2765, 1, 5520, 5536)
        slice_scatter_default_2766: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1383, slice_22818, 2, 0, 16);  slice_tensor_1383 = slice_22818 = None
        slice_scatter_default_2767: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2765, slice_scatter_default_2766, 1, 5520, 5536);  slice_scatter_default_2765 = slice_scatter_default_2766 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22837: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5536, 5552)
        slice_22838: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22837, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_695: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22838, memory_format = torch.contiguous_format);  slice_22838 = None
        view_1394: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_695, [32, 16]);  clone_695 = None
        mm_692: "f32[32, 8]" = torch.ops.aten.mm.default(view_1394, slice_7)
        view_1395: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_692, [2, 16, 8]);  mm_692 = None
        slice_22845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2767, 1, 5536, 5552)
        slice_22846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22845, 2, 0, 16);  slice_22845 = None
        add_694: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22846, view_1395);  slice_22846 = view_1395 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2767, 1, 5536, 5552)
        slice_scatter_default_2768: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1384, add_694, 2, 0, 16);  slice_tensor_1384 = add_694 = None
        slice_scatter_default_2769: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2767, slice_scatter_default_2768, 1, 5536, 5552);  slice_scatter_default_2767 = slice_scatter_default_2768 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2769, 1, 5536, 5552)
        slice_22851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22850, 2, 0, 16);  slice_22850 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2769, 1, 5536, 5552)
        slice_scatter_default_2770: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1385, slice_22851, 2, 0, 16);  slice_tensor_1385 = slice_22851 = None
        slice_scatter_default_2771: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2769, slice_scatter_default_2770, 1, 5536, 5552);  slice_scatter_default_2769 = slice_scatter_default_2770 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22871: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22837, 2, 16, 32);  slice_22837 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_696: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22871, memory_format = torch.contiguous_format);  slice_22871 = None
        view_1396: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_696, [32, 11]);  clone_696 = None
        mm_693: "f32[32, 8]" = torch.ops.aten.mm.default(view_1396, slice_37)
        view_1397: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_693, [2, 16, 8]);  mm_693 = None
        slice_22878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2771, 1, 5536, 5552)
        slice_22879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22878, 2, 0, 16);  slice_22878 = None
        add_695: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22879, view_1397);  slice_22879 = view_1397 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2771, 1, 5536, 5552)
        slice_scatter_default_2772: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1386, add_695, 2, 0, 16);  slice_tensor_1386 = add_695 = None
        slice_scatter_default_2773: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2771, slice_scatter_default_2772, 1, 5536, 5552);  slice_scatter_default_2771 = slice_scatter_default_2772 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2773, 1, 5536, 5552)
        slice_22884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22883, 2, 0, 16);  slice_22883 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2773, 1, 5536, 5552)
        slice_scatter_default_2774: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1387, slice_22884, 2, 0, 16);  slice_tensor_1387 = slice_22884 = None
        slice_scatter_default_2775: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2773, slice_scatter_default_2774, 1, 5536, 5552);  slice_scatter_default_2773 = slice_scatter_default_2774 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22903: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5552, 5568)
        slice_22904: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22903, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_697: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22904, memory_format = torch.contiguous_format);  slice_22904 = None
        view_1398: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_697, [32, 16]);  clone_697 = None
        mm_694: "f32[32, 8]" = torch.ops.aten.mm.default(view_1398, slice_7)
        view_1399: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_694, [2, 16, 8]);  mm_694 = None
        slice_22911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2775, 1, 5552, 5568)
        slice_22912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22911, 2, 0, 16);  slice_22911 = None
        add_696: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22912, view_1399);  slice_22912 = view_1399 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2775, 1, 5552, 5568)
        slice_scatter_default_2776: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1388, add_696, 2, 0, 16);  slice_tensor_1388 = add_696 = None
        slice_scatter_default_2777: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2775, slice_scatter_default_2776, 1, 5552, 5568);  slice_scatter_default_2775 = slice_scatter_default_2776 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2777, 1, 5552, 5568)
        slice_22917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22916, 2, 0, 16);  slice_22916 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2777, 1, 5552, 5568)
        slice_scatter_default_2778: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1389, slice_22917, 2, 0, 16);  slice_tensor_1389 = slice_22917 = None
        slice_scatter_default_2779: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2777, slice_scatter_default_2778, 1, 5552, 5568);  slice_scatter_default_2777 = slice_scatter_default_2778 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22937: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22903, 2, 16, 32);  slice_22903 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_698: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_22937, memory_format = torch.contiguous_format);  slice_22937 = None
        view_1400: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_698, [32, 11]);  clone_698 = None
        mm_695: "f32[32, 8]" = torch.ops.aten.mm.default(view_1400, slice_37)
        view_1401: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_695, [2, 16, 8]);  mm_695 = None
        slice_22944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2779, 1, 5552, 5568)
        slice_22945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22944, 2, 0, 16);  slice_22944 = None
        add_697: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22945, view_1401);  slice_22945 = view_1401 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2779, 1, 5552, 5568)
        slice_scatter_default_2780: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1390, add_697, 2, 0, 16);  slice_tensor_1390 = add_697 = None
        slice_scatter_default_2781: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2779, slice_scatter_default_2780, 1, 5552, 5568);  slice_scatter_default_2779 = slice_scatter_default_2780 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2781, 1, 5552, 5568)
        slice_22950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22949, 2, 0, 16);  slice_22949 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2781, 1, 5552, 5568)
        slice_scatter_default_2782: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1391, slice_22950, 2, 0, 16);  slice_tensor_1391 = slice_22950 = None
        slice_scatter_default_2783: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2781, slice_scatter_default_2782, 1, 5552, 5568);  slice_scatter_default_2781 = slice_scatter_default_2782 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_22969: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5568, 5584)
        slice_22970: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_22969, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_699: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_22970, memory_format = torch.contiguous_format);  slice_22970 = None
        view_1402: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_699, [32, 16]);  clone_699 = None
        mm_696: "f32[32, 8]" = torch.ops.aten.mm.default(view_1402, slice_7)
        view_1403: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_696, [2, 16, 8]);  mm_696 = None
        slice_22977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2783, 1, 5568, 5584)
        slice_22978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22977, 2, 0, 16);  slice_22977 = None
        add_698: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_22978, view_1403);  slice_22978 = view_1403 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2783, 1, 5568, 5584)
        slice_scatter_default_2784: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1392, add_698, 2, 0, 16);  slice_tensor_1392 = add_698 = None
        slice_scatter_default_2785: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2783, slice_scatter_default_2784, 1, 5568, 5584);  slice_scatter_default_2783 = slice_scatter_default_2784 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_22982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2785, 1, 5568, 5584)
        slice_22983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_22982, 2, 0, 16);  slice_22982 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2785, 1, 5568, 5584)
        slice_scatter_default_2786: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1393, slice_22983, 2, 0, 16);  slice_tensor_1393 = slice_22983 = None
        slice_scatter_default_2787: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2785, slice_scatter_default_2786, 1, 5568, 5584);  slice_scatter_default_2785 = slice_scatter_default_2786 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23003: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_22969, 2, 16, 32);  slice_22969 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_700: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23003, memory_format = torch.contiguous_format);  slice_23003 = None
        view_1404: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_700, [32, 11]);  clone_700 = None
        mm_697: "f32[32, 8]" = torch.ops.aten.mm.default(view_1404, slice_37)
        view_1405: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_697, [2, 16, 8]);  mm_697 = None
        slice_23010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2787, 1, 5568, 5584)
        slice_23011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23010, 2, 0, 16);  slice_23010 = None
        add_699: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23011, view_1405);  slice_23011 = view_1405 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2787, 1, 5568, 5584)
        slice_scatter_default_2788: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1394, add_699, 2, 0, 16);  slice_tensor_1394 = add_699 = None
        slice_scatter_default_2789: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2787, slice_scatter_default_2788, 1, 5568, 5584);  slice_scatter_default_2787 = slice_scatter_default_2788 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2789, 1, 5568, 5584)
        slice_23016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23015, 2, 0, 16);  slice_23015 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2789, 1, 5568, 5584)
        slice_scatter_default_2790: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1395, slice_23016, 2, 0, 16);  slice_tensor_1395 = slice_23016 = None
        slice_scatter_default_2791: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2789, slice_scatter_default_2790, 1, 5568, 5584);  slice_scatter_default_2789 = slice_scatter_default_2790 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23035: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5584, 5600)
        slice_23036: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23035, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_701: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23036, memory_format = torch.contiguous_format);  slice_23036 = None
        view_1406: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_701, [32, 16]);  clone_701 = None
        mm_698: "f32[32, 8]" = torch.ops.aten.mm.default(view_1406, slice_7)
        view_1407: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_698, [2, 16, 8]);  mm_698 = None
        slice_23043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2791, 1, 5584, 5600)
        slice_23044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23043, 2, 0, 16);  slice_23043 = None
        add_700: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23044, view_1407);  slice_23044 = view_1407 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2791, 1, 5584, 5600)
        slice_scatter_default_2792: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1396, add_700, 2, 0, 16);  slice_tensor_1396 = add_700 = None
        slice_scatter_default_2793: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2791, slice_scatter_default_2792, 1, 5584, 5600);  slice_scatter_default_2791 = slice_scatter_default_2792 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2793, 1, 5584, 5600)
        slice_23049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23048, 2, 0, 16);  slice_23048 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2793, 1, 5584, 5600)
        slice_scatter_default_2794: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1397, slice_23049, 2, 0, 16);  slice_tensor_1397 = slice_23049 = None
        slice_scatter_default_2795: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2793, slice_scatter_default_2794, 1, 5584, 5600);  slice_scatter_default_2793 = slice_scatter_default_2794 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23069: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23035, 2, 16, 32);  slice_23035 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_702: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23069, memory_format = torch.contiguous_format);  slice_23069 = None
        view_1408: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_702, [32, 11]);  clone_702 = None
        mm_699: "f32[32, 8]" = torch.ops.aten.mm.default(view_1408, slice_37)
        view_1409: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_699, [2, 16, 8]);  mm_699 = None
        slice_23076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2795, 1, 5584, 5600)
        slice_23077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23076, 2, 0, 16);  slice_23076 = None
        add_701: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23077, view_1409);  slice_23077 = view_1409 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2795, 1, 5584, 5600)
        slice_scatter_default_2796: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1398, add_701, 2, 0, 16);  slice_tensor_1398 = add_701 = None
        slice_scatter_default_2797: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2795, slice_scatter_default_2796, 1, 5584, 5600);  slice_scatter_default_2795 = slice_scatter_default_2796 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2797, 1, 5584, 5600)
        slice_23082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23081, 2, 0, 16);  slice_23081 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2797, 1, 5584, 5600)
        slice_scatter_default_2798: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1399, slice_23082, 2, 0, 16);  slice_tensor_1399 = slice_23082 = None
        slice_scatter_default_2799: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2797, slice_scatter_default_2798, 1, 5584, 5600);  slice_scatter_default_2797 = slice_scatter_default_2798 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23101: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5600, 5616)
        slice_23102: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23101, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_703: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23102, memory_format = torch.contiguous_format);  slice_23102 = None
        view_1410: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_703, [32, 16]);  clone_703 = None
        mm_700: "f32[32, 8]" = torch.ops.aten.mm.default(view_1410, slice_7)
        view_1411: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_700, [2, 16, 8]);  mm_700 = None
        slice_23109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2799, 1, 5600, 5616)
        slice_23110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23109, 2, 0, 16);  slice_23109 = None
        add_702: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23110, view_1411);  slice_23110 = view_1411 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2799, 1, 5600, 5616)
        slice_scatter_default_2800: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1400, add_702, 2, 0, 16);  slice_tensor_1400 = add_702 = None
        slice_scatter_default_2801: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2799, slice_scatter_default_2800, 1, 5600, 5616);  slice_scatter_default_2799 = slice_scatter_default_2800 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2801, 1, 5600, 5616)
        slice_23115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23114, 2, 0, 16);  slice_23114 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2801, 1, 5600, 5616)
        slice_scatter_default_2802: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1401, slice_23115, 2, 0, 16);  slice_tensor_1401 = slice_23115 = None
        slice_scatter_default_2803: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2801, slice_scatter_default_2802, 1, 5600, 5616);  slice_scatter_default_2801 = slice_scatter_default_2802 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23135: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23101, 2, 16, 32);  slice_23101 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_704: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23135, memory_format = torch.contiguous_format);  slice_23135 = None
        view_1412: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_704, [32, 11]);  clone_704 = None
        mm_701: "f32[32, 8]" = torch.ops.aten.mm.default(view_1412, slice_37)
        view_1413: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_701, [2, 16, 8]);  mm_701 = None
        slice_23142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2803, 1, 5600, 5616)
        slice_23143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23142, 2, 0, 16);  slice_23142 = None
        add_703: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23143, view_1413);  slice_23143 = view_1413 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2803, 1, 5600, 5616)
        slice_scatter_default_2804: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1402, add_703, 2, 0, 16);  slice_tensor_1402 = add_703 = None
        slice_scatter_default_2805: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2803, slice_scatter_default_2804, 1, 5600, 5616);  slice_scatter_default_2803 = slice_scatter_default_2804 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2805, 1, 5600, 5616)
        slice_23148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23147, 2, 0, 16);  slice_23147 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2805, 1, 5600, 5616)
        slice_scatter_default_2806: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1403, slice_23148, 2, 0, 16);  slice_tensor_1403 = slice_23148 = None
        slice_scatter_default_2807: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2805, slice_scatter_default_2806, 1, 5600, 5616);  slice_scatter_default_2805 = slice_scatter_default_2806 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23167: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5616, 5632)
        slice_23168: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23167, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_705: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23168, memory_format = torch.contiguous_format);  slice_23168 = None
        view_1414: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_705, [32, 16]);  clone_705 = None
        mm_702: "f32[32, 8]" = torch.ops.aten.mm.default(view_1414, slice_7)
        view_1415: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_702, [2, 16, 8]);  mm_702 = None
        slice_23175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2807, 1, 5616, 5632)
        slice_23176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23175, 2, 0, 16);  slice_23175 = None
        add_704: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23176, view_1415);  slice_23176 = view_1415 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2807, 1, 5616, 5632)
        slice_scatter_default_2808: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1404, add_704, 2, 0, 16);  slice_tensor_1404 = add_704 = None
        slice_scatter_default_2809: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2807, slice_scatter_default_2808, 1, 5616, 5632);  slice_scatter_default_2807 = slice_scatter_default_2808 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2809, 1, 5616, 5632)
        slice_23181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23180, 2, 0, 16);  slice_23180 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2809, 1, 5616, 5632)
        slice_scatter_default_2810: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1405, slice_23181, 2, 0, 16);  slice_tensor_1405 = slice_23181 = None
        slice_scatter_default_2811: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2809, slice_scatter_default_2810, 1, 5616, 5632);  slice_scatter_default_2809 = slice_scatter_default_2810 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23201: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23167, 2, 16, 32);  slice_23167 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_706: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23201, memory_format = torch.contiguous_format);  slice_23201 = None
        view_1416: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_706, [32, 11]);  clone_706 = None
        mm_703: "f32[32, 8]" = torch.ops.aten.mm.default(view_1416, slice_37)
        view_1417: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_703, [2, 16, 8]);  mm_703 = None
        slice_23208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2811, 1, 5616, 5632)
        slice_23209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23208, 2, 0, 16);  slice_23208 = None
        add_705: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23209, view_1417);  slice_23209 = view_1417 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2811, 1, 5616, 5632)
        slice_scatter_default_2812: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1406, add_705, 2, 0, 16);  slice_tensor_1406 = add_705 = None
        slice_scatter_default_2813: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2811, slice_scatter_default_2812, 1, 5616, 5632);  slice_scatter_default_2811 = slice_scatter_default_2812 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2813, 1, 5616, 5632)
        slice_23214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23213, 2, 0, 16);  slice_23213 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2813, 1, 5616, 5632)
        slice_scatter_default_2814: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1407, slice_23214, 2, 0, 16);  slice_tensor_1407 = slice_23214 = None
        slice_scatter_default_2815: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2813, slice_scatter_default_2814, 1, 5616, 5632);  slice_scatter_default_2813 = slice_scatter_default_2814 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23233: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5632, 5648)
        slice_23234: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23233, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_707: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23234, memory_format = torch.contiguous_format);  slice_23234 = None
        view_1418: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_707, [32, 16]);  clone_707 = None
        mm_704: "f32[32, 8]" = torch.ops.aten.mm.default(view_1418, slice_7)
        view_1419: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_704, [2, 16, 8]);  mm_704 = None
        slice_23241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2815, 1, 5632, 5648)
        slice_23242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23241, 2, 0, 16);  slice_23241 = None
        add_706: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23242, view_1419);  slice_23242 = view_1419 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2815, 1, 5632, 5648)
        slice_scatter_default_2816: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1408, add_706, 2, 0, 16);  slice_tensor_1408 = add_706 = None
        slice_scatter_default_2817: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2815, slice_scatter_default_2816, 1, 5632, 5648);  slice_scatter_default_2815 = slice_scatter_default_2816 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2817, 1, 5632, 5648)
        slice_23247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23246, 2, 0, 16);  slice_23246 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2817, 1, 5632, 5648)
        slice_scatter_default_2818: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1409, slice_23247, 2, 0, 16);  slice_tensor_1409 = slice_23247 = None
        slice_scatter_default_2819: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2817, slice_scatter_default_2818, 1, 5632, 5648);  slice_scatter_default_2817 = slice_scatter_default_2818 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23267: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23233, 2, 16, 32);  slice_23233 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_708: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23267, memory_format = torch.contiguous_format);  slice_23267 = None
        view_1420: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_708, [32, 11]);  clone_708 = None
        mm_705: "f32[32, 8]" = torch.ops.aten.mm.default(view_1420, slice_37)
        view_1421: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_705, [2, 16, 8]);  mm_705 = None
        slice_23274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2819, 1, 5632, 5648)
        slice_23275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23274, 2, 0, 16);  slice_23274 = None
        add_707: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23275, view_1421);  slice_23275 = view_1421 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2819, 1, 5632, 5648)
        slice_scatter_default_2820: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1410, add_707, 2, 0, 16);  slice_tensor_1410 = add_707 = None
        slice_scatter_default_2821: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2819, slice_scatter_default_2820, 1, 5632, 5648);  slice_scatter_default_2819 = slice_scatter_default_2820 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2821, 1, 5632, 5648)
        slice_23280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23279, 2, 0, 16);  slice_23279 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2821, 1, 5632, 5648)
        slice_scatter_default_2822: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1411, slice_23280, 2, 0, 16);  slice_tensor_1411 = slice_23280 = None
        slice_scatter_default_2823: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2821, slice_scatter_default_2822, 1, 5632, 5648);  slice_scatter_default_2821 = slice_scatter_default_2822 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23299: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5648, 5664)
        slice_23300: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23299, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_709: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23300, memory_format = torch.contiguous_format);  slice_23300 = None
        view_1422: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_709, [32, 16]);  clone_709 = None
        mm_706: "f32[32, 8]" = torch.ops.aten.mm.default(view_1422, slice_7)
        view_1423: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_706, [2, 16, 8]);  mm_706 = None
        slice_23307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2823, 1, 5648, 5664)
        slice_23308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23307, 2, 0, 16);  slice_23307 = None
        add_708: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23308, view_1423);  slice_23308 = view_1423 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2823, 1, 5648, 5664)
        slice_scatter_default_2824: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1412, add_708, 2, 0, 16);  slice_tensor_1412 = add_708 = None
        slice_scatter_default_2825: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2823, slice_scatter_default_2824, 1, 5648, 5664);  slice_scatter_default_2823 = slice_scatter_default_2824 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2825, 1, 5648, 5664)
        slice_23313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23312, 2, 0, 16);  slice_23312 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2825, 1, 5648, 5664)
        slice_scatter_default_2826: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1413, slice_23313, 2, 0, 16);  slice_tensor_1413 = slice_23313 = None
        slice_scatter_default_2827: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2825, slice_scatter_default_2826, 1, 5648, 5664);  slice_scatter_default_2825 = slice_scatter_default_2826 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23333: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23299, 2, 16, 32);  slice_23299 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_710: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23333, memory_format = torch.contiguous_format);  slice_23333 = None
        view_1424: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_710, [32, 11]);  clone_710 = None
        mm_707: "f32[32, 8]" = torch.ops.aten.mm.default(view_1424, slice_37)
        view_1425: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_707, [2, 16, 8]);  mm_707 = None
        slice_23340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2827, 1, 5648, 5664)
        slice_23341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23340, 2, 0, 16);  slice_23340 = None
        add_709: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23341, view_1425);  slice_23341 = view_1425 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2827, 1, 5648, 5664)
        slice_scatter_default_2828: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1414, add_709, 2, 0, 16);  slice_tensor_1414 = add_709 = None
        slice_scatter_default_2829: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2827, slice_scatter_default_2828, 1, 5648, 5664);  slice_scatter_default_2827 = slice_scatter_default_2828 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2829, 1, 5648, 5664)
        slice_23346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23345, 2, 0, 16);  slice_23345 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2829, 1, 5648, 5664)
        slice_scatter_default_2830: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1415, slice_23346, 2, 0, 16);  slice_tensor_1415 = slice_23346 = None
        slice_scatter_default_2831: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2829, slice_scatter_default_2830, 1, 5648, 5664);  slice_scatter_default_2829 = slice_scatter_default_2830 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23365: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5664, 5680)
        slice_23366: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23365, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_711: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23366, memory_format = torch.contiguous_format);  slice_23366 = None
        view_1426: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_711, [32, 16]);  clone_711 = None
        mm_708: "f32[32, 8]" = torch.ops.aten.mm.default(view_1426, slice_7)
        view_1427: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_708, [2, 16, 8]);  mm_708 = None
        slice_23373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2831, 1, 5664, 5680)
        slice_23374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23373, 2, 0, 16);  slice_23373 = None
        add_710: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23374, view_1427);  slice_23374 = view_1427 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2831, 1, 5664, 5680)
        slice_scatter_default_2832: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1416, add_710, 2, 0, 16);  slice_tensor_1416 = add_710 = None
        slice_scatter_default_2833: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2831, slice_scatter_default_2832, 1, 5664, 5680);  slice_scatter_default_2831 = slice_scatter_default_2832 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2833, 1, 5664, 5680)
        slice_23379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23378, 2, 0, 16);  slice_23378 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2833, 1, 5664, 5680)
        slice_scatter_default_2834: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1417, slice_23379, 2, 0, 16);  slice_tensor_1417 = slice_23379 = None
        slice_scatter_default_2835: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2833, slice_scatter_default_2834, 1, 5664, 5680);  slice_scatter_default_2833 = slice_scatter_default_2834 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23399: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23365, 2, 16, 32);  slice_23365 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_712: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23399, memory_format = torch.contiguous_format);  slice_23399 = None
        view_1428: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_712, [32, 11]);  clone_712 = None
        mm_709: "f32[32, 8]" = torch.ops.aten.mm.default(view_1428, slice_37)
        view_1429: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_709, [2, 16, 8]);  mm_709 = None
        slice_23406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2835, 1, 5664, 5680)
        slice_23407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23406, 2, 0, 16);  slice_23406 = None
        add_711: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23407, view_1429);  slice_23407 = view_1429 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2835, 1, 5664, 5680)
        slice_scatter_default_2836: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1418, add_711, 2, 0, 16);  slice_tensor_1418 = add_711 = None
        slice_scatter_default_2837: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2835, slice_scatter_default_2836, 1, 5664, 5680);  slice_scatter_default_2835 = slice_scatter_default_2836 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2837, 1, 5664, 5680)
        slice_23412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23411, 2, 0, 16);  slice_23411 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2837, 1, 5664, 5680)
        slice_scatter_default_2838: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1419, slice_23412, 2, 0, 16);  slice_tensor_1419 = slice_23412 = None
        slice_scatter_default_2839: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2837, slice_scatter_default_2838, 1, 5664, 5680);  slice_scatter_default_2837 = slice_scatter_default_2838 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23431: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5680, 5696)
        slice_23432: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23431, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_713: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23432, memory_format = torch.contiguous_format);  slice_23432 = None
        view_1430: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_713, [32, 16]);  clone_713 = None
        mm_710: "f32[32, 8]" = torch.ops.aten.mm.default(view_1430, slice_7)
        view_1431: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_710, [2, 16, 8]);  mm_710 = None
        slice_23439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2839, 1, 5680, 5696)
        slice_23440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23439, 2, 0, 16);  slice_23439 = None
        add_712: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23440, view_1431);  slice_23440 = view_1431 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2839, 1, 5680, 5696)
        slice_scatter_default_2840: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1420, add_712, 2, 0, 16);  slice_tensor_1420 = add_712 = None
        slice_scatter_default_2841: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2839, slice_scatter_default_2840, 1, 5680, 5696);  slice_scatter_default_2839 = slice_scatter_default_2840 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2841, 1, 5680, 5696)
        slice_23445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23444, 2, 0, 16);  slice_23444 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2841, 1, 5680, 5696)
        slice_scatter_default_2842: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1421, slice_23445, 2, 0, 16);  slice_tensor_1421 = slice_23445 = None
        slice_scatter_default_2843: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2841, slice_scatter_default_2842, 1, 5680, 5696);  slice_scatter_default_2841 = slice_scatter_default_2842 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23465: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23431, 2, 16, 32);  slice_23431 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_714: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23465, memory_format = torch.contiguous_format);  slice_23465 = None
        view_1432: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_714, [32, 11]);  clone_714 = None
        mm_711: "f32[32, 8]" = torch.ops.aten.mm.default(view_1432, slice_37)
        view_1433: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_711, [2, 16, 8]);  mm_711 = None
        slice_23472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2843, 1, 5680, 5696)
        slice_23473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23472, 2, 0, 16);  slice_23472 = None
        add_713: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23473, view_1433);  slice_23473 = view_1433 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2843, 1, 5680, 5696)
        slice_scatter_default_2844: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1422, add_713, 2, 0, 16);  slice_tensor_1422 = add_713 = None
        slice_scatter_default_2845: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2843, slice_scatter_default_2844, 1, 5680, 5696);  slice_scatter_default_2843 = slice_scatter_default_2844 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2845, 1, 5680, 5696)
        slice_23478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23477, 2, 0, 16);  slice_23477 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2845, 1, 5680, 5696)
        slice_scatter_default_2846: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1423, slice_23478, 2, 0, 16);  slice_tensor_1423 = slice_23478 = None
        slice_scatter_default_2847: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2845, slice_scatter_default_2846, 1, 5680, 5696);  slice_scatter_default_2845 = slice_scatter_default_2846 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23497: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5696, 5712)
        slice_23498: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23497, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_715: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23498, memory_format = torch.contiguous_format);  slice_23498 = None
        view_1434: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_715, [32, 16]);  clone_715 = None
        mm_712: "f32[32, 8]" = torch.ops.aten.mm.default(view_1434, slice_7)
        view_1435: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_712, [2, 16, 8]);  mm_712 = None
        slice_23505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2847, 1, 5696, 5712)
        slice_23506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23505, 2, 0, 16);  slice_23505 = None
        add_714: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23506, view_1435);  slice_23506 = view_1435 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2847, 1, 5696, 5712)
        slice_scatter_default_2848: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1424, add_714, 2, 0, 16);  slice_tensor_1424 = add_714 = None
        slice_scatter_default_2849: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2847, slice_scatter_default_2848, 1, 5696, 5712);  slice_scatter_default_2847 = slice_scatter_default_2848 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2849, 1, 5696, 5712)
        slice_23511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23510, 2, 0, 16);  slice_23510 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2849, 1, 5696, 5712)
        slice_scatter_default_2850: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1425, slice_23511, 2, 0, 16);  slice_tensor_1425 = slice_23511 = None
        slice_scatter_default_2851: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2849, slice_scatter_default_2850, 1, 5696, 5712);  slice_scatter_default_2849 = slice_scatter_default_2850 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23531: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23497, 2, 16, 32);  slice_23497 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_716: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23531, memory_format = torch.contiguous_format);  slice_23531 = None
        view_1436: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_716, [32, 11]);  clone_716 = None
        mm_713: "f32[32, 8]" = torch.ops.aten.mm.default(view_1436, slice_37)
        view_1437: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_713, [2, 16, 8]);  mm_713 = None
        slice_23538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2851, 1, 5696, 5712)
        slice_23539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23538, 2, 0, 16);  slice_23538 = None
        add_715: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23539, view_1437);  slice_23539 = view_1437 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2851, 1, 5696, 5712)
        slice_scatter_default_2852: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1426, add_715, 2, 0, 16);  slice_tensor_1426 = add_715 = None
        slice_scatter_default_2853: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2851, slice_scatter_default_2852, 1, 5696, 5712);  slice_scatter_default_2851 = slice_scatter_default_2852 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2853, 1, 5696, 5712)
        slice_23544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23543, 2, 0, 16);  slice_23543 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2853, 1, 5696, 5712)
        slice_scatter_default_2854: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1427, slice_23544, 2, 0, 16);  slice_tensor_1427 = slice_23544 = None
        slice_scatter_default_2855: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2853, slice_scatter_default_2854, 1, 5696, 5712);  slice_scatter_default_2853 = slice_scatter_default_2854 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23563: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5712, 5728)
        slice_23564: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23563, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_717: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23564, memory_format = torch.contiguous_format);  slice_23564 = None
        view_1438: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_717, [32, 16]);  clone_717 = None
        mm_714: "f32[32, 8]" = torch.ops.aten.mm.default(view_1438, slice_7)
        view_1439: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_714, [2, 16, 8]);  mm_714 = None
        slice_23571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2855, 1, 5712, 5728)
        slice_23572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23571, 2, 0, 16);  slice_23571 = None
        add_716: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23572, view_1439);  slice_23572 = view_1439 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2855, 1, 5712, 5728)
        slice_scatter_default_2856: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1428, add_716, 2, 0, 16);  slice_tensor_1428 = add_716 = None
        slice_scatter_default_2857: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2855, slice_scatter_default_2856, 1, 5712, 5728);  slice_scatter_default_2855 = slice_scatter_default_2856 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2857, 1, 5712, 5728)
        slice_23577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23576, 2, 0, 16);  slice_23576 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2857, 1, 5712, 5728)
        slice_scatter_default_2858: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1429, slice_23577, 2, 0, 16);  slice_tensor_1429 = slice_23577 = None
        slice_scatter_default_2859: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2857, slice_scatter_default_2858, 1, 5712, 5728);  slice_scatter_default_2857 = slice_scatter_default_2858 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23597: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23563, 2, 16, 32);  slice_23563 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_718: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23597, memory_format = torch.contiguous_format);  slice_23597 = None
        view_1440: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_718, [32, 11]);  clone_718 = None
        mm_715: "f32[32, 8]" = torch.ops.aten.mm.default(view_1440, slice_37)
        view_1441: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_715, [2, 16, 8]);  mm_715 = None
        slice_23604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2859, 1, 5712, 5728)
        slice_23605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23604, 2, 0, 16);  slice_23604 = None
        add_717: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23605, view_1441);  slice_23605 = view_1441 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2859, 1, 5712, 5728)
        slice_scatter_default_2860: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1430, add_717, 2, 0, 16);  slice_tensor_1430 = add_717 = None
        slice_scatter_default_2861: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2859, slice_scatter_default_2860, 1, 5712, 5728);  slice_scatter_default_2859 = slice_scatter_default_2860 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2861, 1, 5712, 5728)
        slice_23610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23609, 2, 0, 16);  slice_23609 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2861, 1, 5712, 5728)
        slice_scatter_default_2862: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1431, slice_23610, 2, 0, 16);  slice_tensor_1431 = slice_23610 = None
        slice_scatter_default_2863: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2861, slice_scatter_default_2862, 1, 5712, 5728);  slice_scatter_default_2861 = slice_scatter_default_2862 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23629: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5728, 5744)
        slice_23630: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23629, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_719: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23630, memory_format = torch.contiguous_format);  slice_23630 = None
        view_1442: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_719, [32, 16]);  clone_719 = None
        mm_716: "f32[32, 8]" = torch.ops.aten.mm.default(view_1442, slice_7)
        view_1443: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_716, [2, 16, 8]);  mm_716 = None
        slice_23637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2863, 1, 5728, 5744)
        slice_23638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23637, 2, 0, 16);  slice_23637 = None
        add_718: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23638, view_1443);  slice_23638 = view_1443 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2863, 1, 5728, 5744)
        slice_scatter_default_2864: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1432, add_718, 2, 0, 16);  slice_tensor_1432 = add_718 = None
        slice_scatter_default_2865: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2863, slice_scatter_default_2864, 1, 5728, 5744);  slice_scatter_default_2863 = slice_scatter_default_2864 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2865, 1, 5728, 5744)
        slice_23643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23642, 2, 0, 16);  slice_23642 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2865, 1, 5728, 5744)
        slice_scatter_default_2866: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1433, slice_23643, 2, 0, 16);  slice_tensor_1433 = slice_23643 = None
        slice_scatter_default_2867: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2865, slice_scatter_default_2866, 1, 5728, 5744);  slice_scatter_default_2865 = slice_scatter_default_2866 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23663: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23629, 2, 16, 32);  slice_23629 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_720: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23663, memory_format = torch.contiguous_format);  slice_23663 = None
        view_1444: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_720, [32, 11]);  clone_720 = None
        mm_717: "f32[32, 8]" = torch.ops.aten.mm.default(view_1444, slice_37)
        view_1445: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_717, [2, 16, 8]);  mm_717 = None
        slice_23670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2867, 1, 5728, 5744)
        slice_23671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23670, 2, 0, 16);  slice_23670 = None
        add_719: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23671, view_1445);  slice_23671 = view_1445 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2867, 1, 5728, 5744)
        slice_scatter_default_2868: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1434, add_719, 2, 0, 16);  slice_tensor_1434 = add_719 = None
        slice_scatter_default_2869: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2867, slice_scatter_default_2868, 1, 5728, 5744);  slice_scatter_default_2867 = slice_scatter_default_2868 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2869, 1, 5728, 5744)
        slice_23676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23675, 2, 0, 16);  slice_23675 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2869, 1, 5728, 5744)
        slice_scatter_default_2870: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1435, slice_23676, 2, 0, 16);  slice_tensor_1435 = slice_23676 = None
        slice_scatter_default_2871: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2869, slice_scatter_default_2870, 1, 5728, 5744);  slice_scatter_default_2869 = slice_scatter_default_2870 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23695: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5744, 5760)
        slice_23696: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23695, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_721: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23696, memory_format = torch.contiguous_format);  slice_23696 = None
        view_1446: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_721, [32, 16]);  clone_721 = None
        mm_718: "f32[32, 8]" = torch.ops.aten.mm.default(view_1446, slice_7)
        view_1447: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_718, [2, 16, 8]);  mm_718 = None
        slice_23703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2871, 1, 5744, 5760)
        slice_23704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23703, 2, 0, 16);  slice_23703 = None
        add_720: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23704, view_1447);  slice_23704 = view_1447 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2871, 1, 5744, 5760)
        slice_scatter_default_2872: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1436, add_720, 2, 0, 16);  slice_tensor_1436 = add_720 = None
        slice_scatter_default_2873: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2871, slice_scatter_default_2872, 1, 5744, 5760);  slice_scatter_default_2871 = slice_scatter_default_2872 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2873, 1, 5744, 5760)
        slice_23709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23708, 2, 0, 16);  slice_23708 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2873, 1, 5744, 5760)
        slice_scatter_default_2874: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1437, slice_23709, 2, 0, 16);  slice_tensor_1437 = slice_23709 = None
        slice_scatter_default_2875: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2873, slice_scatter_default_2874, 1, 5744, 5760);  slice_scatter_default_2873 = slice_scatter_default_2874 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23729: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23695, 2, 16, 32);  slice_23695 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_722: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23729, memory_format = torch.contiguous_format);  slice_23729 = None
        view_1448: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_722, [32, 11]);  clone_722 = None
        mm_719: "f32[32, 8]" = torch.ops.aten.mm.default(view_1448, slice_37)
        view_1449: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_719, [2, 16, 8]);  mm_719 = None
        slice_23736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2875, 1, 5744, 5760)
        slice_23737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23736, 2, 0, 16);  slice_23736 = None
        add_721: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23737, view_1449);  slice_23737 = view_1449 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2875, 1, 5744, 5760)
        slice_scatter_default_2876: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1438, add_721, 2, 0, 16);  slice_tensor_1438 = add_721 = None
        slice_scatter_default_2877: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2875, slice_scatter_default_2876, 1, 5744, 5760);  slice_scatter_default_2875 = slice_scatter_default_2876 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2877, 1, 5744, 5760)
        slice_23742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23741, 2, 0, 16);  slice_23741 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2877, 1, 5744, 5760)
        slice_scatter_default_2878: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1439, slice_23742, 2, 0, 16);  slice_tensor_1439 = slice_23742 = None
        slice_scatter_default_2879: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2877, slice_scatter_default_2878, 1, 5744, 5760);  slice_scatter_default_2877 = slice_scatter_default_2878 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23761: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5760, 5776)
        slice_23762: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23761, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_723: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23762, memory_format = torch.contiguous_format);  slice_23762 = None
        view_1450: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_723, [32, 16]);  clone_723 = None
        mm_720: "f32[32, 8]" = torch.ops.aten.mm.default(view_1450, slice_7)
        view_1451: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_720, [2, 16, 8]);  mm_720 = None
        slice_23769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2879, 1, 5760, 5776)
        slice_23770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23769, 2, 0, 16);  slice_23769 = None
        add_722: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23770, view_1451);  slice_23770 = view_1451 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2879, 1, 5760, 5776)
        slice_scatter_default_2880: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1440, add_722, 2, 0, 16);  slice_tensor_1440 = add_722 = None
        slice_scatter_default_2881: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2879, slice_scatter_default_2880, 1, 5760, 5776);  slice_scatter_default_2879 = slice_scatter_default_2880 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2881, 1, 5760, 5776)
        slice_23775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23774, 2, 0, 16);  slice_23774 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2881, 1, 5760, 5776)
        slice_scatter_default_2882: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1441, slice_23775, 2, 0, 16);  slice_tensor_1441 = slice_23775 = None
        slice_scatter_default_2883: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2881, slice_scatter_default_2882, 1, 5760, 5776);  slice_scatter_default_2881 = slice_scatter_default_2882 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23795: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23761, 2, 16, 32);  slice_23761 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_724: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23795, memory_format = torch.contiguous_format);  slice_23795 = None
        view_1452: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_724, [32, 11]);  clone_724 = None
        mm_721: "f32[32, 8]" = torch.ops.aten.mm.default(view_1452, slice_37)
        view_1453: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_721, [2, 16, 8]);  mm_721 = None
        slice_23802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2883, 1, 5760, 5776)
        slice_23803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23802, 2, 0, 16);  slice_23802 = None
        add_723: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23803, view_1453);  slice_23803 = view_1453 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2883, 1, 5760, 5776)
        slice_scatter_default_2884: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1442, add_723, 2, 0, 16);  slice_tensor_1442 = add_723 = None
        slice_scatter_default_2885: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2883, slice_scatter_default_2884, 1, 5760, 5776);  slice_scatter_default_2883 = slice_scatter_default_2884 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2885, 1, 5760, 5776)
        slice_23808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23807, 2, 0, 16);  slice_23807 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2885, 1, 5760, 5776)
        slice_scatter_default_2886: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1443, slice_23808, 2, 0, 16);  slice_tensor_1443 = slice_23808 = None
        slice_scatter_default_2887: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2885, slice_scatter_default_2886, 1, 5760, 5776);  slice_scatter_default_2885 = slice_scatter_default_2886 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23827: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5776, 5792)
        slice_23828: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23827, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_725: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23828, memory_format = torch.contiguous_format);  slice_23828 = None
        view_1454: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_725, [32, 16]);  clone_725 = None
        mm_722: "f32[32, 8]" = torch.ops.aten.mm.default(view_1454, slice_7)
        view_1455: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_722, [2, 16, 8]);  mm_722 = None
        slice_23835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2887, 1, 5776, 5792)
        slice_23836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23835, 2, 0, 16);  slice_23835 = None
        add_724: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23836, view_1455);  slice_23836 = view_1455 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2887, 1, 5776, 5792)
        slice_scatter_default_2888: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1444, add_724, 2, 0, 16);  slice_tensor_1444 = add_724 = None
        slice_scatter_default_2889: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2887, slice_scatter_default_2888, 1, 5776, 5792);  slice_scatter_default_2887 = slice_scatter_default_2888 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2889, 1, 5776, 5792)
        slice_23841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23840, 2, 0, 16);  slice_23840 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2889, 1, 5776, 5792)
        slice_scatter_default_2890: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1445, slice_23841, 2, 0, 16);  slice_tensor_1445 = slice_23841 = None
        slice_scatter_default_2891: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2889, slice_scatter_default_2890, 1, 5776, 5792);  slice_scatter_default_2889 = slice_scatter_default_2890 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23861: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23827, 2, 16, 32);  slice_23827 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_726: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23861, memory_format = torch.contiguous_format);  slice_23861 = None
        view_1456: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_726, [32, 11]);  clone_726 = None
        mm_723: "f32[32, 8]" = torch.ops.aten.mm.default(view_1456, slice_37)
        view_1457: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_723, [2, 16, 8]);  mm_723 = None
        slice_23868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2891, 1, 5776, 5792)
        slice_23869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23868, 2, 0, 16);  slice_23868 = None
        add_725: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23869, view_1457);  slice_23869 = view_1457 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2891, 1, 5776, 5792)
        slice_scatter_default_2892: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1446, add_725, 2, 0, 16);  slice_tensor_1446 = add_725 = None
        slice_scatter_default_2893: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2891, slice_scatter_default_2892, 1, 5776, 5792);  slice_scatter_default_2891 = slice_scatter_default_2892 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2893, 1, 5776, 5792)
        slice_23874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23873, 2, 0, 16);  slice_23873 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2893, 1, 5776, 5792)
        slice_scatter_default_2894: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1447, slice_23874, 2, 0, 16);  slice_tensor_1447 = slice_23874 = None
        slice_scatter_default_2895: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2893, slice_scatter_default_2894, 1, 5776, 5792);  slice_scatter_default_2893 = slice_scatter_default_2894 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23893: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5792, 5808)
        slice_23894: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23893, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_727: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23894, memory_format = torch.contiguous_format);  slice_23894 = None
        view_1458: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_727, [32, 16]);  clone_727 = None
        mm_724: "f32[32, 8]" = torch.ops.aten.mm.default(view_1458, slice_7)
        view_1459: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_724, [2, 16, 8]);  mm_724 = None
        slice_23901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2895, 1, 5792, 5808)
        slice_23902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23901, 2, 0, 16);  slice_23901 = None
        add_726: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23902, view_1459);  slice_23902 = view_1459 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2895, 1, 5792, 5808)
        slice_scatter_default_2896: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1448, add_726, 2, 0, 16);  slice_tensor_1448 = add_726 = None
        slice_scatter_default_2897: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2895, slice_scatter_default_2896, 1, 5792, 5808);  slice_scatter_default_2895 = slice_scatter_default_2896 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2897, 1, 5792, 5808)
        slice_23907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23906, 2, 0, 16);  slice_23906 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2897, 1, 5792, 5808)
        slice_scatter_default_2898: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1449, slice_23907, 2, 0, 16);  slice_tensor_1449 = slice_23907 = None
        slice_scatter_default_2899: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2897, slice_scatter_default_2898, 1, 5792, 5808);  slice_scatter_default_2897 = slice_scatter_default_2898 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23927: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23893, 2, 16, 32);  slice_23893 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_728: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23927, memory_format = torch.contiguous_format);  slice_23927 = None
        view_1460: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_728, [32, 11]);  clone_728 = None
        mm_725: "f32[32, 8]" = torch.ops.aten.mm.default(view_1460, slice_37)
        view_1461: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_725, [2, 16, 8]);  mm_725 = None
        slice_23934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2899, 1, 5792, 5808)
        slice_23935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23934, 2, 0, 16);  slice_23934 = None
        add_727: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23935, view_1461);  slice_23935 = view_1461 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2899, 1, 5792, 5808)
        slice_scatter_default_2900: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1450, add_727, 2, 0, 16);  slice_tensor_1450 = add_727 = None
        slice_scatter_default_2901: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2899, slice_scatter_default_2900, 1, 5792, 5808);  slice_scatter_default_2899 = slice_scatter_default_2900 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2901, 1, 5792, 5808)
        slice_23940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23939, 2, 0, 16);  slice_23939 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2901, 1, 5792, 5808)
        slice_scatter_default_2902: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1451, slice_23940, 2, 0, 16);  slice_tensor_1451 = slice_23940 = None
        slice_scatter_default_2903: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2901, slice_scatter_default_2902, 1, 5792, 5808);  slice_scatter_default_2901 = slice_scatter_default_2902 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23959: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5808, 5824)
        slice_23960: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_23959, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_729: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_23960, memory_format = torch.contiguous_format);  slice_23960 = None
        view_1462: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_729, [32, 16]);  clone_729 = None
        mm_726: "f32[32, 8]" = torch.ops.aten.mm.default(view_1462, slice_7)
        view_1463: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_726, [2, 16, 8]);  mm_726 = None
        slice_23967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2903, 1, 5808, 5824)
        slice_23968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23967, 2, 0, 16);  slice_23967 = None
        add_728: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_23968, view_1463);  slice_23968 = view_1463 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2903, 1, 5808, 5824)
        slice_scatter_default_2904: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1452, add_728, 2, 0, 16);  slice_tensor_1452 = add_728 = None
        slice_scatter_default_2905: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2903, slice_scatter_default_2904, 1, 5808, 5824);  slice_scatter_default_2903 = slice_scatter_default_2904 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_23972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2905, 1, 5808, 5824)
        slice_23973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_23972, 2, 0, 16);  slice_23972 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2905, 1, 5808, 5824)
        slice_scatter_default_2906: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1453, slice_23973, 2, 0, 16);  slice_tensor_1453 = slice_23973 = None
        slice_scatter_default_2907: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2905, slice_scatter_default_2906, 1, 5808, 5824);  slice_scatter_default_2905 = slice_scatter_default_2906 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_23993: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_23959, 2, 16, 32);  slice_23959 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_730: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_23993, memory_format = torch.contiguous_format);  slice_23993 = None
        view_1464: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_730, [32, 11]);  clone_730 = None
        mm_727: "f32[32, 8]" = torch.ops.aten.mm.default(view_1464, slice_37)
        view_1465: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_727, [2, 16, 8]);  mm_727 = None
        slice_24000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2907, 1, 5808, 5824)
        slice_24001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24000, 2, 0, 16);  slice_24000 = None
        add_729: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24001, view_1465);  slice_24001 = view_1465 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2907, 1, 5808, 5824)
        slice_scatter_default_2908: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1454, add_729, 2, 0, 16);  slice_tensor_1454 = add_729 = None
        slice_scatter_default_2909: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2907, slice_scatter_default_2908, 1, 5808, 5824);  slice_scatter_default_2907 = slice_scatter_default_2908 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2909, 1, 5808, 5824)
        slice_24006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24005, 2, 0, 16);  slice_24005 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2909, 1, 5808, 5824)
        slice_scatter_default_2910: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1455, slice_24006, 2, 0, 16);  slice_tensor_1455 = slice_24006 = None
        slice_scatter_default_2911: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2909, slice_scatter_default_2910, 1, 5808, 5824);  slice_scatter_default_2909 = slice_scatter_default_2910 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24025: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5824, 5840)
        slice_24026: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24025, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_731: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24026, memory_format = torch.contiguous_format);  slice_24026 = None
        view_1466: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_731, [32, 16]);  clone_731 = None
        mm_728: "f32[32, 8]" = torch.ops.aten.mm.default(view_1466, slice_7)
        view_1467: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_728, [2, 16, 8]);  mm_728 = None
        slice_24033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2911, 1, 5824, 5840)
        slice_24034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24033, 2, 0, 16);  slice_24033 = None
        add_730: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24034, view_1467);  slice_24034 = view_1467 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2911, 1, 5824, 5840)
        slice_scatter_default_2912: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1456, add_730, 2, 0, 16);  slice_tensor_1456 = add_730 = None
        slice_scatter_default_2913: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2911, slice_scatter_default_2912, 1, 5824, 5840);  slice_scatter_default_2911 = slice_scatter_default_2912 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2913, 1, 5824, 5840)
        slice_24039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24038, 2, 0, 16);  slice_24038 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2913, 1, 5824, 5840)
        slice_scatter_default_2914: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1457, slice_24039, 2, 0, 16);  slice_tensor_1457 = slice_24039 = None
        slice_scatter_default_2915: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2913, slice_scatter_default_2914, 1, 5824, 5840);  slice_scatter_default_2913 = slice_scatter_default_2914 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24059: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24025, 2, 16, 32);  slice_24025 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_732: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24059, memory_format = torch.contiguous_format);  slice_24059 = None
        view_1468: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_732, [32, 11]);  clone_732 = None
        mm_729: "f32[32, 8]" = torch.ops.aten.mm.default(view_1468, slice_37)
        view_1469: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_729, [2, 16, 8]);  mm_729 = None
        slice_24066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2915, 1, 5824, 5840)
        slice_24067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24066, 2, 0, 16);  slice_24066 = None
        add_731: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24067, view_1469);  slice_24067 = view_1469 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2915, 1, 5824, 5840)
        slice_scatter_default_2916: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1458, add_731, 2, 0, 16);  slice_tensor_1458 = add_731 = None
        slice_scatter_default_2917: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2915, slice_scatter_default_2916, 1, 5824, 5840);  slice_scatter_default_2915 = slice_scatter_default_2916 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2917, 1, 5824, 5840)
        slice_24072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24071, 2, 0, 16);  slice_24071 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2917, 1, 5824, 5840)
        slice_scatter_default_2918: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1459, slice_24072, 2, 0, 16);  slice_tensor_1459 = slice_24072 = None
        slice_scatter_default_2919: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2917, slice_scatter_default_2918, 1, 5824, 5840);  slice_scatter_default_2917 = slice_scatter_default_2918 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24091: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5840, 5856)
        slice_24092: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24091, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_733: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24092, memory_format = torch.contiguous_format);  slice_24092 = None
        view_1470: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_733, [32, 16]);  clone_733 = None
        mm_730: "f32[32, 8]" = torch.ops.aten.mm.default(view_1470, slice_7)
        view_1471: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_730, [2, 16, 8]);  mm_730 = None
        slice_24099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2919, 1, 5840, 5856)
        slice_24100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24099, 2, 0, 16);  slice_24099 = None
        add_732: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24100, view_1471);  slice_24100 = view_1471 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2919, 1, 5840, 5856)
        slice_scatter_default_2920: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1460, add_732, 2, 0, 16);  slice_tensor_1460 = add_732 = None
        slice_scatter_default_2921: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2919, slice_scatter_default_2920, 1, 5840, 5856);  slice_scatter_default_2919 = slice_scatter_default_2920 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2921, 1, 5840, 5856)
        slice_24105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24104, 2, 0, 16);  slice_24104 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2921, 1, 5840, 5856)
        slice_scatter_default_2922: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1461, slice_24105, 2, 0, 16);  slice_tensor_1461 = slice_24105 = None
        slice_scatter_default_2923: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2921, slice_scatter_default_2922, 1, 5840, 5856);  slice_scatter_default_2921 = slice_scatter_default_2922 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24125: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24091, 2, 16, 32);  slice_24091 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_734: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24125, memory_format = torch.contiguous_format);  slice_24125 = None
        view_1472: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_734, [32, 11]);  clone_734 = None
        mm_731: "f32[32, 8]" = torch.ops.aten.mm.default(view_1472, slice_37)
        view_1473: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_731, [2, 16, 8]);  mm_731 = None
        slice_24132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2923, 1, 5840, 5856)
        slice_24133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24132, 2, 0, 16);  slice_24132 = None
        add_733: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24133, view_1473);  slice_24133 = view_1473 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2923, 1, 5840, 5856)
        slice_scatter_default_2924: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1462, add_733, 2, 0, 16);  slice_tensor_1462 = add_733 = None
        slice_scatter_default_2925: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2923, slice_scatter_default_2924, 1, 5840, 5856);  slice_scatter_default_2923 = slice_scatter_default_2924 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2925, 1, 5840, 5856)
        slice_24138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24137, 2, 0, 16);  slice_24137 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2925, 1, 5840, 5856)
        slice_scatter_default_2926: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1463, slice_24138, 2, 0, 16);  slice_tensor_1463 = slice_24138 = None
        slice_scatter_default_2927: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2925, slice_scatter_default_2926, 1, 5840, 5856);  slice_scatter_default_2925 = slice_scatter_default_2926 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24157: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5856, 5872)
        slice_24158: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24157, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_735: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24158, memory_format = torch.contiguous_format);  slice_24158 = None
        view_1474: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_735, [32, 16]);  clone_735 = None
        mm_732: "f32[32, 8]" = torch.ops.aten.mm.default(view_1474, slice_7)
        view_1475: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_732, [2, 16, 8]);  mm_732 = None
        slice_24165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2927, 1, 5856, 5872)
        slice_24166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24165, 2, 0, 16);  slice_24165 = None
        add_734: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24166, view_1475);  slice_24166 = view_1475 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2927, 1, 5856, 5872)
        slice_scatter_default_2928: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1464, add_734, 2, 0, 16);  slice_tensor_1464 = add_734 = None
        slice_scatter_default_2929: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2927, slice_scatter_default_2928, 1, 5856, 5872);  slice_scatter_default_2927 = slice_scatter_default_2928 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2929, 1, 5856, 5872)
        slice_24171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24170, 2, 0, 16);  slice_24170 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2929, 1, 5856, 5872)
        slice_scatter_default_2930: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1465, slice_24171, 2, 0, 16);  slice_tensor_1465 = slice_24171 = None
        slice_scatter_default_2931: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2929, slice_scatter_default_2930, 1, 5856, 5872);  slice_scatter_default_2929 = slice_scatter_default_2930 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24191: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24157, 2, 16, 32);  slice_24157 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_736: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24191, memory_format = torch.contiguous_format);  slice_24191 = None
        view_1476: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_736, [32, 11]);  clone_736 = None
        mm_733: "f32[32, 8]" = torch.ops.aten.mm.default(view_1476, slice_37)
        view_1477: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_733, [2, 16, 8]);  mm_733 = None
        slice_24198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2931, 1, 5856, 5872)
        slice_24199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24198, 2, 0, 16);  slice_24198 = None
        add_735: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24199, view_1477);  slice_24199 = view_1477 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2931, 1, 5856, 5872)
        slice_scatter_default_2932: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1466, add_735, 2, 0, 16);  slice_tensor_1466 = add_735 = None
        slice_scatter_default_2933: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2931, slice_scatter_default_2932, 1, 5856, 5872);  slice_scatter_default_2931 = slice_scatter_default_2932 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2933, 1, 5856, 5872)
        slice_24204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24203, 2, 0, 16);  slice_24203 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2933, 1, 5856, 5872)
        slice_scatter_default_2934: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1467, slice_24204, 2, 0, 16);  slice_tensor_1467 = slice_24204 = None
        slice_scatter_default_2935: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2933, slice_scatter_default_2934, 1, 5856, 5872);  slice_scatter_default_2933 = slice_scatter_default_2934 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24223: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5872, 5888)
        slice_24224: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24223, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_737: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24224, memory_format = torch.contiguous_format);  slice_24224 = None
        view_1478: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_737, [32, 16]);  clone_737 = None
        mm_734: "f32[32, 8]" = torch.ops.aten.mm.default(view_1478, slice_7)
        view_1479: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_734, [2, 16, 8]);  mm_734 = None
        slice_24231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2935, 1, 5872, 5888)
        slice_24232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24231, 2, 0, 16);  slice_24231 = None
        add_736: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24232, view_1479);  slice_24232 = view_1479 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2935, 1, 5872, 5888)
        slice_scatter_default_2936: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1468, add_736, 2, 0, 16);  slice_tensor_1468 = add_736 = None
        slice_scatter_default_2937: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2935, slice_scatter_default_2936, 1, 5872, 5888);  slice_scatter_default_2935 = slice_scatter_default_2936 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2937, 1, 5872, 5888)
        slice_24237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24236, 2, 0, 16);  slice_24236 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2937, 1, 5872, 5888)
        slice_scatter_default_2938: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1469, slice_24237, 2, 0, 16);  slice_tensor_1469 = slice_24237 = None
        slice_scatter_default_2939: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2937, slice_scatter_default_2938, 1, 5872, 5888);  slice_scatter_default_2937 = slice_scatter_default_2938 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24257: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24223, 2, 16, 32);  slice_24223 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_738: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24257, memory_format = torch.contiguous_format);  slice_24257 = None
        view_1480: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_738, [32, 11]);  clone_738 = None
        mm_735: "f32[32, 8]" = torch.ops.aten.mm.default(view_1480, slice_37)
        view_1481: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_735, [2, 16, 8]);  mm_735 = None
        slice_24264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2939, 1, 5872, 5888)
        slice_24265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24264, 2, 0, 16);  slice_24264 = None
        add_737: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24265, view_1481);  slice_24265 = view_1481 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2939, 1, 5872, 5888)
        slice_scatter_default_2940: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1470, add_737, 2, 0, 16);  slice_tensor_1470 = add_737 = None
        slice_scatter_default_2941: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2939, slice_scatter_default_2940, 1, 5872, 5888);  slice_scatter_default_2939 = slice_scatter_default_2940 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2941, 1, 5872, 5888)
        slice_24270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24269, 2, 0, 16);  slice_24269 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2941, 1, 5872, 5888)
        slice_scatter_default_2942: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1471, slice_24270, 2, 0, 16);  slice_tensor_1471 = slice_24270 = None
        slice_scatter_default_2943: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2941, slice_scatter_default_2942, 1, 5872, 5888);  slice_scatter_default_2941 = slice_scatter_default_2942 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24289: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5888, 5904)
        slice_24290: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24289, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_739: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24290, memory_format = torch.contiguous_format);  slice_24290 = None
        view_1482: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_739, [32, 16]);  clone_739 = None
        mm_736: "f32[32, 8]" = torch.ops.aten.mm.default(view_1482, slice_7)
        view_1483: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_736, [2, 16, 8]);  mm_736 = None
        slice_24297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2943, 1, 5888, 5904)
        slice_24298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24297, 2, 0, 16);  slice_24297 = None
        add_738: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24298, view_1483);  slice_24298 = view_1483 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2943, 1, 5888, 5904)
        slice_scatter_default_2944: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1472, add_738, 2, 0, 16);  slice_tensor_1472 = add_738 = None
        slice_scatter_default_2945: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2943, slice_scatter_default_2944, 1, 5888, 5904);  slice_scatter_default_2943 = slice_scatter_default_2944 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2945, 1, 5888, 5904)
        slice_24303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24302, 2, 0, 16);  slice_24302 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2945, 1, 5888, 5904)
        slice_scatter_default_2946: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1473, slice_24303, 2, 0, 16);  slice_tensor_1473 = slice_24303 = None
        slice_scatter_default_2947: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2945, slice_scatter_default_2946, 1, 5888, 5904);  slice_scatter_default_2945 = slice_scatter_default_2946 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24323: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24289, 2, 16, 32);  slice_24289 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_740: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24323, memory_format = torch.contiguous_format);  slice_24323 = None
        view_1484: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_740, [32, 11]);  clone_740 = None
        mm_737: "f32[32, 8]" = torch.ops.aten.mm.default(view_1484, slice_37)
        view_1485: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_737, [2, 16, 8]);  mm_737 = None
        slice_24330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2947, 1, 5888, 5904)
        slice_24331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24330, 2, 0, 16);  slice_24330 = None
        add_739: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24331, view_1485);  slice_24331 = view_1485 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2947, 1, 5888, 5904)
        slice_scatter_default_2948: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1474, add_739, 2, 0, 16);  slice_tensor_1474 = add_739 = None
        slice_scatter_default_2949: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2947, slice_scatter_default_2948, 1, 5888, 5904);  slice_scatter_default_2947 = slice_scatter_default_2948 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2949, 1, 5888, 5904)
        slice_24336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24335, 2, 0, 16);  slice_24335 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2949, 1, 5888, 5904)
        slice_scatter_default_2950: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1475, slice_24336, 2, 0, 16);  slice_tensor_1475 = slice_24336 = None
        slice_scatter_default_2951: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2949, slice_scatter_default_2950, 1, 5888, 5904);  slice_scatter_default_2949 = slice_scatter_default_2950 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24355: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5904, 5920)
        slice_24356: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24355, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_741: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24356, memory_format = torch.contiguous_format);  slice_24356 = None
        view_1486: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_741, [32, 16]);  clone_741 = None
        mm_738: "f32[32, 8]" = torch.ops.aten.mm.default(view_1486, slice_7)
        view_1487: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_738, [2, 16, 8]);  mm_738 = None
        slice_24363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2951, 1, 5904, 5920)
        slice_24364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24363, 2, 0, 16);  slice_24363 = None
        add_740: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24364, view_1487);  slice_24364 = view_1487 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2951, 1, 5904, 5920)
        slice_scatter_default_2952: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1476, add_740, 2, 0, 16);  slice_tensor_1476 = add_740 = None
        slice_scatter_default_2953: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2951, slice_scatter_default_2952, 1, 5904, 5920);  slice_scatter_default_2951 = slice_scatter_default_2952 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2953, 1, 5904, 5920)
        slice_24369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24368, 2, 0, 16);  slice_24368 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2953, 1, 5904, 5920)
        slice_scatter_default_2954: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1477, slice_24369, 2, 0, 16);  slice_tensor_1477 = slice_24369 = None
        slice_scatter_default_2955: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2953, slice_scatter_default_2954, 1, 5904, 5920);  slice_scatter_default_2953 = slice_scatter_default_2954 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24389: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24355, 2, 16, 32);  slice_24355 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_742: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24389, memory_format = torch.contiguous_format);  slice_24389 = None
        view_1488: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_742, [32, 11]);  clone_742 = None
        mm_739: "f32[32, 8]" = torch.ops.aten.mm.default(view_1488, slice_37)
        view_1489: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_739, [2, 16, 8]);  mm_739 = None
        slice_24396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2955, 1, 5904, 5920)
        slice_24397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24396, 2, 0, 16);  slice_24396 = None
        add_741: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24397, view_1489);  slice_24397 = view_1489 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2955, 1, 5904, 5920)
        slice_scatter_default_2956: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1478, add_741, 2, 0, 16);  slice_tensor_1478 = add_741 = None
        slice_scatter_default_2957: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2955, slice_scatter_default_2956, 1, 5904, 5920);  slice_scatter_default_2955 = slice_scatter_default_2956 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2957, 1, 5904, 5920)
        slice_24402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24401, 2, 0, 16);  slice_24401 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2957, 1, 5904, 5920)
        slice_scatter_default_2958: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1479, slice_24402, 2, 0, 16);  slice_tensor_1479 = slice_24402 = None
        slice_scatter_default_2959: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2957, slice_scatter_default_2958, 1, 5904, 5920);  slice_scatter_default_2957 = slice_scatter_default_2958 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24421: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5920, 5936)
        slice_24422: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24421, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_743: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24422, memory_format = torch.contiguous_format);  slice_24422 = None
        view_1490: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_743, [32, 16]);  clone_743 = None
        mm_740: "f32[32, 8]" = torch.ops.aten.mm.default(view_1490, slice_7)
        view_1491: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_740, [2, 16, 8]);  mm_740 = None
        slice_24429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2959, 1, 5920, 5936)
        slice_24430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24429, 2, 0, 16);  slice_24429 = None
        add_742: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24430, view_1491);  slice_24430 = view_1491 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2959, 1, 5920, 5936)
        slice_scatter_default_2960: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1480, add_742, 2, 0, 16);  slice_tensor_1480 = add_742 = None
        slice_scatter_default_2961: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2959, slice_scatter_default_2960, 1, 5920, 5936);  slice_scatter_default_2959 = slice_scatter_default_2960 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2961, 1, 5920, 5936)
        slice_24435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24434, 2, 0, 16);  slice_24434 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2961, 1, 5920, 5936)
        slice_scatter_default_2962: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1481, slice_24435, 2, 0, 16);  slice_tensor_1481 = slice_24435 = None
        slice_scatter_default_2963: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2961, slice_scatter_default_2962, 1, 5920, 5936);  slice_scatter_default_2961 = slice_scatter_default_2962 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24455: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24421, 2, 16, 32);  slice_24421 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_744: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24455, memory_format = torch.contiguous_format);  slice_24455 = None
        view_1492: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_744, [32, 11]);  clone_744 = None
        mm_741: "f32[32, 8]" = torch.ops.aten.mm.default(view_1492, slice_37)
        view_1493: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_741, [2, 16, 8]);  mm_741 = None
        slice_24462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2963, 1, 5920, 5936)
        slice_24463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24462, 2, 0, 16);  slice_24462 = None
        add_743: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24463, view_1493);  slice_24463 = view_1493 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2963, 1, 5920, 5936)
        slice_scatter_default_2964: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1482, add_743, 2, 0, 16);  slice_tensor_1482 = add_743 = None
        slice_scatter_default_2965: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2963, slice_scatter_default_2964, 1, 5920, 5936);  slice_scatter_default_2963 = slice_scatter_default_2964 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2965, 1, 5920, 5936)
        slice_24468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24467, 2, 0, 16);  slice_24467 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2965, 1, 5920, 5936)
        slice_scatter_default_2966: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1483, slice_24468, 2, 0, 16);  slice_tensor_1483 = slice_24468 = None
        slice_scatter_default_2967: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2965, slice_scatter_default_2966, 1, 5920, 5936);  slice_scatter_default_2965 = slice_scatter_default_2966 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24487: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5936, 5952)
        slice_24488: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24487, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_745: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24488, memory_format = torch.contiguous_format);  slice_24488 = None
        view_1494: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_745, [32, 16]);  clone_745 = None
        mm_742: "f32[32, 8]" = torch.ops.aten.mm.default(view_1494, slice_7)
        view_1495: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_742, [2, 16, 8]);  mm_742 = None
        slice_24495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2967, 1, 5936, 5952)
        slice_24496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24495, 2, 0, 16);  slice_24495 = None
        add_744: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24496, view_1495);  slice_24496 = view_1495 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2967, 1, 5936, 5952)
        slice_scatter_default_2968: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1484, add_744, 2, 0, 16);  slice_tensor_1484 = add_744 = None
        slice_scatter_default_2969: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2967, slice_scatter_default_2968, 1, 5936, 5952);  slice_scatter_default_2967 = slice_scatter_default_2968 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2969, 1, 5936, 5952)
        slice_24501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24500, 2, 0, 16);  slice_24500 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2969, 1, 5936, 5952)
        slice_scatter_default_2970: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1485, slice_24501, 2, 0, 16);  slice_tensor_1485 = slice_24501 = None
        slice_scatter_default_2971: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2969, slice_scatter_default_2970, 1, 5936, 5952);  slice_scatter_default_2969 = slice_scatter_default_2970 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24521: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24487, 2, 16, 32);  slice_24487 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_746: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24521, memory_format = torch.contiguous_format);  slice_24521 = None
        view_1496: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_746, [32, 11]);  clone_746 = None
        mm_743: "f32[32, 8]" = torch.ops.aten.mm.default(view_1496, slice_37)
        view_1497: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_743, [2, 16, 8]);  mm_743 = None
        slice_24528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2971, 1, 5936, 5952)
        slice_24529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24528, 2, 0, 16);  slice_24528 = None
        add_745: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24529, view_1497);  slice_24529 = view_1497 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2971, 1, 5936, 5952)
        slice_scatter_default_2972: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1486, add_745, 2, 0, 16);  slice_tensor_1486 = add_745 = None
        slice_scatter_default_2973: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2971, slice_scatter_default_2972, 1, 5936, 5952);  slice_scatter_default_2971 = slice_scatter_default_2972 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2973, 1, 5936, 5952)
        slice_24534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24533, 2, 0, 16);  slice_24533 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2973, 1, 5936, 5952)
        slice_scatter_default_2974: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1487, slice_24534, 2, 0, 16);  slice_tensor_1487 = slice_24534 = None
        slice_scatter_default_2975: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2973, slice_scatter_default_2974, 1, 5936, 5952);  slice_scatter_default_2973 = slice_scatter_default_2974 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24553: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5952, 5968)
        slice_24554: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24553, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_747: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24554, memory_format = torch.contiguous_format);  slice_24554 = None
        view_1498: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_747, [32, 16]);  clone_747 = None
        mm_744: "f32[32, 8]" = torch.ops.aten.mm.default(view_1498, slice_7)
        view_1499: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_744, [2, 16, 8]);  mm_744 = None
        slice_24561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2975, 1, 5952, 5968)
        slice_24562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24561, 2, 0, 16);  slice_24561 = None
        add_746: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24562, view_1499);  slice_24562 = view_1499 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2975, 1, 5952, 5968)
        slice_scatter_default_2976: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1488, add_746, 2, 0, 16);  slice_tensor_1488 = add_746 = None
        slice_scatter_default_2977: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2975, slice_scatter_default_2976, 1, 5952, 5968);  slice_scatter_default_2975 = slice_scatter_default_2976 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2977, 1, 5952, 5968)
        slice_24567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24566, 2, 0, 16);  slice_24566 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2977, 1, 5952, 5968)
        slice_scatter_default_2978: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1489, slice_24567, 2, 0, 16);  slice_tensor_1489 = slice_24567 = None
        slice_scatter_default_2979: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2977, slice_scatter_default_2978, 1, 5952, 5968);  slice_scatter_default_2977 = slice_scatter_default_2978 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24587: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24553, 2, 16, 32);  slice_24553 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_748: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24587, memory_format = torch.contiguous_format);  slice_24587 = None
        view_1500: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_748, [32, 11]);  clone_748 = None
        mm_745: "f32[32, 8]" = torch.ops.aten.mm.default(view_1500, slice_37)
        view_1501: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_745, [2, 16, 8]);  mm_745 = None
        slice_24594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2979, 1, 5952, 5968)
        slice_24595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24594, 2, 0, 16);  slice_24594 = None
        add_747: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24595, view_1501);  slice_24595 = view_1501 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2979, 1, 5952, 5968)
        slice_scatter_default_2980: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1490, add_747, 2, 0, 16);  slice_tensor_1490 = add_747 = None
        slice_scatter_default_2981: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2979, slice_scatter_default_2980, 1, 5952, 5968);  slice_scatter_default_2979 = slice_scatter_default_2980 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2981, 1, 5952, 5968)
        slice_24600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24599, 2, 0, 16);  slice_24599 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2981, 1, 5952, 5968)
        slice_scatter_default_2982: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1491, slice_24600, 2, 0, 16);  slice_tensor_1491 = slice_24600 = None
        slice_scatter_default_2983: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2981, slice_scatter_default_2982, 1, 5952, 5968);  slice_scatter_default_2981 = slice_scatter_default_2982 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24619: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5968, 5984)
        slice_24620: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24619, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_749: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24620, memory_format = torch.contiguous_format);  slice_24620 = None
        view_1502: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_749, [32, 16]);  clone_749 = None
        mm_746: "f32[32, 8]" = torch.ops.aten.mm.default(view_1502, slice_7)
        view_1503: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_746, [2, 16, 8]);  mm_746 = None
        slice_24627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2983, 1, 5968, 5984)
        slice_24628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24627, 2, 0, 16);  slice_24627 = None
        add_748: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24628, view_1503);  slice_24628 = view_1503 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2983, 1, 5968, 5984)
        slice_scatter_default_2984: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1492, add_748, 2, 0, 16);  slice_tensor_1492 = add_748 = None
        slice_scatter_default_2985: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2983, slice_scatter_default_2984, 1, 5968, 5984);  slice_scatter_default_2983 = slice_scatter_default_2984 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2985, 1, 5968, 5984)
        slice_24633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24632, 2, 0, 16);  slice_24632 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2985, 1, 5968, 5984)
        slice_scatter_default_2986: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1493, slice_24633, 2, 0, 16);  slice_tensor_1493 = slice_24633 = None
        slice_scatter_default_2987: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2985, slice_scatter_default_2986, 1, 5968, 5984);  slice_scatter_default_2985 = slice_scatter_default_2986 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24653: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24619, 2, 16, 32);  slice_24619 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_750: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24653, memory_format = torch.contiguous_format);  slice_24653 = None
        view_1504: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_750, [32, 11]);  clone_750 = None
        mm_747: "f32[32, 8]" = torch.ops.aten.mm.default(view_1504, slice_37)
        view_1505: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_747, [2, 16, 8]);  mm_747 = None
        slice_24660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2987, 1, 5968, 5984)
        slice_24661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24660, 2, 0, 16);  slice_24660 = None
        add_749: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24661, view_1505);  slice_24661 = view_1505 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2987, 1, 5968, 5984)
        slice_scatter_default_2988: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1494, add_749, 2, 0, 16);  slice_tensor_1494 = add_749 = None
        slice_scatter_default_2989: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2987, slice_scatter_default_2988, 1, 5968, 5984);  slice_scatter_default_2987 = slice_scatter_default_2988 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2989, 1, 5968, 5984)
        slice_24666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24665, 2, 0, 16);  slice_24665 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2989, 1, 5968, 5984)
        slice_scatter_default_2990: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1495, slice_24666, 2, 0, 16);  slice_tensor_1495 = slice_24666 = None
        slice_scatter_default_2991: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2989, slice_scatter_default_2990, 1, 5968, 5984);  slice_scatter_default_2989 = slice_scatter_default_2990 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24685: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 5984, 6000)
        slice_24686: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24685, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_751: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24686, memory_format = torch.contiguous_format);  slice_24686 = None
        view_1506: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_751, [32, 16]);  clone_751 = None
        mm_748: "f32[32, 8]" = torch.ops.aten.mm.default(view_1506, slice_7)
        view_1507: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_748, [2, 16, 8]);  mm_748 = None
        slice_24693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2991, 1, 5984, 6000)
        slice_24694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24693, 2, 0, 16);  slice_24693 = None
        add_750: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24694, view_1507);  slice_24694 = view_1507 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2991, 1, 5984, 6000)
        slice_scatter_default_2992: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1496, add_750, 2, 0, 16);  slice_tensor_1496 = add_750 = None
        slice_scatter_default_2993: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2991, slice_scatter_default_2992, 1, 5984, 6000);  slice_scatter_default_2991 = slice_scatter_default_2992 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2993, 1, 5984, 6000)
        slice_24699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24698, 2, 0, 16);  slice_24698 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2993, 1, 5984, 6000)
        slice_scatter_default_2994: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1497, slice_24699, 2, 0, 16);  slice_tensor_1497 = slice_24699 = None
        slice_scatter_default_2995: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2993, slice_scatter_default_2994, 1, 5984, 6000);  slice_scatter_default_2993 = slice_scatter_default_2994 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24719: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24685, 2, 16, 32);  slice_24685 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_752: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24719, memory_format = torch.contiguous_format);  slice_24719 = None
        view_1508: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_752, [32, 11]);  clone_752 = None
        mm_749: "f32[32, 8]" = torch.ops.aten.mm.default(view_1508, slice_37)
        view_1509: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_749, [2, 16, 8]);  mm_749 = None
        slice_24726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2995, 1, 5984, 6000)
        slice_24727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24726, 2, 0, 16);  slice_24726 = None
        add_751: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24727, view_1509);  slice_24727 = view_1509 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2995, 1, 5984, 6000)
        slice_scatter_default_2996: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1498, add_751, 2, 0, 16);  slice_tensor_1498 = add_751 = None
        slice_scatter_default_2997: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2995, slice_scatter_default_2996, 1, 5984, 6000);  slice_scatter_default_2995 = slice_scatter_default_2996 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2997, 1, 5984, 6000)
        slice_24732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24731, 2, 0, 16);  slice_24731 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2997, 1, 5984, 6000)
        slice_scatter_default_2998: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1499, slice_24732, 2, 0, 16);  slice_tensor_1499 = slice_24732 = None
        slice_scatter_default_2999: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2997, slice_scatter_default_2998, 1, 5984, 6000);  slice_scatter_default_2997 = slice_scatter_default_2998 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24751: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6000, 6016)
        slice_24752: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24751, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_753: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24752, memory_format = torch.contiguous_format);  slice_24752 = None
        view_1510: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_753, [32, 16]);  clone_753 = None
        mm_750: "f32[32, 8]" = torch.ops.aten.mm.default(view_1510, slice_7)
        view_1511: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_750, [2, 16, 8]);  mm_750 = None
        slice_24759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2999, 1, 6000, 6016)
        slice_24760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24759, 2, 0, 16);  slice_24759 = None
        add_752: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24760, view_1511);  slice_24760 = view_1511 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_2999, 1, 6000, 6016)
        slice_scatter_default_3000: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1500, add_752, 2, 0, 16);  slice_tensor_1500 = add_752 = None
        slice_scatter_default_3001: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_2999, slice_scatter_default_3000, 1, 6000, 6016);  slice_scatter_default_2999 = slice_scatter_default_3000 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3001, 1, 6000, 6016)
        slice_24765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24764, 2, 0, 16);  slice_24764 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3001, 1, 6000, 6016)
        slice_scatter_default_3002: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1501, slice_24765, 2, 0, 16);  slice_tensor_1501 = slice_24765 = None
        slice_scatter_default_3003: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3001, slice_scatter_default_3002, 1, 6000, 6016);  slice_scatter_default_3001 = slice_scatter_default_3002 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24785: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24751, 2, 16, 32);  slice_24751 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_754: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24785, memory_format = torch.contiguous_format);  slice_24785 = None
        view_1512: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_754, [32, 11]);  clone_754 = None
        mm_751: "f32[32, 8]" = torch.ops.aten.mm.default(view_1512, slice_37)
        view_1513: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_751, [2, 16, 8]);  mm_751 = None
        slice_24792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3003, 1, 6000, 6016)
        slice_24793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24792, 2, 0, 16);  slice_24792 = None
        add_753: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24793, view_1513);  slice_24793 = view_1513 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3003, 1, 6000, 6016)
        slice_scatter_default_3004: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1502, add_753, 2, 0, 16);  slice_tensor_1502 = add_753 = None
        slice_scatter_default_3005: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3003, slice_scatter_default_3004, 1, 6000, 6016);  slice_scatter_default_3003 = slice_scatter_default_3004 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3005, 1, 6000, 6016)
        slice_24798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24797, 2, 0, 16);  slice_24797 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3005, 1, 6000, 6016)
        slice_scatter_default_3006: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1503, slice_24798, 2, 0, 16);  slice_tensor_1503 = slice_24798 = None
        slice_scatter_default_3007: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3005, slice_scatter_default_3006, 1, 6000, 6016);  slice_scatter_default_3005 = slice_scatter_default_3006 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24817: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6016, 6032)
        slice_24818: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24817, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_755: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24818, memory_format = torch.contiguous_format);  slice_24818 = None
        view_1514: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_755, [32, 16]);  clone_755 = None
        mm_752: "f32[32, 8]" = torch.ops.aten.mm.default(view_1514, slice_7)
        view_1515: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_752, [2, 16, 8]);  mm_752 = None
        slice_24825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3007, 1, 6016, 6032)
        slice_24826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24825, 2, 0, 16);  slice_24825 = None
        add_754: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24826, view_1515);  slice_24826 = view_1515 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3007, 1, 6016, 6032)
        slice_scatter_default_3008: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1504, add_754, 2, 0, 16);  slice_tensor_1504 = add_754 = None
        slice_scatter_default_3009: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3007, slice_scatter_default_3008, 1, 6016, 6032);  slice_scatter_default_3007 = slice_scatter_default_3008 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3009, 1, 6016, 6032)
        slice_24831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24830, 2, 0, 16);  slice_24830 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3009, 1, 6016, 6032)
        slice_scatter_default_3010: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1505, slice_24831, 2, 0, 16);  slice_tensor_1505 = slice_24831 = None
        slice_scatter_default_3011: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3009, slice_scatter_default_3010, 1, 6016, 6032);  slice_scatter_default_3009 = slice_scatter_default_3010 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24851: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24817, 2, 16, 32);  slice_24817 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_756: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24851, memory_format = torch.contiguous_format);  slice_24851 = None
        view_1516: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_756, [32, 11]);  clone_756 = None
        mm_753: "f32[32, 8]" = torch.ops.aten.mm.default(view_1516, slice_37)
        view_1517: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_753, [2, 16, 8]);  mm_753 = None
        slice_24858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3011, 1, 6016, 6032)
        slice_24859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24858, 2, 0, 16);  slice_24858 = None
        add_755: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24859, view_1517);  slice_24859 = view_1517 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3011, 1, 6016, 6032)
        slice_scatter_default_3012: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1506, add_755, 2, 0, 16);  slice_tensor_1506 = add_755 = None
        slice_scatter_default_3013: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3011, slice_scatter_default_3012, 1, 6016, 6032);  slice_scatter_default_3011 = slice_scatter_default_3012 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3013, 1, 6016, 6032)
        slice_24864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24863, 2, 0, 16);  slice_24863 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3013, 1, 6016, 6032)
        slice_scatter_default_3014: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1507, slice_24864, 2, 0, 16);  slice_tensor_1507 = slice_24864 = None
        slice_scatter_default_3015: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3013, slice_scatter_default_3014, 1, 6016, 6032);  slice_scatter_default_3013 = slice_scatter_default_3014 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24883: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6032, 6048)
        slice_24884: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24883, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_757: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24884, memory_format = torch.contiguous_format);  slice_24884 = None
        view_1518: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_757, [32, 16]);  clone_757 = None
        mm_754: "f32[32, 8]" = torch.ops.aten.mm.default(view_1518, slice_7)
        view_1519: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_754, [2, 16, 8]);  mm_754 = None
        slice_24891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3015, 1, 6032, 6048)
        slice_24892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24891, 2, 0, 16);  slice_24891 = None
        add_756: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24892, view_1519);  slice_24892 = view_1519 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3015, 1, 6032, 6048)
        slice_scatter_default_3016: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1508, add_756, 2, 0, 16);  slice_tensor_1508 = add_756 = None
        slice_scatter_default_3017: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3015, slice_scatter_default_3016, 1, 6032, 6048);  slice_scatter_default_3015 = slice_scatter_default_3016 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3017, 1, 6032, 6048)
        slice_24897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24896, 2, 0, 16);  slice_24896 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3017, 1, 6032, 6048)
        slice_scatter_default_3018: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1509, slice_24897, 2, 0, 16);  slice_tensor_1509 = slice_24897 = None
        slice_scatter_default_3019: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3017, slice_scatter_default_3018, 1, 6032, 6048);  slice_scatter_default_3017 = slice_scatter_default_3018 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24917: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24883, 2, 16, 32);  slice_24883 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_758: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24917, memory_format = torch.contiguous_format);  slice_24917 = None
        view_1520: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_758, [32, 11]);  clone_758 = None
        mm_755: "f32[32, 8]" = torch.ops.aten.mm.default(view_1520, slice_37)
        view_1521: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_755, [2, 16, 8]);  mm_755 = None
        slice_24924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3019, 1, 6032, 6048)
        slice_24925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24924, 2, 0, 16);  slice_24924 = None
        add_757: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24925, view_1521);  slice_24925 = view_1521 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3019, 1, 6032, 6048)
        slice_scatter_default_3020: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1510, add_757, 2, 0, 16);  slice_tensor_1510 = add_757 = None
        slice_scatter_default_3021: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3019, slice_scatter_default_3020, 1, 6032, 6048);  slice_scatter_default_3019 = slice_scatter_default_3020 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3021, 1, 6032, 6048)
        slice_24930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24929, 2, 0, 16);  slice_24929 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3021, 1, 6032, 6048)
        slice_scatter_default_3022: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1511, slice_24930, 2, 0, 16);  slice_tensor_1511 = slice_24930 = None
        slice_scatter_default_3023: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3021, slice_scatter_default_3022, 1, 6032, 6048);  slice_scatter_default_3021 = slice_scatter_default_3022 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24949: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6048, 6064)
        slice_24950: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_24949, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_759: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_24950, memory_format = torch.contiguous_format);  slice_24950 = None
        view_1522: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_759, [32, 16]);  clone_759 = None
        mm_756: "f32[32, 8]" = torch.ops.aten.mm.default(view_1522, slice_7)
        view_1523: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_756, [2, 16, 8]);  mm_756 = None
        slice_24957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3023, 1, 6048, 6064)
        slice_24958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24957, 2, 0, 16);  slice_24957 = None
        add_758: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24958, view_1523);  slice_24958 = view_1523 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3023, 1, 6048, 6064)
        slice_scatter_default_3024: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1512, add_758, 2, 0, 16);  slice_tensor_1512 = add_758 = None
        slice_scatter_default_3025: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3023, slice_scatter_default_3024, 1, 6048, 6064);  slice_scatter_default_3023 = slice_scatter_default_3024 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3025, 1, 6048, 6064)
        slice_24963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24962, 2, 0, 16);  slice_24962 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3025, 1, 6048, 6064)
        slice_scatter_default_3026: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1513, slice_24963, 2, 0, 16);  slice_tensor_1513 = slice_24963 = None
        slice_scatter_default_3027: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3025, slice_scatter_default_3026, 1, 6048, 6064);  slice_scatter_default_3025 = slice_scatter_default_3026 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_24983: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_24949, 2, 16, 32);  slice_24949 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_760: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_24983, memory_format = torch.contiguous_format);  slice_24983 = None
        view_1524: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_760, [32, 11]);  clone_760 = None
        mm_757: "f32[32, 8]" = torch.ops.aten.mm.default(view_1524, slice_37)
        view_1525: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_757, [2, 16, 8]);  mm_757 = None
        slice_24990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3027, 1, 6048, 6064)
        slice_24991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24990, 2, 0, 16);  slice_24990 = None
        add_759: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_24991, view_1525);  slice_24991 = view_1525 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3027, 1, 6048, 6064)
        slice_scatter_default_3028: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1514, add_759, 2, 0, 16);  slice_tensor_1514 = add_759 = None
        slice_scatter_default_3029: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3027, slice_scatter_default_3028, 1, 6048, 6064);  slice_scatter_default_3027 = slice_scatter_default_3028 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_24995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3029, 1, 6048, 6064)
        slice_24996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_24995, 2, 0, 16);  slice_24995 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3029, 1, 6048, 6064)
        slice_scatter_default_3030: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1515, slice_24996, 2, 0, 16);  slice_tensor_1515 = slice_24996 = None
        slice_scatter_default_3031: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3029, slice_scatter_default_3030, 1, 6048, 6064);  slice_scatter_default_3029 = slice_scatter_default_3030 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25015: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6064, 6080)
        slice_25016: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25015, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_761: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25016, memory_format = torch.contiguous_format);  slice_25016 = None
        view_1526: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_761, [32, 16]);  clone_761 = None
        mm_758: "f32[32, 8]" = torch.ops.aten.mm.default(view_1526, slice_7)
        view_1527: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_758, [2, 16, 8]);  mm_758 = None
        slice_25023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3031, 1, 6064, 6080)
        slice_25024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25023, 2, 0, 16);  slice_25023 = None
        add_760: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25024, view_1527);  slice_25024 = view_1527 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3031, 1, 6064, 6080)
        slice_scatter_default_3032: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1516, add_760, 2, 0, 16);  slice_tensor_1516 = add_760 = None
        slice_scatter_default_3033: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3031, slice_scatter_default_3032, 1, 6064, 6080);  slice_scatter_default_3031 = slice_scatter_default_3032 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3033, 1, 6064, 6080)
        slice_25029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25028, 2, 0, 16);  slice_25028 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3033, 1, 6064, 6080)
        slice_scatter_default_3034: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1517, slice_25029, 2, 0, 16);  slice_tensor_1517 = slice_25029 = None
        slice_scatter_default_3035: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3033, slice_scatter_default_3034, 1, 6064, 6080);  slice_scatter_default_3033 = slice_scatter_default_3034 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25049: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25015, 2, 16, 32);  slice_25015 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_762: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25049, memory_format = torch.contiguous_format);  slice_25049 = None
        view_1528: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_762, [32, 11]);  clone_762 = None
        mm_759: "f32[32, 8]" = torch.ops.aten.mm.default(view_1528, slice_37)
        view_1529: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_759, [2, 16, 8]);  mm_759 = None
        slice_25056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3035, 1, 6064, 6080)
        slice_25057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25056, 2, 0, 16);  slice_25056 = None
        add_761: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25057, view_1529);  slice_25057 = view_1529 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3035, 1, 6064, 6080)
        slice_scatter_default_3036: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1518, add_761, 2, 0, 16);  slice_tensor_1518 = add_761 = None
        slice_scatter_default_3037: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3035, slice_scatter_default_3036, 1, 6064, 6080);  slice_scatter_default_3035 = slice_scatter_default_3036 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3037, 1, 6064, 6080)
        slice_25062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25061, 2, 0, 16);  slice_25061 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3037, 1, 6064, 6080)
        slice_scatter_default_3038: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1519, slice_25062, 2, 0, 16);  slice_tensor_1519 = slice_25062 = None
        slice_scatter_default_3039: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3037, slice_scatter_default_3038, 1, 6064, 6080);  slice_scatter_default_3037 = slice_scatter_default_3038 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25081: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6080, 6096)
        slice_25082: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25081, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_763: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25082, memory_format = torch.contiguous_format);  slice_25082 = None
        view_1530: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_763, [32, 16]);  clone_763 = None
        mm_760: "f32[32, 8]" = torch.ops.aten.mm.default(view_1530, slice_7)
        view_1531: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_760, [2, 16, 8]);  mm_760 = None
        slice_25089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3039, 1, 6080, 6096)
        slice_25090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25089, 2, 0, 16);  slice_25089 = None
        add_762: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25090, view_1531);  slice_25090 = view_1531 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3039, 1, 6080, 6096)
        slice_scatter_default_3040: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1520, add_762, 2, 0, 16);  slice_tensor_1520 = add_762 = None
        slice_scatter_default_3041: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3039, slice_scatter_default_3040, 1, 6080, 6096);  slice_scatter_default_3039 = slice_scatter_default_3040 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3041, 1, 6080, 6096)
        slice_25095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25094, 2, 0, 16);  slice_25094 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3041, 1, 6080, 6096)
        slice_scatter_default_3042: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1521, slice_25095, 2, 0, 16);  slice_tensor_1521 = slice_25095 = None
        slice_scatter_default_3043: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3041, slice_scatter_default_3042, 1, 6080, 6096);  slice_scatter_default_3041 = slice_scatter_default_3042 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25115: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25081, 2, 16, 32);  slice_25081 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_764: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25115, memory_format = torch.contiguous_format);  slice_25115 = None
        view_1532: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_764, [32, 11]);  clone_764 = None
        mm_761: "f32[32, 8]" = torch.ops.aten.mm.default(view_1532, slice_37)
        view_1533: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_761, [2, 16, 8]);  mm_761 = None
        slice_25122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3043, 1, 6080, 6096)
        slice_25123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25122, 2, 0, 16);  slice_25122 = None
        add_763: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25123, view_1533);  slice_25123 = view_1533 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3043, 1, 6080, 6096)
        slice_scatter_default_3044: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1522, add_763, 2, 0, 16);  slice_tensor_1522 = add_763 = None
        slice_scatter_default_3045: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3043, slice_scatter_default_3044, 1, 6080, 6096);  slice_scatter_default_3043 = slice_scatter_default_3044 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3045, 1, 6080, 6096)
        slice_25128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25127, 2, 0, 16);  slice_25127 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3045, 1, 6080, 6096)
        slice_scatter_default_3046: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1523, slice_25128, 2, 0, 16);  slice_tensor_1523 = slice_25128 = None
        slice_scatter_default_3047: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3045, slice_scatter_default_3046, 1, 6080, 6096);  slice_scatter_default_3045 = slice_scatter_default_3046 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25147: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6096, 6112)
        slice_25148: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25147, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_765: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25148, memory_format = torch.contiguous_format);  slice_25148 = None
        view_1534: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_765, [32, 16]);  clone_765 = None
        mm_762: "f32[32, 8]" = torch.ops.aten.mm.default(view_1534, slice_7)
        view_1535: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_762, [2, 16, 8]);  mm_762 = None
        slice_25155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3047, 1, 6096, 6112)
        slice_25156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25155, 2, 0, 16);  slice_25155 = None
        add_764: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25156, view_1535);  slice_25156 = view_1535 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3047, 1, 6096, 6112)
        slice_scatter_default_3048: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1524, add_764, 2, 0, 16);  slice_tensor_1524 = add_764 = None
        slice_scatter_default_3049: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3047, slice_scatter_default_3048, 1, 6096, 6112);  slice_scatter_default_3047 = slice_scatter_default_3048 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3049, 1, 6096, 6112)
        slice_25161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25160, 2, 0, 16);  slice_25160 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3049, 1, 6096, 6112)
        slice_scatter_default_3050: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1525, slice_25161, 2, 0, 16);  slice_tensor_1525 = slice_25161 = None
        slice_scatter_default_3051: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3049, slice_scatter_default_3050, 1, 6096, 6112);  slice_scatter_default_3049 = slice_scatter_default_3050 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25181: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25147, 2, 16, 32);  slice_25147 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_766: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25181, memory_format = torch.contiguous_format);  slice_25181 = None
        view_1536: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_766, [32, 11]);  clone_766 = None
        mm_763: "f32[32, 8]" = torch.ops.aten.mm.default(view_1536, slice_37)
        view_1537: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_763, [2, 16, 8]);  mm_763 = None
        slice_25188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3051, 1, 6096, 6112)
        slice_25189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25188, 2, 0, 16);  slice_25188 = None
        add_765: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25189, view_1537);  slice_25189 = view_1537 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3051, 1, 6096, 6112)
        slice_scatter_default_3052: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1526, add_765, 2, 0, 16);  slice_tensor_1526 = add_765 = None
        slice_scatter_default_3053: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3051, slice_scatter_default_3052, 1, 6096, 6112);  slice_scatter_default_3051 = slice_scatter_default_3052 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3053, 1, 6096, 6112)
        slice_25194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25193, 2, 0, 16);  slice_25193 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3053, 1, 6096, 6112)
        slice_scatter_default_3054: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1527, slice_25194, 2, 0, 16);  slice_tensor_1527 = slice_25194 = None
        slice_scatter_default_3055: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3053, slice_scatter_default_3054, 1, 6096, 6112);  slice_scatter_default_3053 = slice_scatter_default_3054 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25213: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6112, 6128)
        slice_25214: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25213, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_767: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25214, memory_format = torch.contiguous_format);  slice_25214 = None
        view_1538: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_767, [32, 16]);  clone_767 = None
        mm_764: "f32[32, 8]" = torch.ops.aten.mm.default(view_1538, slice_7)
        view_1539: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_764, [2, 16, 8]);  mm_764 = None
        slice_25221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3055, 1, 6112, 6128)
        slice_25222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25221, 2, 0, 16);  slice_25221 = None
        add_766: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25222, view_1539);  slice_25222 = view_1539 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3055, 1, 6112, 6128)
        slice_scatter_default_3056: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1528, add_766, 2, 0, 16);  slice_tensor_1528 = add_766 = None
        slice_scatter_default_3057: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3055, slice_scatter_default_3056, 1, 6112, 6128);  slice_scatter_default_3055 = slice_scatter_default_3056 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3057, 1, 6112, 6128)
        slice_25227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25226, 2, 0, 16);  slice_25226 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3057, 1, 6112, 6128)
        slice_scatter_default_3058: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1529, slice_25227, 2, 0, 16);  slice_tensor_1529 = slice_25227 = None
        slice_scatter_default_3059: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3057, slice_scatter_default_3058, 1, 6112, 6128);  slice_scatter_default_3057 = slice_scatter_default_3058 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25247: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25213, 2, 16, 32);  slice_25213 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_768: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25247, memory_format = torch.contiguous_format);  slice_25247 = None
        view_1540: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_768, [32, 11]);  clone_768 = None
        mm_765: "f32[32, 8]" = torch.ops.aten.mm.default(view_1540, slice_37)
        view_1541: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_765, [2, 16, 8]);  mm_765 = None
        slice_25254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3059, 1, 6112, 6128)
        slice_25255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25254, 2, 0, 16);  slice_25254 = None
        add_767: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25255, view_1541);  slice_25255 = view_1541 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3059, 1, 6112, 6128)
        slice_scatter_default_3060: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1530, add_767, 2, 0, 16);  slice_tensor_1530 = add_767 = None
        slice_scatter_default_3061: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3059, slice_scatter_default_3060, 1, 6112, 6128);  slice_scatter_default_3059 = slice_scatter_default_3060 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3061, 1, 6112, 6128)
        slice_25260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25259, 2, 0, 16);  slice_25259 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3061, 1, 6112, 6128)
        slice_scatter_default_3062: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1531, slice_25260, 2, 0, 16);  slice_tensor_1531 = slice_25260 = None
        slice_scatter_default_3063: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3061, slice_scatter_default_3062, 1, 6112, 6128);  slice_scatter_default_3061 = slice_scatter_default_3062 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25279: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6128, 6144)
        slice_25280: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25279, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_769: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25280, memory_format = torch.contiguous_format);  slice_25280 = None
        view_1542: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_769, [32, 16]);  clone_769 = None
        mm_766: "f32[32, 8]" = torch.ops.aten.mm.default(view_1542, slice_7)
        view_1543: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_766, [2, 16, 8]);  mm_766 = None
        slice_25287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3063, 1, 6128, 6144)
        slice_25288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25287, 2, 0, 16);  slice_25287 = None
        add_768: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25288, view_1543);  slice_25288 = view_1543 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3063, 1, 6128, 6144)
        slice_scatter_default_3064: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1532, add_768, 2, 0, 16);  slice_tensor_1532 = add_768 = None
        slice_scatter_default_3065: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3063, slice_scatter_default_3064, 1, 6128, 6144);  slice_scatter_default_3063 = slice_scatter_default_3064 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3065, 1, 6128, 6144)
        slice_25293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25292, 2, 0, 16);  slice_25292 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3065, 1, 6128, 6144)
        slice_scatter_default_3066: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1533, slice_25293, 2, 0, 16);  slice_tensor_1533 = slice_25293 = None
        slice_scatter_default_3067: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3065, slice_scatter_default_3066, 1, 6128, 6144);  slice_scatter_default_3065 = slice_scatter_default_3066 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25313: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25279, 2, 16, 32);  slice_25279 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_770: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25313, memory_format = torch.contiguous_format);  slice_25313 = None
        view_1544: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_770, [32, 11]);  clone_770 = None
        mm_767: "f32[32, 8]" = torch.ops.aten.mm.default(view_1544, slice_37)
        view_1545: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_767, [2, 16, 8]);  mm_767 = None
        slice_25320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3067, 1, 6128, 6144)
        slice_25321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25320, 2, 0, 16);  slice_25320 = None
        add_769: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25321, view_1545);  slice_25321 = view_1545 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3067, 1, 6128, 6144)
        slice_scatter_default_3068: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1534, add_769, 2, 0, 16);  slice_tensor_1534 = add_769 = None
        slice_scatter_default_3069: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3067, slice_scatter_default_3068, 1, 6128, 6144);  slice_scatter_default_3067 = slice_scatter_default_3068 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3069, 1, 6128, 6144)
        slice_25326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25325, 2, 0, 16);  slice_25325 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3069, 1, 6128, 6144)
        slice_scatter_default_3070: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1535, slice_25326, 2, 0, 16);  slice_tensor_1535 = slice_25326 = None
        slice_scatter_default_3071: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3069, slice_scatter_default_3070, 1, 6128, 6144);  slice_scatter_default_3069 = slice_scatter_default_3070 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25345: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6144, 6160)
        slice_25346: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25345, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_771: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25346, memory_format = torch.contiguous_format);  slice_25346 = None
        view_1546: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_771, [32, 16]);  clone_771 = None
        mm_768: "f32[32, 8]" = torch.ops.aten.mm.default(view_1546, slice_7)
        view_1547: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_768, [2, 16, 8]);  mm_768 = None
        slice_25353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3071, 1, 6144, 6160)
        slice_25354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25353, 2, 0, 16);  slice_25353 = None
        add_770: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25354, view_1547);  slice_25354 = view_1547 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3071, 1, 6144, 6160)
        slice_scatter_default_3072: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1536, add_770, 2, 0, 16);  slice_tensor_1536 = add_770 = None
        slice_scatter_default_3073: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3071, slice_scatter_default_3072, 1, 6144, 6160);  slice_scatter_default_3071 = slice_scatter_default_3072 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3073, 1, 6144, 6160)
        slice_25359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25358, 2, 0, 16);  slice_25358 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3073, 1, 6144, 6160)
        slice_scatter_default_3074: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1537, slice_25359, 2, 0, 16);  slice_tensor_1537 = slice_25359 = None
        slice_scatter_default_3075: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3073, slice_scatter_default_3074, 1, 6144, 6160);  slice_scatter_default_3073 = slice_scatter_default_3074 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25379: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25345, 2, 16, 32);  slice_25345 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_772: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25379, memory_format = torch.contiguous_format);  slice_25379 = None
        view_1548: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_772, [32, 11]);  clone_772 = None
        mm_769: "f32[32, 8]" = torch.ops.aten.mm.default(view_1548, slice_37)
        view_1549: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_769, [2, 16, 8]);  mm_769 = None
        slice_25386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3075, 1, 6144, 6160)
        slice_25387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25386, 2, 0, 16);  slice_25386 = None
        add_771: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25387, view_1549);  slice_25387 = view_1549 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3075, 1, 6144, 6160)
        slice_scatter_default_3076: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1538, add_771, 2, 0, 16);  slice_tensor_1538 = add_771 = None
        slice_scatter_default_3077: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3075, slice_scatter_default_3076, 1, 6144, 6160);  slice_scatter_default_3075 = slice_scatter_default_3076 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3077, 1, 6144, 6160)
        slice_25392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25391, 2, 0, 16);  slice_25391 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3077, 1, 6144, 6160)
        slice_scatter_default_3078: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1539, slice_25392, 2, 0, 16);  slice_tensor_1539 = slice_25392 = None
        slice_scatter_default_3079: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3077, slice_scatter_default_3078, 1, 6144, 6160);  slice_scatter_default_3077 = slice_scatter_default_3078 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25411: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6160, 6176)
        slice_25412: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25411, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_773: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25412, memory_format = torch.contiguous_format);  slice_25412 = None
        view_1550: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_773, [32, 16]);  clone_773 = None
        mm_770: "f32[32, 8]" = torch.ops.aten.mm.default(view_1550, slice_7)
        view_1551: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_770, [2, 16, 8]);  mm_770 = None
        slice_25419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3079, 1, 6160, 6176)
        slice_25420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25419, 2, 0, 16);  slice_25419 = None
        add_772: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25420, view_1551);  slice_25420 = view_1551 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3079, 1, 6160, 6176)
        slice_scatter_default_3080: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1540, add_772, 2, 0, 16);  slice_tensor_1540 = add_772 = None
        slice_scatter_default_3081: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3079, slice_scatter_default_3080, 1, 6160, 6176);  slice_scatter_default_3079 = slice_scatter_default_3080 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3081, 1, 6160, 6176)
        slice_25425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25424, 2, 0, 16);  slice_25424 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3081, 1, 6160, 6176)
        slice_scatter_default_3082: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1541, slice_25425, 2, 0, 16);  slice_tensor_1541 = slice_25425 = None
        slice_scatter_default_3083: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3081, slice_scatter_default_3082, 1, 6160, 6176);  slice_scatter_default_3081 = slice_scatter_default_3082 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25445: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25411, 2, 16, 32);  slice_25411 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_774: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25445, memory_format = torch.contiguous_format);  slice_25445 = None
        view_1552: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_774, [32, 11]);  clone_774 = None
        mm_771: "f32[32, 8]" = torch.ops.aten.mm.default(view_1552, slice_37)
        view_1553: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_771, [2, 16, 8]);  mm_771 = None
        slice_25452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3083, 1, 6160, 6176)
        slice_25453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25452, 2, 0, 16);  slice_25452 = None
        add_773: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25453, view_1553);  slice_25453 = view_1553 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3083, 1, 6160, 6176)
        slice_scatter_default_3084: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1542, add_773, 2, 0, 16);  slice_tensor_1542 = add_773 = None
        slice_scatter_default_3085: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3083, slice_scatter_default_3084, 1, 6160, 6176);  slice_scatter_default_3083 = slice_scatter_default_3084 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3085, 1, 6160, 6176)
        slice_25458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25457, 2, 0, 16);  slice_25457 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3085, 1, 6160, 6176)
        slice_scatter_default_3086: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1543, slice_25458, 2, 0, 16);  slice_tensor_1543 = slice_25458 = None
        slice_scatter_default_3087: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3085, slice_scatter_default_3086, 1, 6160, 6176);  slice_scatter_default_3085 = slice_scatter_default_3086 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25477: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6176, 6192)
        slice_25478: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25477, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_775: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25478, memory_format = torch.contiguous_format);  slice_25478 = None
        view_1554: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_775, [32, 16]);  clone_775 = None
        mm_772: "f32[32, 8]" = torch.ops.aten.mm.default(view_1554, slice_7)
        view_1555: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_772, [2, 16, 8]);  mm_772 = None
        slice_25485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3087, 1, 6176, 6192)
        slice_25486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25485, 2, 0, 16);  slice_25485 = None
        add_774: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25486, view_1555);  slice_25486 = view_1555 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3087, 1, 6176, 6192)
        slice_scatter_default_3088: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1544, add_774, 2, 0, 16);  slice_tensor_1544 = add_774 = None
        slice_scatter_default_3089: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3087, slice_scatter_default_3088, 1, 6176, 6192);  slice_scatter_default_3087 = slice_scatter_default_3088 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3089, 1, 6176, 6192)
        slice_25491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25490, 2, 0, 16);  slice_25490 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3089, 1, 6176, 6192)
        slice_scatter_default_3090: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1545, slice_25491, 2, 0, 16);  slice_tensor_1545 = slice_25491 = None
        slice_scatter_default_3091: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3089, slice_scatter_default_3090, 1, 6176, 6192);  slice_scatter_default_3089 = slice_scatter_default_3090 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25511: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25477, 2, 16, 32);  slice_25477 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_776: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25511, memory_format = torch.contiguous_format);  slice_25511 = None
        view_1556: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_776, [32, 11]);  clone_776 = None
        mm_773: "f32[32, 8]" = torch.ops.aten.mm.default(view_1556, slice_37)
        view_1557: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_773, [2, 16, 8]);  mm_773 = None
        slice_25518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3091, 1, 6176, 6192)
        slice_25519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25518, 2, 0, 16);  slice_25518 = None
        add_775: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25519, view_1557);  slice_25519 = view_1557 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3091, 1, 6176, 6192)
        slice_scatter_default_3092: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1546, add_775, 2, 0, 16);  slice_tensor_1546 = add_775 = None
        slice_scatter_default_3093: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3091, slice_scatter_default_3092, 1, 6176, 6192);  slice_scatter_default_3091 = slice_scatter_default_3092 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3093, 1, 6176, 6192)
        slice_25524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25523, 2, 0, 16);  slice_25523 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3093, 1, 6176, 6192)
        slice_scatter_default_3094: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1547, slice_25524, 2, 0, 16);  slice_tensor_1547 = slice_25524 = None
        slice_scatter_default_3095: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3093, slice_scatter_default_3094, 1, 6176, 6192);  slice_scatter_default_3093 = slice_scatter_default_3094 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25543: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6192, 6208)
        slice_25544: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25543, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_777: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25544, memory_format = torch.contiguous_format);  slice_25544 = None
        view_1558: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_777, [32, 16]);  clone_777 = None
        mm_774: "f32[32, 8]" = torch.ops.aten.mm.default(view_1558, slice_7)
        view_1559: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_774, [2, 16, 8]);  mm_774 = None
        slice_25551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3095, 1, 6192, 6208)
        slice_25552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25551, 2, 0, 16);  slice_25551 = None
        add_776: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25552, view_1559);  slice_25552 = view_1559 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3095, 1, 6192, 6208)
        slice_scatter_default_3096: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1548, add_776, 2, 0, 16);  slice_tensor_1548 = add_776 = None
        slice_scatter_default_3097: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3095, slice_scatter_default_3096, 1, 6192, 6208);  slice_scatter_default_3095 = slice_scatter_default_3096 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3097, 1, 6192, 6208)
        slice_25557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25556, 2, 0, 16);  slice_25556 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3097, 1, 6192, 6208)
        slice_scatter_default_3098: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1549, slice_25557, 2, 0, 16);  slice_tensor_1549 = slice_25557 = None
        slice_scatter_default_3099: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3097, slice_scatter_default_3098, 1, 6192, 6208);  slice_scatter_default_3097 = slice_scatter_default_3098 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25577: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25543, 2, 16, 32);  slice_25543 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_778: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25577, memory_format = torch.contiguous_format);  slice_25577 = None
        view_1560: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_778, [32, 11]);  clone_778 = None
        mm_775: "f32[32, 8]" = torch.ops.aten.mm.default(view_1560, slice_37)
        view_1561: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_775, [2, 16, 8]);  mm_775 = None
        slice_25584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3099, 1, 6192, 6208)
        slice_25585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25584, 2, 0, 16);  slice_25584 = None
        add_777: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25585, view_1561);  slice_25585 = view_1561 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3099, 1, 6192, 6208)
        slice_scatter_default_3100: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1550, add_777, 2, 0, 16);  slice_tensor_1550 = add_777 = None
        slice_scatter_default_3101: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3099, slice_scatter_default_3100, 1, 6192, 6208);  slice_scatter_default_3099 = slice_scatter_default_3100 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3101, 1, 6192, 6208)
        slice_25590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25589, 2, 0, 16);  slice_25589 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3101, 1, 6192, 6208)
        slice_scatter_default_3102: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1551, slice_25590, 2, 0, 16);  slice_tensor_1551 = slice_25590 = None
        slice_scatter_default_3103: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3101, slice_scatter_default_3102, 1, 6192, 6208);  slice_scatter_default_3101 = slice_scatter_default_3102 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25609: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6208, 6224)
        slice_25610: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25609, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_779: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25610, memory_format = torch.contiguous_format);  slice_25610 = None
        view_1562: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_779, [32, 16]);  clone_779 = None
        mm_776: "f32[32, 8]" = torch.ops.aten.mm.default(view_1562, slice_7)
        view_1563: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_776, [2, 16, 8]);  mm_776 = None
        slice_25617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3103, 1, 6208, 6224)
        slice_25618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25617, 2, 0, 16);  slice_25617 = None
        add_778: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25618, view_1563);  slice_25618 = view_1563 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3103, 1, 6208, 6224)
        slice_scatter_default_3104: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1552, add_778, 2, 0, 16);  slice_tensor_1552 = add_778 = None
        slice_scatter_default_3105: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3103, slice_scatter_default_3104, 1, 6208, 6224);  slice_scatter_default_3103 = slice_scatter_default_3104 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3105, 1, 6208, 6224)
        slice_25623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25622, 2, 0, 16);  slice_25622 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3105, 1, 6208, 6224)
        slice_scatter_default_3106: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1553, slice_25623, 2, 0, 16);  slice_tensor_1553 = slice_25623 = None
        slice_scatter_default_3107: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3105, slice_scatter_default_3106, 1, 6208, 6224);  slice_scatter_default_3105 = slice_scatter_default_3106 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25643: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25609, 2, 16, 32);  slice_25609 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_780: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25643, memory_format = torch.contiguous_format);  slice_25643 = None
        view_1564: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_780, [32, 11]);  clone_780 = None
        mm_777: "f32[32, 8]" = torch.ops.aten.mm.default(view_1564, slice_37)
        view_1565: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_777, [2, 16, 8]);  mm_777 = None
        slice_25650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3107, 1, 6208, 6224)
        slice_25651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25650, 2, 0, 16);  slice_25650 = None
        add_779: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25651, view_1565);  slice_25651 = view_1565 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3107, 1, 6208, 6224)
        slice_scatter_default_3108: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1554, add_779, 2, 0, 16);  slice_tensor_1554 = add_779 = None
        slice_scatter_default_3109: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3107, slice_scatter_default_3108, 1, 6208, 6224);  slice_scatter_default_3107 = slice_scatter_default_3108 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3109, 1, 6208, 6224)
        slice_25656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25655, 2, 0, 16);  slice_25655 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3109, 1, 6208, 6224)
        slice_scatter_default_3110: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1555, slice_25656, 2, 0, 16);  slice_tensor_1555 = slice_25656 = None
        slice_scatter_default_3111: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3109, slice_scatter_default_3110, 1, 6208, 6224);  slice_scatter_default_3109 = slice_scatter_default_3110 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25675: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6224, 6240)
        slice_25676: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25675, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_781: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25676, memory_format = torch.contiguous_format);  slice_25676 = None
        view_1566: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_781, [32, 16]);  clone_781 = None
        mm_778: "f32[32, 8]" = torch.ops.aten.mm.default(view_1566, slice_7)
        view_1567: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_778, [2, 16, 8]);  mm_778 = None
        slice_25683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3111, 1, 6224, 6240)
        slice_25684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25683, 2, 0, 16);  slice_25683 = None
        add_780: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25684, view_1567);  slice_25684 = view_1567 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3111, 1, 6224, 6240)
        slice_scatter_default_3112: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1556, add_780, 2, 0, 16);  slice_tensor_1556 = add_780 = None
        slice_scatter_default_3113: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3111, slice_scatter_default_3112, 1, 6224, 6240);  slice_scatter_default_3111 = slice_scatter_default_3112 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3113, 1, 6224, 6240)
        slice_25689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25688, 2, 0, 16);  slice_25688 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3113, 1, 6224, 6240)
        slice_scatter_default_3114: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1557, slice_25689, 2, 0, 16);  slice_tensor_1557 = slice_25689 = None
        slice_scatter_default_3115: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3113, slice_scatter_default_3114, 1, 6224, 6240);  slice_scatter_default_3113 = slice_scatter_default_3114 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25709: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25675, 2, 16, 32);  slice_25675 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_782: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25709, memory_format = torch.contiguous_format);  slice_25709 = None
        view_1568: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_782, [32, 11]);  clone_782 = None
        mm_779: "f32[32, 8]" = torch.ops.aten.mm.default(view_1568, slice_37)
        view_1569: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_779, [2, 16, 8]);  mm_779 = None
        slice_25716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3115, 1, 6224, 6240)
        slice_25717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25716, 2, 0, 16);  slice_25716 = None
        add_781: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25717, view_1569);  slice_25717 = view_1569 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3115, 1, 6224, 6240)
        slice_scatter_default_3116: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1558, add_781, 2, 0, 16);  slice_tensor_1558 = add_781 = None
        slice_scatter_default_3117: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3115, slice_scatter_default_3116, 1, 6224, 6240);  slice_scatter_default_3115 = slice_scatter_default_3116 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3117, 1, 6224, 6240)
        slice_25722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25721, 2, 0, 16);  slice_25721 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3117, 1, 6224, 6240)
        slice_scatter_default_3118: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1559, slice_25722, 2, 0, 16);  slice_tensor_1559 = slice_25722 = None
        slice_scatter_default_3119: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3117, slice_scatter_default_3118, 1, 6224, 6240);  slice_scatter_default_3117 = slice_scatter_default_3118 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25741: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6240, 6256)
        slice_25742: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25741, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_783: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25742, memory_format = torch.contiguous_format);  slice_25742 = None
        view_1570: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_783, [32, 16]);  clone_783 = None
        mm_780: "f32[32, 8]" = torch.ops.aten.mm.default(view_1570, slice_7)
        view_1571: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_780, [2, 16, 8]);  mm_780 = None
        slice_25749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3119, 1, 6240, 6256)
        slice_25750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25749, 2, 0, 16);  slice_25749 = None
        add_782: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25750, view_1571);  slice_25750 = view_1571 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3119, 1, 6240, 6256)
        slice_scatter_default_3120: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1560, add_782, 2, 0, 16);  slice_tensor_1560 = add_782 = None
        slice_scatter_default_3121: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3119, slice_scatter_default_3120, 1, 6240, 6256);  slice_scatter_default_3119 = slice_scatter_default_3120 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3121, 1, 6240, 6256)
        slice_25755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25754, 2, 0, 16);  slice_25754 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3121, 1, 6240, 6256)
        slice_scatter_default_3122: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1561, slice_25755, 2, 0, 16);  slice_tensor_1561 = slice_25755 = None
        slice_scatter_default_3123: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3121, slice_scatter_default_3122, 1, 6240, 6256);  slice_scatter_default_3121 = slice_scatter_default_3122 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25775: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25741, 2, 16, 32);  slice_25741 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_784: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25775, memory_format = torch.contiguous_format);  slice_25775 = None
        view_1572: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_784, [32, 11]);  clone_784 = None
        mm_781: "f32[32, 8]" = torch.ops.aten.mm.default(view_1572, slice_37)
        view_1573: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_781, [2, 16, 8]);  mm_781 = None
        slice_25782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3123, 1, 6240, 6256)
        slice_25783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25782, 2, 0, 16);  slice_25782 = None
        add_783: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25783, view_1573);  slice_25783 = view_1573 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3123, 1, 6240, 6256)
        slice_scatter_default_3124: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1562, add_783, 2, 0, 16);  slice_tensor_1562 = add_783 = None
        slice_scatter_default_3125: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3123, slice_scatter_default_3124, 1, 6240, 6256);  slice_scatter_default_3123 = slice_scatter_default_3124 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3125, 1, 6240, 6256)
        slice_25788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25787, 2, 0, 16);  slice_25787 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3125, 1, 6240, 6256)
        slice_scatter_default_3126: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1563, slice_25788, 2, 0, 16);  slice_tensor_1563 = slice_25788 = None
        slice_scatter_default_3127: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3125, slice_scatter_default_3126, 1, 6240, 6256);  slice_scatter_default_3125 = slice_scatter_default_3126 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25807: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6256, 6272)
        slice_25808: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25807, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_785: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25808, memory_format = torch.contiguous_format);  slice_25808 = None
        view_1574: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_785, [32, 16]);  clone_785 = None
        mm_782: "f32[32, 8]" = torch.ops.aten.mm.default(view_1574, slice_7)
        view_1575: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_782, [2, 16, 8]);  mm_782 = None
        slice_25815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3127, 1, 6256, 6272)
        slice_25816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25815, 2, 0, 16);  slice_25815 = None
        add_784: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25816, view_1575);  slice_25816 = view_1575 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3127, 1, 6256, 6272)
        slice_scatter_default_3128: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1564, add_784, 2, 0, 16);  slice_tensor_1564 = add_784 = None
        slice_scatter_default_3129: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3127, slice_scatter_default_3128, 1, 6256, 6272);  slice_scatter_default_3127 = slice_scatter_default_3128 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3129, 1, 6256, 6272)
        slice_25821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25820, 2, 0, 16);  slice_25820 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3129, 1, 6256, 6272)
        slice_scatter_default_3130: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1565, slice_25821, 2, 0, 16);  slice_tensor_1565 = slice_25821 = None
        slice_scatter_default_3131: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3129, slice_scatter_default_3130, 1, 6256, 6272);  slice_scatter_default_3129 = slice_scatter_default_3130 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25841: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25807, 2, 16, 32);  slice_25807 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_786: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25841, memory_format = torch.contiguous_format);  slice_25841 = None
        view_1576: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_786, [32, 11]);  clone_786 = None
        mm_783: "f32[32, 8]" = torch.ops.aten.mm.default(view_1576, slice_37)
        view_1577: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_783, [2, 16, 8]);  mm_783 = None
        slice_25848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3131, 1, 6256, 6272)
        slice_25849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25848, 2, 0, 16);  slice_25848 = None
        add_785: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25849, view_1577);  slice_25849 = view_1577 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3131, 1, 6256, 6272)
        slice_scatter_default_3132: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1566, add_785, 2, 0, 16);  slice_tensor_1566 = add_785 = None
        slice_scatter_default_3133: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3131, slice_scatter_default_3132, 1, 6256, 6272);  slice_scatter_default_3131 = slice_scatter_default_3132 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3133, 1, 6256, 6272)
        slice_25854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25853, 2, 0, 16);  slice_25853 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3133, 1, 6256, 6272)
        slice_scatter_default_3134: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1567, slice_25854, 2, 0, 16);  slice_tensor_1567 = slice_25854 = None
        slice_scatter_default_3135: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3133, slice_scatter_default_3134, 1, 6256, 6272);  slice_scatter_default_3133 = slice_scatter_default_3134 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25873: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6272, 6288)
        slice_25874: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25873, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_787: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25874, memory_format = torch.contiguous_format);  slice_25874 = None
        view_1578: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_787, [32, 16]);  clone_787 = None
        mm_784: "f32[32, 8]" = torch.ops.aten.mm.default(view_1578, slice_7)
        view_1579: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_784, [2, 16, 8]);  mm_784 = None
        slice_25881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3135, 1, 6272, 6288)
        slice_25882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25881, 2, 0, 16);  slice_25881 = None
        add_786: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25882, view_1579);  slice_25882 = view_1579 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3135, 1, 6272, 6288)
        slice_scatter_default_3136: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1568, add_786, 2, 0, 16);  slice_tensor_1568 = add_786 = None
        slice_scatter_default_3137: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3135, slice_scatter_default_3136, 1, 6272, 6288);  slice_scatter_default_3135 = slice_scatter_default_3136 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3137, 1, 6272, 6288)
        slice_25887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25886, 2, 0, 16);  slice_25886 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3137, 1, 6272, 6288)
        slice_scatter_default_3138: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1569, slice_25887, 2, 0, 16);  slice_tensor_1569 = slice_25887 = None
        slice_scatter_default_3139: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3137, slice_scatter_default_3138, 1, 6272, 6288);  slice_scatter_default_3137 = slice_scatter_default_3138 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25907: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25873, 2, 16, 32);  slice_25873 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_788: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25907, memory_format = torch.contiguous_format);  slice_25907 = None
        view_1580: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_788, [32, 11]);  clone_788 = None
        mm_785: "f32[32, 8]" = torch.ops.aten.mm.default(view_1580, slice_37)
        view_1581: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_785, [2, 16, 8]);  mm_785 = None
        slice_25914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3139, 1, 6272, 6288)
        slice_25915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25914, 2, 0, 16);  slice_25914 = None
        add_787: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25915, view_1581);  slice_25915 = view_1581 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3139, 1, 6272, 6288)
        slice_scatter_default_3140: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1570, add_787, 2, 0, 16);  slice_tensor_1570 = add_787 = None
        slice_scatter_default_3141: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3139, slice_scatter_default_3140, 1, 6272, 6288);  slice_scatter_default_3139 = slice_scatter_default_3140 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3141, 1, 6272, 6288)
        slice_25920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25919, 2, 0, 16);  slice_25919 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3141, 1, 6272, 6288)
        slice_scatter_default_3142: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1571, slice_25920, 2, 0, 16);  slice_tensor_1571 = slice_25920 = None
        slice_scatter_default_3143: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3141, slice_scatter_default_3142, 1, 6272, 6288);  slice_scatter_default_3141 = slice_scatter_default_3142 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25939: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6288, 6304)
        slice_25940: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_25939, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_789: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_25940, memory_format = torch.contiguous_format);  slice_25940 = None
        view_1582: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_789, [32, 16]);  clone_789 = None
        mm_786: "f32[32, 8]" = torch.ops.aten.mm.default(view_1582, slice_7)
        view_1583: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_786, [2, 16, 8]);  mm_786 = None
        slice_25947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3143, 1, 6288, 6304)
        slice_25948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25947, 2, 0, 16);  slice_25947 = None
        add_788: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25948, view_1583);  slice_25948 = view_1583 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3143, 1, 6288, 6304)
        slice_scatter_default_3144: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1572, add_788, 2, 0, 16);  slice_tensor_1572 = add_788 = None
        slice_scatter_default_3145: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3143, slice_scatter_default_3144, 1, 6288, 6304);  slice_scatter_default_3143 = slice_scatter_default_3144 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3145, 1, 6288, 6304)
        slice_25953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25952, 2, 0, 16);  slice_25952 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3145, 1, 6288, 6304)
        slice_scatter_default_3146: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1573, slice_25953, 2, 0, 16);  slice_tensor_1573 = slice_25953 = None
        slice_scatter_default_3147: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3145, slice_scatter_default_3146, 1, 6288, 6304);  slice_scatter_default_3145 = slice_scatter_default_3146 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_25973: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_25939, 2, 16, 32);  slice_25939 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_790: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_25973, memory_format = torch.contiguous_format);  slice_25973 = None
        view_1584: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_790, [32, 11]);  clone_790 = None
        mm_787: "f32[32, 8]" = torch.ops.aten.mm.default(view_1584, slice_37)
        view_1585: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_787, [2, 16, 8]);  mm_787 = None
        slice_25980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3147, 1, 6288, 6304)
        slice_25981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25980, 2, 0, 16);  slice_25980 = None
        add_789: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_25981, view_1585);  slice_25981 = view_1585 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3147, 1, 6288, 6304)
        slice_scatter_default_3148: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1574, add_789, 2, 0, 16);  slice_tensor_1574 = add_789 = None
        slice_scatter_default_3149: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3147, slice_scatter_default_3148, 1, 6288, 6304);  slice_scatter_default_3147 = slice_scatter_default_3148 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_25985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3149, 1, 6288, 6304)
        slice_25986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_25985, 2, 0, 16);  slice_25985 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3149, 1, 6288, 6304)
        slice_scatter_default_3150: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1575, slice_25986, 2, 0, 16);  slice_tensor_1575 = slice_25986 = None
        slice_scatter_default_3151: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3149, slice_scatter_default_3150, 1, 6288, 6304);  slice_scatter_default_3149 = slice_scatter_default_3150 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26005: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6304, 6320)
        slice_26006: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26005, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_791: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26006, memory_format = torch.contiguous_format);  slice_26006 = None
        view_1586: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_791, [32, 16]);  clone_791 = None
        mm_788: "f32[32, 8]" = torch.ops.aten.mm.default(view_1586, slice_7)
        view_1587: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_788, [2, 16, 8]);  mm_788 = None
        slice_26013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3151, 1, 6304, 6320)
        slice_26014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26013, 2, 0, 16);  slice_26013 = None
        add_790: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26014, view_1587);  slice_26014 = view_1587 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3151, 1, 6304, 6320)
        slice_scatter_default_3152: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1576, add_790, 2, 0, 16);  slice_tensor_1576 = add_790 = None
        slice_scatter_default_3153: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3151, slice_scatter_default_3152, 1, 6304, 6320);  slice_scatter_default_3151 = slice_scatter_default_3152 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3153, 1, 6304, 6320)
        slice_26019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26018, 2, 0, 16);  slice_26018 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3153, 1, 6304, 6320)
        slice_scatter_default_3154: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1577, slice_26019, 2, 0, 16);  slice_tensor_1577 = slice_26019 = None
        slice_scatter_default_3155: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3153, slice_scatter_default_3154, 1, 6304, 6320);  slice_scatter_default_3153 = slice_scatter_default_3154 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26039: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26005, 2, 16, 32);  slice_26005 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_792: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26039, memory_format = torch.contiguous_format);  slice_26039 = None
        view_1588: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_792, [32, 11]);  clone_792 = None
        mm_789: "f32[32, 8]" = torch.ops.aten.mm.default(view_1588, slice_37)
        view_1589: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_789, [2, 16, 8]);  mm_789 = None
        slice_26046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3155, 1, 6304, 6320)
        slice_26047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26046, 2, 0, 16);  slice_26046 = None
        add_791: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26047, view_1589);  slice_26047 = view_1589 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3155, 1, 6304, 6320)
        slice_scatter_default_3156: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1578, add_791, 2, 0, 16);  slice_tensor_1578 = add_791 = None
        slice_scatter_default_3157: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3155, slice_scatter_default_3156, 1, 6304, 6320);  slice_scatter_default_3155 = slice_scatter_default_3156 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3157, 1, 6304, 6320)
        slice_26052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26051, 2, 0, 16);  slice_26051 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3157, 1, 6304, 6320)
        slice_scatter_default_3158: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1579, slice_26052, 2, 0, 16);  slice_tensor_1579 = slice_26052 = None
        slice_scatter_default_3159: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3157, slice_scatter_default_3158, 1, 6304, 6320);  slice_scatter_default_3157 = slice_scatter_default_3158 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26071: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6320, 6336)
        slice_26072: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26071, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_793: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26072, memory_format = torch.contiguous_format);  slice_26072 = None
        view_1590: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_793, [32, 16]);  clone_793 = None
        mm_790: "f32[32, 8]" = torch.ops.aten.mm.default(view_1590, slice_7)
        view_1591: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_790, [2, 16, 8]);  mm_790 = None
        slice_26079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3159, 1, 6320, 6336)
        slice_26080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26079, 2, 0, 16);  slice_26079 = None
        add_792: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26080, view_1591);  slice_26080 = view_1591 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3159, 1, 6320, 6336)
        slice_scatter_default_3160: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1580, add_792, 2, 0, 16);  slice_tensor_1580 = add_792 = None
        slice_scatter_default_3161: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3159, slice_scatter_default_3160, 1, 6320, 6336);  slice_scatter_default_3159 = slice_scatter_default_3160 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3161, 1, 6320, 6336)
        slice_26085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26084, 2, 0, 16);  slice_26084 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3161, 1, 6320, 6336)
        slice_scatter_default_3162: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1581, slice_26085, 2, 0, 16);  slice_tensor_1581 = slice_26085 = None
        slice_scatter_default_3163: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3161, slice_scatter_default_3162, 1, 6320, 6336);  slice_scatter_default_3161 = slice_scatter_default_3162 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26105: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26071, 2, 16, 32);  slice_26071 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_794: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26105, memory_format = torch.contiguous_format);  slice_26105 = None
        view_1592: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_794, [32, 11]);  clone_794 = None
        mm_791: "f32[32, 8]" = torch.ops.aten.mm.default(view_1592, slice_37)
        view_1593: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_791, [2, 16, 8]);  mm_791 = None
        slice_26112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3163, 1, 6320, 6336)
        slice_26113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26112, 2, 0, 16);  slice_26112 = None
        add_793: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26113, view_1593);  slice_26113 = view_1593 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3163, 1, 6320, 6336)
        slice_scatter_default_3164: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1582, add_793, 2, 0, 16);  slice_tensor_1582 = add_793 = None
        slice_scatter_default_3165: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3163, slice_scatter_default_3164, 1, 6320, 6336);  slice_scatter_default_3163 = slice_scatter_default_3164 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3165, 1, 6320, 6336)
        slice_26118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26117, 2, 0, 16);  slice_26117 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3165, 1, 6320, 6336)
        slice_scatter_default_3166: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1583, slice_26118, 2, 0, 16);  slice_tensor_1583 = slice_26118 = None
        slice_scatter_default_3167: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3165, slice_scatter_default_3166, 1, 6320, 6336);  slice_scatter_default_3165 = slice_scatter_default_3166 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26137: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6336, 6352)
        slice_26138: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26137, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_795: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26138, memory_format = torch.contiguous_format);  slice_26138 = None
        view_1594: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_795, [32, 16]);  clone_795 = None
        mm_792: "f32[32, 8]" = torch.ops.aten.mm.default(view_1594, slice_7)
        view_1595: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_792, [2, 16, 8]);  mm_792 = None
        slice_26145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3167, 1, 6336, 6352)
        slice_26146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26145, 2, 0, 16);  slice_26145 = None
        add_794: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26146, view_1595);  slice_26146 = view_1595 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3167, 1, 6336, 6352)
        slice_scatter_default_3168: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1584, add_794, 2, 0, 16);  slice_tensor_1584 = add_794 = None
        slice_scatter_default_3169: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3167, slice_scatter_default_3168, 1, 6336, 6352);  slice_scatter_default_3167 = slice_scatter_default_3168 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3169, 1, 6336, 6352)
        slice_26151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26150, 2, 0, 16);  slice_26150 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3169, 1, 6336, 6352)
        slice_scatter_default_3170: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1585, slice_26151, 2, 0, 16);  slice_tensor_1585 = slice_26151 = None
        slice_scatter_default_3171: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3169, slice_scatter_default_3170, 1, 6336, 6352);  slice_scatter_default_3169 = slice_scatter_default_3170 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26171: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26137, 2, 16, 32);  slice_26137 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_796: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26171, memory_format = torch.contiguous_format);  slice_26171 = None
        view_1596: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_796, [32, 11]);  clone_796 = None
        mm_793: "f32[32, 8]" = torch.ops.aten.mm.default(view_1596, slice_37)
        view_1597: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_793, [2, 16, 8]);  mm_793 = None
        slice_26178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3171, 1, 6336, 6352)
        slice_26179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26178, 2, 0, 16);  slice_26178 = None
        add_795: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26179, view_1597);  slice_26179 = view_1597 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3171, 1, 6336, 6352)
        slice_scatter_default_3172: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1586, add_795, 2, 0, 16);  slice_tensor_1586 = add_795 = None
        slice_scatter_default_3173: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3171, slice_scatter_default_3172, 1, 6336, 6352);  slice_scatter_default_3171 = slice_scatter_default_3172 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3173, 1, 6336, 6352)
        slice_26184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26183, 2, 0, 16);  slice_26183 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3173, 1, 6336, 6352)
        slice_scatter_default_3174: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1587, slice_26184, 2, 0, 16);  slice_tensor_1587 = slice_26184 = None
        slice_scatter_default_3175: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3173, slice_scatter_default_3174, 1, 6336, 6352);  slice_scatter_default_3173 = slice_scatter_default_3174 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26203: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6352, 6368)
        slice_26204: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26203, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_797: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26204, memory_format = torch.contiguous_format);  slice_26204 = None
        view_1598: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_797, [32, 16]);  clone_797 = None
        mm_794: "f32[32, 8]" = torch.ops.aten.mm.default(view_1598, slice_7)
        view_1599: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_794, [2, 16, 8]);  mm_794 = None
        slice_26211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3175, 1, 6352, 6368)
        slice_26212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26211, 2, 0, 16);  slice_26211 = None
        add_796: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26212, view_1599);  slice_26212 = view_1599 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3175, 1, 6352, 6368)
        slice_scatter_default_3176: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1588, add_796, 2, 0, 16);  slice_tensor_1588 = add_796 = None
        slice_scatter_default_3177: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3175, slice_scatter_default_3176, 1, 6352, 6368);  slice_scatter_default_3175 = slice_scatter_default_3176 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3177, 1, 6352, 6368)
        slice_26217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26216, 2, 0, 16);  slice_26216 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3177, 1, 6352, 6368)
        slice_scatter_default_3178: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1589, slice_26217, 2, 0, 16);  slice_tensor_1589 = slice_26217 = None
        slice_scatter_default_3179: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3177, slice_scatter_default_3178, 1, 6352, 6368);  slice_scatter_default_3177 = slice_scatter_default_3178 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26237: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26203, 2, 16, 32);  slice_26203 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_798: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26237, memory_format = torch.contiguous_format);  slice_26237 = None
        view_1600: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_798, [32, 11]);  clone_798 = None
        mm_795: "f32[32, 8]" = torch.ops.aten.mm.default(view_1600, slice_37)
        view_1601: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_795, [2, 16, 8]);  mm_795 = None
        slice_26244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3179, 1, 6352, 6368)
        slice_26245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26244, 2, 0, 16);  slice_26244 = None
        add_797: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26245, view_1601);  slice_26245 = view_1601 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3179, 1, 6352, 6368)
        slice_scatter_default_3180: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1590, add_797, 2, 0, 16);  slice_tensor_1590 = add_797 = None
        slice_scatter_default_3181: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3179, slice_scatter_default_3180, 1, 6352, 6368);  slice_scatter_default_3179 = slice_scatter_default_3180 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3181, 1, 6352, 6368)
        slice_26250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26249, 2, 0, 16);  slice_26249 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3181, 1, 6352, 6368)
        slice_scatter_default_3182: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1591, slice_26250, 2, 0, 16);  slice_tensor_1591 = slice_26250 = None
        slice_scatter_default_3183: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3181, slice_scatter_default_3182, 1, 6352, 6368);  slice_scatter_default_3181 = slice_scatter_default_3182 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26269: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6368, 6384)
        slice_26270: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26269, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_799: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26270, memory_format = torch.contiguous_format);  slice_26270 = None
        view_1602: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_799, [32, 16]);  clone_799 = None
        mm_796: "f32[32, 8]" = torch.ops.aten.mm.default(view_1602, slice_7)
        view_1603: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_796, [2, 16, 8]);  mm_796 = None
        slice_26277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3183, 1, 6368, 6384)
        slice_26278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26277, 2, 0, 16);  slice_26277 = None
        add_798: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26278, view_1603);  slice_26278 = view_1603 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3183, 1, 6368, 6384)
        slice_scatter_default_3184: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1592, add_798, 2, 0, 16);  slice_tensor_1592 = add_798 = None
        slice_scatter_default_3185: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3183, slice_scatter_default_3184, 1, 6368, 6384);  slice_scatter_default_3183 = slice_scatter_default_3184 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3185, 1, 6368, 6384)
        slice_26283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26282, 2, 0, 16);  slice_26282 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3185, 1, 6368, 6384)
        slice_scatter_default_3186: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1593, slice_26283, 2, 0, 16);  slice_tensor_1593 = slice_26283 = None
        slice_scatter_default_3187: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3185, slice_scatter_default_3186, 1, 6368, 6384);  slice_scatter_default_3185 = slice_scatter_default_3186 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26303: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26269, 2, 16, 32);  slice_26269 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_800: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26303, memory_format = torch.contiguous_format);  slice_26303 = None
        view_1604: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_800, [32, 11]);  clone_800 = None
        mm_797: "f32[32, 8]" = torch.ops.aten.mm.default(view_1604, slice_37)
        view_1605: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_797, [2, 16, 8]);  mm_797 = None
        slice_26310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3187, 1, 6368, 6384)
        slice_26311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26310, 2, 0, 16);  slice_26310 = None
        add_799: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26311, view_1605);  slice_26311 = view_1605 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3187, 1, 6368, 6384)
        slice_scatter_default_3188: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1594, add_799, 2, 0, 16);  slice_tensor_1594 = add_799 = None
        slice_scatter_default_3189: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3187, slice_scatter_default_3188, 1, 6368, 6384);  slice_scatter_default_3187 = slice_scatter_default_3188 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3189, 1, 6368, 6384)
        slice_26316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26315, 2, 0, 16);  slice_26315 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3189, 1, 6368, 6384)
        slice_scatter_default_3190: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1595, slice_26316, 2, 0, 16);  slice_tensor_1595 = slice_26316 = None
        slice_scatter_default_3191: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3189, slice_scatter_default_3190, 1, 6368, 6384);  slice_scatter_default_3189 = slice_scatter_default_3190 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26335: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6384, 6400)
        slice_26336: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26335, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_801: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26336, memory_format = torch.contiguous_format);  slice_26336 = None
        view_1606: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_801, [32, 16]);  clone_801 = None
        mm_798: "f32[32, 8]" = torch.ops.aten.mm.default(view_1606, slice_7)
        view_1607: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_798, [2, 16, 8]);  mm_798 = None
        slice_26343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3191, 1, 6384, 6400)
        slice_26344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26343, 2, 0, 16);  slice_26343 = None
        add_800: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26344, view_1607);  slice_26344 = view_1607 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3191, 1, 6384, 6400)
        slice_scatter_default_3192: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1596, add_800, 2, 0, 16);  slice_tensor_1596 = add_800 = None
        slice_scatter_default_3193: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3191, slice_scatter_default_3192, 1, 6384, 6400);  slice_scatter_default_3191 = slice_scatter_default_3192 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3193, 1, 6384, 6400)
        slice_26349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26348, 2, 0, 16);  slice_26348 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3193, 1, 6384, 6400)
        slice_scatter_default_3194: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1597, slice_26349, 2, 0, 16);  slice_tensor_1597 = slice_26349 = None
        slice_scatter_default_3195: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3193, slice_scatter_default_3194, 1, 6384, 6400);  slice_scatter_default_3193 = slice_scatter_default_3194 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26369: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26335, 2, 16, 32);  slice_26335 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_802: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26369, memory_format = torch.contiguous_format);  slice_26369 = None
        view_1608: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_802, [32, 11]);  clone_802 = None
        mm_799: "f32[32, 8]" = torch.ops.aten.mm.default(view_1608, slice_37)
        view_1609: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_799, [2, 16, 8]);  mm_799 = None
        slice_26376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3195, 1, 6384, 6400)
        slice_26377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26376, 2, 0, 16);  slice_26376 = None
        add_801: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26377, view_1609);  slice_26377 = view_1609 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3195, 1, 6384, 6400)
        slice_scatter_default_3196: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1598, add_801, 2, 0, 16);  slice_tensor_1598 = add_801 = None
        slice_scatter_default_3197: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3195, slice_scatter_default_3196, 1, 6384, 6400);  slice_scatter_default_3195 = slice_scatter_default_3196 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3197, 1, 6384, 6400)
        slice_26382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26381, 2, 0, 16);  slice_26381 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3197, 1, 6384, 6400)
        slice_scatter_default_3198: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1599, slice_26382, 2, 0, 16);  slice_tensor_1599 = slice_26382 = None
        slice_scatter_default_3199: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3197, slice_scatter_default_3198, 1, 6384, 6400);  slice_scatter_default_3197 = slice_scatter_default_3198 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26401: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6400, 6416)
        slice_26402: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26401, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_803: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26402, memory_format = torch.contiguous_format);  slice_26402 = None
        view_1610: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_803, [32, 16]);  clone_803 = None
        mm_800: "f32[32, 8]" = torch.ops.aten.mm.default(view_1610, slice_7)
        view_1611: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_800, [2, 16, 8]);  mm_800 = None
        slice_26409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3199, 1, 6400, 6416)
        slice_26410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26409, 2, 0, 16);  slice_26409 = None
        add_802: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26410, view_1611);  slice_26410 = view_1611 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3199, 1, 6400, 6416)
        slice_scatter_default_3200: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1600, add_802, 2, 0, 16);  slice_tensor_1600 = add_802 = None
        slice_scatter_default_3201: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3199, slice_scatter_default_3200, 1, 6400, 6416);  slice_scatter_default_3199 = slice_scatter_default_3200 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3201, 1, 6400, 6416)
        slice_26415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26414, 2, 0, 16);  slice_26414 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3201, 1, 6400, 6416)
        slice_scatter_default_3202: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1601, slice_26415, 2, 0, 16);  slice_tensor_1601 = slice_26415 = None
        slice_scatter_default_3203: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3201, slice_scatter_default_3202, 1, 6400, 6416);  slice_scatter_default_3201 = slice_scatter_default_3202 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26435: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26401, 2, 16, 32);  slice_26401 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_804: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26435, memory_format = torch.contiguous_format);  slice_26435 = None
        view_1612: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_804, [32, 11]);  clone_804 = None
        mm_801: "f32[32, 8]" = torch.ops.aten.mm.default(view_1612, slice_37)
        view_1613: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_801, [2, 16, 8]);  mm_801 = None
        slice_26442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3203, 1, 6400, 6416)
        slice_26443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26442, 2, 0, 16);  slice_26442 = None
        add_803: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26443, view_1613);  slice_26443 = view_1613 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3203, 1, 6400, 6416)
        slice_scatter_default_3204: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1602, add_803, 2, 0, 16);  slice_tensor_1602 = add_803 = None
        slice_scatter_default_3205: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3203, slice_scatter_default_3204, 1, 6400, 6416);  slice_scatter_default_3203 = slice_scatter_default_3204 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3205, 1, 6400, 6416)
        slice_26448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26447, 2, 0, 16);  slice_26447 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3205, 1, 6400, 6416)
        slice_scatter_default_3206: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1603, slice_26448, 2, 0, 16);  slice_tensor_1603 = slice_26448 = None
        slice_scatter_default_3207: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3205, slice_scatter_default_3206, 1, 6400, 6416);  slice_scatter_default_3205 = slice_scatter_default_3206 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26467: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6416, 6432)
        slice_26468: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26467, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_805: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26468, memory_format = torch.contiguous_format);  slice_26468 = None
        view_1614: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_805, [32, 16]);  clone_805 = None
        mm_802: "f32[32, 8]" = torch.ops.aten.mm.default(view_1614, slice_7)
        view_1615: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_802, [2, 16, 8]);  mm_802 = None
        slice_26475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3207, 1, 6416, 6432)
        slice_26476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26475, 2, 0, 16);  slice_26475 = None
        add_804: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26476, view_1615);  slice_26476 = view_1615 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3207, 1, 6416, 6432)
        slice_scatter_default_3208: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1604, add_804, 2, 0, 16);  slice_tensor_1604 = add_804 = None
        slice_scatter_default_3209: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3207, slice_scatter_default_3208, 1, 6416, 6432);  slice_scatter_default_3207 = slice_scatter_default_3208 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3209, 1, 6416, 6432)
        slice_26481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26480, 2, 0, 16);  slice_26480 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3209, 1, 6416, 6432)
        slice_scatter_default_3210: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1605, slice_26481, 2, 0, 16);  slice_tensor_1605 = slice_26481 = None
        slice_scatter_default_3211: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3209, slice_scatter_default_3210, 1, 6416, 6432);  slice_scatter_default_3209 = slice_scatter_default_3210 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26501: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26467, 2, 16, 32);  slice_26467 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_806: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26501, memory_format = torch.contiguous_format);  slice_26501 = None
        view_1616: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_806, [32, 11]);  clone_806 = None
        mm_803: "f32[32, 8]" = torch.ops.aten.mm.default(view_1616, slice_37)
        view_1617: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_803, [2, 16, 8]);  mm_803 = None
        slice_26508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3211, 1, 6416, 6432)
        slice_26509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26508, 2, 0, 16);  slice_26508 = None
        add_805: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26509, view_1617);  slice_26509 = view_1617 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3211, 1, 6416, 6432)
        slice_scatter_default_3212: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1606, add_805, 2, 0, 16);  slice_tensor_1606 = add_805 = None
        slice_scatter_default_3213: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3211, slice_scatter_default_3212, 1, 6416, 6432);  slice_scatter_default_3211 = slice_scatter_default_3212 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3213, 1, 6416, 6432)
        slice_26514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26513, 2, 0, 16);  slice_26513 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3213, 1, 6416, 6432)
        slice_scatter_default_3214: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1607, slice_26514, 2, 0, 16);  slice_tensor_1607 = slice_26514 = None
        slice_scatter_default_3215: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3213, slice_scatter_default_3214, 1, 6416, 6432);  slice_scatter_default_3213 = slice_scatter_default_3214 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26533: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6432, 6448)
        slice_26534: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26533, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_807: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26534, memory_format = torch.contiguous_format);  slice_26534 = None
        view_1618: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_807, [32, 16]);  clone_807 = None
        mm_804: "f32[32, 8]" = torch.ops.aten.mm.default(view_1618, slice_7)
        view_1619: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_804, [2, 16, 8]);  mm_804 = None
        slice_26541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3215, 1, 6432, 6448)
        slice_26542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26541, 2, 0, 16);  slice_26541 = None
        add_806: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26542, view_1619);  slice_26542 = view_1619 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3215, 1, 6432, 6448)
        slice_scatter_default_3216: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1608, add_806, 2, 0, 16);  slice_tensor_1608 = add_806 = None
        slice_scatter_default_3217: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3215, slice_scatter_default_3216, 1, 6432, 6448);  slice_scatter_default_3215 = slice_scatter_default_3216 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3217, 1, 6432, 6448)
        slice_26547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26546, 2, 0, 16);  slice_26546 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3217, 1, 6432, 6448)
        slice_scatter_default_3218: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1609, slice_26547, 2, 0, 16);  slice_tensor_1609 = slice_26547 = None
        slice_scatter_default_3219: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3217, slice_scatter_default_3218, 1, 6432, 6448);  slice_scatter_default_3217 = slice_scatter_default_3218 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26567: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26533, 2, 16, 32);  slice_26533 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_808: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26567, memory_format = torch.contiguous_format);  slice_26567 = None
        view_1620: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_808, [32, 11]);  clone_808 = None
        mm_805: "f32[32, 8]" = torch.ops.aten.mm.default(view_1620, slice_37)
        view_1621: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_805, [2, 16, 8]);  mm_805 = None
        slice_26574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3219, 1, 6432, 6448)
        slice_26575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26574, 2, 0, 16);  slice_26574 = None
        add_807: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26575, view_1621);  slice_26575 = view_1621 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3219, 1, 6432, 6448)
        slice_scatter_default_3220: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1610, add_807, 2, 0, 16);  slice_tensor_1610 = add_807 = None
        slice_scatter_default_3221: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3219, slice_scatter_default_3220, 1, 6432, 6448);  slice_scatter_default_3219 = slice_scatter_default_3220 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3221, 1, 6432, 6448)
        slice_26580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26579, 2, 0, 16);  slice_26579 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3221, 1, 6432, 6448)
        slice_scatter_default_3222: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1611, slice_26580, 2, 0, 16);  slice_tensor_1611 = slice_26580 = None
        slice_scatter_default_3223: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3221, slice_scatter_default_3222, 1, 6432, 6448);  slice_scatter_default_3221 = slice_scatter_default_3222 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26599: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6448, 6464)
        slice_26600: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26599, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_809: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26600, memory_format = torch.contiguous_format);  slice_26600 = None
        view_1622: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_809, [32, 16]);  clone_809 = None
        mm_806: "f32[32, 8]" = torch.ops.aten.mm.default(view_1622, slice_7)
        view_1623: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_806, [2, 16, 8]);  mm_806 = None
        slice_26607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3223, 1, 6448, 6464)
        slice_26608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26607, 2, 0, 16);  slice_26607 = None
        add_808: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26608, view_1623);  slice_26608 = view_1623 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3223, 1, 6448, 6464)
        slice_scatter_default_3224: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1612, add_808, 2, 0, 16);  slice_tensor_1612 = add_808 = None
        slice_scatter_default_3225: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3223, slice_scatter_default_3224, 1, 6448, 6464);  slice_scatter_default_3223 = slice_scatter_default_3224 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3225, 1, 6448, 6464)
        slice_26613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26612, 2, 0, 16);  slice_26612 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3225, 1, 6448, 6464)
        slice_scatter_default_3226: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1613, slice_26613, 2, 0, 16);  slice_tensor_1613 = slice_26613 = None
        slice_scatter_default_3227: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3225, slice_scatter_default_3226, 1, 6448, 6464);  slice_scatter_default_3225 = slice_scatter_default_3226 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26633: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26599, 2, 16, 32);  slice_26599 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_810: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26633, memory_format = torch.contiguous_format);  slice_26633 = None
        view_1624: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_810, [32, 11]);  clone_810 = None
        mm_807: "f32[32, 8]" = torch.ops.aten.mm.default(view_1624, slice_37)
        view_1625: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_807, [2, 16, 8]);  mm_807 = None
        slice_26640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3227, 1, 6448, 6464)
        slice_26641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26640, 2, 0, 16);  slice_26640 = None
        add_809: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26641, view_1625);  slice_26641 = view_1625 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3227, 1, 6448, 6464)
        slice_scatter_default_3228: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1614, add_809, 2, 0, 16);  slice_tensor_1614 = add_809 = None
        slice_scatter_default_3229: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3227, slice_scatter_default_3228, 1, 6448, 6464);  slice_scatter_default_3227 = slice_scatter_default_3228 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3229, 1, 6448, 6464)
        slice_26646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26645, 2, 0, 16);  slice_26645 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3229, 1, 6448, 6464)
        slice_scatter_default_3230: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1615, slice_26646, 2, 0, 16);  slice_tensor_1615 = slice_26646 = None
        slice_scatter_default_3231: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3229, slice_scatter_default_3230, 1, 6448, 6464);  slice_scatter_default_3229 = slice_scatter_default_3230 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26665: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6464, 6480)
        slice_26666: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26665, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_811: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26666, memory_format = torch.contiguous_format);  slice_26666 = None
        view_1626: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_811, [32, 16]);  clone_811 = None
        mm_808: "f32[32, 8]" = torch.ops.aten.mm.default(view_1626, slice_7)
        view_1627: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_808, [2, 16, 8]);  mm_808 = None
        slice_26673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3231, 1, 6464, 6480)
        slice_26674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26673, 2, 0, 16);  slice_26673 = None
        add_810: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26674, view_1627);  slice_26674 = view_1627 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3231, 1, 6464, 6480)
        slice_scatter_default_3232: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1616, add_810, 2, 0, 16);  slice_tensor_1616 = add_810 = None
        slice_scatter_default_3233: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3231, slice_scatter_default_3232, 1, 6464, 6480);  slice_scatter_default_3231 = slice_scatter_default_3232 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3233, 1, 6464, 6480)
        slice_26679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26678, 2, 0, 16);  slice_26678 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3233, 1, 6464, 6480)
        slice_scatter_default_3234: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1617, slice_26679, 2, 0, 16);  slice_tensor_1617 = slice_26679 = None
        slice_scatter_default_3235: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3233, slice_scatter_default_3234, 1, 6464, 6480);  slice_scatter_default_3233 = slice_scatter_default_3234 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26699: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26665, 2, 16, 32);  slice_26665 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_812: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26699, memory_format = torch.contiguous_format);  slice_26699 = None
        view_1628: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_812, [32, 11]);  clone_812 = None
        mm_809: "f32[32, 8]" = torch.ops.aten.mm.default(view_1628, slice_37)
        view_1629: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_809, [2, 16, 8]);  mm_809 = None
        slice_26706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3235, 1, 6464, 6480)
        slice_26707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26706, 2, 0, 16);  slice_26706 = None
        add_811: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26707, view_1629);  slice_26707 = view_1629 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3235, 1, 6464, 6480)
        slice_scatter_default_3236: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1618, add_811, 2, 0, 16);  slice_tensor_1618 = add_811 = None
        slice_scatter_default_3237: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3235, slice_scatter_default_3236, 1, 6464, 6480);  slice_scatter_default_3235 = slice_scatter_default_3236 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3237, 1, 6464, 6480)
        slice_26712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26711, 2, 0, 16);  slice_26711 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3237, 1, 6464, 6480)
        slice_scatter_default_3238: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1619, slice_26712, 2, 0, 16);  slice_tensor_1619 = slice_26712 = None
        slice_scatter_default_3239: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3237, slice_scatter_default_3238, 1, 6464, 6480);  slice_scatter_default_3237 = slice_scatter_default_3238 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26731: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6480, 6496)
        slice_26732: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26731, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_813: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26732, memory_format = torch.contiguous_format);  slice_26732 = None
        view_1630: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_813, [32, 16]);  clone_813 = None
        mm_810: "f32[32, 8]" = torch.ops.aten.mm.default(view_1630, slice_7)
        view_1631: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_810, [2, 16, 8]);  mm_810 = None
        slice_26739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3239, 1, 6480, 6496)
        slice_26740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26739, 2, 0, 16);  slice_26739 = None
        add_812: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26740, view_1631);  slice_26740 = view_1631 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3239, 1, 6480, 6496)
        slice_scatter_default_3240: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1620, add_812, 2, 0, 16);  slice_tensor_1620 = add_812 = None
        slice_scatter_default_3241: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3239, slice_scatter_default_3240, 1, 6480, 6496);  slice_scatter_default_3239 = slice_scatter_default_3240 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3241, 1, 6480, 6496)
        slice_26745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26744, 2, 0, 16);  slice_26744 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3241, 1, 6480, 6496)
        slice_scatter_default_3242: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1621, slice_26745, 2, 0, 16);  slice_tensor_1621 = slice_26745 = None
        slice_scatter_default_3243: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3241, slice_scatter_default_3242, 1, 6480, 6496);  slice_scatter_default_3241 = slice_scatter_default_3242 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26765: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26731, 2, 16, 32);  slice_26731 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_814: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26765, memory_format = torch.contiguous_format);  slice_26765 = None
        view_1632: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_814, [32, 11]);  clone_814 = None
        mm_811: "f32[32, 8]" = torch.ops.aten.mm.default(view_1632, slice_37)
        view_1633: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_811, [2, 16, 8]);  mm_811 = None
        slice_26772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3243, 1, 6480, 6496)
        slice_26773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26772, 2, 0, 16);  slice_26772 = None
        add_813: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26773, view_1633);  slice_26773 = view_1633 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3243, 1, 6480, 6496)
        slice_scatter_default_3244: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1622, add_813, 2, 0, 16);  slice_tensor_1622 = add_813 = None
        slice_scatter_default_3245: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3243, slice_scatter_default_3244, 1, 6480, 6496);  slice_scatter_default_3243 = slice_scatter_default_3244 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3245, 1, 6480, 6496)
        slice_26778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26777, 2, 0, 16);  slice_26777 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3245, 1, 6480, 6496)
        slice_scatter_default_3246: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1623, slice_26778, 2, 0, 16);  slice_tensor_1623 = slice_26778 = None
        slice_scatter_default_3247: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3245, slice_scatter_default_3246, 1, 6480, 6496);  slice_scatter_default_3245 = slice_scatter_default_3246 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26797: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6496, 6512)
        slice_26798: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26797, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_815: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26798, memory_format = torch.contiguous_format);  slice_26798 = None
        view_1634: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_815, [32, 16]);  clone_815 = None
        mm_812: "f32[32, 8]" = torch.ops.aten.mm.default(view_1634, slice_7)
        view_1635: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_812, [2, 16, 8]);  mm_812 = None
        slice_26805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3247, 1, 6496, 6512)
        slice_26806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26805, 2, 0, 16);  slice_26805 = None
        add_814: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26806, view_1635);  slice_26806 = view_1635 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3247, 1, 6496, 6512)
        slice_scatter_default_3248: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1624, add_814, 2, 0, 16);  slice_tensor_1624 = add_814 = None
        slice_scatter_default_3249: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3247, slice_scatter_default_3248, 1, 6496, 6512);  slice_scatter_default_3247 = slice_scatter_default_3248 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3249, 1, 6496, 6512)
        slice_26811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26810, 2, 0, 16);  slice_26810 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3249, 1, 6496, 6512)
        slice_scatter_default_3250: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1625, slice_26811, 2, 0, 16);  slice_tensor_1625 = slice_26811 = None
        slice_scatter_default_3251: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3249, slice_scatter_default_3250, 1, 6496, 6512);  slice_scatter_default_3249 = slice_scatter_default_3250 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26831: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26797, 2, 16, 32);  slice_26797 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_816: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26831, memory_format = torch.contiguous_format);  slice_26831 = None
        view_1636: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_816, [32, 11]);  clone_816 = None
        mm_813: "f32[32, 8]" = torch.ops.aten.mm.default(view_1636, slice_37)
        view_1637: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_813, [2, 16, 8]);  mm_813 = None
        slice_26838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3251, 1, 6496, 6512)
        slice_26839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26838, 2, 0, 16);  slice_26838 = None
        add_815: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26839, view_1637);  slice_26839 = view_1637 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3251, 1, 6496, 6512)
        slice_scatter_default_3252: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1626, add_815, 2, 0, 16);  slice_tensor_1626 = add_815 = None
        slice_scatter_default_3253: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3251, slice_scatter_default_3252, 1, 6496, 6512);  slice_scatter_default_3251 = slice_scatter_default_3252 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3253, 1, 6496, 6512)
        slice_26844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26843, 2, 0, 16);  slice_26843 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3253, 1, 6496, 6512)
        slice_scatter_default_3254: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1627, slice_26844, 2, 0, 16);  slice_tensor_1627 = slice_26844 = None
        slice_scatter_default_3255: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3253, slice_scatter_default_3254, 1, 6496, 6512);  slice_scatter_default_3253 = slice_scatter_default_3254 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26863: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6512, 6528)
        slice_26864: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26863, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_817: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26864, memory_format = torch.contiguous_format);  slice_26864 = None
        view_1638: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_817, [32, 16]);  clone_817 = None
        mm_814: "f32[32, 8]" = torch.ops.aten.mm.default(view_1638, slice_7)
        view_1639: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_814, [2, 16, 8]);  mm_814 = None
        slice_26871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3255, 1, 6512, 6528)
        slice_26872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26871, 2, 0, 16);  slice_26871 = None
        add_816: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26872, view_1639);  slice_26872 = view_1639 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3255, 1, 6512, 6528)
        slice_scatter_default_3256: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1628, add_816, 2, 0, 16);  slice_tensor_1628 = add_816 = None
        slice_scatter_default_3257: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3255, slice_scatter_default_3256, 1, 6512, 6528);  slice_scatter_default_3255 = slice_scatter_default_3256 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3257, 1, 6512, 6528)
        slice_26877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26876, 2, 0, 16);  slice_26876 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3257, 1, 6512, 6528)
        slice_scatter_default_3258: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1629, slice_26877, 2, 0, 16);  slice_tensor_1629 = slice_26877 = None
        slice_scatter_default_3259: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3257, slice_scatter_default_3258, 1, 6512, 6528);  slice_scatter_default_3257 = slice_scatter_default_3258 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26897: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26863, 2, 16, 32);  slice_26863 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_818: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26897, memory_format = torch.contiguous_format);  slice_26897 = None
        view_1640: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_818, [32, 11]);  clone_818 = None
        mm_815: "f32[32, 8]" = torch.ops.aten.mm.default(view_1640, slice_37)
        view_1641: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_815, [2, 16, 8]);  mm_815 = None
        slice_26904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3259, 1, 6512, 6528)
        slice_26905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26904, 2, 0, 16);  slice_26904 = None
        add_817: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26905, view_1641);  slice_26905 = view_1641 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3259, 1, 6512, 6528)
        slice_scatter_default_3260: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1630, add_817, 2, 0, 16);  slice_tensor_1630 = add_817 = None
        slice_scatter_default_3261: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3259, slice_scatter_default_3260, 1, 6512, 6528);  slice_scatter_default_3259 = slice_scatter_default_3260 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3261, 1, 6512, 6528)
        slice_26910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26909, 2, 0, 16);  slice_26909 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3261, 1, 6512, 6528)
        slice_scatter_default_3262: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1631, slice_26910, 2, 0, 16);  slice_tensor_1631 = slice_26910 = None
        slice_scatter_default_3263: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3261, slice_scatter_default_3262, 1, 6512, 6528);  slice_scatter_default_3261 = slice_scatter_default_3262 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26929: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6528, 6544)
        slice_26930: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26929, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_819: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26930, memory_format = torch.contiguous_format);  slice_26930 = None
        view_1642: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_819, [32, 16]);  clone_819 = None
        mm_816: "f32[32, 8]" = torch.ops.aten.mm.default(view_1642, slice_7)
        view_1643: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_816, [2, 16, 8]);  mm_816 = None
        slice_26937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3263, 1, 6528, 6544)
        slice_26938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26937, 2, 0, 16);  slice_26937 = None
        add_818: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26938, view_1643);  slice_26938 = view_1643 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3263, 1, 6528, 6544)
        slice_scatter_default_3264: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1632, add_818, 2, 0, 16);  slice_tensor_1632 = add_818 = None
        slice_scatter_default_3265: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3263, slice_scatter_default_3264, 1, 6528, 6544);  slice_scatter_default_3263 = slice_scatter_default_3264 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3265, 1, 6528, 6544)
        slice_26943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26942, 2, 0, 16);  slice_26942 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3265, 1, 6528, 6544)
        slice_scatter_default_3266: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1633, slice_26943, 2, 0, 16);  slice_tensor_1633 = slice_26943 = None
        slice_scatter_default_3267: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3265, slice_scatter_default_3266, 1, 6528, 6544);  slice_scatter_default_3265 = slice_scatter_default_3266 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26963: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26929, 2, 16, 32);  slice_26929 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_820: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_26963, memory_format = torch.contiguous_format);  slice_26963 = None
        view_1644: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_820, [32, 11]);  clone_820 = None
        mm_817: "f32[32, 8]" = torch.ops.aten.mm.default(view_1644, slice_37)
        view_1645: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_817, [2, 16, 8]);  mm_817 = None
        slice_26970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3267, 1, 6528, 6544)
        slice_26971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26970, 2, 0, 16);  slice_26970 = None
        add_819: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_26971, view_1645);  slice_26971 = view_1645 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3267, 1, 6528, 6544)
        slice_scatter_default_3268: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1634, add_819, 2, 0, 16);  slice_tensor_1634 = add_819 = None
        slice_scatter_default_3269: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3267, slice_scatter_default_3268, 1, 6528, 6544);  slice_scatter_default_3267 = slice_scatter_default_3268 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_26975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3269, 1, 6528, 6544)
        slice_26976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_26975, 2, 0, 16);  slice_26975 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3269, 1, 6528, 6544)
        slice_scatter_default_3270: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1635, slice_26976, 2, 0, 16);  slice_tensor_1635 = slice_26976 = None
        slice_scatter_default_3271: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3269, slice_scatter_default_3270, 1, 6528, 6544);  slice_scatter_default_3269 = slice_scatter_default_3270 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_26995: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6544, 6560)
        slice_26996: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_26995, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_821: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_26996, memory_format = torch.contiguous_format);  slice_26996 = None
        view_1646: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_821, [32, 16]);  clone_821 = None
        mm_818: "f32[32, 8]" = torch.ops.aten.mm.default(view_1646, slice_7)
        view_1647: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_818, [2, 16, 8]);  mm_818 = None
        slice_27003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3271, 1, 6544, 6560)
        slice_27004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27003, 2, 0, 16);  slice_27003 = None
        add_820: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27004, view_1647);  slice_27004 = view_1647 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3271, 1, 6544, 6560)
        slice_scatter_default_3272: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1636, add_820, 2, 0, 16);  slice_tensor_1636 = add_820 = None
        slice_scatter_default_3273: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3271, slice_scatter_default_3272, 1, 6544, 6560);  slice_scatter_default_3271 = slice_scatter_default_3272 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3273, 1, 6544, 6560)
        slice_27009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27008, 2, 0, 16);  slice_27008 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3273, 1, 6544, 6560)
        slice_scatter_default_3274: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1637, slice_27009, 2, 0, 16);  slice_tensor_1637 = slice_27009 = None
        slice_scatter_default_3275: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3273, slice_scatter_default_3274, 1, 6544, 6560);  slice_scatter_default_3273 = slice_scatter_default_3274 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27029: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_26995, 2, 16, 32);  slice_26995 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_822: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27029, memory_format = torch.contiguous_format);  slice_27029 = None
        view_1648: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_822, [32, 11]);  clone_822 = None
        mm_819: "f32[32, 8]" = torch.ops.aten.mm.default(view_1648, slice_37)
        view_1649: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_819, [2, 16, 8]);  mm_819 = None
        slice_27036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3275, 1, 6544, 6560)
        slice_27037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27036, 2, 0, 16);  slice_27036 = None
        add_821: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27037, view_1649);  slice_27037 = view_1649 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3275, 1, 6544, 6560)
        slice_scatter_default_3276: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1638, add_821, 2, 0, 16);  slice_tensor_1638 = add_821 = None
        slice_scatter_default_3277: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3275, slice_scatter_default_3276, 1, 6544, 6560);  slice_scatter_default_3275 = slice_scatter_default_3276 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3277, 1, 6544, 6560)
        slice_27042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27041, 2, 0, 16);  slice_27041 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3277, 1, 6544, 6560)
        slice_scatter_default_3278: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1639, slice_27042, 2, 0, 16);  slice_tensor_1639 = slice_27042 = None
        slice_scatter_default_3279: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3277, slice_scatter_default_3278, 1, 6544, 6560);  slice_scatter_default_3277 = slice_scatter_default_3278 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27061: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6560, 6576)
        slice_27062: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27061, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_823: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27062, memory_format = torch.contiguous_format);  slice_27062 = None
        view_1650: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_823, [32, 16]);  clone_823 = None
        mm_820: "f32[32, 8]" = torch.ops.aten.mm.default(view_1650, slice_7)
        view_1651: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_820, [2, 16, 8]);  mm_820 = None
        slice_27069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3279, 1, 6560, 6576)
        slice_27070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27069, 2, 0, 16);  slice_27069 = None
        add_822: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27070, view_1651);  slice_27070 = view_1651 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3279, 1, 6560, 6576)
        slice_scatter_default_3280: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1640, add_822, 2, 0, 16);  slice_tensor_1640 = add_822 = None
        slice_scatter_default_3281: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3279, slice_scatter_default_3280, 1, 6560, 6576);  slice_scatter_default_3279 = slice_scatter_default_3280 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3281, 1, 6560, 6576)
        slice_27075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27074, 2, 0, 16);  slice_27074 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3281, 1, 6560, 6576)
        slice_scatter_default_3282: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1641, slice_27075, 2, 0, 16);  slice_tensor_1641 = slice_27075 = None
        slice_scatter_default_3283: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3281, slice_scatter_default_3282, 1, 6560, 6576);  slice_scatter_default_3281 = slice_scatter_default_3282 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27095: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27061, 2, 16, 32);  slice_27061 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_824: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27095, memory_format = torch.contiguous_format);  slice_27095 = None
        view_1652: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_824, [32, 11]);  clone_824 = None
        mm_821: "f32[32, 8]" = torch.ops.aten.mm.default(view_1652, slice_37)
        view_1653: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_821, [2, 16, 8]);  mm_821 = None
        slice_27102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3283, 1, 6560, 6576)
        slice_27103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27102, 2, 0, 16);  slice_27102 = None
        add_823: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27103, view_1653);  slice_27103 = view_1653 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3283, 1, 6560, 6576)
        slice_scatter_default_3284: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1642, add_823, 2, 0, 16);  slice_tensor_1642 = add_823 = None
        slice_scatter_default_3285: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3283, slice_scatter_default_3284, 1, 6560, 6576);  slice_scatter_default_3283 = slice_scatter_default_3284 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3285, 1, 6560, 6576)
        slice_27108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27107, 2, 0, 16);  slice_27107 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3285, 1, 6560, 6576)
        slice_scatter_default_3286: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1643, slice_27108, 2, 0, 16);  slice_tensor_1643 = slice_27108 = None
        slice_scatter_default_3287: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3285, slice_scatter_default_3286, 1, 6560, 6576);  slice_scatter_default_3285 = slice_scatter_default_3286 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27127: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6576, 6592)
        slice_27128: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27127, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_825: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27128, memory_format = torch.contiguous_format);  slice_27128 = None
        view_1654: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_825, [32, 16]);  clone_825 = None
        mm_822: "f32[32, 8]" = torch.ops.aten.mm.default(view_1654, slice_7)
        view_1655: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_822, [2, 16, 8]);  mm_822 = None
        slice_27135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3287, 1, 6576, 6592)
        slice_27136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27135, 2, 0, 16);  slice_27135 = None
        add_824: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27136, view_1655);  slice_27136 = view_1655 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3287, 1, 6576, 6592)
        slice_scatter_default_3288: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1644, add_824, 2, 0, 16);  slice_tensor_1644 = add_824 = None
        slice_scatter_default_3289: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3287, slice_scatter_default_3288, 1, 6576, 6592);  slice_scatter_default_3287 = slice_scatter_default_3288 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3289, 1, 6576, 6592)
        slice_27141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27140, 2, 0, 16);  slice_27140 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3289, 1, 6576, 6592)
        slice_scatter_default_3290: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1645, slice_27141, 2, 0, 16);  slice_tensor_1645 = slice_27141 = None
        slice_scatter_default_3291: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3289, slice_scatter_default_3290, 1, 6576, 6592);  slice_scatter_default_3289 = slice_scatter_default_3290 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27161: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27127, 2, 16, 32);  slice_27127 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_826: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27161, memory_format = torch.contiguous_format);  slice_27161 = None
        view_1656: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_826, [32, 11]);  clone_826 = None
        mm_823: "f32[32, 8]" = torch.ops.aten.mm.default(view_1656, slice_37)
        view_1657: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_823, [2, 16, 8]);  mm_823 = None
        slice_27168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3291, 1, 6576, 6592)
        slice_27169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27168, 2, 0, 16);  slice_27168 = None
        add_825: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27169, view_1657);  slice_27169 = view_1657 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3291, 1, 6576, 6592)
        slice_scatter_default_3292: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1646, add_825, 2, 0, 16);  slice_tensor_1646 = add_825 = None
        slice_scatter_default_3293: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3291, slice_scatter_default_3292, 1, 6576, 6592);  slice_scatter_default_3291 = slice_scatter_default_3292 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3293, 1, 6576, 6592)
        slice_27174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27173, 2, 0, 16);  slice_27173 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3293, 1, 6576, 6592)
        slice_scatter_default_3294: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1647, slice_27174, 2, 0, 16);  slice_tensor_1647 = slice_27174 = None
        slice_scatter_default_3295: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3293, slice_scatter_default_3294, 1, 6576, 6592);  slice_scatter_default_3293 = slice_scatter_default_3294 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27193: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6592, 6608)
        slice_27194: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27193, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_827: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27194, memory_format = torch.contiguous_format);  slice_27194 = None
        view_1658: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_827, [32, 16]);  clone_827 = None
        mm_824: "f32[32, 8]" = torch.ops.aten.mm.default(view_1658, slice_7)
        view_1659: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_824, [2, 16, 8]);  mm_824 = None
        slice_27201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3295, 1, 6592, 6608)
        slice_27202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27201, 2, 0, 16);  slice_27201 = None
        add_826: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27202, view_1659);  slice_27202 = view_1659 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3295, 1, 6592, 6608)
        slice_scatter_default_3296: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1648, add_826, 2, 0, 16);  slice_tensor_1648 = add_826 = None
        slice_scatter_default_3297: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3295, slice_scatter_default_3296, 1, 6592, 6608);  slice_scatter_default_3295 = slice_scatter_default_3296 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3297, 1, 6592, 6608)
        slice_27207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27206, 2, 0, 16);  slice_27206 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3297, 1, 6592, 6608)
        slice_scatter_default_3298: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1649, slice_27207, 2, 0, 16);  slice_tensor_1649 = slice_27207 = None
        slice_scatter_default_3299: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3297, slice_scatter_default_3298, 1, 6592, 6608);  slice_scatter_default_3297 = slice_scatter_default_3298 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27227: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27193, 2, 16, 32);  slice_27193 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_828: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27227, memory_format = torch.contiguous_format);  slice_27227 = None
        view_1660: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_828, [32, 11]);  clone_828 = None
        mm_825: "f32[32, 8]" = torch.ops.aten.mm.default(view_1660, slice_37)
        view_1661: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_825, [2, 16, 8]);  mm_825 = None
        slice_27234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3299, 1, 6592, 6608)
        slice_27235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27234, 2, 0, 16);  slice_27234 = None
        add_827: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27235, view_1661);  slice_27235 = view_1661 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3299, 1, 6592, 6608)
        slice_scatter_default_3300: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1650, add_827, 2, 0, 16);  slice_tensor_1650 = add_827 = None
        slice_scatter_default_3301: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3299, slice_scatter_default_3300, 1, 6592, 6608);  slice_scatter_default_3299 = slice_scatter_default_3300 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3301, 1, 6592, 6608)
        slice_27240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27239, 2, 0, 16);  slice_27239 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3301, 1, 6592, 6608)
        slice_scatter_default_3302: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1651, slice_27240, 2, 0, 16);  slice_tensor_1651 = slice_27240 = None
        slice_scatter_default_3303: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3301, slice_scatter_default_3302, 1, 6592, 6608);  slice_scatter_default_3301 = slice_scatter_default_3302 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27259: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6608, 6624)
        slice_27260: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27259, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_829: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27260, memory_format = torch.contiguous_format);  slice_27260 = None
        view_1662: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_829, [32, 16]);  clone_829 = None
        mm_826: "f32[32, 8]" = torch.ops.aten.mm.default(view_1662, slice_7)
        view_1663: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_826, [2, 16, 8]);  mm_826 = None
        slice_27267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3303, 1, 6608, 6624)
        slice_27268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27267, 2, 0, 16);  slice_27267 = None
        add_828: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27268, view_1663);  slice_27268 = view_1663 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3303, 1, 6608, 6624)
        slice_scatter_default_3304: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1652, add_828, 2, 0, 16);  slice_tensor_1652 = add_828 = None
        slice_scatter_default_3305: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3303, slice_scatter_default_3304, 1, 6608, 6624);  slice_scatter_default_3303 = slice_scatter_default_3304 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3305, 1, 6608, 6624)
        slice_27273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27272, 2, 0, 16);  slice_27272 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3305, 1, 6608, 6624)
        slice_scatter_default_3306: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1653, slice_27273, 2, 0, 16);  slice_tensor_1653 = slice_27273 = None
        slice_scatter_default_3307: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3305, slice_scatter_default_3306, 1, 6608, 6624);  slice_scatter_default_3305 = slice_scatter_default_3306 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27293: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27259, 2, 16, 32);  slice_27259 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_830: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27293, memory_format = torch.contiguous_format);  slice_27293 = None
        view_1664: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_830, [32, 11]);  clone_830 = None
        mm_827: "f32[32, 8]" = torch.ops.aten.mm.default(view_1664, slice_37)
        view_1665: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_827, [2, 16, 8]);  mm_827 = None
        slice_27300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3307, 1, 6608, 6624)
        slice_27301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27300, 2, 0, 16);  slice_27300 = None
        add_829: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27301, view_1665);  slice_27301 = view_1665 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3307, 1, 6608, 6624)
        slice_scatter_default_3308: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1654, add_829, 2, 0, 16);  slice_tensor_1654 = add_829 = None
        slice_scatter_default_3309: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3307, slice_scatter_default_3308, 1, 6608, 6624);  slice_scatter_default_3307 = slice_scatter_default_3308 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3309, 1, 6608, 6624)
        slice_27306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27305, 2, 0, 16);  slice_27305 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3309, 1, 6608, 6624)
        slice_scatter_default_3310: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1655, slice_27306, 2, 0, 16);  slice_tensor_1655 = slice_27306 = None
        slice_scatter_default_3311: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3309, slice_scatter_default_3310, 1, 6608, 6624);  slice_scatter_default_3309 = slice_scatter_default_3310 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27325: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6624, 6640)
        slice_27326: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27325, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_831: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27326, memory_format = torch.contiguous_format);  slice_27326 = None
        view_1666: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_831, [32, 16]);  clone_831 = None
        mm_828: "f32[32, 8]" = torch.ops.aten.mm.default(view_1666, slice_7)
        view_1667: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_828, [2, 16, 8]);  mm_828 = None
        slice_27333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3311, 1, 6624, 6640)
        slice_27334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27333, 2, 0, 16);  slice_27333 = None
        add_830: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27334, view_1667);  slice_27334 = view_1667 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3311, 1, 6624, 6640)
        slice_scatter_default_3312: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1656, add_830, 2, 0, 16);  slice_tensor_1656 = add_830 = None
        slice_scatter_default_3313: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3311, slice_scatter_default_3312, 1, 6624, 6640);  slice_scatter_default_3311 = slice_scatter_default_3312 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3313, 1, 6624, 6640)
        slice_27339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27338, 2, 0, 16);  slice_27338 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3313, 1, 6624, 6640)
        slice_scatter_default_3314: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1657, slice_27339, 2, 0, 16);  slice_tensor_1657 = slice_27339 = None
        slice_scatter_default_3315: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3313, slice_scatter_default_3314, 1, 6624, 6640);  slice_scatter_default_3313 = slice_scatter_default_3314 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27359: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27325, 2, 16, 32);  slice_27325 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_832: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27359, memory_format = torch.contiguous_format);  slice_27359 = None
        view_1668: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_832, [32, 11]);  clone_832 = None
        mm_829: "f32[32, 8]" = torch.ops.aten.mm.default(view_1668, slice_37)
        view_1669: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_829, [2, 16, 8]);  mm_829 = None
        slice_27366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3315, 1, 6624, 6640)
        slice_27367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27366, 2, 0, 16);  slice_27366 = None
        add_831: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27367, view_1669);  slice_27367 = view_1669 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3315, 1, 6624, 6640)
        slice_scatter_default_3316: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1658, add_831, 2, 0, 16);  slice_tensor_1658 = add_831 = None
        slice_scatter_default_3317: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3315, slice_scatter_default_3316, 1, 6624, 6640);  slice_scatter_default_3315 = slice_scatter_default_3316 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3317, 1, 6624, 6640)
        slice_27372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27371, 2, 0, 16);  slice_27371 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3317, 1, 6624, 6640)
        slice_scatter_default_3318: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1659, slice_27372, 2, 0, 16);  slice_tensor_1659 = slice_27372 = None
        slice_scatter_default_3319: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3317, slice_scatter_default_3318, 1, 6624, 6640);  slice_scatter_default_3317 = slice_scatter_default_3318 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27391: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6640, 6656)
        slice_27392: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27391, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_833: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27392, memory_format = torch.contiguous_format);  slice_27392 = None
        view_1670: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_833, [32, 16]);  clone_833 = None
        mm_830: "f32[32, 8]" = torch.ops.aten.mm.default(view_1670, slice_7)
        view_1671: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_830, [2, 16, 8]);  mm_830 = None
        slice_27399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3319, 1, 6640, 6656)
        slice_27400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27399, 2, 0, 16);  slice_27399 = None
        add_832: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27400, view_1671);  slice_27400 = view_1671 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3319, 1, 6640, 6656)
        slice_scatter_default_3320: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1660, add_832, 2, 0, 16);  slice_tensor_1660 = add_832 = None
        slice_scatter_default_3321: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3319, slice_scatter_default_3320, 1, 6640, 6656);  slice_scatter_default_3319 = slice_scatter_default_3320 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3321, 1, 6640, 6656)
        slice_27405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27404, 2, 0, 16);  slice_27404 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3321, 1, 6640, 6656)
        slice_scatter_default_3322: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1661, slice_27405, 2, 0, 16);  slice_tensor_1661 = slice_27405 = None
        slice_scatter_default_3323: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3321, slice_scatter_default_3322, 1, 6640, 6656);  slice_scatter_default_3321 = slice_scatter_default_3322 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27425: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27391, 2, 16, 32);  slice_27391 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_834: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27425, memory_format = torch.contiguous_format);  slice_27425 = None
        view_1672: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_834, [32, 11]);  clone_834 = None
        mm_831: "f32[32, 8]" = torch.ops.aten.mm.default(view_1672, slice_37)
        view_1673: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_831, [2, 16, 8]);  mm_831 = None
        slice_27432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3323, 1, 6640, 6656)
        slice_27433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27432, 2, 0, 16);  slice_27432 = None
        add_833: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27433, view_1673);  slice_27433 = view_1673 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3323, 1, 6640, 6656)
        slice_scatter_default_3324: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1662, add_833, 2, 0, 16);  slice_tensor_1662 = add_833 = None
        slice_scatter_default_3325: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3323, slice_scatter_default_3324, 1, 6640, 6656);  slice_scatter_default_3323 = slice_scatter_default_3324 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3325, 1, 6640, 6656)
        slice_27438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27437, 2, 0, 16);  slice_27437 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3325, 1, 6640, 6656)
        slice_scatter_default_3326: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1663, slice_27438, 2, 0, 16);  slice_tensor_1663 = slice_27438 = None
        slice_scatter_default_3327: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3325, slice_scatter_default_3326, 1, 6640, 6656);  slice_scatter_default_3325 = slice_scatter_default_3326 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27457: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6656, 6672)
        slice_27458: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27457, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_835: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27458, memory_format = torch.contiguous_format);  slice_27458 = None
        view_1674: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_835, [32, 16]);  clone_835 = None
        mm_832: "f32[32, 8]" = torch.ops.aten.mm.default(view_1674, slice_7)
        view_1675: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_832, [2, 16, 8]);  mm_832 = None
        slice_27465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3327, 1, 6656, 6672)
        slice_27466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27465, 2, 0, 16);  slice_27465 = None
        add_834: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27466, view_1675);  slice_27466 = view_1675 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3327, 1, 6656, 6672)
        slice_scatter_default_3328: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1664, add_834, 2, 0, 16);  slice_tensor_1664 = add_834 = None
        slice_scatter_default_3329: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3327, slice_scatter_default_3328, 1, 6656, 6672);  slice_scatter_default_3327 = slice_scatter_default_3328 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3329, 1, 6656, 6672)
        slice_27471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27470, 2, 0, 16);  slice_27470 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3329, 1, 6656, 6672)
        slice_scatter_default_3330: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1665, slice_27471, 2, 0, 16);  slice_tensor_1665 = slice_27471 = None
        slice_scatter_default_3331: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3329, slice_scatter_default_3330, 1, 6656, 6672);  slice_scatter_default_3329 = slice_scatter_default_3330 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27491: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27457, 2, 16, 32);  slice_27457 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_836: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27491, memory_format = torch.contiguous_format);  slice_27491 = None
        view_1676: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_836, [32, 11]);  clone_836 = None
        mm_833: "f32[32, 8]" = torch.ops.aten.mm.default(view_1676, slice_37)
        view_1677: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_833, [2, 16, 8]);  mm_833 = None
        slice_27498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3331, 1, 6656, 6672)
        slice_27499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27498, 2, 0, 16);  slice_27498 = None
        add_835: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27499, view_1677);  slice_27499 = view_1677 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3331, 1, 6656, 6672)
        slice_scatter_default_3332: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1666, add_835, 2, 0, 16);  slice_tensor_1666 = add_835 = None
        slice_scatter_default_3333: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3331, slice_scatter_default_3332, 1, 6656, 6672);  slice_scatter_default_3331 = slice_scatter_default_3332 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3333, 1, 6656, 6672)
        slice_27504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27503, 2, 0, 16);  slice_27503 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3333, 1, 6656, 6672)
        slice_scatter_default_3334: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1667, slice_27504, 2, 0, 16);  slice_tensor_1667 = slice_27504 = None
        slice_scatter_default_3335: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3333, slice_scatter_default_3334, 1, 6656, 6672);  slice_scatter_default_3333 = slice_scatter_default_3334 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27523: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6672, 6688)
        slice_27524: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27523, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_837: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27524, memory_format = torch.contiguous_format);  slice_27524 = None
        view_1678: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_837, [32, 16]);  clone_837 = None
        mm_834: "f32[32, 8]" = torch.ops.aten.mm.default(view_1678, slice_7)
        view_1679: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_834, [2, 16, 8]);  mm_834 = None
        slice_27531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3335, 1, 6672, 6688)
        slice_27532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27531, 2, 0, 16);  slice_27531 = None
        add_836: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27532, view_1679);  slice_27532 = view_1679 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3335, 1, 6672, 6688)
        slice_scatter_default_3336: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1668, add_836, 2, 0, 16);  slice_tensor_1668 = add_836 = None
        slice_scatter_default_3337: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3335, slice_scatter_default_3336, 1, 6672, 6688);  slice_scatter_default_3335 = slice_scatter_default_3336 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3337, 1, 6672, 6688)
        slice_27537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27536, 2, 0, 16);  slice_27536 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3337, 1, 6672, 6688)
        slice_scatter_default_3338: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1669, slice_27537, 2, 0, 16);  slice_tensor_1669 = slice_27537 = None
        slice_scatter_default_3339: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3337, slice_scatter_default_3338, 1, 6672, 6688);  slice_scatter_default_3337 = slice_scatter_default_3338 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27557: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27523, 2, 16, 32);  slice_27523 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_838: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27557, memory_format = torch.contiguous_format);  slice_27557 = None
        view_1680: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_838, [32, 11]);  clone_838 = None
        mm_835: "f32[32, 8]" = torch.ops.aten.mm.default(view_1680, slice_37)
        view_1681: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_835, [2, 16, 8]);  mm_835 = None
        slice_27564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3339, 1, 6672, 6688)
        slice_27565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27564, 2, 0, 16);  slice_27564 = None
        add_837: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27565, view_1681);  slice_27565 = view_1681 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3339, 1, 6672, 6688)
        slice_scatter_default_3340: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1670, add_837, 2, 0, 16);  slice_tensor_1670 = add_837 = None
        slice_scatter_default_3341: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3339, slice_scatter_default_3340, 1, 6672, 6688);  slice_scatter_default_3339 = slice_scatter_default_3340 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3341, 1, 6672, 6688)
        slice_27570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27569, 2, 0, 16);  slice_27569 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3341, 1, 6672, 6688)
        slice_scatter_default_3342: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1671, slice_27570, 2, 0, 16);  slice_tensor_1671 = slice_27570 = None
        slice_scatter_default_3343: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3341, slice_scatter_default_3342, 1, 6672, 6688);  slice_scatter_default_3341 = slice_scatter_default_3342 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27589: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6688, 6704)
        slice_27590: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27589, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_839: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27590, memory_format = torch.contiguous_format);  slice_27590 = None
        view_1682: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_839, [32, 16]);  clone_839 = None
        mm_836: "f32[32, 8]" = torch.ops.aten.mm.default(view_1682, slice_7)
        view_1683: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_836, [2, 16, 8]);  mm_836 = None
        slice_27597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3343, 1, 6688, 6704)
        slice_27598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27597, 2, 0, 16);  slice_27597 = None
        add_838: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27598, view_1683);  slice_27598 = view_1683 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3343, 1, 6688, 6704)
        slice_scatter_default_3344: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1672, add_838, 2, 0, 16);  slice_tensor_1672 = add_838 = None
        slice_scatter_default_3345: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3343, slice_scatter_default_3344, 1, 6688, 6704);  slice_scatter_default_3343 = slice_scatter_default_3344 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3345, 1, 6688, 6704)
        slice_27603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27602, 2, 0, 16);  slice_27602 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3345, 1, 6688, 6704)
        slice_scatter_default_3346: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1673, slice_27603, 2, 0, 16);  slice_tensor_1673 = slice_27603 = None
        slice_scatter_default_3347: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3345, slice_scatter_default_3346, 1, 6688, 6704);  slice_scatter_default_3345 = slice_scatter_default_3346 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27623: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27589, 2, 16, 32);  slice_27589 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_840: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27623, memory_format = torch.contiguous_format);  slice_27623 = None
        view_1684: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_840, [32, 11]);  clone_840 = None
        mm_837: "f32[32, 8]" = torch.ops.aten.mm.default(view_1684, slice_37)
        view_1685: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_837, [2, 16, 8]);  mm_837 = None
        slice_27630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3347, 1, 6688, 6704)
        slice_27631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27630, 2, 0, 16);  slice_27630 = None
        add_839: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27631, view_1685);  slice_27631 = view_1685 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3347, 1, 6688, 6704)
        slice_scatter_default_3348: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1674, add_839, 2, 0, 16);  slice_tensor_1674 = add_839 = None
        slice_scatter_default_3349: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3347, slice_scatter_default_3348, 1, 6688, 6704);  slice_scatter_default_3347 = slice_scatter_default_3348 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3349, 1, 6688, 6704)
        slice_27636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27635, 2, 0, 16);  slice_27635 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3349, 1, 6688, 6704)
        slice_scatter_default_3350: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1675, slice_27636, 2, 0, 16);  slice_tensor_1675 = slice_27636 = None
        slice_scatter_default_3351: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3349, slice_scatter_default_3350, 1, 6688, 6704);  slice_scatter_default_3349 = slice_scatter_default_3350 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27655: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6704, 6720)
        slice_27656: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27655, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_841: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27656, memory_format = torch.contiguous_format);  slice_27656 = None
        view_1686: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_841, [32, 16]);  clone_841 = None
        mm_838: "f32[32, 8]" = torch.ops.aten.mm.default(view_1686, slice_7)
        view_1687: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_838, [2, 16, 8]);  mm_838 = None
        slice_27663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3351, 1, 6704, 6720)
        slice_27664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27663, 2, 0, 16);  slice_27663 = None
        add_840: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27664, view_1687);  slice_27664 = view_1687 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3351, 1, 6704, 6720)
        slice_scatter_default_3352: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1676, add_840, 2, 0, 16);  slice_tensor_1676 = add_840 = None
        slice_scatter_default_3353: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3351, slice_scatter_default_3352, 1, 6704, 6720);  slice_scatter_default_3351 = slice_scatter_default_3352 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3353, 1, 6704, 6720)
        slice_27669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27668, 2, 0, 16);  slice_27668 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3353, 1, 6704, 6720)
        slice_scatter_default_3354: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1677, slice_27669, 2, 0, 16);  slice_tensor_1677 = slice_27669 = None
        slice_scatter_default_3355: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3353, slice_scatter_default_3354, 1, 6704, 6720);  slice_scatter_default_3353 = slice_scatter_default_3354 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27689: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27655, 2, 16, 32);  slice_27655 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_842: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27689, memory_format = torch.contiguous_format);  slice_27689 = None
        view_1688: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_842, [32, 11]);  clone_842 = None
        mm_839: "f32[32, 8]" = torch.ops.aten.mm.default(view_1688, slice_37)
        view_1689: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_839, [2, 16, 8]);  mm_839 = None
        slice_27696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3355, 1, 6704, 6720)
        slice_27697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27696, 2, 0, 16);  slice_27696 = None
        add_841: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27697, view_1689);  slice_27697 = view_1689 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3355, 1, 6704, 6720)
        slice_scatter_default_3356: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1678, add_841, 2, 0, 16);  slice_tensor_1678 = add_841 = None
        slice_scatter_default_3357: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3355, slice_scatter_default_3356, 1, 6704, 6720);  slice_scatter_default_3355 = slice_scatter_default_3356 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3357, 1, 6704, 6720)
        slice_27702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27701, 2, 0, 16);  slice_27701 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3357, 1, 6704, 6720)
        slice_scatter_default_3358: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1679, slice_27702, 2, 0, 16);  slice_tensor_1679 = slice_27702 = None
        slice_scatter_default_3359: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3357, slice_scatter_default_3358, 1, 6704, 6720);  slice_scatter_default_3357 = slice_scatter_default_3358 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27721: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6720, 6736)
        slice_27722: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27721, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_843: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27722, memory_format = torch.contiguous_format);  slice_27722 = None
        view_1690: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_843, [32, 16]);  clone_843 = None
        mm_840: "f32[32, 8]" = torch.ops.aten.mm.default(view_1690, slice_7)
        view_1691: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_840, [2, 16, 8]);  mm_840 = None
        slice_27729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3359, 1, 6720, 6736)
        slice_27730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27729, 2, 0, 16);  slice_27729 = None
        add_842: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27730, view_1691);  slice_27730 = view_1691 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3359, 1, 6720, 6736)
        slice_scatter_default_3360: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1680, add_842, 2, 0, 16);  slice_tensor_1680 = add_842 = None
        slice_scatter_default_3361: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3359, slice_scatter_default_3360, 1, 6720, 6736);  slice_scatter_default_3359 = slice_scatter_default_3360 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3361, 1, 6720, 6736)
        slice_27735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27734, 2, 0, 16);  slice_27734 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3361, 1, 6720, 6736)
        slice_scatter_default_3362: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1681, slice_27735, 2, 0, 16);  slice_tensor_1681 = slice_27735 = None
        slice_scatter_default_3363: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3361, slice_scatter_default_3362, 1, 6720, 6736);  slice_scatter_default_3361 = slice_scatter_default_3362 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27755: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27721, 2, 16, 32);  slice_27721 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_844: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27755, memory_format = torch.contiguous_format);  slice_27755 = None
        view_1692: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_844, [32, 11]);  clone_844 = None
        mm_841: "f32[32, 8]" = torch.ops.aten.mm.default(view_1692, slice_37)
        view_1693: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_841, [2, 16, 8]);  mm_841 = None
        slice_27762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3363, 1, 6720, 6736)
        slice_27763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27762, 2, 0, 16);  slice_27762 = None
        add_843: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27763, view_1693);  slice_27763 = view_1693 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3363, 1, 6720, 6736)
        slice_scatter_default_3364: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1682, add_843, 2, 0, 16);  slice_tensor_1682 = add_843 = None
        slice_scatter_default_3365: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3363, slice_scatter_default_3364, 1, 6720, 6736);  slice_scatter_default_3363 = slice_scatter_default_3364 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3365, 1, 6720, 6736)
        slice_27768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27767, 2, 0, 16);  slice_27767 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3365, 1, 6720, 6736)
        slice_scatter_default_3366: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1683, slice_27768, 2, 0, 16);  slice_tensor_1683 = slice_27768 = None
        slice_scatter_default_3367: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3365, slice_scatter_default_3366, 1, 6720, 6736);  slice_scatter_default_3365 = slice_scatter_default_3366 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27787: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6736, 6752)
        slice_27788: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27787, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_845: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27788, memory_format = torch.contiguous_format);  slice_27788 = None
        view_1694: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_845, [32, 16]);  clone_845 = None
        mm_842: "f32[32, 8]" = torch.ops.aten.mm.default(view_1694, slice_7)
        view_1695: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_842, [2, 16, 8]);  mm_842 = None
        slice_27795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3367, 1, 6736, 6752)
        slice_27796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27795, 2, 0, 16);  slice_27795 = None
        add_844: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27796, view_1695);  slice_27796 = view_1695 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3367, 1, 6736, 6752)
        slice_scatter_default_3368: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1684, add_844, 2, 0, 16);  slice_tensor_1684 = add_844 = None
        slice_scatter_default_3369: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3367, slice_scatter_default_3368, 1, 6736, 6752);  slice_scatter_default_3367 = slice_scatter_default_3368 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3369, 1, 6736, 6752)
        slice_27801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27800, 2, 0, 16);  slice_27800 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3369, 1, 6736, 6752)
        slice_scatter_default_3370: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1685, slice_27801, 2, 0, 16);  slice_tensor_1685 = slice_27801 = None
        slice_scatter_default_3371: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3369, slice_scatter_default_3370, 1, 6736, 6752);  slice_scatter_default_3369 = slice_scatter_default_3370 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27821: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27787, 2, 16, 32);  slice_27787 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_846: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27821, memory_format = torch.contiguous_format);  slice_27821 = None
        view_1696: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_846, [32, 11]);  clone_846 = None
        mm_843: "f32[32, 8]" = torch.ops.aten.mm.default(view_1696, slice_37)
        view_1697: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_843, [2, 16, 8]);  mm_843 = None
        slice_27828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3371, 1, 6736, 6752)
        slice_27829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27828, 2, 0, 16);  slice_27828 = None
        add_845: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27829, view_1697);  slice_27829 = view_1697 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3371, 1, 6736, 6752)
        slice_scatter_default_3372: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1686, add_845, 2, 0, 16);  slice_tensor_1686 = add_845 = None
        slice_scatter_default_3373: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3371, slice_scatter_default_3372, 1, 6736, 6752);  slice_scatter_default_3371 = slice_scatter_default_3372 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3373, 1, 6736, 6752)
        slice_27834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27833, 2, 0, 16);  slice_27833 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3373, 1, 6736, 6752)
        slice_scatter_default_3374: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1687, slice_27834, 2, 0, 16);  slice_tensor_1687 = slice_27834 = None
        slice_scatter_default_3375: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3373, slice_scatter_default_3374, 1, 6736, 6752);  slice_scatter_default_3373 = slice_scatter_default_3374 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27853: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6752, 6768)
        slice_27854: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27853, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_847: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27854, memory_format = torch.contiguous_format);  slice_27854 = None
        view_1698: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_847, [32, 16]);  clone_847 = None
        mm_844: "f32[32, 8]" = torch.ops.aten.mm.default(view_1698, slice_7)
        view_1699: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_844, [2, 16, 8]);  mm_844 = None
        slice_27861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3375, 1, 6752, 6768)
        slice_27862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27861, 2, 0, 16);  slice_27861 = None
        add_846: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27862, view_1699);  slice_27862 = view_1699 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3375, 1, 6752, 6768)
        slice_scatter_default_3376: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1688, add_846, 2, 0, 16);  slice_tensor_1688 = add_846 = None
        slice_scatter_default_3377: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3375, slice_scatter_default_3376, 1, 6752, 6768);  slice_scatter_default_3375 = slice_scatter_default_3376 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3377, 1, 6752, 6768)
        slice_27867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27866, 2, 0, 16);  slice_27866 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3377, 1, 6752, 6768)
        slice_scatter_default_3378: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1689, slice_27867, 2, 0, 16);  slice_tensor_1689 = slice_27867 = None
        slice_scatter_default_3379: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3377, slice_scatter_default_3378, 1, 6752, 6768);  slice_scatter_default_3377 = slice_scatter_default_3378 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27887: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27853, 2, 16, 32);  slice_27853 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_848: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27887, memory_format = torch.contiguous_format);  slice_27887 = None
        view_1700: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_848, [32, 11]);  clone_848 = None
        mm_845: "f32[32, 8]" = torch.ops.aten.mm.default(view_1700, slice_37)
        view_1701: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_845, [2, 16, 8]);  mm_845 = None
        slice_27894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3379, 1, 6752, 6768)
        slice_27895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27894, 2, 0, 16);  slice_27894 = None
        add_847: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27895, view_1701);  slice_27895 = view_1701 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3379, 1, 6752, 6768)
        slice_scatter_default_3380: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1690, add_847, 2, 0, 16);  slice_tensor_1690 = add_847 = None
        slice_scatter_default_3381: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3379, slice_scatter_default_3380, 1, 6752, 6768);  slice_scatter_default_3379 = slice_scatter_default_3380 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3381, 1, 6752, 6768)
        slice_27900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27899, 2, 0, 16);  slice_27899 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3381, 1, 6752, 6768)
        slice_scatter_default_3382: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1691, slice_27900, 2, 0, 16);  slice_tensor_1691 = slice_27900 = None
        slice_scatter_default_3383: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3381, slice_scatter_default_3382, 1, 6752, 6768);  slice_scatter_default_3381 = slice_scatter_default_3382 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27919: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6768, 6784)
        slice_27920: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27919, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_849: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27920, memory_format = torch.contiguous_format);  slice_27920 = None
        view_1702: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_849, [32, 16]);  clone_849 = None
        mm_846: "f32[32, 8]" = torch.ops.aten.mm.default(view_1702, slice_7)
        view_1703: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_846, [2, 16, 8]);  mm_846 = None
        slice_27927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3383, 1, 6768, 6784)
        slice_27928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27927, 2, 0, 16);  slice_27927 = None
        add_848: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27928, view_1703);  slice_27928 = view_1703 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3383, 1, 6768, 6784)
        slice_scatter_default_3384: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1692, add_848, 2, 0, 16);  slice_tensor_1692 = add_848 = None
        slice_scatter_default_3385: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3383, slice_scatter_default_3384, 1, 6768, 6784);  slice_scatter_default_3383 = slice_scatter_default_3384 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3385, 1, 6768, 6784)
        slice_27933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27932, 2, 0, 16);  slice_27932 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3385, 1, 6768, 6784)
        slice_scatter_default_3386: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1693, slice_27933, 2, 0, 16);  slice_tensor_1693 = slice_27933 = None
        slice_scatter_default_3387: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3385, slice_scatter_default_3386, 1, 6768, 6784);  slice_scatter_default_3385 = slice_scatter_default_3386 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27953: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27919, 2, 16, 32);  slice_27919 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_850: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_27953, memory_format = torch.contiguous_format);  slice_27953 = None
        view_1704: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_850, [32, 11]);  clone_850 = None
        mm_847: "f32[32, 8]" = torch.ops.aten.mm.default(view_1704, slice_37)
        view_1705: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_847, [2, 16, 8]);  mm_847 = None
        slice_27960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3387, 1, 6768, 6784)
        slice_27961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27960, 2, 0, 16);  slice_27960 = None
        add_849: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27961, view_1705);  slice_27961 = view_1705 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3387, 1, 6768, 6784)
        slice_scatter_default_3388: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1694, add_849, 2, 0, 16);  slice_tensor_1694 = add_849 = None
        slice_scatter_default_3389: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3387, slice_scatter_default_3388, 1, 6768, 6784);  slice_scatter_default_3387 = slice_scatter_default_3388 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3389, 1, 6768, 6784)
        slice_27966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27965, 2, 0, 16);  slice_27965 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3389, 1, 6768, 6784)
        slice_scatter_default_3390: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1695, slice_27966, 2, 0, 16);  slice_tensor_1695 = slice_27966 = None
        slice_scatter_default_3391: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3389, slice_scatter_default_3390, 1, 6768, 6784);  slice_scatter_default_3389 = slice_scatter_default_3390 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_27985: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6784, 6800)
        slice_27986: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_27985, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_851: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_27986, memory_format = torch.contiguous_format);  slice_27986 = None
        view_1706: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_851, [32, 16]);  clone_851 = None
        mm_848: "f32[32, 8]" = torch.ops.aten.mm.default(view_1706, slice_7)
        view_1707: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_848, [2, 16, 8]);  mm_848 = None
        slice_27993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3391, 1, 6784, 6800)
        slice_27994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27993, 2, 0, 16);  slice_27993 = None
        add_850: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_27994, view_1707);  slice_27994 = view_1707 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3391, 1, 6784, 6800)
        slice_scatter_default_3392: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1696, add_850, 2, 0, 16);  slice_tensor_1696 = add_850 = None
        slice_scatter_default_3393: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3391, slice_scatter_default_3392, 1, 6784, 6800);  slice_scatter_default_3391 = slice_scatter_default_3392 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_27998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3393, 1, 6784, 6800)
        slice_27999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_27998, 2, 0, 16);  slice_27998 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3393, 1, 6784, 6800)
        slice_scatter_default_3394: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1697, slice_27999, 2, 0, 16);  slice_tensor_1697 = slice_27999 = None
        slice_scatter_default_3395: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3393, slice_scatter_default_3394, 1, 6784, 6800);  slice_scatter_default_3393 = slice_scatter_default_3394 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28019: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_27985, 2, 16, 32);  slice_27985 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_852: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28019, memory_format = torch.contiguous_format);  slice_28019 = None
        view_1708: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_852, [32, 11]);  clone_852 = None
        mm_849: "f32[32, 8]" = torch.ops.aten.mm.default(view_1708, slice_37)
        view_1709: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_849, [2, 16, 8]);  mm_849 = None
        slice_28026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3395, 1, 6784, 6800)
        slice_28027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28026, 2, 0, 16);  slice_28026 = None
        add_851: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28027, view_1709);  slice_28027 = view_1709 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3395, 1, 6784, 6800)
        slice_scatter_default_3396: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1698, add_851, 2, 0, 16);  slice_tensor_1698 = add_851 = None
        slice_scatter_default_3397: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3395, slice_scatter_default_3396, 1, 6784, 6800);  slice_scatter_default_3395 = slice_scatter_default_3396 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3397, 1, 6784, 6800)
        slice_28032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28031, 2, 0, 16);  slice_28031 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3397, 1, 6784, 6800)
        slice_scatter_default_3398: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1699, slice_28032, 2, 0, 16);  slice_tensor_1699 = slice_28032 = None
        slice_scatter_default_3399: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3397, slice_scatter_default_3398, 1, 6784, 6800);  slice_scatter_default_3397 = slice_scatter_default_3398 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28051: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6800, 6816)
        slice_28052: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28051, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_853: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28052, memory_format = torch.contiguous_format);  slice_28052 = None
        view_1710: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_853, [32, 16]);  clone_853 = None
        mm_850: "f32[32, 8]" = torch.ops.aten.mm.default(view_1710, slice_7)
        view_1711: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_850, [2, 16, 8]);  mm_850 = None
        slice_28059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3399, 1, 6800, 6816)
        slice_28060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28059, 2, 0, 16);  slice_28059 = None
        add_852: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28060, view_1711);  slice_28060 = view_1711 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3399, 1, 6800, 6816)
        slice_scatter_default_3400: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1700, add_852, 2, 0, 16);  slice_tensor_1700 = add_852 = None
        slice_scatter_default_3401: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3399, slice_scatter_default_3400, 1, 6800, 6816);  slice_scatter_default_3399 = slice_scatter_default_3400 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3401, 1, 6800, 6816)
        slice_28065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28064, 2, 0, 16);  slice_28064 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3401, 1, 6800, 6816)
        slice_scatter_default_3402: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1701, slice_28065, 2, 0, 16);  slice_tensor_1701 = slice_28065 = None
        slice_scatter_default_3403: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3401, slice_scatter_default_3402, 1, 6800, 6816);  slice_scatter_default_3401 = slice_scatter_default_3402 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28085: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28051, 2, 16, 32);  slice_28051 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_854: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28085, memory_format = torch.contiguous_format);  slice_28085 = None
        view_1712: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_854, [32, 11]);  clone_854 = None
        mm_851: "f32[32, 8]" = torch.ops.aten.mm.default(view_1712, slice_37)
        view_1713: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_851, [2, 16, 8]);  mm_851 = None
        slice_28092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3403, 1, 6800, 6816)
        slice_28093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28092, 2, 0, 16);  slice_28092 = None
        add_853: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28093, view_1713);  slice_28093 = view_1713 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3403, 1, 6800, 6816)
        slice_scatter_default_3404: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1702, add_853, 2, 0, 16);  slice_tensor_1702 = add_853 = None
        slice_scatter_default_3405: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3403, slice_scatter_default_3404, 1, 6800, 6816);  slice_scatter_default_3403 = slice_scatter_default_3404 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3405, 1, 6800, 6816)
        slice_28098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28097, 2, 0, 16);  slice_28097 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3405, 1, 6800, 6816)
        slice_scatter_default_3406: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1703, slice_28098, 2, 0, 16);  slice_tensor_1703 = slice_28098 = None
        slice_scatter_default_3407: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3405, slice_scatter_default_3406, 1, 6800, 6816);  slice_scatter_default_3405 = slice_scatter_default_3406 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28117: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6816, 6832)
        slice_28118: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28117, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_855: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28118, memory_format = torch.contiguous_format);  slice_28118 = None
        view_1714: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_855, [32, 16]);  clone_855 = None
        mm_852: "f32[32, 8]" = torch.ops.aten.mm.default(view_1714, slice_7)
        view_1715: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_852, [2, 16, 8]);  mm_852 = None
        slice_28125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3407, 1, 6816, 6832)
        slice_28126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28125, 2, 0, 16);  slice_28125 = None
        add_854: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28126, view_1715);  slice_28126 = view_1715 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3407, 1, 6816, 6832)
        slice_scatter_default_3408: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1704, add_854, 2, 0, 16);  slice_tensor_1704 = add_854 = None
        slice_scatter_default_3409: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3407, slice_scatter_default_3408, 1, 6816, 6832);  slice_scatter_default_3407 = slice_scatter_default_3408 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3409, 1, 6816, 6832)
        slice_28131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28130, 2, 0, 16);  slice_28130 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3409, 1, 6816, 6832)
        slice_scatter_default_3410: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1705, slice_28131, 2, 0, 16);  slice_tensor_1705 = slice_28131 = None
        slice_scatter_default_3411: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3409, slice_scatter_default_3410, 1, 6816, 6832);  slice_scatter_default_3409 = slice_scatter_default_3410 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28151: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28117, 2, 16, 32);  slice_28117 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_856: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28151, memory_format = torch.contiguous_format);  slice_28151 = None
        view_1716: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_856, [32, 11]);  clone_856 = None
        mm_853: "f32[32, 8]" = torch.ops.aten.mm.default(view_1716, slice_37)
        view_1717: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_853, [2, 16, 8]);  mm_853 = None
        slice_28158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3411, 1, 6816, 6832)
        slice_28159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28158, 2, 0, 16);  slice_28158 = None
        add_855: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28159, view_1717);  slice_28159 = view_1717 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3411, 1, 6816, 6832)
        slice_scatter_default_3412: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1706, add_855, 2, 0, 16);  slice_tensor_1706 = add_855 = None
        slice_scatter_default_3413: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3411, slice_scatter_default_3412, 1, 6816, 6832);  slice_scatter_default_3411 = slice_scatter_default_3412 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3413, 1, 6816, 6832)
        slice_28164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28163, 2, 0, 16);  slice_28163 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3413, 1, 6816, 6832)
        slice_scatter_default_3414: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1707, slice_28164, 2, 0, 16);  slice_tensor_1707 = slice_28164 = None
        slice_scatter_default_3415: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3413, slice_scatter_default_3414, 1, 6816, 6832);  slice_scatter_default_3413 = slice_scatter_default_3414 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28183: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6832, 6848)
        slice_28184: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28183, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_857: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28184, memory_format = torch.contiguous_format);  slice_28184 = None
        view_1718: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_857, [32, 16]);  clone_857 = None
        mm_854: "f32[32, 8]" = torch.ops.aten.mm.default(view_1718, slice_7)
        view_1719: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_854, [2, 16, 8]);  mm_854 = None
        slice_28191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3415, 1, 6832, 6848)
        slice_28192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28191, 2, 0, 16);  slice_28191 = None
        add_856: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28192, view_1719);  slice_28192 = view_1719 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3415, 1, 6832, 6848)
        slice_scatter_default_3416: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1708, add_856, 2, 0, 16);  slice_tensor_1708 = add_856 = None
        slice_scatter_default_3417: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3415, slice_scatter_default_3416, 1, 6832, 6848);  slice_scatter_default_3415 = slice_scatter_default_3416 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3417, 1, 6832, 6848)
        slice_28197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28196, 2, 0, 16);  slice_28196 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3417, 1, 6832, 6848)
        slice_scatter_default_3418: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1709, slice_28197, 2, 0, 16);  slice_tensor_1709 = slice_28197 = None
        slice_scatter_default_3419: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3417, slice_scatter_default_3418, 1, 6832, 6848);  slice_scatter_default_3417 = slice_scatter_default_3418 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28217: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28183, 2, 16, 32);  slice_28183 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_858: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28217, memory_format = torch.contiguous_format);  slice_28217 = None
        view_1720: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_858, [32, 11]);  clone_858 = None
        mm_855: "f32[32, 8]" = torch.ops.aten.mm.default(view_1720, slice_37)
        view_1721: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_855, [2, 16, 8]);  mm_855 = None
        slice_28224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3419, 1, 6832, 6848)
        slice_28225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28224, 2, 0, 16);  slice_28224 = None
        add_857: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28225, view_1721);  slice_28225 = view_1721 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3419, 1, 6832, 6848)
        slice_scatter_default_3420: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1710, add_857, 2, 0, 16);  slice_tensor_1710 = add_857 = None
        slice_scatter_default_3421: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3419, slice_scatter_default_3420, 1, 6832, 6848);  slice_scatter_default_3419 = slice_scatter_default_3420 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3421, 1, 6832, 6848)
        slice_28230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28229, 2, 0, 16);  slice_28229 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3421, 1, 6832, 6848)
        slice_scatter_default_3422: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1711, slice_28230, 2, 0, 16);  slice_tensor_1711 = slice_28230 = None
        slice_scatter_default_3423: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3421, slice_scatter_default_3422, 1, 6832, 6848);  slice_scatter_default_3421 = slice_scatter_default_3422 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28249: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6848, 6864)
        slice_28250: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28249, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_859: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28250, memory_format = torch.contiguous_format);  slice_28250 = None
        view_1722: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_859, [32, 16]);  clone_859 = None
        mm_856: "f32[32, 8]" = torch.ops.aten.mm.default(view_1722, slice_7)
        view_1723: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_856, [2, 16, 8]);  mm_856 = None
        slice_28257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3423, 1, 6848, 6864)
        slice_28258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28257, 2, 0, 16);  slice_28257 = None
        add_858: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28258, view_1723);  slice_28258 = view_1723 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3423, 1, 6848, 6864)
        slice_scatter_default_3424: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1712, add_858, 2, 0, 16);  slice_tensor_1712 = add_858 = None
        slice_scatter_default_3425: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3423, slice_scatter_default_3424, 1, 6848, 6864);  slice_scatter_default_3423 = slice_scatter_default_3424 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3425, 1, 6848, 6864)
        slice_28263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28262, 2, 0, 16);  slice_28262 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3425, 1, 6848, 6864)
        slice_scatter_default_3426: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1713, slice_28263, 2, 0, 16);  slice_tensor_1713 = slice_28263 = None
        slice_scatter_default_3427: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3425, slice_scatter_default_3426, 1, 6848, 6864);  slice_scatter_default_3425 = slice_scatter_default_3426 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28283: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28249, 2, 16, 32);  slice_28249 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_860: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28283, memory_format = torch.contiguous_format);  slice_28283 = None
        view_1724: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_860, [32, 11]);  clone_860 = None
        mm_857: "f32[32, 8]" = torch.ops.aten.mm.default(view_1724, slice_37)
        view_1725: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_857, [2, 16, 8]);  mm_857 = None
        slice_28290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3427, 1, 6848, 6864)
        slice_28291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28290, 2, 0, 16);  slice_28290 = None
        add_859: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28291, view_1725);  slice_28291 = view_1725 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3427, 1, 6848, 6864)
        slice_scatter_default_3428: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1714, add_859, 2, 0, 16);  slice_tensor_1714 = add_859 = None
        slice_scatter_default_3429: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3427, slice_scatter_default_3428, 1, 6848, 6864);  slice_scatter_default_3427 = slice_scatter_default_3428 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3429, 1, 6848, 6864)
        slice_28296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28295, 2, 0, 16);  slice_28295 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3429, 1, 6848, 6864)
        slice_scatter_default_3430: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1715, slice_28296, 2, 0, 16);  slice_tensor_1715 = slice_28296 = None
        slice_scatter_default_3431: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3429, slice_scatter_default_3430, 1, 6848, 6864);  slice_scatter_default_3429 = slice_scatter_default_3430 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28315: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6864, 6880)
        slice_28316: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28315, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_861: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28316, memory_format = torch.contiguous_format);  slice_28316 = None
        view_1726: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_861, [32, 16]);  clone_861 = None
        mm_858: "f32[32, 8]" = torch.ops.aten.mm.default(view_1726, slice_7)
        view_1727: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_858, [2, 16, 8]);  mm_858 = None
        slice_28323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3431, 1, 6864, 6880)
        slice_28324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28323, 2, 0, 16);  slice_28323 = None
        add_860: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28324, view_1727);  slice_28324 = view_1727 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3431, 1, 6864, 6880)
        slice_scatter_default_3432: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1716, add_860, 2, 0, 16);  slice_tensor_1716 = add_860 = None
        slice_scatter_default_3433: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3431, slice_scatter_default_3432, 1, 6864, 6880);  slice_scatter_default_3431 = slice_scatter_default_3432 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3433, 1, 6864, 6880)
        slice_28329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28328, 2, 0, 16);  slice_28328 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3433, 1, 6864, 6880)
        slice_scatter_default_3434: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1717, slice_28329, 2, 0, 16);  slice_tensor_1717 = slice_28329 = None
        slice_scatter_default_3435: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3433, slice_scatter_default_3434, 1, 6864, 6880);  slice_scatter_default_3433 = slice_scatter_default_3434 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28349: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28315, 2, 16, 32);  slice_28315 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_862: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28349, memory_format = torch.contiguous_format);  slice_28349 = None
        view_1728: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_862, [32, 11]);  clone_862 = None
        mm_859: "f32[32, 8]" = torch.ops.aten.mm.default(view_1728, slice_37)
        view_1729: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_859, [2, 16, 8]);  mm_859 = None
        slice_28356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3435, 1, 6864, 6880)
        slice_28357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28356, 2, 0, 16);  slice_28356 = None
        add_861: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28357, view_1729);  slice_28357 = view_1729 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3435, 1, 6864, 6880)
        slice_scatter_default_3436: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1718, add_861, 2, 0, 16);  slice_tensor_1718 = add_861 = None
        slice_scatter_default_3437: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3435, slice_scatter_default_3436, 1, 6864, 6880);  slice_scatter_default_3435 = slice_scatter_default_3436 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3437, 1, 6864, 6880)
        slice_28362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28361, 2, 0, 16);  slice_28361 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3437, 1, 6864, 6880)
        slice_scatter_default_3438: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1719, slice_28362, 2, 0, 16);  slice_tensor_1719 = slice_28362 = None
        slice_scatter_default_3439: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3437, slice_scatter_default_3438, 1, 6864, 6880);  slice_scatter_default_3437 = slice_scatter_default_3438 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28381: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6880, 6896)
        slice_28382: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28381, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_863: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28382, memory_format = torch.contiguous_format);  slice_28382 = None
        view_1730: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_863, [32, 16]);  clone_863 = None
        mm_860: "f32[32, 8]" = torch.ops.aten.mm.default(view_1730, slice_7)
        view_1731: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_860, [2, 16, 8]);  mm_860 = None
        slice_28389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3439, 1, 6880, 6896)
        slice_28390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28389, 2, 0, 16);  slice_28389 = None
        add_862: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28390, view_1731);  slice_28390 = view_1731 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3439, 1, 6880, 6896)
        slice_scatter_default_3440: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1720, add_862, 2, 0, 16);  slice_tensor_1720 = add_862 = None
        slice_scatter_default_3441: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3439, slice_scatter_default_3440, 1, 6880, 6896);  slice_scatter_default_3439 = slice_scatter_default_3440 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3441, 1, 6880, 6896)
        slice_28395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28394, 2, 0, 16);  slice_28394 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3441, 1, 6880, 6896)
        slice_scatter_default_3442: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1721, slice_28395, 2, 0, 16);  slice_tensor_1721 = slice_28395 = None
        slice_scatter_default_3443: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3441, slice_scatter_default_3442, 1, 6880, 6896);  slice_scatter_default_3441 = slice_scatter_default_3442 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28415: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28381, 2, 16, 32);  slice_28381 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_864: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28415, memory_format = torch.contiguous_format);  slice_28415 = None
        view_1732: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_864, [32, 11]);  clone_864 = None
        mm_861: "f32[32, 8]" = torch.ops.aten.mm.default(view_1732, slice_37)
        view_1733: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_861, [2, 16, 8]);  mm_861 = None
        slice_28422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3443, 1, 6880, 6896)
        slice_28423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28422, 2, 0, 16);  slice_28422 = None
        add_863: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28423, view_1733);  slice_28423 = view_1733 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3443, 1, 6880, 6896)
        slice_scatter_default_3444: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1722, add_863, 2, 0, 16);  slice_tensor_1722 = add_863 = None
        slice_scatter_default_3445: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3443, slice_scatter_default_3444, 1, 6880, 6896);  slice_scatter_default_3443 = slice_scatter_default_3444 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3445, 1, 6880, 6896)
        slice_28428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28427, 2, 0, 16);  slice_28427 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3445, 1, 6880, 6896)
        slice_scatter_default_3446: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1723, slice_28428, 2, 0, 16);  slice_tensor_1723 = slice_28428 = None
        slice_scatter_default_3447: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3445, slice_scatter_default_3446, 1, 6880, 6896);  slice_scatter_default_3445 = slice_scatter_default_3446 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28447: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6896, 6912)
        slice_28448: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28447, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_865: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28448, memory_format = torch.contiguous_format);  slice_28448 = None
        view_1734: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_865, [32, 16]);  clone_865 = None
        mm_862: "f32[32, 8]" = torch.ops.aten.mm.default(view_1734, slice_7)
        view_1735: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_862, [2, 16, 8]);  mm_862 = None
        slice_28455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3447, 1, 6896, 6912)
        slice_28456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28455, 2, 0, 16);  slice_28455 = None
        add_864: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28456, view_1735);  slice_28456 = view_1735 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3447, 1, 6896, 6912)
        slice_scatter_default_3448: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1724, add_864, 2, 0, 16);  slice_tensor_1724 = add_864 = None
        slice_scatter_default_3449: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3447, slice_scatter_default_3448, 1, 6896, 6912);  slice_scatter_default_3447 = slice_scatter_default_3448 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3449, 1, 6896, 6912)
        slice_28461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28460, 2, 0, 16);  slice_28460 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3449, 1, 6896, 6912)
        slice_scatter_default_3450: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1725, slice_28461, 2, 0, 16);  slice_tensor_1725 = slice_28461 = None
        slice_scatter_default_3451: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3449, slice_scatter_default_3450, 1, 6896, 6912);  slice_scatter_default_3449 = slice_scatter_default_3450 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28481: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28447, 2, 16, 32);  slice_28447 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_866: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28481, memory_format = torch.contiguous_format);  slice_28481 = None
        view_1736: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_866, [32, 11]);  clone_866 = None
        mm_863: "f32[32, 8]" = torch.ops.aten.mm.default(view_1736, slice_37)
        view_1737: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_863, [2, 16, 8]);  mm_863 = None
        slice_28488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3451, 1, 6896, 6912)
        slice_28489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28488, 2, 0, 16);  slice_28488 = None
        add_865: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28489, view_1737);  slice_28489 = view_1737 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3451, 1, 6896, 6912)
        slice_scatter_default_3452: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1726, add_865, 2, 0, 16);  slice_tensor_1726 = add_865 = None
        slice_scatter_default_3453: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3451, slice_scatter_default_3452, 1, 6896, 6912);  slice_scatter_default_3451 = slice_scatter_default_3452 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3453, 1, 6896, 6912)
        slice_28494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28493, 2, 0, 16);  slice_28493 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3453, 1, 6896, 6912)
        slice_scatter_default_3454: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1727, slice_28494, 2, 0, 16);  slice_tensor_1727 = slice_28494 = None
        slice_scatter_default_3455: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3453, slice_scatter_default_3454, 1, 6896, 6912);  slice_scatter_default_3453 = slice_scatter_default_3454 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28513: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6912, 6928)
        slice_28514: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28513, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_867: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28514, memory_format = torch.contiguous_format);  slice_28514 = None
        view_1738: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_867, [32, 16]);  clone_867 = None
        mm_864: "f32[32, 8]" = torch.ops.aten.mm.default(view_1738, slice_7)
        view_1739: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_864, [2, 16, 8]);  mm_864 = None
        slice_28521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3455, 1, 6912, 6928)
        slice_28522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28521, 2, 0, 16);  slice_28521 = None
        add_866: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28522, view_1739);  slice_28522 = view_1739 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3455, 1, 6912, 6928)
        slice_scatter_default_3456: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1728, add_866, 2, 0, 16);  slice_tensor_1728 = add_866 = None
        slice_scatter_default_3457: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3455, slice_scatter_default_3456, 1, 6912, 6928);  slice_scatter_default_3455 = slice_scatter_default_3456 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3457, 1, 6912, 6928)
        slice_28527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28526, 2, 0, 16);  slice_28526 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3457, 1, 6912, 6928)
        slice_scatter_default_3458: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1729, slice_28527, 2, 0, 16);  slice_tensor_1729 = slice_28527 = None
        slice_scatter_default_3459: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3457, slice_scatter_default_3458, 1, 6912, 6928);  slice_scatter_default_3457 = slice_scatter_default_3458 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28547: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28513, 2, 16, 32);  slice_28513 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_868: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28547, memory_format = torch.contiguous_format);  slice_28547 = None
        view_1740: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_868, [32, 11]);  clone_868 = None
        mm_865: "f32[32, 8]" = torch.ops.aten.mm.default(view_1740, slice_37)
        view_1741: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_865, [2, 16, 8]);  mm_865 = None
        slice_28554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3459, 1, 6912, 6928)
        slice_28555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28554, 2, 0, 16);  slice_28554 = None
        add_867: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28555, view_1741);  slice_28555 = view_1741 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3459, 1, 6912, 6928)
        slice_scatter_default_3460: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1730, add_867, 2, 0, 16);  slice_tensor_1730 = add_867 = None
        slice_scatter_default_3461: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3459, slice_scatter_default_3460, 1, 6912, 6928);  slice_scatter_default_3459 = slice_scatter_default_3460 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3461, 1, 6912, 6928)
        slice_28560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28559, 2, 0, 16);  slice_28559 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3461, 1, 6912, 6928)
        slice_scatter_default_3462: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1731, slice_28560, 2, 0, 16);  slice_tensor_1731 = slice_28560 = None
        slice_scatter_default_3463: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3461, slice_scatter_default_3462, 1, 6912, 6928);  slice_scatter_default_3461 = slice_scatter_default_3462 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28579: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6928, 6944)
        slice_28580: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28579, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_869: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28580, memory_format = torch.contiguous_format);  slice_28580 = None
        view_1742: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_869, [32, 16]);  clone_869 = None
        mm_866: "f32[32, 8]" = torch.ops.aten.mm.default(view_1742, slice_7)
        view_1743: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_866, [2, 16, 8]);  mm_866 = None
        slice_28587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3463, 1, 6928, 6944)
        slice_28588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28587, 2, 0, 16);  slice_28587 = None
        add_868: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28588, view_1743);  slice_28588 = view_1743 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3463, 1, 6928, 6944)
        slice_scatter_default_3464: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1732, add_868, 2, 0, 16);  slice_tensor_1732 = add_868 = None
        slice_scatter_default_3465: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3463, slice_scatter_default_3464, 1, 6928, 6944);  slice_scatter_default_3463 = slice_scatter_default_3464 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3465, 1, 6928, 6944)
        slice_28593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28592, 2, 0, 16);  slice_28592 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3465, 1, 6928, 6944)
        slice_scatter_default_3466: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1733, slice_28593, 2, 0, 16);  slice_tensor_1733 = slice_28593 = None
        slice_scatter_default_3467: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3465, slice_scatter_default_3466, 1, 6928, 6944);  slice_scatter_default_3465 = slice_scatter_default_3466 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28613: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28579, 2, 16, 32);  slice_28579 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_870: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28613, memory_format = torch.contiguous_format);  slice_28613 = None
        view_1744: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_870, [32, 11]);  clone_870 = None
        mm_867: "f32[32, 8]" = torch.ops.aten.mm.default(view_1744, slice_37)
        view_1745: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_867, [2, 16, 8]);  mm_867 = None
        slice_28620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3467, 1, 6928, 6944)
        slice_28621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28620, 2, 0, 16);  slice_28620 = None
        add_869: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28621, view_1745);  slice_28621 = view_1745 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3467, 1, 6928, 6944)
        slice_scatter_default_3468: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1734, add_869, 2, 0, 16);  slice_tensor_1734 = add_869 = None
        slice_scatter_default_3469: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3467, slice_scatter_default_3468, 1, 6928, 6944);  slice_scatter_default_3467 = slice_scatter_default_3468 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3469, 1, 6928, 6944)
        slice_28626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28625, 2, 0, 16);  slice_28625 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3469, 1, 6928, 6944)
        slice_scatter_default_3470: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1735, slice_28626, 2, 0, 16);  slice_tensor_1735 = slice_28626 = None
        slice_scatter_default_3471: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3469, slice_scatter_default_3470, 1, 6928, 6944);  slice_scatter_default_3469 = slice_scatter_default_3470 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28645: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6944, 6960)
        slice_28646: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28645, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_871: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28646, memory_format = torch.contiguous_format);  slice_28646 = None
        view_1746: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_871, [32, 16]);  clone_871 = None
        mm_868: "f32[32, 8]" = torch.ops.aten.mm.default(view_1746, slice_7)
        view_1747: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_868, [2, 16, 8]);  mm_868 = None
        slice_28653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3471, 1, 6944, 6960)
        slice_28654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28653, 2, 0, 16);  slice_28653 = None
        add_870: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28654, view_1747);  slice_28654 = view_1747 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3471, 1, 6944, 6960)
        slice_scatter_default_3472: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1736, add_870, 2, 0, 16);  slice_tensor_1736 = add_870 = None
        slice_scatter_default_3473: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3471, slice_scatter_default_3472, 1, 6944, 6960);  slice_scatter_default_3471 = slice_scatter_default_3472 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3473, 1, 6944, 6960)
        slice_28659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28658, 2, 0, 16);  slice_28658 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3473, 1, 6944, 6960)
        slice_scatter_default_3474: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1737, slice_28659, 2, 0, 16);  slice_tensor_1737 = slice_28659 = None
        slice_scatter_default_3475: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3473, slice_scatter_default_3474, 1, 6944, 6960);  slice_scatter_default_3473 = slice_scatter_default_3474 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28679: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28645, 2, 16, 32);  slice_28645 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_872: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28679, memory_format = torch.contiguous_format);  slice_28679 = None
        view_1748: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_872, [32, 11]);  clone_872 = None
        mm_869: "f32[32, 8]" = torch.ops.aten.mm.default(view_1748, slice_37)
        view_1749: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_869, [2, 16, 8]);  mm_869 = None
        slice_28686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3475, 1, 6944, 6960)
        slice_28687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28686, 2, 0, 16);  slice_28686 = None
        add_871: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28687, view_1749);  slice_28687 = view_1749 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3475, 1, 6944, 6960)
        slice_scatter_default_3476: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1738, add_871, 2, 0, 16);  slice_tensor_1738 = add_871 = None
        slice_scatter_default_3477: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3475, slice_scatter_default_3476, 1, 6944, 6960);  slice_scatter_default_3475 = slice_scatter_default_3476 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3477, 1, 6944, 6960)
        slice_28692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28691, 2, 0, 16);  slice_28691 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3477, 1, 6944, 6960)
        slice_scatter_default_3478: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1739, slice_28692, 2, 0, 16);  slice_tensor_1739 = slice_28692 = None
        slice_scatter_default_3479: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3477, slice_scatter_default_3478, 1, 6944, 6960);  slice_scatter_default_3477 = slice_scatter_default_3478 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28711: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6960, 6976)
        slice_28712: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28711, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_873: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28712, memory_format = torch.contiguous_format);  slice_28712 = None
        view_1750: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_873, [32, 16]);  clone_873 = None
        mm_870: "f32[32, 8]" = torch.ops.aten.mm.default(view_1750, slice_7)
        view_1751: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_870, [2, 16, 8]);  mm_870 = None
        slice_28719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3479, 1, 6960, 6976)
        slice_28720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28719, 2, 0, 16);  slice_28719 = None
        add_872: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28720, view_1751);  slice_28720 = view_1751 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3479, 1, 6960, 6976)
        slice_scatter_default_3480: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1740, add_872, 2, 0, 16);  slice_tensor_1740 = add_872 = None
        slice_scatter_default_3481: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3479, slice_scatter_default_3480, 1, 6960, 6976);  slice_scatter_default_3479 = slice_scatter_default_3480 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3481, 1, 6960, 6976)
        slice_28725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28724, 2, 0, 16);  slice_28724 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3481, 1, 6960, 6976)
        slice_scatter_default_3482: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1741, slice_28725, 2, 0, 16);  slice_tensor_1741 = slice_28725 = None
        slice_scatter_default_3483: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3481, slice_scatter_default_3482, 1, 6960, 6976);  slice_scatter_default_3481 = slice_scatter_default_3482 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28745: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28711, 2, 16, 32);  slice_28711 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_874: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28745, memory_format = torch.contiguous_format);  slice_28745 = None
        view_1752: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_874, [32, 11]);  clone_874 = None
        mm_871: "f32[32, 8]" = torch.ops.aten.mm.default(view_1752, slice_37)
        view_1753: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_871, [2, 16, 8]);  mm_871 = None
        slice_28752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3483, 1, 6960, 6976)
        slice_28753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28752, 2, 0, 16);  slice_28752 = None
        add_873: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28753, view_1753);  slice_28753 = view_1753 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3483, 1, 6960, 6976)
        slice_scatter_default_3484: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1742, add_873, 2, 0, 16);  slice_tensor_1742 = add_873 = None
        slice_scatter_default_3485: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3483, slice_scatter_default_3484, 1, 6960, 6976);  slice_scatter_default_3483 = slice_scatter_default_3484 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3485, 1, 6960, 6976)
        slice_28758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28757, 2, 0, 16);  slice_28757 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3485, 1, 6960, 6976)
        slice_scatter_default_3486: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1743, slice_28758, 2, 0, 16);  slice_tensor_1743 = slice_28758 = None
        slice_scatter_default_3487: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3485, slice_scatter_default_3486, 1, 6960, 6976);  slice_scatter_default_3485 = slice_scatter_default_3486 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28777: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6976, 6992)
        slice_28778: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28777, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_875: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28778, memory_format = torch.contiguous_format);  slice_28778 = None
        view_1754: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_875, [32, 16]);  clone_875 = None
        mm_872: "f32[32, 8]" = torch.ops.aten.mm.default(view_1754, slice_7)
        view_1755: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_872, [2, 16, 8]);  mm_872 = None
        slice_28785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3487, 1, 6976, 6992)
        slice_28786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28785, 2, 0, 16);  slice_28785 = None
        add_874: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28786, view_1755);  slice_28786 = view_1755 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3487, 1, 6976, 6992)
        slice_scatter_default_3488: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1744, add_874, 2, 0, 16);  slice_tensor_1744 = add_874 = None
        slice_scatter_default_3489: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3487, slice_scatter_default_3488, 1, 6976, 6992);  slice_scatter_default_3487 = slice_scatter_default_3488 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3489, 1, 6976, 6992)
        slice_28791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28790, 2, 0, 16);  slice_28790 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3489, 1, 6976, 6992)
        slice_scatter_default_3490: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1745, slice_28791, 2, 0, 16);  slice_tensor_1745 = slice_28791 = None
        slice_scatter_default_3491: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3489, slice_scatter_default_3490, 1, 6976, 6992);  slice_scatter_default_3489 = slice_scatter_default_3490 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28811: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28777, 2, 16, 32);  slice_28777 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_876: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28811, memory_format = torch.contiguous_format);  slice_28811 = None
        view_1756: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_876, [32, 11]);  clone_876 = None
        mm_873: "f32[32, 8]" = torch.ops.aten.mm.default(view_1756, slice_37)
        view_1757: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_873, [2, 16, 8]);  mm_873 = None
        slice_28818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3491, 1, 6976, 6992)
        slice_28819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28818, 2, 0, 16);  slice_28818 = None
        add_875: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28819, view_1757);  slice_28819 = view_1757 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3491, 1, 6976, 6992)
        slice_scatter_default_3492: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1746, add_875, 2, 0, 16);  slice_tensor_1746 = add_875 = None
        slice_scatter_default_3493: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3491, slice_scatter_default_3492, 1, 6976, 6992);  slice_scatter_default_3491 = slice_scatter_default_3492 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3493, 1, 6976, 6992)
        slice_28824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28823, 2, 0, 16);  slice_28823 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3493, 1, 6976, 6992)
        slice_scatter_default_3494: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1747, slice_28824, 2, 0, 16);  slice_tensor_1747 = slice_28824 = None
        slice_scatter_default_3495: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3493, slice_scatter_default_3494, 1, 6976, 6992);  slice_scatter_default_3493 = slice_scatter_default_3494 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28843: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 6992, 7008)
        slice_28844: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28843, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_877: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28844, memory_format = torch.contiguous_format);  slice_28844 = None
        view_1758: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_877, [32, 16]);  clone_877 = None
        mm_874: "f32[32, 8]" = torch.ops.aten.mm.default(view_1758, slice_7)
        view_1759: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_874, [2, 16, 8]);  mm_874 = None
        slice_28851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3495, 1, 6992, 7008)
        slice_28852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28851, 2, 0, 16);  slice_28851 = None
        add_876: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28852, view_1759);  slice_28852 = view_1759 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3495, 1, 6992, 7008)
        slice_scatter_default_3496: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1748, add_876, 2, 0, 16);  slice_tensor_1748 = add_876 = None
        slice_scatter_default_3497: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3495, slice_scatter_default_3496, 1, 6992, 7008);  slice_scatter_default_3495 = slice_scatter_default_3496 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3497, 1, 6992, 7008)
        slice_28857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28856, 2, 0, 16);  slice_28856 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3497, 1, 6992, 7008)
        slice_scatter_default_3498: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1749, slice_28857, 2, 0, 16);  slice_tensor_1749 = slice_28857 = None
        slice_scatter_default_3499: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3497, slice_scatter_default_3498, 1, 6992, 7008);  slice_scatter_default_3497 = slice_scatter_default_3498 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28877: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28843, 2, 16, 32);  slice_28843 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_878: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28877, memory_format = torch.contiguous_format);  slice_28877 = None
        view_1760: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_878, [32, 11]);  clone_878 = None
        mm_875: "f32[32, 8]" = torch.ops.aten.mm.default(view_1760, slice_37)
        view_1761: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_875, [2, 16, 8]);  mm_875 = None
        slice_28884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3499, 1, 6992, 7008)
        slice_28885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28884, 2, 0, 16);  slice_28884 = None
        add_877: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28885, view_1761);  slice_28885 = view_1761 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3499, 1, 6992, 7008)
        slice_scatter_default_3500: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1750, add_877, 2, 0, 16);  slice_tensor_1750 = add_877 = None
        slice_scatter_default_3501: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3499, slice_scatter_default_3500, 1, 6992, 7008);  slice_scatter_default_3499 = slice_scatter_default_3500 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3501, 1, 6992, 7008)
        slice_28890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28889, 2, 0, 16);  slice_28889 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3501, 1, 6992, 7008)
        slice_scatter_default_3502: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1751, slice_28890, 2, 0, 16);  slice_tensor_1751 = slice_28890 = None
        slice_scatter_default_3503: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3501, slice_scatter_default_3502, 1, 6992, 7008);  slice_scatter_default_3501 = slice_scatter_default_3502 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28909: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7008, 7024)
        slice_28910: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28909, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_879: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28910, memory_format = torch.contiguous_format);  slice_28910 = None
        view_1762: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_879, [32, 16]);  clone_879 = None
        mm_876: "f32[32, 8]" = torch.ops.aten.mm.default(view_1762, slice_7)
        view_1763: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_876, [2, 16, 8]);  mm_876 = None
        slice_28917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3503, 1, 7008, 7024)
        slice_28918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28917, 2, 0, 16);  slice_28917 = None
        add_878: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28918, view_1763);  slice_28918 = view_1763 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3503, 1, 7008, 7024)
        slice_scatter_default_3504: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1752, add_878, 2, 0, 16);  slice_tensor_1752 = add_878 = None
        slice_scatter_default_3505: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3503, slice_scatter_default_3504, 1, 7008, 7024);  slice_scatter_default_3503 = slice_scatter_default_3504 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3505, 1, 7008, 7024)
        slice_28923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28922, 2, 0, 16);  slice_28922 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3505, 1, 7008, 7024)
        slice_scatter_default_3506: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1753, slice_28923, 2, 0, 16);  slice_tensor_1753 = slice_28923 = None
        slice_scatter_default_3507: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3505, slice_scatter_default_3506, 1, 7008, 7024);  slice_scatter_default_3505 = slice_scatter_default_3506 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28943: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28909, 2, 16, 32);  slice_28909 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_880: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_28943, memory_format = torch.contiguous_format);  slice_28943 = None
        view_1764: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_880, [32, 11]);  clone_880 = None
        mm_877: "f32[32, 8]" = torch.ops.aten.mm.default(view_1764, slice_37)
        view_1765: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_877, [2, 16, 8]);  mm_877 = None
        slice_28950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3507, 1, 7008, 7024)
        slice_28951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28950, 2, 0, 16);  slice_28950 = None
        add_879: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28951, view_1765);  slice_28951 = view_1765 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3507, 1, 7008, 7024)
        slice_scatter_default_3508: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1754, add_879, 2, 0, 16);  slice_tensor_1754 = add_879 = None
        slice_scatter_default_3509: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3507, slice_scatter_default_3508, 1, 7008, 7024);  slice_scatter_default_3507 = slice_scatter_default_3508 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3509, 1, 7008, 7024)
        slice_28956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28955, 2, 0, 16);  slice_28955 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3509, 1, 7008, 7024)
        slice_scatter_default_3510: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1755, slice_28956, 2, 0, 16);  slice_tensor_1755 = slice_28956 = None
        slice_scatter_default_3511: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3509, slice_scatter_default_3510, 1, 7008, 7024);  slice_scatter_default_3509 = slice_scatter_default_3510 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_28975: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7024, 7040)
        slice_28976: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_28975, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_881: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_28976, memory_format = torch.contiguous_format);  slice_28976 = None
        view_1766: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_881, [32, 16]);  clone_881 = None
        mm_878: "f32[32, 8]" = torch.ops.aten.mm.default(view_1766, slice_7)
        view_1767: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_878, [2, 16, 8]);  mm_878 = None
        slice_28983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3511, 1, 7024, 7040)
        slice_28984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28983, 2, 0, 16);  slice_28983 = None
        add_880: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_28984, view_1767);  slice_28984 = view_1767 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3511, 1, 7024, 7040)
        slice_scatter_default_3512: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1756, add_880, 2, 0, 16);  slice_tensor_1756 = add_880 = None
        slice_scatter_default_3513: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3511, slice_scatter_default_3512, 1, 7024, 7040);  slice_scatter_default_3511 = slice_scatter_default_3512 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_28988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3513, 1, 7024, 7040)
        slice_28989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_28988, 2, 0, 16);  slice_28988 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3513, 1, 7024, 7040)
        slice_scatter_default_3514: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1757, slice_28989, 2, 0, 16);  slice_tensor_1757 = slice_28989 = None
        slice_scatter_default_3515: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3513, slice_scatter_default_3514, 1, 7024, 7040);  slice_scatter_default_3513 = slice_scatter_default_3514 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29009: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_28975, 2, 16, 32);  slice_28975 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_882: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29009, memory_format = torch.contiguous_format);  slice_29009 = None
        view_1768: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_882, [32, 11]);  clone_882 = None
        mm_879: "f32[32, 8]" = torch.ops.aten.mm.default(view_1768, slice_37)
        view_1769: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_879, [2, 16, 8]);  mm_879 = None
        slice_29016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3515, 1, 7024, 7040)
        slice_29017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29016, 2, 0, 16);  slice_29016 = None
        add_881: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29017, view_1769);  slice_29017 = view_1769 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3515, 1, 7024, 7040)
        slice_scatter_default_3516: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1758, add_881, 2, 0, 16);  slice_tensor_1758 = add_881 = None
        slice_scatter_default_3517: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3515, slice_scatter_default_3516, 1, 7024, 7040);  slice_scatter_default_3515 = slice_scatter_default_3516 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3517, 1, 7024, 7040)
        slice_29022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29021, 2, 0, 16);  slice_29021 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3517, 1, 7024, 7040)
        slice_scatter_default_3518: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1759, slice_29022, 2, 0, 16);  slice_tensor_1759 = slice_29022 = None
        slice_scatter_default_3519: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3517, slice_scatter_default_3518, 1, 7024, 7040);  slice_scatter_default_3517 = slice_scatter_default_3518 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29041: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7040, 7056)
        slice_29042: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29041, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_883: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29042, memory_format = torch.contiguous_format);  slice_29042 = None
        view_1770: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_883, [32, 16]);  clone_883 = None
        mm_880: "f32[32, 8]" = torch.ops.aten.mm.default(view_1770, slice_7)
        view_1771: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_880, [2, 16, 8]);  mm_880 = None
        slice_29049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3519, 1, 7040, 7056)
        slice_29050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29049, 2, 0, 16);  slice_29049 = None
        add_882: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29050, view_1771);  slice_29050 = view_1771 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3519, 1, 7040, 7056)
        slice_scatter_default_3520: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1760, add_882, 2, 0, 16);  slice_tensor_1760 = add_882 = None
        slice_scatter_default_3521: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3519, slice_scatter_default_3520, 1, 7040, 7056);  slice_scatter_default_3519 = slice_scatter_default_3520 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3521, 1, 7040, 7056)
        slice_29055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29054, 2, 0, 16);  slice_29054 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3521, 1, 7040, 7056)
        slice_scatter_default_3522: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1761, slice_29055, 2, 0, 16);  slice_tensor_1761 = slice_29055 = None
        slice_scatter_default_3523: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3521, slice_scatter_default_3522, 1, 7040, 7056);  slice_scatter_default_3521 = slice_scatter_default_3522 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29075: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29041, 2, 16, 32);  slice_29041 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_884: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29075, memory_format = torch.contiguous_format);  slice_29075 = None
        view_1772: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_884, [32, 11]);  clone_884 = None
        mm_881: "f32[32, 8]" = torch.ops.aten.mm.default(view_1772, slice_37)
        view_1773: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_881, [2, 16, 8]);  mm_881 = None
        slice_29082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3523, 1, 7040, 7056)
        slice_29083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29082, 2, 0, 16);  slice_29082 = None
        add_883: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29083, view_1773);  slice_29083 = view_1773 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3523, 1, 7040, 7056)
        slice_scatter_default_3524: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1762, add_883, 2, 0, 16);  slice_tensor_1762 = add_883 = None
        slice_scatter_default_3525: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3523, slice_scatter_default_3524, 1, 7040, 7056);  slice_scatter_default_3523 = slice_scatter_default_3524 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3525, 1, 7040, 7056)
        slice_29088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29087, 2, 0, 16);  slice_29087 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3525, 1, 7040, 7056)
        slice_scatter_default_3526: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1763, slice_29088, 2, 0, 16);  slice_tensor_1763 = slice_29088 = None
        slice_scatter_default_3527: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3525, slice_scatter_default_3526, 1, 7040, 7056);  slice_scatter_default_3525 = slice_scatter_default_3526 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29107: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7056, 7072)
        slice_29108: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29107, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_885: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29108, memory_format = torch.contiguous_format);  slice_29108 = None
        view_1774: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_885, [32, 16]);  clone_885 = None
        mm_882: "f32[32, 8]" = torch.ops.aten.mm.default(view_1774, slice_7)
        view_1775: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_882, [2, 16, 8]);  mm_882 = None
        slice_29115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3527, 1, 7056, 7072)
        slice_29116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29115, 2, 0, 16);  slice_29115 = None
        add_884: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29116, view_1775);  slice_29116 = view_1775 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3527, 1, 7056, 7072)
        slice_scatter_default_3528: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1764, add_884, 2, 0, 16);  slice_tensor_1764 = add_884 = None
        slice_scatter_default_3529: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3527, slice_scatter_default_3528, 1, 7056, 7072);  slice_scatter_default_3527 = slice_scatter_default_3528 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3529, 1, 7056, 7072)
        slice_29121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29120, 2, 0, 16);  slice_29120 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3529, 1, 7056, 7072)
        slice_scatter_default_3530: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1765, slice_29121, 2, 0, 16);  slice_tensor_1765 = slice_29121 = None
        slice_scatter_default_3531: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3529, slice_scatter_default_3530, 1, 7056, 7072);  slice_scatter_default_3529 = slice_scatter_default_3530 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29141: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29107, 2, 16, 32);  slice_29107 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_886: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29141, memory_format = torch.contiguous_format);  slice_29141 = None
        view_1776: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_886, [32, 11]);  clone_886 = None
        mm_883: "f32[32, 8]" = torch.ops.aten.mm.default(view_1776, slice_37)
        view_1777: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_883, [2, 16, 8]);  mm_883 = None
        slice_29148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3531, 1, 7056, 7072)
        slice_29149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29148, 2, 0, 16);  slice_29148 = None
        add_885: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29149, view_1777);  slice_29149 = view_1777 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3531, 1, 7056, 7072)
        slice_scatter_default_3532: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1766, add_885, 2, 0, 16);  slice_tensor_1766 = add_885 = None
        slice_scatter_default_3533: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3531, slice_scatter_default_3532, 1, 7056, 7072);  slice_scatter_default_3531 = slice_scatter_default_3532 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3533, 1, 7056, 7072)
        slice_29154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29153, 2, 0, 16);  slice_29153 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3533, 1, 7056, 7072)
        slice_scatter_default_3534: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1767, slice_29154, 2, 0, 16);  slice_tensor_1767 = slice_29154 = None
        slice_scatter_default_3535: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3533, slice_scatter_default_3534, 1, 7056, 7072);  slice_scatter_default_3533 = slice_scatter_default_3534 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29173: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7072, 7088)
        slice_29174: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29173, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_887: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29174, memory_format = torch.contiguous_format);  slice_29174 = None
        view_1778: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_887, [32, 16]);  clone_887 = None
        mm_884: "f32[32, 8]" = torch.ops.aten.mm.default(view_1778, slice_7)
        view_1779: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_884, [2, 16, 8]);  mm_884 = None
        slice_29181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3535, 1, 7072, 7088)
        slice_29182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29181, 2, 0, 16);  slice_29181 = None
        add_886: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29182, view_1779);  slice_29182 = view_1779 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3535, 1, 7072, 7088)
        slice_scatter_default_3536: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1768, add_886, 2, 0, 16);  slice_tensor_1768 = add_886 = None
        slice_scatter_default_3537: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3535, slice_scatter_default_3536, 1, 7072, 7088);  slice_scatter_default_3535 = slice_scatter_default_3536 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3537, 1, 7072, 7088)
        slice_29187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29186, 2, 0, 16);  slice_29186 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3537, 1, 7072, 7088)
        slice_scatter_default_3538: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1769, slice_29187, 2, 0, 16);  slice_tensor_1769 = slice_29187 = None
        slice_scatter_default_3539: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3537, slice_scatter_default_3538, 1, 7072, 7088);  slice_scatter_default_3537 = slice_scatter_default_3538 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29207: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29173, 2, 16, 32);  slice_29173 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_888: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29207, memory_format = torch.contiguous_format);  slice_29207 = None
        view_1780: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_888, [32, 11]);  clone_888 = None
        mm_885: "f32[32, 8]" = torch.ops.aten.mm.default(view_1780, slice_37)
        view_1781: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_885, [2, 16, 8]);  mm_885 = None
        slice_29214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3539, 1, 7072, 7088)
        slice_29215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29214, 2, 0, 16);  slice_29214 = None
        add_887: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29215, view_1781);  slice_29215 = view_1781 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3539, 1, 7072, 7088)
        slice_scatter_default_3540: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1770, add_887, 2, 0, 16);  slice_tensor_1770 = add_887 = None
        slice_scatter_default_3541: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3539, slice_scatter_default_3540, 1, 7072, 7088);  slice_scatter_default_3539 = slice_scatter_default_3540 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3541, 1, 7072, 7088)
        slice_29220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29219, 2, 0, 16);  slice_29219 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3541, 1, 7072, 7088)
        slice_scatter_default_3542: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1771, slice_29220, 2, 0, 16);  slice_tensor_1771 = slice_29220 = None
        slice_scatter_default_3543: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3541, slice_scatter_default_3542, 1, 7072, 7088);  slice_scatter_default_3541 = slice_scatter_default_3542 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29239: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7088, 7104)
        slice_29240: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29239, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_889: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29240, memory_format = torch.contiguous_format);  slice_29240 = None
        view_1782: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_889, [32, 16]);  clone_889 = None
        mm_886: "f32[32, 8]" = torch.ops.aten.mm.default(view_1782, slice_7)
        view_1783: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_886, [2, 16, 8]);  mm_886 = None
        slice_29247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3543, 1, 7088, 7104)
        slice_29248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29247, 2, 0, 16);  slice_29247 = None
        add_888: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29248, view_1783);  slice_29248 = view_1783 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3543, 1, 7088, 7104)
        slice_scatter_default_3544: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1772, add_888, 2, 0, 16);  slice_tensor_1772 = add_888 = None
        slice_scatter_default_3545: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3543, slice_scatter_default_3544, 1, 7088, 7104);  slice_scatter_default_3543 = slice_scatter_default_3544 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3545, 1, 7088, 7104)
        slice_29253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29252, 2, 0, 16);  slice_29252 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3545, 1, 7088, 7104)
        slice_scatter_default_3546: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1773, slice_29253, 2, 0, 16);  slice_tensor_1773 = slice_29253 = None
        slice_scatter_default_3547: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3545, slice_scatter_default_3546, 1, 7088, 7104);  slice_scatter_default_3545 = slice_scatter_default_3546 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29273: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29239, 2, 16, 32);  slice_29239 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_890: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29273, memory_format = torch.contiguous_format);  slice_29273 = None
        view_1784: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_890, [32, 11]);  clone_890 = None
        mm_887: "f32[32, 8]" = torch.ops.aten.mm.default(view_1784, slice_37)
        view_1785: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_887, [2, 16, 8]);  mm_887 = None
        slice_29280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3547, 1, 7088, 7104)
        slice_29281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29280, 2, 0, 16);  slice_29280 = None
        add_889: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29281, view_1785);  slice_29281 = view_1785 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3547, 1, 7088, 7104)
        slice_scatter_default_3548: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1774, add_889, 2, 0, 16);  slice_tensor_1774 = add_889 = None
        slice_scatter_default_3549: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3547, slice_scatter_default_3548, 1, 7088, 7104);  slice_scatter_default_3547 = slice_scatter_default_3548 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3549, 1, 7088, 7104)
        slice_29286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29285, 2, 0, 16);  slice_29285 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3549, 1, 7088, 7104)
        slice_scatter_default_3550: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1775, slice_29286, 2, 0, 16);  slice_tensor_1775 = slice_29286 = None
        slice_scatter_default_3551: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3549, slice_scatter_default_3550, 1, 7088, 7104);  slice_scatter_default_3549 = slice_scatter_default_3550 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29305: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7104, 7120)
        slice_29306: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29305, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_891: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29306, memory_format = torch.contiguous_format);  slice_29306 = None
        view_1786: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_891, [32, 16]);  clone_891 = None
        mm_888: "f32[32, 8]" = torch.ops.aten.mm.default(view_1786, slice_7)
        view_1787: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_888, [2, 16, 8]);  mm_888 = None
        slice_29313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3551, 1, 7104, 7120)
        slice_29314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29313, 2, 0, 16);  slice_29313 = None
        add_890: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29314, view_1787);  slice_29314 = view_1787 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3551, 1, 7104, 7120)
        slice_scatter_default_3552: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1776, add_890, 2, 0, 16);  slice_tensor_1776 = add_890 = None
        slice_scatter_default_3553: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3551, slice_scatter_default_3552, 1, 7104, 7120);  slice_scatter_default_3551 = slice_scatter_default_3552 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3553, 1, 7104, 7120)
        slice_29319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29318, 2, 0, 16);  slice_29318 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3553, 1, 7104, 7120)
        slice_scatter_default_3554: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1777, slice_29319, 2, 0, 16);  slice_tensor_1777 = slice_29319 = None
        slice_scatter_default_3555: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3553, slice_scatter_default_3554, 1, 7104, 7120);  slice_scatter_default_3553 = slice_scatter_default_3554 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29339: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29305, 2, 16, 32);  slice_29305 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_892: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29339, memory_format = torch.contiguous_format);  slice_29339 = None
        view_1788: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_892, [32, 11]);  clone_892 = None
        mm_889: "f32[32, 8]" = torch.ops.aten.mm.default(view_1788, slice_37)
        view_1789: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_889, [2, 16, 8]);  mm_889 = None
        slice_29346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3555, 1, 7104, 7120)
        slice_29347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29346, 2, 0, 16);  slice_29346 = None
        add_891: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29347, view_1789);  slice_29347 = view_1789 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3555, 1, 7104, 7120)
        slice_scatter_default_3556: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1778, add_891, 2, 0, 16);  slice_tensor_1778 = add_891 = None
        slice_scatter_default_3557: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3555, slice_scatter_default_3556, 1, 7104, 7120);  slice_scatter_default_3555 = slice_scatter_default_3556 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3557, 1, 7104, 7120)
        slice_29352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29351, 2, 0, 16);  slice_29351 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3557, 1, 7104, 7120)
        slice_scatter_default_3558: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1779, slice_29352, 2, 0, 16);  slice_tensor_1779 = slice_29352 = None
        slice_scatter_default_3559: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3557, slice_scatter_default_3558, 1, 7104, 7120);  slice_scatter_default_3557 = slice_scatter_default_3558 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29371: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7120, 7136)
        slice_29372: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29371, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_893: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29372, memory_format = torch.contiguous_format);  slice_29372 = None
        view_1790: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_893, [32, 16]);  clone_893 = None
        mm_890: "f32[32, 8]" = torch.ops.aten.mm.default(view_1790, slice_7)
        view_1791: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_890, [2, 16, 8]);  mm_890 = None
        slice_29379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3559, 1, 7120, 7136)
        slice_29380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29379, 2, 0, 16);  slice_29379 = None
        add_892: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29380, view_1791);  slice_29380 = view_1791 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3559, 1, 7120, 7136)
        slice_scatter_default_3560: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1780, add_892, 2, 0, 16);  slice_tensor_1780 = add_892 = None
        slice_scatter_default_3561: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3559, slice_scatter_default_3560, 1, 7120, 7136);  slice_scatter_default_3559 = slice_scatter_default_3560 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3561, 1, 7120, 7136)
        slice_29385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29384, 2, 0, 16);  slice_29384 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3561, 1, 7120, 7136)
        slice_scatter_default_3562: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1781, slice_29385, 2, 0, 16);  slice_tensor_1781 = slice_29385 = None
        slice_scatter_default_3563: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3561, slice_scatter_default_3562, 1, 7120, 7136);  slice_scatter_default_3561 = slice_scatter_default_3562 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29405: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29371, 2, 16, 32);  slice_29371 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_894: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29405, memory_format = torch.contiguous_format);  slice_29405 = None
        view_1792: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_894, [32, 11]);  clone_894 = None
        mm_891: "f32[32, 8]" = torch.ops.aten.mm.default(view_1792, slice_37)
        view_1793: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_891, [2, 16, 8]);  mm_891 = None
        slice_29412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3563, 1, 7120, 7136)
        slice_29413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29412, 2, 0, 16);  slice_29412 = None
        add_893: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29413, view_1793);  slice_29413 = view_1793 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3563, 1, 7120, 7136)
        slice_scatter_default_3564: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1782, add_893, 2, 0, 16);  slice_tensor_1782 = add_893 = None
        slice_scatter_default_3565: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3563, slice_scatter_default_3564, 1, 7120, 7136);  slice_scatter_default_3563 = slice_scatter_default_3564 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3565, 1, 7120, 7136)
        slice_29418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29417, 2, 0, 16);  slice_29417 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3565, 1, 7120, 7136)
        slice_scatter_default_3566: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1783, slice_29418, 2, 0, 16);  slice_tensor_1783 = slice_29418 = None
        slice_scatter_default_3567: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3565, slice_scatter_default_3566, 1, 7120, 7136);  slice_scatter_default_3565 = slice_scatter_default_3566 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29437: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7136, 7152)
        slice_29438: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29437, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_895: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29438, memory_format = torch.contiguous_format);  slice_29438 = None
        view_1794: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_895, [32, 16]);  clone_895 = None
        mm_892: "f32[32, 8]" = torch.ops.aten.mm.default(view_1794, slice_7)
        view_1795: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_892, [2, 16, 8]);  mm_892 = None
        slice_29445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3567, 1, 7136, 7152)
        slice_29446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29445, 2, 0, 16);  slice_29445 = None
        add_894: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29446, view_1795);  slice_29446 = view_1795 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3567, 1, 7136, 7152)
        slice_scatter_default_3568: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1784, add_894, 2, 0, 16);  slice_tensor_1784 = add_894 = None
        slice_scatter_default_3569: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3567, slice_scatter_default_3568, 1, 7136, 7152);  slice_scatter_default_3567 = slice_scatter_default_3568 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3569, 1, 7136, 7152)
        slice_29451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29450, 2, 0, 16);  slice_29450 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3569, 1, 7136, 7152)
        slice_scatter_default_3570: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1785, slice_29451, 2, 0, 16);  slice_tensor_1785 = slice_29451 = None
        slice_scatter_default_3571: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3569, slice_scatter_default_3570, 1, 7136, 7152);  slice_scatter_default_3569 = slice_scatter_default_3570 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29471: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29437, 2, 16, 32);  slice_29437 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_896: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29471, memory_format = torch.contiguous_format);  slice_29471 = None
        view_1796: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_896, [32, 11]);  clone_896 = None
        mm_893: "f32[32, 8]" = torch.ops.aten.mm.default(view_1796, slice_37)
        view_1797: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_893, [2, 16, 8]);  mm_893 = None
        slice_29478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3571, 1, 7136, 7152)
        slice_29479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29478, 2, 0, 16);  slice_29478 = None
        add_895: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29479, view_1797);  slice_29479 = view_1797 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3571, 1, 7136, 7152)
        slice_scatter_default_3572: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1786, add_895, 2, 0, 16);  slice_tensor_1786 = add_895 = None
        slice_scatter_default_3573: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3571, slice_scatter_default_3572, 1, 7136, 7152);  slice_scatter_default_3571 = slice_scatter_default_3572 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3573, 1, 7136, 7152)
        slice_29484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29483, 2, 0, 16);  slice_29483 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3573, 1, 7136, 7152)
        slice_scatter_default_3574: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1787, slice_29484, 2, 0, 16);  slice_tensor_1787 = slice_29484 = None
        slice_scatter_default_3575: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3573, slice_scatter_default_3574, 1, 7136, 7152);  slice_scatter_default_3573 = slice_scatter_default_3574 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29503: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7152, 7168)
        slice_29504: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29503, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_897: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29504, memory_format = torch.contiguous_format);  slice_29504 = None
        view_1798: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_897, [32, 16]);  clone_897 = None
        mm_894: "f32[32, 8]" = torch.ops.aten.mm.default(view_1798, slice_7)
        view_1799: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_894, [2, 16, 8]);  mm_894 = None
        slice_29511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3575, 1, 7152, 7168)
        slice_29512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29511, 2, 0, 16);  slice_29511 = None
        add_896: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29512, view_1799);  slice_29512 = view_1799 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3575, 1, 7152, 7168)
        slice_scatter_default_3576: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1788, add_896, 2, 0, 16);  slice_tensor_1788 = add_896 = None
        slice_scatter_default_3577: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3575, slice_scatter_default_3576, 1, 7152, 7168);  slice_scatter_default_3575 = slice_scatter_default_3576 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3577, 1, 7152, 7168)
        slice_29517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29516, 2, 0, 16);  slice_29516 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3577, 1, 7152, 7168)
        slice_scatter_default_3578: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1789, slice_29517, 2, 0, 16);  slice_tensor_1789 = slice_29517 = None
        slice_scatter_default_3579: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3577, slice_scatter_default_3578, 1, 7152, 7168);  slice_scatter_default_3577 = slice_scatter_default_3578 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29537: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29503, 2, 16, 32);  slice_29503 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_898: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29537, memory_format = torch.contiguous_format);  slice_29537 = None
        view_1800: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_898, [32, 11]);  clone_898 = None
        mm_895: "f32[32, 8]" = torch.ops.aten.mm.default(view_1800, slice_37)
        view_1801: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_895, [2, 16, 8]);  mm_895 = None
        slice_29544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3579, 1, 7152, 7168)
        slice_29545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29544, 2, 0, 16);  slice_29544 = None
        add_897: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29545, view_1801);  slice_29545 = view_1801 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3579, 1, 7152, 7168)
        slice_scatter_default_3580: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1790, add_897, 2, 0, 16);  slice_tensor_1790 = add_897 = None
        slice_scatter_default_3581: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3579, slice_scatter_default_3580, 1, 7152, 7168);  slice_scatter_default_3579 = slice_scatter_default_3580 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3581, 1, 7152, 7168)
        slice_29550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29549, 2, 0, 16);  slice_29549 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3581, 1, 7152, 7168)
        slice_scatter_default_3582: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1791, slice_29550, 2, 0, 16);  slice_tensor_1791 = slice_29550 = None
        slice_scatter_default_3583: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3581, slice_scatter_default_3582, 1, 7152, 7168);  slice_scatter_default_3581 = slice_scatter_default_3582 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29569: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7168, 7184)
        slice_29570: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29569, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_899: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29570, memory_format = torch.contiguous_format);  slice_29570 = None
        view_1802: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_899, [32, 16]);  clone_899 = None
        mm_896: "f32[32, 8]" = torch.ops.aten.mm.default(view_1802, slice_7)
        view_1803: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_896, [2, 16, 8]);  mm_896 = None
        slice_29577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3583, 1, 7168, 7184)
        slice_29578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29577, 2, 0, 16);  slice_29577 = None
        add_898: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29578, view_1803);  slice_29578 = view_1803 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3583, 1, 7168, 7184)
        slice_scatter_default_3584: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1792, add_898, 2, 0, 16);  slice_tensor_1792 = add_898 = None
        slice_scatter_default_3585: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3583, slice_scatter_default_3584, 1, 7168, 7184);  slice_scatter_default_3583 = slice_scatter_default_3584 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3585, 1, 7168, 7184)
        slice_29583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29582, 2, 0, 16);  slice_29582 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3585, 1, 7168, 7184)
        slice_scatter_default_3586: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1793, slice_29583, 2, 0, 16);  slice_tensor_1793 = slice_29583 = None
        slice_scatter_default_3587: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3585, slice_scatter_default_3586, 1, 7168, 7184);  slice_scatter_default_3585 = slice_scatter_default_3586 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29603: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29569, 2, 16, 32);  slice_29569 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_900: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29603, memory_format = torch.contiguous_format);  slice_29603 = None
        view_1804: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_900, [32, 11]);  clone_900 = None
        mm_897: "f32[32, 8]" = torch.ops.aten.mm.default(view_1804, slice_37)
        view_1805: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_897, [2, 16, 8]);  mm_897 = None
        slice_29610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3587, 1, 7168, 7184)
        slice_29611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29610, 2, 0, 16);  slice_29610 = None
        add_899: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29611, view_1805);  slice_29611 = view_1805 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3587, 1, 7168, 7184)
        slice_scatter_default_3588: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1794, add_899, 2, 0, 16);  slice_tensor_1794 = add_899 = None
        slice_scatter_default_3589: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3587, slice_scatter_default_3588, 1, 7168, 7184);  slice_scatter_default_3587 = slice_scatter_default_3588 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3589, 1, 7168, 7184)
        slice_29616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29615, 2, 0, 16);  slice_29615 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3589, 1, 7168, 7184)
        slice_scatter_default_3590: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1795, slice_29616, 2, 0, 16);  slice_tensor_1795 = slice_29616 = None
        slice_scatter_default_3591: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3589, slice_scatter_default_3590, 1, 7168, 7184);  slice_scatter_default_3589 = slice_scatter_default_3590 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29635: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7184, 7200)
        slice_29636: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29635, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_901: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29636, memory_format = torch.contiguous_format);  slice_29636 = None
        view_1806: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_901, [32, 16]);  clone_901 = None
        mm_898: "f32[32, 8]" = torch.ops.aten.mm.default(view_1806, slice_7)
        view_1807: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_898, [2, 16, 8]);  mm_898 = None
        slice_29643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3591, 1, 7184, 7200)
        slice_29644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29643, 2, 0, 16);  slice_29643 = None
        add_900: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29644, view_1807);  slice_29644 = view_1807 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3591, 1, 7184, 7200)
        slice_scatter_default_3592: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1796, add_900, 2, 0, 16);  slice_tensor_1796 = add_900 = None
        slice_scatter_default_3593: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3591, slice_scatter_default_3592, 1, 7184, 7200);  slice_scatter_default_3591 = slice_scatter_default_3592 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3593, 1, 7184, 7200)
        slice_29649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29648, 2, 0, 16);  slice_29648 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3593, 1, 7184, 7200)
        slice_scatter_default_3594: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1797, slice_29649, 2, 0, 16);  slice_tensor_1797 = slice_29649 = None
        slice_scatter_default_3595: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3593, slice_scatter_default_3594, 1, 7184, 7200);  slice_scatter_default_3593 = slice_scatter_default_3594 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29669: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29635, 2, 16, 32);  slice_29635 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_902: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29669, memory_format = torch.contiguous_format);  slice_29669 = None
        view_1808: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_902, [32, 11]);  clone_902 = None
        mm_899: "f32[32, 8]" = torch.ops.aten.mm.default(view_1808, slice_37)
        view_1809: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_899, [2, 16, 8]);  mm_899 = None
        slice_29676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3595, 1, 7184, 7200)
        slice_29677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29676, 2, 0, 16);  slice_29676 = None
        add_901: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29677, view_1809);  slice_29677 = view_1809 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3595, 1, 7184, 7200)
        slice_scatter_default_3596: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1798, add_901, 2, 0, 16);  slice_tensor_1798 = add_901 = None
        slice_scatter_default_3597: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3595, slice_scatter_default_3596, 1, 7184, 7200);  slice_scatter_default_3595 = slice_scatter_default_3596 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3597, 1, 7184, 7200)
        slice_29682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29681, 2, 0, 16);  slice_29681 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3597, 1, 7184, 7200)
        slice_scatter_default_3598: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1799, slice_29682, 2, 0, 16);  slice_tensor_1799 = slice_29682 = None
        slice_scatter_default_3599: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3597, slice_scatter_default_3598, 1, 7184, 7200);  slice_scatter_default_3597 = slice_scatter_default_3598 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29701: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7200, 7216)
        slice_29702: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29701, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_903: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29702, memory_format = torch.contiguous_format);  slice_29702 = None
        view_1810: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_903, [32, 16]);  clone_903 = None
        mm_900: "f32[32, 8]" = torch.ops.aten.mm.default(view_1810, slice_7)
        view_1811: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_900, [2, 16, 8]);  mm_900 = None
        slice_29709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3599, 1, 7200, 7216)
        slice_29710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29709, 2, 0, 16);  slice_29709 = None
        add_902: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29710, view_1811);  slice_29710 = view_1811 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3599, 1, 7200, 7216)
        slice_scatter_default_3600: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1800, add_902, 2, 0, 16);  slice_tensor_1800 = add_902 = None
        slice_scatter_default_3601: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3599, slice_scatter_default_3600, 1, 7200, 7216);  slice_scatter_default_3599 = slice_scatter_default_3600 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3601, 1, 7200, 7216)
        slice_29715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29714, 2, 0, 16);  slice_29714 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3601, 1, 7200, 7216)
        slice_scatter_default_3602: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1801, slice_29715, 2, 0, 16);  slice_tensor_1801 = slice_29715 = None
        slice_scatter_default_3603: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3601, slice_scatter_default_3602, 1, 7200, 7216);  slice_scatter_default_3601 = slice_scatter_default_3602 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29735: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29701, 2, 16, 32);  slice_29701 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_904: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29735, memory_format = torch.contiguous_format);  slice_29735 = None
        view_1812: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_904, [32, 11]);  clone_904 = None
        mm_901: "f32[32, 8]" = torch.ops.aten.mm.default(view_1812, slice_37)
        view_1813: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_901, [2, 16, 8]);  mm_901 = None
        slice_29742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3603, 1, 7200, 7216)
        slice_29743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29742, 2, 0, 16);  slice_29742 = None
        add_903: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29743, view_1813);  slice_29743 = view_1813 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3603, 1, 7200, 7216)
        slice_scatter_default_3604: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1802, add_903, 2, 0, 16);  slice_tensor_1802 = add_903 = None
        slice_scatter_default_3605: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3603, slice_scatter_default_3604, 1, 7200, 7216);  slice_scatter_default_3603 = slice_scatter_default_3604 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3605, 1, 7200, 7216)
        slice_29748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29747, 2, 0, 16);  slice_29747 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3605, 1, 7200, 7216)
        slice_scatter_default_3606: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1803, slice_29748, 2, 0, 16);  slice_tensor_1803 = slice_29748 = None
        slice_scatter_default_3607: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3605, slice_scatter_default_3606, 1, 7200, 7216);  slice_scatter_default_3605 = slice_scatter_default_3606 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29767: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7216, 7232)
        slice_29768: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29767, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_905: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29768, memory_format = torch.contiguous_format);  slice_29768 = None
        view_1814: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_905, [32, 16]);  clone_905 = None
        mm_902: "f32[32, 8]" = torch.ops.aten.mm.default(view_1814, slice_7)
        view_1815: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_902, [2, 16, 8]);  mm_902 = None
        slice_29775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3607, 1, 7216, 7232)
        slice_29776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29775, 2, 0, 16);  slice_29775 = None
        add_904: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29776, view_1815);  slice_29776 = view_1815 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3607, 1, 7216, 7232)
        slice_scatter_default_3608: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1804, add_904, 2, 0, 16);  slice_tensor_1804 = add_904 = None
        slice_scatter_default_3609: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3607, slice_scatter_default_3608, 1, 7216, 7232);  slice_scatter_default_3607 = slice_scatter_default_3608 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3609, 1, 7216, 7232)
        slice_29781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29780, 2, 0, 16);  slice_29780 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3609, 1, 7216, 7232)
        slice_scatter_default_3610: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1805, slice_29781, 2, 0, 16);  slice_tensor_1805 = slice_29781 = None
        slice_scatter_default_3611: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3609, slice_scatter_default_3610, 1, 7216, 7232);  slice_scatter_default_3609 = slice_scatter_default_3610 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29801: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29767, 2, 16, 32);  slice_29767 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_906: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29801, memory_format = torch.contiguous_format);  slice_29801 = None
        view_1816: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_906, [32, 11]);  clone_906 = None
        mm_903: "f32[32, 8]" = torch.ops.aten.mm.default(view_1816, slice_37)
        view_1817: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_903, [2, 16, 8]);  mm_903 = None
        slice_29808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3611, 1, 7216, 7232)
        slice_29809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29808, 2, 0, 16);  slice_29808 = None
        add_905: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29809, view_1817);  slice_29809 = view_1817 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3611, 1, 7216, 7232)
        slice_scatter_default_3612: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1806, add_905, 2, 0, 16);  slice_tensor_1806 = add_905 = None
        slice_scatter_default_3613: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3611, slice_scatter_default_3612, 1, 7216, 7232);  slice_scatter_default_3611 = slice_scatter_default_3612 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3613, 1, 7216, 7232)
        slice_29814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29813, 2, 0, 16);  slice_29813 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3613, 1, 7216, 7232)
        slice_scatter_default_3614: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1807, slice_29814, 2, 0, 16);  slice_tensor_1807 = slice_29814 = None
        slice_scatter_default_3615: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3613, slice_scatter_default_3614, 1, 7216, 7232);  slice_scatter_default_3613 = slice_scatter_default_3614 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29833: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7232, 7248)
        slice_29834: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29833, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_907: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29834, memory_format = torch.contiguous_format);  slice_29834 = None
        view_1818: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_907, [32, 16]);  clone_907 = None
        mm_904: "f32[32, 8]" = torch.ops.aten.mm.default(view_1818, slice_7)
        view_1819: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_904, [2, 16, 8]);  mm_904 = None
        slice_29841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3615, 1, 7232, 7248)
        slice_29842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29841, 2, 0, 16);  slice_29841 = None
        add_906: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29842, view_1819);  slice_29842 = view_1819 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3615, 1, 7232, 7248)
        slice_scatter_default_3616: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1808, add_906, 2, 0, 16);  slice_tensor_1808 = add_906 = None
        slice_scatter_default_3617: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3615, slice_scatter_default_3616, 1, 7232, 7248);  slice_scatter_default_3615 = slice_scatter_default_3616 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3617, 1, 7232, 7248)
        slice_29847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29846, 2, 0, 16);  slice_29846 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3617, 1, 7232, 7248)
        slice_scatter_default_3618: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1809, slice_29847, 2, 0, 16);  slice_tensor_1809 = slice_29847 = None
        slice_scatter_default_3619: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3617, slice_scatter_default_3618, 1, 7232, 7248);  slice_scatter_default_3617 = slice_scatter_default_3618 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29867: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29833, 2, 16, 32);  slice_29833 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_908: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29867, memory_format = torch.contiguous_format);  slice_29867 = None
        view_1820: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_908, [32, 11]);  clone_908 = None
        mm_905: "f32[32, 8]" = torch.ops.aten.mm.default(view_1820, slice_37)
        view_1821: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_905, [2, 16, 8]);  mm_905 = None
        slice_29874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3619, 1, 7232, 7248)
        slice_29875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29874, 2, 0, 16);  slice_29874 = None
        add_907: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29875, view_1821);  slice_29875 = view_1821 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3619, 1, 7232, 7248)
        slice_scatter_default_3620: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1810, add_907, 2, 0, 16);  slice_tensor_1810 = add_907 = None
        slice_scatter_default_3621: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3619, slice_scatter_default_3620, 1, 7232, 7248);  slice_scatter_default_3619 = slice_scatter_default_3620 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3621, 1, 7232, 7248)
        slice_29880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29879, 2, 0, 16);  slice_29879 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3621, 1, 7232, 7248)
        slice_scatter_default_3622: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1811, slice_29880, 2, 0, 16);  slice_tensor_1811 = slice_29880 = None
        slice_scatter_default_3623: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3621, slice_scatter_default_3622, 1, 7232, 7248);  slice_scatter_default_3621 = slice_scatter_default_3622 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29899: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7248, 7264)
        slice_29900: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29899, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_909: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29900, memory_format = torch.contiguous_format);  slice_29900 = None
        view_1822: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_909, [32, 16]);  clone_909 = None
        mm_906: "f32[32, 8]" = torch.ops.aten.mm.default(view_1822, slice_7)
        view_1823: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_906, [2, 16, 8]);  mm_906 = None
        slice_29907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3623, 1, 7248, 7264)
        slice_29908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29907, 2, 0, 16);  slice_29907 = None
        add_908: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29908, view_1823);  slice_29908 = view_1823 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3623, 1, 7248, 7264)
        slice_scatter_default_3624: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1812, add_908, 2, 0, 16);  slice_tensor_1812 = add_908 = None
        slice_scatter_default_3625: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3623, slice_scatter_default_3624, 1, 7248, 7264);  slice_scatter_default_3623 = slice_scatter_default_3624 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3625, 1, 7248, 7264)
        slice_29913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29912, 2, 0, 16);  slice_29912 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3625, 1, 7248, 7264)
        slice_scatter_default_3626: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1813, slice_29913, 2, 0, 16);  slice_tensor_1813 = slice_29913 = None
        slice_scatter_default_3627: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3625, slice_scatter_default_3626, 1, 7248, 7264);  slice_scatter_default_3625 = slice_scatter_default_3626 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29933: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29899, 2, 16, 32);  slice_29899 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_910: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29933, memory_format = torch.contiguous_format);  slice_29933 = None
        view_1824: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_910, [32, 11]);  clone_910 = None
        mm_907: "f32[32, 8]" = torch.ops.aten.mm.default(view_1824, slice_37)
        view_1825: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_907, [2, 16, 8]);  mm_907 = None
        slice_29940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3627, 1, 7248, 7264)
        slice_29941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29940, 2, 0, 16);  slice_29940 = None
        add_909: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29941, view_1825);  slice_29941 = view_1825 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3627, 1, 7248, 7264)
        slice_scatter_default_3628: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1814, add_909, 2, 0, 16);  slice_tensor_1814 = add_909 = None
        slice_scatter_default_3629: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3627, slice_scatter_default_3628, 1, 7248, 7264);  slice_scatter_default_3627 = slice_scatter_default_3628 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3629, 1, 7248, 7264)
        slice_29946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29945, 2, 0, 16);  slice_29945 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3629, 1, 7248, 7264)
        slice_scatter_default_3630: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1815, slice_29946, 2, 0, 16);  slice_tensor_1815 = slice_29946 = None
        slice_scatter_default_3631: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3629, slice_scatter_default_3630, 1, 7248, 7264);  slice_scatter_default_3629 = slice_scatter_default_3630 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29965: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7264, 7280)
        slice_29966: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_29965, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_911: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_29966, memory_format = torch.contiguous_format);  slice_29966 = None
        view_1826: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_911, [32, 16]);  clone_911 = None
        mm_908: "f32[32, 8]" = torch.ops.aten.mm.default(view_1826, slice_7)
        view_1827: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_908, [2, 16, 8]);  mm_908 = None
        slice_29973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3631, 1, 7264, 7280)
        slice_29974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29973, 2, 0, 16);  slice_29973 = None
        add_910: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_29974, view_1827);  slice_29974 = view_1827 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3631, 1, 7264, 7280)
        slice_scatter_default_3632: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1816, add_910, 2, 0, 16);  slice_tensor_1816 = add_910 = None
        slice_scatter_default_3633: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3631, slice_scatter_default_3632, 1, 7264, 7280);  slice_scatter_default_3631 = slice_scatter_default_3632 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_29978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3633, 1, 7264, 7280)
        slice_29979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_29978, 2, 0, 16);  slice_29978 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3633, 1, 7264, 7280)
        slice_scatter_default_3634: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1817, slice_29979, 2, 0, 16);  slice_tensor_1817 = slice_29979 = None
        slice_scatter_default_3635: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3633, slice_scatter_default_3634, 1, 7264, 7280);  slice_scatter_default_3633 = slice_scatter_default_3634 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_29999: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_29965, 2, 16, 32);  slice_29965 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_912: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_29999, memory_format = torch.contiguous_format);  slice_29999 = None
        view_1828: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_912, [32, 11]);  clone_912 = None
        mm_909: "f32[32, 8]" = torch.ops.aten.mm.default(view_1828, slice_37)
        view_1829: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_909, [2, 16, 8]);  mm_909 = None
        slice_30006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3635, 1, 7264, 7280)
        slice_30007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30006, 2, 0, 16);  slice_30006 = None
        add_911: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30007, view_1829);  slice_30007 = view_1829 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3635, 1, 7264, 7280)
        slice_scatter_default_3636: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1818, add_911, 2, 0, 16);  slice_tensor_1818 = add_911 = None
        slice_scatter_default_3637: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3635, slice_scatter_default_3636, 1, 7264, 7280);  slice_scatter_default_3635 = slice_scatter_default_3636 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3637, 1, 7264, 7280)
        slice_30012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30011, 2, 0, 16);  slice_30011 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3637, 1, 7264, 7280)
        slice_scatter_default_3638: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1819, slice_30012, 2, 0, 16);  slice_tensor_1819 = slice_30012 = None
        slice_scatter_default_3639: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3637, slice_scatter_default_3638, 1, 7264, 7280);  slice_scatter_default_3637 = slice_scatter_default_3638 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30031: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7280, 7296)
        slice_30032: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30031, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_913: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30032, memory_format = torch.contiguous_format);  slice_30032 = None
        view_1830: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_913, [32, 16]);  clone_913 = None
        mm_910: "f32[32, 8]" = torch.ops.aten.mm.default(view_1830, slice_7)
        view_1831: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_910, [2, 16, 8]);  mm_910 = None
        slice_30039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3639, 1, 7280, 7296)
        slice_30040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30039, 2, 0, 16);  slice_30039 = None
        add_912: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30040, view_1831);  slice_30040 = view_1831 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3639, 1, 7280, 7296)
        slice_scatter_default_3640: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1820, add_912, 2, 0, 16);  slice_tensor_1820 = add_912 = None
        slice_scatter_default_3641: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3639, slice_scatter_default_3640, 1, 7280, 7296);  slice_scatter_default_3639 = slice_scatter_default_3640 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3641, 1, 7280, 7296)
        slice_30045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30044, 2, 0, 16);  slice_30044 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3641, 1, 7280, 7296)
        slice_scatter_default_3642: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1821, slice_30045, 2, 0, 16);  slice_tensor_1821 = slice_30045 = None
        slice_scatter_default_3643: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3641, slice_scatter_default_3642, 1, 7280, 7296);  slice_scatter_default_3641 = slice_scatter_default_3642 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30065: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30031, 2, 16, 32);  slice_30031 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_914: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30065, memory_format = torch.contiguous_format);  slice_30065 = None
        view_1832: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_914, [32, 11]);  clone_914 = None
        mm_911: "f32[32, 8]" = torch.ops.aten.mm.default(view_1832, slice_37)
        view_1833: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_911, [2, 16, 8]);  mm_911 = None
        slice_30072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3643, 1, 7280, 7296)
        slice_30073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30072, 2, 0, 16);  slice_30072 = None
        add_913: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30073, view_1833);  slice_30073 = view_1833 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3643, 1, 7280, 7296)
        slice_scatter_default_3644: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1822, add_913, 2, 0, 16);  slice_tensor_1822 = add_913 = None
        slice_scatter_default_3645: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3643, slice_scatter_default_3644, 1, 7280, 7296);  slice_scatter_default_3643 = slice_scatter_default_3644 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3645, 1, 7280, 7296)
        slice_30078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30077, 2, 0, 16);  slice_30077 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3645, 1, 7280, 7296)
        slice_scatter_default_3646: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1823, slice_30078, 2, 0, 16);  slice_tensor_1823 = slice_30078 = None
        slice_scatter_default_3647: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3645, slice_scatter_default_3646, 1, 7280, 7296);  slice_scatter_default_3645 = slice_scatter_default_3646 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30097: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7296, 7312)
        slice_30098: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30097, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_915: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30098, memory_format = torch.contiguous_format);  slice_30098 = None
        view_1834: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_915, [32, 16]);  clone_915 = None
        mm_912: "f32[32, 8]" = torch.ops.aten.mm.default(view_1834, slice_7)
        view_1835: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_912, [2, 16, 8]);  mm_912 = None
        slice_30105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3647, 1, 7296, 7312)
        slice_30106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30105, 2, 0, 16);  slice_30105 = None
        add_914: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30106, view_1835);  slice_30106 = view_1835 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3647, 1, 7296, 7312)
        slice_scatter_default_3648: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1824, add_914, 2, 0, 16);  slice_tensor_1824 = add_914 = None
        slice_scatter_default_3649: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3647, slice_scatter_default_3648, 1, 7296, 7312);  slice_scatter_default_3647 = slice_scatter_default_3648 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3649, 1, 7296, 7312)
        slice_30111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30110, 2, 0, 16);  slice_30110 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3649, 1, 7296, 7312)
        slice_scatter_default_3650: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1825, slice_30111, 2, 0, 16);  slice_tensor_1825 = slice_30111 = None
        slice_scatter_default_3651: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3649, slice_scatter_default_3650, 1, 7296, 7312);  slice_scatter_default_3649 = slice_scatter_default_3650 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30131: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30097, 2, 16, 32);  slice_30097 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_916: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30131, memory_format = torch.contiguous_format);  slice_30131 = None
        view_1836: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_916, [32, 11]);  clone_916 = None
        mm_913: "f32[32, 8]" = torch.ops.aten.mm.default(view_1836, slice_37)
        view_1837: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_913, [2, 16, 8]);  mm_913 = None
        slice_30138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3651, 1, 7296, 7312)
        slice_30139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30138, 2, 0, 16);  slice_30138 = None
        add_915: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30139, view_1837);  slice_30139 = view_1837 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3651, 1, 7296, 7312)
        slice_scatter_default_3652: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1826, add_915, 2, 0, 16);  slice_tensor_1826 = add_915 = None
        slice_scatter_default_3653: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3651, slice_scatter_default_3652, 1, 7296, 7312);  slice_scatter_default_3651 = slice_scatter_default_3652 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3653, 1, 7296, 7312)
        slice_30144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30143, 2, 0, 16);  slice_30143 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3653, 1, 7296, 7312)
        slice_scatter_default_3654: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1827, slice_30144, 2, 0, 16);  slice_tensor_1827 = slice_30144 = None
        slice_scatter_default_3655: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3653, slice_scatter_default_3654, 1, 7296, 7312);  slice_scatter_default_3653 = slice_scatter_default_3654 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30163: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7312, 7328)
        slice_30164: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30163, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_917: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30164, memory_format = torch.contiguous_format);  slice_30164 = None
        view_1838: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_917, [32, 16]);  clone_917 = None
        mm_914: "f32[32, 8]" = torch.ops.aten.mm.default(view_1838, slice_7)
        view_1839: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_914, [2, 16, 8]);  mm_914 = None
        slice_30171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3655, 1, 7312, 7328)
        slice_30172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30171, 2, 0, 16);  slice_30171 = None
        add_916: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30172, view_1839);  slice_30172 = view_1839 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3655, 1, 7312, 7328)
        slice_scatter_default_3656: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1828, add_916, 2, 0, 16);  slice_tensor_1828 = add_916 = None
        slice_scatter_default_3657: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3655, slice_scatter_default_3656, 1, 7312, 7328);  slice_scatter_default_3655 = slice_scatter_default_3656 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3657, 1, 7312, 7328)
        slice_30177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30176, 2, 0, 16);  slice_30176 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3657, 1, 7312, 7328)
        slice_scatter_default_3658: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1829, slice_30177, 2, 0, 16);  slice_tensor_1829 = slice_30177 = None
        slice_scatter_default_3659: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3657, slice_scatter_default_3658, 1, 7312, 7328);  slice_scatter_default_3657 = slice_scatter_default_3658 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30197: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30163, 2, 16, 32);  slice_30163 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_918: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30197, memory_format = torch.contiguous_format);  slice_30197 = None
        view_1840: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_918, [32, 11]);  clone_918 = None
        mm_915: "f32[32, 8]" = torch.ops.aten.mm.default(view_1840, slice_37)
        view_1841: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_915, [2, 16, 8]);  mm_915 = None
        slice_30204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3659, 1, 7312, 7328)
        slice_30205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30204, 2, 0, 16);  slice_30204 = None
        add_917: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30205, view_1841);  slice_30205 = view_1841 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3659, 1, 7312, 7328)
        slice_scatter_default_3660: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1830, add_917, 2, 0, 16);  slice_tensor_1830 = add_917 = None
        slice_scatter_default_3661: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3659, slice_scatter_default_3660, 1, 7312, 7328);  slice_scatter_default_3659 = slice_scatter_default_3660 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3661, 1, 7312, 7328)
        slice_30210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30209, 2, 0, 16);  slice_30209 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3661, 1, 7312, 7328)
        slice_scatter_default_3662: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1831, slice_30210, 2, 0, 16);  slice_tensor_1831 = slice_30210 = None
        slice_scatter_default_3663: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3661, slice_scatter_default_3662, 1, 7312, 7328);  slice_scatter_default_3661 = slice_scatter_default_3662 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30229: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7328, 7344)
        slice_30230: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30229, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_919: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30230, memory_format = torch.contiguous_format);  slice_30230 = None
        view_1842: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_919, [32, 16]);  clone_919 = None
        mm_916: "f32[32, 8]" = torch.ops.aten.mm.default(view_1842, slice_7)
        view_1843: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_916, [2, 16, 8]);  mm_916 = None
        slice_30237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3663, 1, 7328, 7344)
        slice_30238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30237, 2, 0, 16);  slice_30237 = None
        add_918: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30238, view_1843);  slice_30238 = view_1843 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3663, 1, 7328, 7344)
        slice_scatter_default_3664: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1832, add_918, 2, 0, 16);  slice_tensor_1832 = add_918 = None
        slice_scatter_default_3665: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3663, slice_scatter_default_3664, 1, 7328, 7344);  slice_scatter_default_3663 = slice_scatter_default_3664 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3665, 1, 7328, 7344)
        slice_30243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30242, 2, 0, 16);  slice_30242 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3665, 1, 7328, 7344)
        slice_scatter_default_3666: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1833, slice_30243, 2, 0, 16);  slice_tensor_1833 = slice_30243 = None
        slice_scatter_default_3667: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3665, slice_scatter_default_3666, 1, 7328, 7344);  slice_scatter_default_3665 = slice_scatter_default_3666 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30263: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30229, 2, 16, 32);  slice_30229 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_920: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30263, memory_format = torch.contiguous_format);  slice_30263 = None
        view_1844: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_920, [32, 11]);  clone_920 = None
        mm_917: "f32[32, 8]" = torch.ops.aten.mm.default(view_1844, slice_37)
        view_1845: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_917, [2, 16, 8]);  mm_917 = None
        slice_30270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3667, 1, 7328, 7344)
        slice_30271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30270, 2, 0, 16);  slice_30270 = None
        add_919: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30271, view_1845);  slice_30271 = view_1845 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3667, 1, 7328, 7344)
        slice_scatter_default_3668: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1834, add_919, 2, 0, 16);  slice_tensor_1834 = add_919 = None
        slice_scatter_default_3669: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3667, slice_scatter_default_3668, 1, 7328, 7344);  slice_scatter_default_3667 = slice_scatter_default_3668 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3669, 1, 7328, 7344)
        slice_30276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30275, 2, 0, 16);  slice_30275 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3669, 1, 7328, 7344)
        slice_scatter_default_3670: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1835, slice_30276, 2, 0, 16);  slice_tensor_1835 = slice_30276 = None
        slice_scatter_default_3671: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3669, slice_scatter_default_3670, 1, 7328, 7344);  slice_scatter_default_3669 = slice_scatter_default_3670 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30295: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7344, 7360)
        slice_30296: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30295, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_921: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30296, memory_format = torch.contiguous_format);  slice_30296 = None
        view_1846: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_921, [32, 16]);  clone_921 = None
        mm_918: "f32[32, 8]" = torch.ops.aten.mm.default(view_1846, slice_7)
        view_1847: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_918, [2, 16, 8]);  mm_918 = None
        slice_30303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3671, 1, 7344, 7360)
        slice_30304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30303, 2, 0, 16);  slice_30303 = None
        add_920: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30304, view_1847);  slice_30304 = view_1847 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3671, 1, 7344, 7360)
        slice_scatter_default_3672: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1836, add_920, 2, 0, 16);  slice_tensor_1836 = add_920 = None
        slice_scatter_default_3673: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3671, slice_scatter_default_3672, 1, 7344, 7360);  slice_scatter_default_3671 = slice_scatter_default_3672 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3673, 1, 7344, 7360)
        slice_30309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30308, 2, 0, 16);  slice_30308 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3673, 1, 7344, 7360)
        slice_scatter_default_3674: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1837, slice_30309, 2, 0, 16);  slice_tensor_1837 = slice_30309 = None
        slice_scatter_default_3675: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3673, slice_scatter_default_3674, 1, 7344, 7360);  slice_scatter_default_3673 = slice_scatter_default_3674 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30329: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30295, 2, 16, 32);  slice_30295 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_922: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30329, memory_format = torch.contiguous_format);  slice_30329 = None
        view_1848: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_922, [32, 11]);  clone_922 = None
        mm_919: "f32[32, 8]" = torch.ops.aten.mm.default(view_1848, slice_37)
        view_1849: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_919, [2, 16, 8]);  mm_919 = None
        slice_30336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3675, 1, 7344, 7360)
        slice_30337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30336, 2, 0, 16);  slice_30336 = None
        add_921: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30337, view_1849);  slice_30337 = view_1849 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3675, 1, 7344, 7360)
        slice_scatter_default_3676: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1838, add_921, 2, 0, 16);  slice_tensor_1838 = add_921 = None
        slice_scatter_default_3677: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3675, slice_scatter_default_3676, 1, 7344, 7360);  slice_scatter_default_3675 = slice_scatter_default_3676 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3677, 1, 7344, 7360)
        slice_30342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30341, 2, 0, 16);  slice_30341 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3677, 1, 7344, 7360)
        slice_scatter_default_3678: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1839, slice_30342, 2, 0, 16);  slice_tensor_1839 = slice_30342 = None
        slice_scatter_default_3679: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3677, slice_scatter_default_3678, 1, 7344, 7360);  slice_scatter_default_3677 = slice_scatter_default_3678 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30361: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7360, 7376)
        slice_30362: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30361, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_923: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30362, memory_format = torch.contiguous_format);  slice_30362 = None
        view_1850: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_923, [32, 16]);  clone_923 = None
        mm_920: "f32[32, 8]" = torch.ops.aten.mm.default(view_1850, slice_7)
        view_1851: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_920, [2, 16, 8]);  mm_920 = None
        slice_30369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3679, 1, 7360, 7376)
        slice_30370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30369, 2, 0, 16);  slice_30369 = None
        add_922: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30370, view_1851);  slice_30370 = view_1851 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3679, 1, 7360, 7376)
        slice_scatter_default_3680: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1840, add_922, 2, 0, 16);  slice_tensor_1840 = add_922 = None
        slice_scatter_default_3681: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3679, slice_scatter_default_3680, 1, 7360, 7376);  slice_scatter_default_3679 = slice_scatter_default_3680 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3681, 1, 7360, 7376)
        slice_30375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30374, 2, 0, 16);  slice_30374 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3681, 1, 7360, 7376)
        slice_scatter_default_3682: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1841, slice_30375, 2, 0, 16);  slice_tensor_1841 = slice_30375 = None
        slice_scatter_default_3683: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3681, slice_scatter_default_3682, 1, 7360, 7376);  slice_scatter_default_3681 = slice_scatter_default_3682 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30395: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30361, 2, 16, 32);  slice_30361 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_924: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30395, memory_format = torch.contiguous_format);  slice_30395 = None
        view_1852: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_924, [32, 11]);  clone_924 = None
        mm_921: "f32[32, 8]" = torch.ops.aten.mm.default(view_1852, slice_37)
        view_1853: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_921, [2, 16, 8]);  mm_921 = None
        slice_30402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3683, 1, 7360, 7376)
        slice_30403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30402, 2, 0, 16);  slice_30402 = None
        add_923: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30403, view_1853);  slice_30403 = view_1853 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3683, 1, 7360, 7376)
        slice_scatter_default_3684: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1842, add_923, 2, 0, 16);  slice_tensor_1842 = add_923 = None
        slice_scatter_default_3685: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3683, slice_scatter_default_3684, 1, 7360, 7376);  slice_scatter_default_3683 = slice_scatter_default_3684 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3685, 1, 7360, 7376)
        slice_30408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30407, 2, 0, 16);  slice_30407 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3685, 1, 7360, 7376)
        slice_scatter_default_3686: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1843, slice_30408, 2, 0, 16);  slice_tensor_1843 = slice_30408 = None
        slice_scatter_default_3687: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3685, slice_scatter_default_3686, 1, 7360, 7376);  slice_scatter_default_3685 = slice_scatter_default_3686 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30427: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7376, 7392)
        slice_30428: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30427, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_925: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30428, memory_format = torch.contiguous_format);  slice_30428 = None
        view_1854: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_925, [32, 16]);  clone_925 = None
        mm_922: "f32[32, 8]" = torch.ops.aten.mm.default(view_1854, slice_7)
        view_1855: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_922, [2, 16, 8]);  mm_922 = None
        slice_30435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3687, 1, 7376, 7392)
        slice_30436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30435, 2, 0, 16);  slice_30435 = None
        add_924: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30436, view_1855);  slice_30436 = view_1855 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3687, 1, 7376, 7392)
        slice_scatter_default_3688: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1844, add_924, 2, 0, 16);  slice_tensor_1844 = add_924 = None
        slice_scatter_default_3689: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3687, slice_scatter_default_3688, 1, 7376, 7392);  slice_scatter_default_3687 = slice_scatter_default_3688 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3689, 1, 7376, 7392)
        slice_30441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30440, 2, 0, 16);  slice_30440 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3689, 1, 7376, 7392)
        slice_scatter_default_3690: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1845, slice_30441, 2, 0, 16);  slice_tensor_1845 = slice_30441 = None
        slice_scatter_default_3691: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3689, slice_scatter_default_3690, 1, 7376, 7392);  slice_scatter_default_3689 = slice_scatter_default_3690 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30461: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30427, 2, 16, 32);  slice_30427 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_926: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30461, memory_format = torch.contiguous_format);  slice_30461 = None
        view_1856: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_926, [32, 11]);  clone_926 = None
        mm_923: "f32[32, 8]" = torch.ops.aten.mm.default(view_1856, slice_37)
        view_1857: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_923, [2, 16, 8]);  mm_923 = None
        slice_30468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3691, 1, 7376, 7392)
        slice_30469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30468, 2, 0, 16);  slice_30468 = None
        add_925: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30469, view_1857);  slice_30469 = view_1857 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3691, 1, 7376, 7392)
        slice_scatter_default_3692: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1846, add_925, 2, 0, 16);  slice_tensor_1846 = add_925 = None
        slice_scatter_default_3693: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3691, slice_scatter_default_3692, 1, 7376, 7392);  slice_scatter_default_3691 = slice_scatter_default_3692 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3693, 1, 7376, 7392)
        slice_30474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30473, 2, 0, 16);  slice_30473 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3693, 1, 7376, 7392)
        slice_scatter_default_3694: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1847, slice_30474, 2, 0, 16);  slice_tensor_1847 = slice_30474 = None
        slice_scatter_default_3695: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3693, slice_scatter_default_3694, 1, 7376, 7392);  slice_scatter_default_3693 = slice_scatter_default_3694 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30493: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7392, 7408)
        slice_30494: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30493, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_927: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30494, memory_format = torch.contiguous_format);  slice_30494 = None
        view_1858: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_927, [32, 16]);  clone_927 = None
        mm_924: "f32[32, 8]" = torch.ops.aten.mm.default(view_1858, slice_7)
        view_1859: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_924, [2, 16, 8]);  mm_924 = None
        slice_30501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3695, 1, 7392, 7408)
        slice_30502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30501, 2, 0, 16);  slice_30501 = None
        add_926: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30502, view_1859);  slice_30502 = view_1859 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3695, 1, 7392, 7408)
        slice_scatter_default_3696: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1848, add_926, 2, 0, 16);  slice_tensor_1848 = add_926 = None
        slice_scatter_default_3697: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3695, slice_scatter_default_3696, 1, 7392, 7408);  slice_scatter_default_3695 = slice_scatter_default_3696 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3697, 1, 7392, 7408)
        slice_30507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30506, 2, 0, 16);  slice_30506 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3697, 1, 7392, 7408)
        slice_scatter_default_3698: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1849, slice_30507, 2, 0, 16);  slice_tensor_1849 = slice_30507 = None
        slice_scatter_default_3699: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3697, slice_scatter_default_3698, 1, 7392, 7408);  slice_scatter_default_3697 = slice_scatter_default_3698 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30527: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30493, 2, 16, 32);  slice_30493 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_928: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30527, memory_format = torch.contiguous_format);  slice_30527 = None
        view_1860: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_928, [32, 11]);  clone_928 = None
        mm_925: "f32[32, 8]" = torch.ops.aten.mm.default(view_1860, slice_37)
        view_1861: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_925, [2, 16, 8]);  mm_925 = None
        slice_30534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3699, 1, 7392, 7408)
        slice_30535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30534, 2, 0, 16);  slice_30534 = None
        add_927: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30535, view_1861);  slice_30535 = view_1861 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3699, 1, 7392, 7408)
        slice_scatter_default_3700: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1850, add_927, 2, 0, 16);  slice_tensor_1850 = add_927 = None
        slice_scatter_default_3701: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3699, slice_scatter_default_3700, 1, 7392, 7408);  slice_scatter_default_3699 = slice_scatter_default_3700 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3701, 1, 7392, 7408)
        slice_30540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30539, 2, 0, 16);  slice_30539 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3701, 1, 7392, 7408)
        slice_scatter_default_3702: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1851, slice_30540, 2, 0, 16);  slice_tensor_1851 = slice_30540 = None
        slice_scatter_default_3703: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3701, slice_scatter_default_3702, 1, 7392, 7408);  slice_scatter_default_3701 = slice_scatter_default_3702 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30559: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7408, 7424)
        slice_30560: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30559, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_929: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30560, memory_format = torch.contiguous_format);  slice_30560 = None
        view_1862: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_929, [32, 16]);  clone_929 = None
        mm_926: "f32[32, 8]" = torch.ops.aten.mm.default(view_1862, slice_7)
        view_1863: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_926, [2, 16, 8]);  mm_926 = None
        slice_30567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3703, 1, 7408, 7424)
        slice_30568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30567, 2, 0, 16);  slice_30567 = None
        add_928: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30568, view_1863);  slice_30568 = view_1863 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3703, 1, 7408, 7424)
        slice_scatter_default_3704: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1852, add_928, 2, 0, 16);  slice_tensor_1852 = add_928 = None
        slice_scatter_default_3705: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3703, slice_scatter_default_3704, 1, 7408, 7424);  slice_scatter_default_3703 = slice_scatter_default_3704 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3705, 1, 7408, 7424)
        slice_30573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30572, 2, 0, 16);  slice_30572 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3705, 1, 7408, 7424)
        slice_scatter_default_3706: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1853, slice_30573, 2, 0, 16);  slice_tensor_1853 = slice_30573 = None
        slice_scatter_default_3707: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3705, slice_scatter_default_3706, 1, 7408, 7424);  slice_scatter_default_3705 = slice_scatter_default_3706 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30593: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30559, 2, 16, 32);  slice_30559 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_930: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30593, memory_format = torch.contiguous_format);  slice_30593 = None
        view_1864: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_930, [32, 11]);  clone_930 = None
        mm_927: "f32[32, 8]" = torch.ops.aten.mm.default(view_1864, slice_37)
        view_1865: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_927, [2, 16, 8]);  mm_927 = None
        slice_30600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3707, 1, 7408, 7424)
        slice_30601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30600, 2, 0, 16);  slice_30600 = None
        add_929: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30601, view_1865);  slice_30601 = view_1865 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3707, 1, 7408, 7424)
        slice_scatter_default_3708: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1854, add_929, 2, 0, 16);  slice_tensor_1854 = add_929 = None
        slice_scatter_default_3709: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3707, slice_scatter_default_3708, 1, 7408, 7424);  slice_scatter_default_3707 = slice_scatter_default_3708 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3709, 1, 7408, 7424)
        slice_30606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30605, 2, 0, 16);  slice_30605 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3709, 1, 7408, 7424)
        slice_scatter_default_3710: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1855, slice_30606, 2, 0, 16);  slice_tensor_1855 = slice_30606 = None
        slice_scatter_default_3711: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3709, slice_scatter_default_3710, 1, 7408, 7424);  slice_scatter_default_3709 = slice_scatter_default_3710 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30625: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7424, 7440)
        slice_30626: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30625, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_931: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30626, memory_format = torch.contiguous_format);  slice_30626 = None
        view_1866: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_931, [32, 16]);  clone_931 = None
        mm_928: "f32[32, 8]" = torch.ops.aten.mm.default(view_1866, slice_7)
        view_1867: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_928, [2, 16, 8]);  mm_928 = None
        slice_30633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3711, 1, 7424, 7440)
        slice_30634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30633, 2, 0, 16);  slice_30633 = None
        add_930: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30634, view_1867);  slice_30634 = view_1867 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3711, 1, 7424, 7440)
        slice_scatter_default_3712: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1856, add_930, 2, 0, 16);  slice_tensor_1856 = add_930 = None
        slice_scatter_default_3713: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3711, slice_scatter_default_3712, 1, 7424, 7440);  slice_scatter_default_3711 = slice_scatter_default_3712 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3713, 1, 7424, 7440)
        slice_30639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30638, 2, 0, 16);  slice_30638 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3713, 1, 7424, 7440)
        slice_scatter_default_3714: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1857, slice_30639, 2, 0, 16);  slice_tensor_1857 = slice_30639 = None
        slice_scatter_default_3715: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3713, slice_scatter_default_3714, 1, 7424, 7440);  slice_scatter_default_3713 = slice_scatter_default_3714 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30659: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30625, 2, 16, 32);  slice_30625 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_932: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30659, memory_format = torch.contiguous_format);  slice_30659 = None
        view_1868: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_932, [32, 11]);  clone_932 = None
        mm_929: "f32[32, 8]" = torch.ops.aten.mm.default(view_1868, slice_37)
        view_1869: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_929, [2, 16, 8]);  mm_929 = None
        slice_30666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3715, 1, 7424, 7440)
        slice_30667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30666, 2, 0, 16);  slice_30666 = None
        add_931: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30667, view_1869);  slice_30667 = view_1869 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3715, 1, 7424, 7440)
        slice_scatter_default_3716: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1858, add_931, 2, 0, 16);  slice_tensor_1858 = add_931 = None
        slice_scatter_default_3717: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3715, slice_scatter_default_3716, 1, 7424, 7440);  slice_scatter_default_3715 = slice_scatter_default_3716 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3717, 1, 7424, 7440)
        slice_30672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30671, 2, 0, 16);  slice_30671 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3717, 1, 7424, 7440)
        slice_scatter_default_3718: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1859, slice_30672, 2, 0, 16);  slice_tensor_1859 = slice_30672 = None
        slice_scatter_default_3719: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3717, slice_scatter_default_3718, 1, 7424, 7440);  slice_scatter_default_3717 = slice_scatter_default_3718 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30691: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7440, 7456)
        slice_30692: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30691, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_933: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30692, memory_format = torch.contiguous_format);  slice_30692 = None
        view_1870: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_933, [32, 16]);  clone_933 = None
        mm_930: "f32[32, 8]" = torch.ops.aten.mm.default(view_1870, slice_7)
        view_1871: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_930, [2, 16, 8]);  mm_930 = None
        slice_30699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3719, 1, 7440, 7456)
        slice_30700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30699, 2, 0, 16);  slice_30699 = None
        add_932: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30700, view_1871);  slice_30700 = view_1871 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3719, 1, 7440, 7456)
        slice_scatter_default_3720: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1860, add_932, 2, 0, 16);  slice_tensor_1860 = add_932 = None
        slice_scatter_default_3721: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3719, slice_scatter_default_3720, 1, 7440, 7456);  slice_scatter_default_3719 = slice_scatter_default_3720 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3721, 1, 7440, 7456)
        slice_30705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30704, 2, 0, 16);  slice_30704 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3721, 1, 7440, 7456)
        slice_scatter_default_3722: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1861, slice_30705, 2, 0, 16);  slice_tensor_1861 = slice_30705 = None
        slice_scatter_default_3723: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3721, slice_scatter_default_3722, 1, 7440, 7456);  slice_scatter_default_3721 = slice_scatter_default_3722 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30725: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30691, 2, 16, 32);  slice_30691 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_934: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30725, memory_format = torch.contiguous_format);  slice_30725 = None
        view_1872: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_934, [32, 11]);  clone_934 = None
        mm_931: "f32[32, 8]" = torch.ops.aten.mm.default(view_1872, slice_37)
        view_1873: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_931, [2, 16, 8]);  mm_931 = None
        slice_30732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3723, 1, 7440, 7456)
        slice_30733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30732, 2, 0, 16);  slice_30732 = None
        add_933: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30733, view_1873);  slice_30733 = view_1873 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3723, 1, 7440, 7456)
        slice_scatter_default_3724: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1862, add_933, 2, 0, 16);  slice_tensor_1862 = add_933 = None
        slice_scatter_default_3725: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3723, slice_scatter_default_3724, 1, 7440, 7456);  slice_scatter_default_3723 = slice_scatter_default_3724 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3725, 1, 7440, 7456)
        slice_30738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30737, 2, 0, 16);  slice_30737 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3725, 1, 7440, 7456)
        slice_scatter_default_3726: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1863, slice_30738, 2, 0, 16);  slice_tensor_1863 = slice_30738 = None
        slice_scatter_default_3727: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3725, slice_scatter_default_3726, 1, 7440, 7456);  slice_scatter_default_3725 = slice_scatter_default_3726 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30757: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7456, 7472)
        slice_30758: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30757, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_935: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30758, memory_format = torch.contiguous_format);  slice_30758 = None
        view_1874: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_935, [32, 16]);  clone_935 = None
        mm_932: "f32[32, 8]" = torch.ops.aten.mm.default(view_1874, slice_7)
        view_1875: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_932, [2, 16, 8]);  mm_932 = None
        slice_30765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3727, 1, 7456, 7472)
        slice_30766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30765, 2, 0, 16);  slice_30765 = None
        add_934: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30766, view_1875);  slice_30766 = view_1875 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3727, 1, 7456, 7472)
        slice_scatter_default_3728: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1864, add_934, 2, 0, 16);  slice_tensor_1864 = add_934 = None
        slice_scatter_default_3729: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3727, slice_scatter_default_3728, 1, 7456, 7472);  slice_scatter_default_3727 = slice_scatter_default_3728 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3729, 1, 7456, 7472)
        slice_30771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30770, 2, 0, 16);  slice_30770 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3729, 1, 7456, 7472)
        slice_scatter_default_3730: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1865, slice_30771, 2, 0, 16);  slice_tensor_1865 = slice_30771 = None
        slice_scatter_default_3731: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3729, slice_scatter_default_3730, 1, 7456, 7472);  slice_scatter_default_3729 = slice_scatter_default_3730 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30791: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30757, 2, 16, 32);  slice_30757 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_936: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30791, memory_format = torch.contiguous_format);  slice_30791 = None
        view_1876: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_936, [32, 11]);  clone_936 = None
        mm_933: "f32[32, 8]" = torch.ops.aten.mm.default(view_1876, slice_37)
        view_1877: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_933, [2, 16, 8]);  mm_933 = None
        slice_30798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3731, 1, 7456, 7472)
        slice_30799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30798, 2, 0, 16);  slice_30798 = None
        add_935: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30799, view_1877);  slice_30799 = view_1877 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3731, 1, 7456, 7472)
        slice_scatter_default_3732: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1866, add_935, 2, 0, 16);  slice_tensor_1866 = add_935 = None
        slice_scatter_default_3733: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3731, slice_scatter_default_3732, 1, 7456, 7472);  slice_scatter_default_3731 = slice_scatter_default_3732 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3733, 1, 7456, 7472)
        slice_30804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30803, 2, 0, 16);  slice_30803 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3733, 1, 7456, 7472)
        slice_scatter_default_3734: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1867, slice_30804, 2, 0, 16);  slice_tensor_1867 = slice_30804 = None
        slice_scatter_default_3735: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3733, slice_scatter_default_3734, 1, 7456, 7472);  slice_scatter_default_3733 = slice_scatter_default_3734 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30823: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7472, 7488)
        slice_30824: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30823, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_937: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30824, memory_format = torch.contiguous_format);  slice_30824 = None
        view_1878: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_937, [32, 16]);  clone_937 = None
        mm_934: "f32[32, 8]" = torch.ops.aten.mm.default(view_1878, slice_7)
        view_1879: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_934, [2, 16, 8]);  mm_934 = None
        slice_30831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3735, 1, 7472, 7488)
        slice_30832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30831, 2, 0, 16);  slice_30831 = None
        add_936: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30832, view_1879);  slice_30832 = view_1879 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3735, 1, 7472, 7488)
        slice_scatter_default_3736: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1868, add_936, 2, 0, 16);  slice_tensor_1868 = add_936 = None
        slice_scatter_default_3737: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3735, slice_scatter_default_3736, 1, 7472, 7488);  slice_scatter_default_3735 = slice_scatter_default_3736 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3737, 1, 7472, 7488)
        slice_30837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30836, 2, 0, 16);  slice_30836 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3737, 1, 7472, 7488)
        slice_scatter_default_3738: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1869, slice_30837, 2, 0, 16);  slice_tensor_1869 = slice_30837 = None
        slice_scatter_default_3739: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3737, slice_scatter_default_3738, 1, 7472, 7488);  slice_scatter_default_3737 = slice_scatter_default_3738 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30857: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30823, 2, 16, 32);  slice_30823 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_938: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30857, memory_format = torch.contiguous_format);  slice_30857 = None
        view_1880: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_938, [32, 11]);  clone_938 = None
        mm_935: "f32[32, 8]" = torch.ops.aten.mm.default(view_1880, slice_37)
        view_1881: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_935, [2, 16, 8]);  mm_935 = None
        slice_30864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3739, 1, 7472, 7488)
        slice_30865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30864, 2, 0, 16);  slice_30864 = None
        add_937: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30865, view_1881);  slice_30865 = view_1881 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3739, 1, 7472, 7488)
        slice_scatter_default_3740: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1870, add_937, 2, 0, 16);  slice_tensor_1870 = add_937 = None
        slice_scatter_default_3741: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3739, slice_scatter_default_3740, 1, 7472, 7488);  slice_scatter_default_3739 = slice_scatter_default_3740 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3741, 1, 7472, 7488)
        slice_30870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30869, 2, 0, 16);  slice_30869 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3741, 1, 7472, 7488)
        slice_scatter_default_3742: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1871, slice_30870, 2, 0, 16);  slice_tensor_1871 = slice_30870 = None
        slice_scatter_default_3743: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3741, slice_scatter_default_3742, 1, 7472, 7488);  slice_scatter_default_3741 = slice_scatter_default_3742 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30889: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7488, 7504)
        slice_30890: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30889, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_939: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30890, memory_format = torch.contiguous_format);  slice_30890 = None
        view_1882: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_939, [32, 16]);  clone_939 = None
        mm_936: "f32[32, 8]" = torch.ops.aten.mm.default(view_1882, slice_7)
        view_1883: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_936, [2, 16, 8]);  mm_936 = None
        slice_30897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3743, 1, 7488, 7504)
        slice_30898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30897, 2, 0, 16);  slice_30897 = None
        add_938: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30898, view_1883);  slice_30898 = view_1883 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3743, 1, 7488, 7504)
        slice_scatter_default_3744: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1872, add_938, 2, 0, 16);  slice_tensor_1872 = add_938 = None
        slice_scatter_default_3745: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3743, slice_scatter_default_3744, 1, 7488, 7504);  slice_scatter_default_3743 = slice_scatter_default_3744 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3745, 1, 7488, 7504)
        slice_30903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30902, 2, 0, 16);  slice_30902 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3745, 1, 7488, 7504)
        slice_scatter_default_3746: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1873, slice_30903, 2, 0, 16);  slice_tensor_1873 = slice_30903 = None
        slice_scatter_default_3747: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3745, slice_scatter_default_3746, 1, 7488, 7504);  slice_scatter_default_3745 = slice_scatter_default_3746 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30923: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30889, 2, 16, 32);  slice_30889 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_940: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30923, memory_format = torch.contiguous_format);  slice_30923 = None
        view_1884: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_940, [32, 11]);  clone_940 = None
        mm_937: "f32[32, 8]" = torch.ops.aten.mm.default(view_1884, slice_37)
        view_1885: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_937, [2, 16, 8]);  mm_937 = None
        slice_30930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3747, 1, 7488, 7504)
        slice_30931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30930, 2, 0, 16);  slice_30930 = None
        add_939: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30931, view_1885);  slice_30931 = view_1885 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3747, 1, 7488, 7504)
        slice_scatter_default_3748: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1874, add_939, 2, 0, 16);  slice_tensor_1874 = add_939 = None
        slice_scatter_default_3749: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3747, slice_scatter_default_3748, 1, 7488, 7504);  slice_scatter_default_3747 = slice_scatter_default_3748 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3749, 1, 7488, 7504)
        slice_30936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30935, 2, 0, 16);  slice_30935 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3749, 1, 7488, 7504)
        slice_scatter_default_3750: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1875, slice_30936, 2, 0, 16);  slice_tensor_1875 = slice_30936 = None
        slice_scatter_default_3751: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3749, slice_scatter_default_3750, 1, 7488, 7504);  slice_scatter_default_3749 = slice_scatter_default_3750 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30955: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7504, 7520)
        slice_30956: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_30955, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_941: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_30956, memory_format = torch.contiguous_format);  slice_30956 = None
        view_1886: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_941, [32, 16]);  clone_941 = None
        mm_938: "f32[32, 8]" = torch.ops.aten.mm.default(view_1886, slice_7)
        view_1887: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_938, [2, 16, 8]);  mm_938 = None
        slice_30963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3751, 1, 7504, 7520)
        slice_30964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30963, 2, 0, 16);  slice_30963 = None
        add_940: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30964, view_1887);  slice_30964 = view_1887 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3751, 1, 7504, 7520)
        slice_scatter_default_3752: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1876, add_940, 2, 0, 16);  slice_tensor_1876 = add_940 = None
        slice_scatter_default_3753: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3751, slice_scatter_default_3752, 1, 7504, 7520);  slice_scatter_default_3751 = slice_scatter_default_3752 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_30968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3753, 1, 7504, 7520)
        slice_30969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30968, 2, 0, 16);  slice_30968 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3753, 1, 7504, 7520)
        slice_scatter_default_3754: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1877, slice_30969, 2, 0, 16);  slice_tensor_1877 = slice_30969 = None
        slice_scatter_default_3755: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3753, slice_scatter_default_3754, 1, 7504, 7520);  slice_scatter_default_3753 = slice_scatter_default_3754 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_30989: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_30955, 2, 16, 32);  slice_30955 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_942: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_30989, memory_format = torch.contiguous_format);  slice_30989 = None
        view_1888: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_942, [32, 11]);  clone_942 = None
        mm_939: "f32[32, 8]" = torch.ops.aten.mm.default(view_1888, slice_37)
        view_1889: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_939, [2, 16, 8]);  mm_939 = None
        slice_30996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3755, 1, 7504, 7520)
        slice_30997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_30996, 2, 0, 16);  slice_30996 = None
        add_941: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_30997, view_1889);  slice_30997 = view_1889 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3755, 1, 7504, 7520)
        slice_scatter_default_3756: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1878, add_941, 2, 0, 16);  slice_tensor_1878 = add_941 = None
        slice_scatter_default_3757: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3755, slice_scatter_default_3756, 1, 7504, 7520);  slice_scatter_default_3755 = slice_scatter_default_3756 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3757, 1, 7504, 7520)
        slice_31002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31001, 2, 0, 16);  slice_31001 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3757, 1, 7504, 7520)
        slice_scatter_default_3758: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1879, slice_31002, 2, 0, 16);  slice_tensor_1879 = slice_31002 = None
        slice_scatter_default_3759: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3757, slice_scatter_default_3758, 1, 7504, 7520);  slice_scatter_default_3757 = slice_scatter_default_3758 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31021: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7520, 7536)
        slice_31022: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31021, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_943: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31022, memory_format = torch.contiguous_format);  slice_31022 = None
        view_1890: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_943, [32, 16]);  clone_943 = None
        mm_940: "f32[32, 8]" = torch.ops.aten.mm.default(view_1890, slice_7)
        view_1891: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_940, [2, 16, 8]);  mm_940 = None
        slice_31029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3759, 1, 7520, 7536)
        slice_31030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31029, 2, 0, 16);  slice_31029 = None
        add_942: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31030, view_1891);  slice_31030 = view_1891 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3759, 1, 7520, 7536)
        slice_scatter_default_3760: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1880, add_942, 2, 0, 16);  slice_tensor_1880 = add_942 = None
        slice_scatter_default_3761: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3759, slice_scatter_default_3760, 1, 7520, 7536);  slice_scatter_default_3759 = slice_scatter_default_3760 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3761, 1, 7520, 7536)
        slice_31035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31034, 2, 0, 16);  slice_31034 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3761, 1, 7520, 7536)
        slice_scatter_default_3762: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1881, slice_31035, 2, 0, 16);  slice_tensor_1881 = slice_31035 = None
        slice_scatter_default_3763: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3761, slice_scatter_default_3762, 1, 7520, 7536);  slice_scatter_default_3761 = slice_scatter_default_3762 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31055: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31021, 2, 16, 32);  slice_31021 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_944: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31055, memory_format = torch.contiguous_format);  slice_31055 = None
        view_1892: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_944, [32, 11]);  clone_944 = None
        mm_941: "f32[32, 8]" = torch.ops.aten.mm.default(view_1892, slice_37)
        view_1893: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_941, [2, 16, 8]);  mm_941 = None
        slice_31062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3763, 1, 7520, 7536)
        slice_31063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31062, 2, 0, 16);  slice_31062 = None
        add_943: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31063, view_1893);  slice_31063 = view_1893 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3763, 1, 7520, 7536)
        slice_scatter_default_3764: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1882, add_943, 2, 0, 16);  slice_tensor_1882 = add_943 = None
        slice_scatter_default_3765: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3763, slice_scatter_default_3764, 1, 7520, 7536);  slice_scatter_default_3763 = slice_scatter_default_3764 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3765, 1, 7520, 7536)
        slice_31068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31067, 2, 0, 16);  slice_31067 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3765, 1, 7520, 7536)
        slice_scatter_default_3766: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1883, slice_31068, 2, 0, 16);  slice_tensor_1883 = slice_31068 = None
        slice_scatter_default_3767: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3765, slice_scatter_default_3766, 1, 7520, 7536);  slice_scatter_default_3765 = slice_scatter_default_3766 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31087: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7536, 7552)
        slice_31088: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31087, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_945: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31088, memory_format = torch.contiguous_format);  slice_31088 = None
        view_1894: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_945, [32, 16]);  clone_945 = None
        mm_942: "f32[32, 8]" = torch.ops.aten.mm.default(view_1894, slice_7)
        view_1895: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_942, [2, 16, 8]);  mm_942 = None
        slice_31095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3767, 1, 7536, 7552)
        slice_31096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31095, 2, 0, 16);  slice_31095 = None
        add_944: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31096, view_1895);  slice_31096 = view_1895 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3767, 1, 7536, 7552)
        slice_scatter_default_3768: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1884, add_944, 2, 0, 16);  slice_tensor_1884 = add_944 = None
        slice_scatter_default_3769: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3767, slice_scatter_default_3768, 1, 7536, 7552);  slice_scatter_default_3767 = slice_scatter_default_3768 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3769, 1, 7536, 7552)
        slice_31101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31100, 2, 0, 16);  slice_31100 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3769, 1, 7536, 7552)
        slice_scatter_default_3770: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1885, slice_31101, 2, 0, 16);  slice_tensor_1885 = slice_31101 = None
        slice_scatter_default_3771: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3769, slice_scatter_default_3770, 1, 7536, 7552);  slice_scatter_default_3769 = slice_scatter_default_3770 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31121: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31087, 2, 16, 32);  slice_31087 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_946: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31121, memory_format = torch.contiguous_format);  slice_31121 = None
        view_1896: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_946, [32, 11]);  clone_946 = None
        mm_943: "f32[32, 8]" = torch.ops.aten.mm.default(view_1896, slice_37)
        view_1897: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_943, [2, 16, 8]);  mm_943 = None
        slice_31128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3771, 1, 7536, 7552)
        slice_31129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31128, 2, 0, 16);  slice_31128 = None
        add_945: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31129, view_1897);  slice_31129 = view_1897 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3771, 1, 7536, 7552)
        slice_scatter_default_3772: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1886, add_945, 2, 0, 16);  slice_tensor_1886 = add_945 = None
        slice_scatter_default_3773: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3771, slice_scatter_default_3772, 1, 7536, 7552);  slice_scatter_default_3771 = slice_scatter_default_3772 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3773, 1, 7536, 7552)
        slice_31134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31133, 2, 0, 16);  slice_31133 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3773, 1, 7536, 7552)
        slice_scatter_default_3774: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1887, slice_31134, 2, 0, 16);  slice_tensor_1887 = slice_31134 = None
        slice_scatter_default_3775: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3773, slice_scatter_default_3774, 1, 7536, 7552);  slice_scatter_default_3773 = slice_scatter_default_3774 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31153: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7552, 7568)
        slice_31154: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31153, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_947: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31154, memory_format = torch.contiguous_format);  slice_31154 = None
        view_1898: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_947, [32, 16]);  clone_947 = None
        mm_944: "f32[32, 8]" = torch.ops.aten.mm.default(view_1898, slice_7)
        view_1899: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_944, [2, 16, 8]);  mm_944 = None
        slice_31161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3775, 1, 7552, 7568)
        slice_31162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31161, 2, 0, 16);  slice_31161 = None
        add_946: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31162, view_1899);  slice_31162 = view_1899 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3775, 1, 7552, 7568)
        slice_scatter_default_3776: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1888, add_946, 2, 0, 16);  slice_tensor_1888 = add_946 = None
        slice_scatter_default_3777: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3775, slice_scatter_default_3776, 1, 7552, 7568);  slice_scatter_default_3775 = slice_scatter_default_3776 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3777, 1, 7552, 7568)
        slice_31167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31166, 2, 0, 16);  slice_31166 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3777, 1, 7552, 7568)
        slice_scatter_default_3778: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1889, slice_31167, 2, 0, 16);  slice_tensor_1889 = slice_31167 = None
        slice_scatter_default_3779: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3777, slice_scatter_default_3778, 1, 7552, 7568);  slice_scatter_default_3777 = slice_scatter_default_3778 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31187: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31153, 2, 16, 32);  slice_31153 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_948: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31187, memory_format = torch.contiguous_format);  slice_31187 = None
        view_1900: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_948, [32, 11]);  clone_948 = None
        mm_945: "f32[32, 8]" = torch.ops.aten.mm.default(view_1900, slice_37)
        view_1901: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_945, [2, 16, 8]);  mm_945 = None
        slice_31194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3779, 1, 7552, 7568)
        slice_31195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31194, 2, 0, 16);  slice_31194 = None
        add_947: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31195, view_1901);  slice_31195 = view_1901 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3779, 1, 7552, 7568)
        slice_scatter_default_3780: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1890, add_947, 2, 0, 16);  slice_tensor_1890 = add_947 = None
        slice_scatter_default_3781: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3779, slice_scatter_default_3780, 1, 7552, 7568);  slice_scatter_default_3779 = slice_scatter_default_3780 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3781, 1, 7552, 7568)
        slice_31200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31199, 2, 0, 16);  slice_31199 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3781, 1, 7552, 7568)
        slice_scatter_default_3782: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1891, slice_31200, 2, 0, 16);  slice_tensor_1891 = slice_31200 = None
        slice_scatter_default_3783: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3781, slice_scatter_default_3782, 1, 7552, 7568);  slice_scatter_default_3781 = slice_scatter_default_3782 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31219: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7568, 7584)
        slice_31220: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31219, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_949: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31220, memory_format = torch.contiguous_format);  slice_31220 = None
        view_1902: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_949, [32, 16]);  clone_949 = None
        mm_946: "f32[32, 8]" = torch.ops.aten.mm.default(view_1902, slice_7)
        view_1903: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_946, [2, 16, 8]);  mm_946 = None
        slice_31227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3783, 1, 7568, 7584)
        slice_31228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31227, 2, 0, 16);  slice_31227 = None
        add_948: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31228, view_1903);  slice_31228 = view_1903 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3783, 1, 7568, 7584)
        slice_scatter_default_3784: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1892, add_948, 2, 0, 16);  slice_tensor_1892 = add_948 = None
        slice_scatter_default_3785: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3783, slice_scatter_default_3784, 1, 7568, 7584);  slice_scatter_default_3783 = slice_scatter_default_3784 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3785, 1, 7568, 7584)
        slice_31233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31232, 2, 0, 16);  slice_31232 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3785, 1, 7568, 7584)
        slice_scatter_default_3786: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1893, slice_31233, 2, 0, 16);  slice_tensor_1893 = slice_31233 = None
        slice_scatter_default_3787: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3785, slice_scatter_default_3786, 1, 7568, 7584);  slice_scatter_default_3785 = slice_scatter_default_3786 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31253: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31219, 2, 16, 32);  slice_31219 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_950: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31253, memory_format = torch.contiguous_format);  slice_31253 = None
        view_1904: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_950, [32, 11]);  clone_950 = None
        mm_947: "f32[32, 8]" = torch.ops.aten.mm.default(view_1904, slice_37)
        view_1905: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_947, [2, 16, 8]);  mm_947 = None
        slice_31260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3787, 1, 7568, 7584)
        slice_31261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31260, 2, 0, 16);  slice_31260 = None
        add_949: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31261, view_1905);  slice_31261 = view_1905 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3787, 1, 7568, 7584)
        slice_scatter_default_3788: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1894, add_949, 2, 0, 16);  slice_tensor_1894 = add_949 = None
        slice_scatter_default_3789: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3787, slice_scatter_default_3788, 1, 7568, 7584);  slice_scatter_default_3787 = slice_scatter_default_3788 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3789, 1, 7568, 7584)
        slice_31266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31265, 2, 0, 16);  slice_31265 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3789, 1, 7568, 7584)
        slice_scatter_default_3790: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1895, slice_31266, 2, 0, 16);  slice_tensor_1895 = slice_31266 = None
        slice_scatter_default_3791: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3789, slice_scatter_default_3790, 1, 7568, 7584);  slice_scatter_default_3789 = slice_scatter_default_3790 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31285: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7584, 7600)
        slice_31286: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31285, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_951: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31286, memory_format = torch.contiguous_format);  slice_31286 = None
        view_1906: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_951, [32, 16]);  clone_951 = None
        mm_948: "f32[32, 8]" = torch.ops.aten.mm.default(view_1906, slice_7)
        view_1907: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_948, [2, 16, 8]);  mm_948 = None
        slice_31293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3791, 1, 7584, 7600)
        slice_31294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31293, 2, 0, 16);  slice_31293 = None
        add_950: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31294, view_1907);  slice_31294 = view_1907 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3791, 1, 7584, 7600)
        slice_scatter_default_3792: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1896, add_950, 2, 0, 16);  slice_tensor_1896 = add_950 = None
        slice_scatter_default_3793: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3791, slice_scatter_default_3792, 1, 7584, 7600);  slice_scatter_default_3791 = slice_scatter_default_3792 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3793, 1, 7584, 7600)
        slice_31299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31298, 2, 0, 16);  slice_31298 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3793, 1, 7584, 7600)
        slice_scatter_default_3794: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1897, slice_31299, 2, 0, 16);  slice_tensor_1897 = slice_31299 = None
        slice_scatter_default_3795: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3793, slice_scatter_default_3794, 1, 7584, 7600);  slice_scatter_default_3793 = slice_scatter_default_3794 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31319: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31285, 2, 16, 32);  slice_31285 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_952: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31319, memory_format = torch.contiguous_format);  slice_31319 = None
        view_1908: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_952, [32, 11]);  clone_952 = None
        mm_949: "f32[32, 8]" = torch.ops.aten.mm.default(view_1908, slice_37)
        view_1909: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_949, [2, 16, 8]);  mm_949 = None
        slice_31326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3795, 1, 7584, 7600)
        slice_31327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31326, 2, 0, 16);  slice_31326 = None
        add_951: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31327, view_1909);  slice_31327 = view_1909 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3795, 1, 7584, 7600)
        slice_scatter_default_3796: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1898, add_951, 2, 0, 16);  slice_tensor_1898 = add_951 = None
        slice_scatter_default_3797: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3795, slice_scatter_default_3796, 1, 7584, 7600);  slice_scatter_default_3795 = slice_scatter_default_3796 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3797, 1, 7584, 7600)
        slice_31332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31331, 2, 0, 16);  slice_31331 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3797, 1, 7584, 7600)
        slice_scatter_default_3798: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1899, slice_31332, 2, 0, 16);  slice_tensor_1899 = slice_31332 = None
        slice_scatter_default_3799: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3797, slice_scatter_default_3798, 1, 7584, 7600);  slice_scatter_default_3797 = slice_scatter_default_3798 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31351: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7600, 7616)
        slice_31352: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31351, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_953: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31352, memory_format = torch.contiguous_format);  slice_31352 = None
        view_1910: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_953, [32, 16]);  clone_953 = None
        mm_950: "f32[32, 8]" = torch.ops.aten.mm.default(view_1910, slice_7)
        view_1911: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_950, [2, 16, 8]);  mm_950 = None
        slice_31359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3799, 1, 7600, 7616)
        slice_31360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31359, 2, 0, 16);  slice_31359 = None
        add_952: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31360, view_1911);  slice_31360 = view_1911 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3799, 1, 7600, 7616)
        slice_scatter_default_3800: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1900, add_952, 2, 0, 16);  slice_tensor_1900 = add_952 = None
        slice_scatter_default_3801: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3799, slice_scatter_default_3800, 1, 7600, 7616);  slice_scatter_default_3799 = slice_scatter_default_3800 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3801, 1, 7600, 7616)
        slice_31365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31364, 2, 0, 16);  slice_31364 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3801, 1, 7600, 7616)
        slice_scatter_default_3802: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1901, slice_31365, 2, 0, 16);  slice_tensor_1901 = slice_31365 = None
        slice_scatter_default_3803: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3801, slice_scatter_default_3802, 1, 7600, 7616);  slice_scatter_default_3801 = slice_scatter_default_3802 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31385: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31351, 2, 16, 32);  slice_31351 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_954: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31385, memory_format = torch.contiguous_format);  slice_31385 = None
        view_1912: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_954, [32, 11]);  clone_954 = None
        mm_951: "f32[32, 8]" = torch.ops.aten.mm.default(view_1912, slice_37)
        view_1913: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_951, [2, 16, 8]);  mm_951 = None
        slice_31392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3803, 1, 7600, 7616)
        slice_31393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31392, 2, 0, 16);  slice_31392 = None
        add_953: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31393, view_1913);  slice_31393 = view_1913 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3803, 1, 7600, 7616)
        slice_scatter_default_3804: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1902, add_953, 2, 0, 16);  slice_tensor_1902 = add_953 = None
        slice_scatter_default_3805: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3803, slice_scatter_default_3804, 1, 7600, 7616);  slice_scatter_default_3803 = slice_scatter_default_3804 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3805, 1, 7600, 7616)
        slice_31398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31397, 2, 0, 16);  slice_31397 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3805, 1, 7600, 7616)
        slice_scatter_default_3806: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1903, slice_31398, 2, 0, 16);  slice_tensor_1903 = slice_31398 = None
        slice_scatter_default_3807: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3805, slice_scatter_default_3806, 1, 7600, 7616);  slice_scatter_default_3805 = slice_scatter_default_3806 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31417: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7616, 7632)
        slice_31418: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31417, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_955: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31418, memory_format = torch.contiguous_format);  slice_31418 = None
        view_1914: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_955, [32, 16]);  clone_955 = None
        mm_952: "f32[32, 8]" = torch.ops.aten.mm.default(view_1914, slice_7)
        view_1915: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_952, [2, 16, 8]);  mm_952 = None
        slice_31425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3807, 1, 7616, 7632)
        slice_31426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31425, 2, 0, 16);  slice_31425 = None
        add_954: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31426, view_1915);  slice_31426 = view_1915 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3807, 1, 7616, 7632)
        slice_scatter_default_3808: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1904, add_954, 2, 0, 16);  slice_tensor_1904 = add_954 = None
        slice_scatter_default_3809: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3807, slice_scatter_default_3808, 1, 7616, 7632);  slice_scatter_default_3807 = slice_scatter_default_3808 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3809, 1, 7616, 7632)
        slice_31431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31430, 2, 0, 16);  slice_31430 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3809, 1, 7616, 7632)
        slice_scatter_default_3810: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1905, slice_31431, 2, 0, 16);  slice_tensor_1905 = slice_31431 = None
        slice_scatter_default_3811: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3809, slice_scatter_default_3810, 1, 7616, 7632);  slice_scatter_default_3809 = slice_scatter_default_3810 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31451: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31417, 2, 16, 32);  slice_31417 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_956: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31451, memory_format = torch.contiguous_format);  slice_31451 = None
        view_1916: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_956, [32, 11]);  clone_956 = None
        mm_953: "f32[32, 8]" = torch.ops.aten.mm.default(view_1916, slice_37)
        view_1917: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_953, [2, 16, 8]);  mm_953 = None
        slice_31458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3811, 1, 7616, 7632)
        slice_31459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31458, 2, 0, 16);  slice_31458 = None
        add_955: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31459, view_1917);  slice_31459 = view_1917 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3811, 1, 7616, 7632)
        slice_scatter_default_3812: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1906, add_955, 2, 0, 16);  slice_tensor_1906 = add_955 = None
        slice_scatter_default_3813: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3811, slice_scatter_default_3812, 1, 7616, 7632);  slice_scatter_default_3811 = slice_scatter_default_3812 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3813, 1, 7616, 7632)
        slice_31464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31463, 2, 0, 16);  slice_31463 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3813, 1, 7616, 7632)
        slice_scatter_default_3814: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1907, slice_31464, 2, 0, 16);  slice_tensor_1907 = slice_31464 = None
        slice_scatter_default_3815: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3813, slice_scatter_default_3814, 1, 7616, 7632);  slice_scatter_default_3813 = slice_scatter_default_3814 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31483: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7632, 7648)
        slice_31484: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31483, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_957: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31484, memory_format = torch.contiguous_format);  slice_31484 = None
        view_1918: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_957, [32, 16]);  clone_957 = None
        mm_954: "f32[32, 8]" = torch.ops.aten.mm.default(view_1918, slice_7)
        view_1919: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_954, [2, 16, 8]);  mm_954 = None
        slice_31491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3815, 1, 7632, 7648)
        slice_31492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31491, 2, 0, 16);  slice_31491 = None
        add_956: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31492, view_1919);  slice_31492 = view_1919 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3815, 1, 7632, 7648)
        slice_scatter_default_3816: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1908, add_956, 2, 0, 16);  slice_tensor_1908 = add_956 = None
        slice_scatter_default_3817: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3815, slice_scatter_default_3816, 1, 7632, 7648);  slice_scatter_default_3815 = slice_scatter_default_3816 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3817, 1, 7632, 7648)
        slice_31497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31496, 2, 0, 16);  slice_31496 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3817, 1, 7632, 7648)
        slice_scatter_default_3818: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1909, slice_31497, 2, 0, 16);  slice_tensor_1909 = slice_31497 = None
        slice_scatter_default_3819: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3817, slice_scatter_default_3818, 1, 7632, 7648);  slice_scatter_default_3817 = slice_scatter_default_3818 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31517: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31483, 2, 16, 32);  slice_31483 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_958: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31517, memory_format = torch.contiguous_format);  slice_31517 = None
        view_1920: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_958, [32, 11]);  clone_958 = None
        mm_955: "f32[32, 8]" = torch.ops.aten.mm.default(view_1920, slice_37)
        view_1921: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_955, [2, 16, 8]);  mm_955 = None
        slice_31524: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3819, 1, 7632, 7648)
        slice_31525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31524, 2, 0, 16);  slice_31524 = None
        add_957: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31525, view_1921);  slice_31525 = view_1921 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3819, 1, 7632, 7648)
        slice_scatter_default_3820: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1910, add_957, 2, 0, 16);  slice_tensor_1910 = add_957 = None
        slice_scatter_default_3821: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3819, slice_scatter_default_3820, 1, 7632, 7648);  slice_scatter_default_3819 = slice_scatter_default_3820 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31529: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3821, 1, 7632, 7648)
        slice_31530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31529, 2, 0, 16);  slice_31529 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3821, 1, 7632, 7648)
        slice_scatter_default_3822: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1911, slice_31530, 2, 0, 16);  slice_tensor_1911 = slice_31530 = None
        slice_scatter_default_3823: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3821, slice_scatter_default_3822, 1, 7632, 7648);  slice_scatter_default_3821 = slice_scatter_default_3822 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31549: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7648, 7664)
        slice_31550: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31549, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_959: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31550, memory_format = torch.contiguous_format);  slice_31550 = None
        view_1922: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_959, [32, 16]);  clone_959 = None
        mm_956: "f32[32, 8]" = torch.ops.aten.mm.default(view_1922, slice_7)
        view_1923: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_956, [2, 16, 8]);  mm_956 = None
        slice_31557: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3823, 1, 7648, 7664)
        slice_31558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31557, 2, 0, 16);  slice_31557 = None
        add_958: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31558, view_1923);  slice_31558 = view_1923 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3823, 1, 7648, 7664)
        slice_scatter_default_3824: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1912, add_958, 2, 0, 16);  slice_tensor_1912 = add_958 = None
        slice_scatter_default_3825: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3823, slice_scatter_default_3824, 1, 7648, 7664);  slice_scatter_default_3823 = slice_scatter_default_3824 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31562: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3825, 1, 7648, 7664)
        slice_31563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31562, 2, 0, 16);  slice_31562 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3825, 1, 7648, 7664)
        slice_scatter_default_3826: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1913, slice_31563, 2, 0, 16);  slice_tensor_1913 = slice_31563 = None
        slice_scatter_default_3827: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3825, slice_scatter_default_3826, 1, 7648, 7664);  slice_scatter_default_3825 = slice_scatter_default_3826 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31583: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31549, 2, 16, 32);  slice_31549 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_960: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31583, memory_format = torch.contiguous_format);  slice_31583 = None
        view_1924: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_960, [32, 11]);  clone_960 = None
        mm_957: "f32[32, 8]" = torch.ops.aten.mm.default(view_1924, slice_37)
        view_1925: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_957, [2, 16, 8]);  mm_957 = None
        slice_31590: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3827, 1, 7648, 7664)
        slice_31591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31590, 2, 0, 16);  slice_31590 = None
        add_959: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31591, view_1925);  slice_31591 = view_1925 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3827, 1, 7648, 7664)
        slice_scatter_default_3828: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1914, add_959, 2, 0, 16);  slice_tensor_1914 = add_959 = None
        slice_scatter_default_3829: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3827, slice_scatter_default_3828, 1, 7648, 7664);  slice_scatter_default_3827 = slice_scatter_default_3828 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31595: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3829, 1, 7648, 7664)
        slice_31596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31595, 2, 0, 16);  slice_31595 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3829, 1, 7648, 7664)
        slice_scatter_default_3830: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1915, slice_31596, 2, 0, 16);  slice_tensor_1915 = slice_31596 = None
        slice_scatter_default_3831: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3829, slice_scatter_default_3830, 1, 7648, 7664);  slice_scatter_default_3829 = slice_scatter_default_3830 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31615: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7664, 7680)
        slice_31616: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31615, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_961: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31616, memory_format = torch.contiguous_format);  slice_31616 = None
        view_1926: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_961, [32, 16]);  clone_961 = None
        mm_958: "f32[32, 8]" = torch.ops.aten.mm.default(view_1926, slice_7)
        view_1927: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_958, [2, 16, 8]);  mm_958 = None
        slice_31623: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3831, 1, 7664, 7680)
        slice_31624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31623, 2, 0, 16);  slice_31623 = None
        add_960: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31624, view_1927);  slice_31624 = view_1927 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3831, 1, 7664, 7680)
        slice_scatter_default_3832: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1916, add_960, 2, 0, 16);  slice_tensor_1916 = add_960 = None
        slice_scatter_default_3833: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3831, slice_scatter_default_3832, 1, 7664, 7680);  slice_scatter_default_3831 = slice_scatter_default_3832 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31628: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3833, 1, 7664, 7680)
        slice_31629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31628, 2, 0, 16);  slice_31628 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3833, 1, 7664, 7680)
        slice_scatter_default_3834: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1917, slice_31629, 2, 0, 16);  slice_tensor_1917 = slice_31629 = None
        slice_scatter_default_3835: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3833, slice_scatter_default_3834, 1, 7664, 7680);  slice_scatter_default_3833 = slice_scatter_default_3834 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31649: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31615, 2, 16, 32);  slice_31615 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_962: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31649, memory_format = torch.contiguous_format);  slice_31649 = None
        view_1928: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_962, [32, 11]);  clone_962 = None
        mm_959: "f32[32, 8]" = torch.ops.aten.mm.default(view_1928, slice_37)
        view_1929: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_959, [2, 16, 8]);  mm_959 = None
        slice_31656: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3835, 1, 7664, 7680)
        slice_31657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31656, 2, 0, 16);  slice_31656 = None
        add_961: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31657, view_1929);  slice_31657 = view_1929 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3835, 1, 7664, 7680)
        slice_scatter_default_3836: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1918, add_961, 2, 0, 16);  slice_tensor_1918 = add_961 = None
        slice_scatter_default_3837: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3835, slice_scatter_default_3836, 1, 7664, 7680);  slice_scatter_default_3835 = slice_scatter_default_3836 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31661: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3837, 1, 7664, 7680)
        slice_31662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31661, 2, 0, 16);  slice_31661 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3837, 1, 7664, 7680)
        slice_scatter_default_3838: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1919, slice_31662, 2, 0, 16);  slice_tensor_1919 = slice_31662 = None
        slice_scatter_default_3839: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3837, slice_scatter_default_3838, 1, 7664, 7680);  slice_scatter_default_3837 = slice_scatter_default_3838 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31681: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7680, 7696)
        slice_31682: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31681, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_963: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31682, memory_format = torch.contiguous_format);  slice_31682 = None
        view_1930: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_963, [32, 16]);  clone_963 = None
        mm_960: "f32[32, 8]" = torch.ops.aten.mm.default(view_1930, slice_7)
        view_1931: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_960, [2, 16, 8]);  mm_960 = None
        slice_31689: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3839, 1, 7680, 7696)
        slice_31690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31689, 2, 0, 16);  slice_31689 = None
        add_962: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31690, view_1931);  slice_31690 = view_1931 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3839, 1, 7680, 7696)
        slice_scatter_default_3840: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1920, add_962, 2, 0, 16);  slice_tensor_1920 = add_962 = None
        slice_scatter_default_3841: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3839, slice_scatter_default_3840, 1, 7680, 7696);  slice_scatter_default_3839 = slice_scatter_default_3840 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31694: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3841, 1, 7680, 7696)
        slice_31695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31694, 2, 0, 16);  slice_31694 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3841, 1, 7680, 7696)
        slice_scatter_default_3842: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1921, slice_31695, 2, 0, 16);  slice_tensor_1921 = slice_31695 = None
        slice_scatter_default_3843: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3841, slice_scatter_default_3842, 1, 7680, 7696);  slice_scatter_default_3841 = slice_scatter_default_3842 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31715: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31681, 2, 16, 32);  slice_31681 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_964: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31715, memory_format = torch.contiguous_format);  slice_31715 = None
        view_1932: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_964, [32, 11]);  clone_964 = None
        mm_961: "f32[32, 8]" = torch.ops.aten.mm.default(view_1932, slice_37)
        view_1933: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_961, [2, 16, 8]);  mm_961 = None
        slice_31722: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3843, 1, 7680, 7696)
        slice_31723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31722, 2, 0, 16);  slice_31722 = None
        add_963: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31723, view_1933);  slice_31723 = view_1933 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3843, 1, 7680, 7696)
        slice_scatter_default_3844: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1922, add_963, 2, 0, 16);  slice_tensor_1922 = add_963 = None
        slice_scatter_default_3845: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3843, slice_scatter_default_3844, 1, 7680, 7696);  slice_scatter_default_3843 = slice_scatter_default_3844 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31727: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3845, 1, 7680, 7696)
        slice_31728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31727, 2, 0, 16);  slice_31727 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3845, 1, 7680, 7696)
        slice_scatter_default_3846: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1923, slice_31728, 2, 0, 16);  slice_tensor_1923 = slice_31728 = None
        slice_scatter_default_3847: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3845, slice_scatter_default_3846, 1, 7680, 7696);  slice_scatter_default_3845 = slice_scatter_default_3846 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31747: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7696, 7712)
        slice_31748: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31747, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_965: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31748, memory_format = torch.contiguous_format);  slice_31748 = None
        view_1934: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_965, [32, 16]);  clone_965 = None
        mm_962: "f32[32, 8]" = torch.ops.aten.mm.default(view_1934, slice_7)
        view_1935: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_962, [2, 16, 8]);  mm_962 = None
        slice_31755: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3847, 1, 7696, 7712)
        slice_31756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31755, 2, 0, 16);  slice_31755 = None
        add_964: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31756, view_1935);  slice_31756 = view_1935 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3847, 1, 7696, 7712)
        slice_scatter_default_3848: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1924, add_964, 2, 0, 16);  slice_tensor_1924 = add_964 = None
        slice_scatter_default_3849: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3847, slice_scatter_default_3848, 1, 7696, 7712);  slice_scatter_default_3847 = slice_scatter_default_3848 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31760: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3849, 1, 7696, 7712)
        slice_31761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31760, 2, 0, 16);  slice_31760 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3849, 1, 7696, 7712)
        slice_scatter_default_3850: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1925, slice_31761, 2, 0, 16);  slice_tensor_1925 = slice_31761 = None
        slice_scatter_default_3851: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3849, slice_scatter_default_3850, 1, 7696, 7712);  slice_scatter_default_3849 = slice_scatter_default_3850 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31781: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31747, 2, 16, 32);  slice_31747 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_966: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31781, memory_format = torch.contiguous_format);  slice_31781 = None
        view_1936: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_966, [32, 11]);  clone_966 = None
        mm_963: "f32[32, 8]" = torch.ops.aten.mm.default(view_1936, slice_37)
        view_1937: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_963, [2, 16, 8]);  mm_963 = None
        slice_31788: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3851, 1, 7696, 7712)
        slice_31789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31788, 2, 0, 16);  slice_31788 = None
        add_965: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31789, view_1937);  slice_31789 = view_1937 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3851, 1, 7696, 7712)
        slice_scatter_default_3852: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1926, add_965, 2, 0, 16);  slice_tensor_1926 = add_965 = None
        slice_scatter_default_3853: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3851, slice_scatter_default_3852, 1, 7696, 7712);  slice_scatter_default_3851 = slice_scatter_default_3852 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31793: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3853, 1, 7696, 7712)
        slice_31794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31793, 2, 0, 16);  slice_31793 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3853, 1, 7696, 7712)
        slice_scatter_default_3854: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1927, slice_31794, 2, 0, 16);  slice_tensor_1927 = slice_31794 = None
        slice_scatter_default_3855: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3853, slice_scatter_default_3854, 1, 7696, 7712);  slice_scatter_default_3853 = slice_scatter_default_3854 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31813: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7712, 7728)
        slice_31814: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31813, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_967: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31814, memory_format = torch.contiguous_format);  slice_31814 = None
        view_1938: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_967, [32, 16]);  clone_967 = None
        mm_964: "f32[32, 8]" = torch.ops.aten.mm.default(view_1938, slice_7)
        view_1939: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_964, [2, 16, 8]);  mm_964 = None
        slice_31821: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3855, 1, 7712, 7728)
        slice_31822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31821, 2, 0, 16);  slice_31821 = None
        add_966: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31822, view_1939);  slice_31822 = view_1939 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3855, 1, 7712, 7728)
        slice_scatter_default_3856: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1928, add_966, 2, 0, 16);  slice_tensor_1928 = add_966 = None
        slice_scatter_default_3857: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3855, slice_scatter_default_3856, 1, 7712, 7728);  slice_scatter_default_3855 = slice_scatter_default_3856 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31826: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3857, 1, 7712, 7728)
        slice_31827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31826, 2, 0, 16);  slice_31826 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3857, 1, 7712, 7728)
        slice_scatter_default_3858: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1929, slice_31827, 2, 0, 16);  slice_tensor_1929 = slice_31827 = None
        slice_scatter_default_3859: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3857, slice_scatter_default_3858, 1, 7712, 7728);  slice_scatter_default_3857 = slice_scatter_default_3858 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31847: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31813, 2, 16, 32);  slice_31813 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_968: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31847, memory_format = torch.contiguous_format);  slice_31847 = None
        view_1940: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_968, [32, 11]);  clone_968 = None
        mm_965: "f32[32, 8]" = torch.ops.aten.mm.default(view_1940, slice_37)
        view_1941: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_965, [2, 16, 8]);  mm_965 = None
        slice_31854: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3859, 1, 7712, 7728)
        slice_31855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31854, 2, 0, 16);  slice_31854 = None
        add_967: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31855, view_1941);  slice_31855 = view_1941 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3859, 1, 7712, 7728)
        slice_scatter_default_3860: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1930, add_967, 2, 0, 16);  slice_tensor_1930 = add_967 = None
        slice_scatter_default_3861: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3859, slice_scatter_default_3860, 1, 7712, 7728);  slice_scatter_default_3859 = slice_scatter_default_3860 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31859: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3861, 1, 7712, 7728)
        slice_31860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31859, 2, 0, 16);  slice_31859 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3861, 1, 7712, 7728)
        slice_scatter_default_3862: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1931, slice_31860, 2, 0, 16);  slice_tensor_1931 = slice_31860 = None
        slice_scatter_default_3863: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3861, slice_scatter_default_3862, 1, 7712, 7728);  slice_scatter_default_3861 = slice_scatter_default_3862 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31879: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7728, 7744)
        slice_31880: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31879, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_969: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31880, memory_format = torch.contiguous_format);  slice_31880 = None
        view_1942: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_969, [32, 16]);  clone_969 = None
        mm_966: "f32[32, 8]" = torch.ops.aten.mm.default(view_1942, slice_7)
        view_1943: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_966, [2, 16, 8]);  mm_966 = None
        slice_31887: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3863, 1, 7728, 7744)
        slice_31888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31887, 2, 0, 16);  slice_31887 = None
        add_968: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31888, view_1943);  slice_31888 = view_1943 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3863, 1, 7728, 7744)
        slice_scatter_default_3864: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1932, add_968, 2, 0, 16);  slice_tensor_1932 = add_968 = None
        slice_scatter_default_3865: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3863, slice_scatter_default_3864, 1, 7728, 7744);  slice_scatter_default_3863 = slice_scatter_default_3864 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31892: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3865, 1, 7728, 7744)
        slice_31893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31892, 2, 0, 16);  slice_31892 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3865, 1, 7728, 7744)
        slice_scatter_default_3866: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1933, slice_31893, 2, 0, 16);  slice_tensor_1933 = slice_31893 = None
        slice_scatter_default_3867: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3865, slice_scatter_default_3866, 1, 7728, 7744);  slice_scatter_default_3865 = slice_scatter_default_3866 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31913: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31879, 2, 16, 32);  slice_31879 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_970: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31913, memory_format = torch.contiguous_format);  slice_31913 = None
        view_1944: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_970, [32, 11]);  clone_970 = None
        mm_967: "f32[32, 8]" = torch.ops.aten.mm.default(view_1944, slice_37)
        view_1945: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_967, [2, 16, 8]);  mm_967 = None
        slice_31920: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3867, 1, 7728, 7744)
        slice_31921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31920, 2, 0, 16);  slice_31920 = None
        add_969: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31921, view_1945);  slice_31921 = view_1945 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3867, 1, 7728, 7744)
        slice_scatter_default_3868: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1934, add_969, 2, 0, 16);  slice_tensor_1934 = add_969 = None
        slice_scatter_default_3869: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3867, slice_scatter_default_3868, 1, 7728, 7744);  slice_scatter_default_3867 = slice_scatter_default_3868 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31925: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3869, 1, 7728, 7744)
        slice_31926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31925, 2, 0, 16);  slice_31925 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3869, 1, 7728, 7744)
        slice_scatter_default_3870: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1935, slice_31926, 2, 0, 16);  slice_tensor_1935 = slice_31926 = None
        slice_scatter_default_3871: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3869, slice_scatter_default_3870, 1, 7728, 7744);  slice_scatter_default_3869 = slice_scatter_default_3870 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31945: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7744, 7760)
        slice_31946: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_31945, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_971: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_31946, memory_format = torch.contiguous_format);  slice_31946 = None
        view_1946: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_971, [32, 16]);  clone_971 = None
        mm_968: "f32[32, 8]" = torch.ops.aten.mm.default(view_1946, slice_7)
        view_1947: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_968, [2, 16, 8]);  mm_968 = None
        slice_31953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3871, 1, 7744, 7760)
        slice_31954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31953, 2, 0, 16);  slice_31953 = None
        add_970: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31954, view_1947);  slice_31954 = view_1947 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3871, 1, 7744, 7760)
        slice_scatter_default_3872: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1936, add_970, 2, 0, 16);  slice_tensor_1936 = add_970 = None
        slice_scatter_default_3873: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3871, slice_scatter_default_3872, 1, 7744, 7760);  slice_scatter_default_3871 = slice_scatter_default_3872 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3873, 1, 7744, 7760)
        slice_31959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31958, 2, 0, 16);  slice_31958 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3873, 1, 7744, 7760)
        slice_scatter_default_3874: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1937, slice_31959, 2, 0, 16);  slice_tensor_1937 = slice_31959 = None
        slice_scatter_default_3875: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3873, slice_scatter_default_3874, 1, 7744, 7760);  slice_scatter_default_3873 = slice_scatter_default_3874 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_31979: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_31945, 2, 16, 32);  slice_31945 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_972: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_31979, memory_format = torch.contiguous_format);  slice_31979 = None
        view_1948: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_972, [32, 11]);  clone_972 = None
        mm_969: "f32[32, 8]" = torch.ops.aten.mm.default(view_1948, slice_37)
        view_1949: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_969, [2, 16, 8]);  mm_969 = None
        slice_31986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3875, 1, 7744, 7760)
        slice_31987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31986, 2, 0, 16);  slice_31986 = None
        add_971: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_31987, view_1949);  slice_31987 = view_1949 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3875, 1, 7744, 7760)
        slice_scatter_default_3876: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1938, add_971, 2, 0, 16);  slice_tensor_1938 = add_971 = None
        slice_scatter_default_3877: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3875, slice_scatter_default_3876, 1, 7744, 7760);  slice_scatter_default_3875 = slice_scatter_default_3876 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_31991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3877, 1, 7744, 7760)
        slice_31992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_31991, 2, 0, 16);  slice_31991 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3877, 1, 7744, 7760)
        slice_scatter_default_3878: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1939, slice_31992, 2, 0, 16);  slice_tensor_1939 = slice_31992 = None
        slice_scatter_default_3879: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3877, slice_scatter_default_3878, 1, 7744, 7760);  slice_scatter_default_3877 = slice_scatter_default_3878 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32011: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7760, 7776)
        slice_32012: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32011, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_973: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32012, memory_format = torch.contiguous_format);  slice_32012 = None
        view_1950: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_973, [32, 16]);  clone_973 = None
        mm_970: "f32[32, 8]" = torch.ops.aten.mm.default(view_1950, slice_7)
        view_1951: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_970, [2, 16, 8]);  mm_970 = None
        slice_32019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3879, 1, 7760, 7776)
        slice_32020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32019, 2, 0, 16);  slice_32019 = None
        add_972: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32020, view_1951);  slice_32020 = view_1951 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3879, 1, 7760, 7776)
        slice_scatter_default_3880: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1940, add_972, 2, 0, 16);  slice_tensor_1940 = add_972 = None
        slice_scatter_default_3881: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3879, slice_scatter_default_3880, 1, 7760, 7776);  slice_scatter_default_3879 = slice_scatter_default_3880 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3881, 1, 7760, 7776)
        slice_32025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32024, 2, 0, 16);  slice_32024 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3881, 1, 7760, 7776)
        slice_scatter_default_3882: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1941, slice_32025, 2, 0, 16);  slice_tensor_1941 = slice_32025 = None
        slice_scatter_default_3883: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3881, slice_scatter_default_3882, 1, 7760, 7776);  slice_scatter_default_3881 = slice_scatter_default_3882 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32045: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32011, 2, 16, 32);  slice_32011 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_974: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32045, memory_format = torch.contiguous_format);  slice_32045 = None
        view_1952: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_974, [32, 11]);  clone_974 = None
        mm_971: "f32[32, 8]" = torch.ops.aten.mm.default(view_1952, slice_37)
        view_1953: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_971, [2, 16, 8]);  mm_971 = None
        slice_32052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3883, 1, 7760, 7776)
        slice_32053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32052, 2, 0, 16);  slice_32052 = None
        add_973: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32053, view_1953);  slice_32053 = view_1953 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3883, 1, 7760, 7776)
        slice_scatter_default_3884: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1942, add_973, 2, 0, 16);  slice_tensor_1942 = add_973 = None
        slice_scatter_default_3885: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3883, slice_scatter_default_3884, 1, 7760, 7776);  slice_scatter_default_3883 = slice_scatter_default_3884 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3885, 1, 7760, 7776)
        slice_32058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32057, 2, 0, 16);  slice_32057 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3885, 1, 7760, 7776)
        slice_scatter_default_3886: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1943, slice_32058, 2, 0, 16);  slice_tensor_1943 = slice_32058 = None
        slice_scatter_default_3887: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3885, slice_scatter_default_3886, 1, 7760, 7776);  slice_scatter_default_3885 = slice_scatter_default_3886 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32077: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7776, 7792)
        slice_32078: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32077, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_975: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32078, memory_format = torch.contiguous_format);  slice_32078 = None
        view_1954: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_975, [32, 16]);  clone_975 = None
        mm_972: "f32[32, 8]" = torch.ops.aten.mm.default(view_1954, slice_7)
        view_1955: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_972, [2, 16, 8]);  mm_972 = None
        slice_32085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3887, 1, 7776, 7792)
        slice_32086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32085, 2, 0, 16);  slice_32085 = None
        add_974: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32086, view_1955);  slice_32086 = view_1955 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3887, 1, 7776, 7792)
        slice_scatter_default_3888: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1944, add_974, 2, 0, 16);  slice_tensor_1944 = add_974 = None
        slice_scatter_default_3889: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3887, slice_scatter_default_3888, 1, 7776, 7792);  slice_scatter_default_3887 = slice_scatter_default_3888 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3889, 1, 7776, 7792)
        slice_32091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32090, 2, 0, 16);  slice_32090 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3889, 1, 7776, 7792)
        slice_scatter_default_3890: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1945, slice_32091, 2, 0, 16);  slice_tensor_1945 = slice_32091 = None
        slice_scatter_default_3891: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3889, slice_scatter_default_3890, 1, 7776, 7792);  slice_scatter_default_3889 = slice_scatter_default_3890 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32111: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32077, 2, 16, 32);  slice_32077 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_976: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32111, memory_format = torch.contiguous_format);  slice_32111 = None
        view_1956: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_976, [32, 11]);  clone_976 = None
        mm_973: "f32[32, 8]" = torch.ops.aten.mm.default(view_1956, slice_37)
        view_1957: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_973, [2, 16, 8]);  mm_973 = None
        slice_32118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3891, 1, 7776, 7792)
        slice_32119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32118, 2, 0, 16);  slice_32118 = None
        add_975: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32119, view_1957);  slice_32119 = view_1957 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3891, 1, 7776, 7792)
        slice_scatter_default_3892: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1946, add_975, 2, 0, 16);  slice_tensor_1946 = add_975 = None
        slice_scatter_default_3893: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3891, slice_scatter_default_3892, 1, 7776, 7792);  slice_scatter_default_3891 = slice_scatter_default_3892 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3893, 1, 7776, 7792)
        slice_32124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32123, 2, 0, 16);  slice_32123 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3893, 1, 7776, 7792)
        slice_scatter_default_3894: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1947, slice_32124, 2, 0, 16);  slice_tensor_1947 = slice_32124 = None
        slice_scatter_default_3895: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3893, slice_scatter_default_3894, 1, 7776, 7792);  slice_scatter_default_3893 = slice_scatter_default_3894 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32143: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7792, 7808)
        slice_32144: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32143, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_977: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32144, memory_format = torch.contiguous_format);  slice_32144 = None
        view_1958: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_977, [32, 16]);  clone_977 = None
        mm_974: "f32[32, 8]" = torch.ops.aten.mm.default(view_1958, slice_7)
        view_1959: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_974, [2, 16, 8]);  mm_974 = None
        slice_32151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3895, 1, 7792, 7808)
        slice_32152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32151, 2, 0, 16);  slice_32151 = None
        add_976: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32152, view_1959);  slice_32152 = view_1959 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3895, 1, 7792, 7808)
        slice_scatter_default_3896: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1948, add_976, 2, 0, 16);  slice_tensor_1948 = add_976 = None
        slice_scatter_default_3897: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3895, slice_scatter_default_3896, 1, 7792, 7808);  slice_scatter_default_3895 = slice_scatter_default_3896 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3897, 1, 7792, 7808)
        slice_32157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32156, 2, 0, 16);  slice_32156 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3897, 1, 7792, 7808)
        slice_scatter_default_3898: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1949, slice_32157, 2, 0, 16);  slice_tensor_1949 = slice_32157 = None
        slice_scatter_default_3899: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3897, slice_scatter_default_3898, 1, 7792, 7808);  slice_scatter_default_3897 = slice_scatter_default_3898 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32177: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32143, 2, 16, 32);  slice_32143 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_978: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32177, memory_format = torch.contiguous_format);  slice_32177 = None
        view_1960: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_978, [32, 11]);  clone_978 = None
        mm_975: "f32[32, 8]" = torch.ops.aten.mm.default(view_1960, slice_37)
        view_1961: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_975, [2, 16, 8]);  mm_975 = None
        slice_32184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3899, 1, 7792, 7808)
        slice_32185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32184, 2, 0, 16);  slice_32184 = None
        add_977: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32185, view_1961);  slice_32185 = view_1961 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3899, 1, 7792, 7808)
        slice_scatter_default_3900: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1950, add_977, 2, 0, 16);  slice_tensor_1950 = add_977 = None
        slice_scatter_default_3901: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3899, slice_scatter_default_3900, 1, 7792, 7808);  slice_scatter_default_3899 = slice_scatter_default_3900 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3901, 1, 7792, 7808)
        slice_32190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32189, 2, 0, 16);  slice_32189 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3901, 1, 7792, 7808)
        slice_scatter_default_3902: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1951, slice_32190, 2, 0, 16);  slice_tensor_1951 = slice_32190 = None
        slice_scatter_default_3903: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3901, slice_scatter_default_3902, 1, 7792, 7808);  slice_scatter_default_3901 = slice_scatter_default_3902 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32209: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7808, 7824)
        slice_32210: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32209, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_979: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32210, memory_format = torch.contiguous_format);  slice_32210 = None
        view_1962: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_979, [32, 16]);  clone_979 = None
        mm_976: "f32[32, 8]" = torch.ops.aten.mm.default(view_1962, slice_7)
        view_1963: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_976, [2, 16, 8]);  mm_976 = None
        slice_32217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3903, 1, 7808, 7824)
        slice_32218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32217, 2, 0, 16);  slice_32217 = None
        add_978: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32218, view_1963);  slice_32218 = view_1963 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3903, 1, 7808, 7824)
        slice_scatter_default_3904: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1952, add_978, 2, 0, 16);  slice_tensor_1952 = add_978 = None
        slice_scatter_default_3905: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3903, slice_scatter_default_3904, 1, 7808, 7824);  slice_scatter_default_3903 = slice_scatter_default_3904 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3905, 1, 7808, 7824)
        slice_32223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32222, 2, 0, 16);  slice_32222 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1953: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3905, 1, 7808, 7824)
        slice_scatter_default_3906: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1953, slice_32223, 2, 0, 16);  slice_tensor_1953 = slice_32223 = None
        slice_scatter_default_3907: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3905, slice_scatter_default_3906, 1, 7808, 7824);  slice_scatter_default_3905 = slice_scatter_default_3906 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32243: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32209, 2, 16, 32);  slice_32209 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_980: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32243, memory_format = torch.contiguous_format);  slice_32243 = None
        view_1964: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_980, [32, 11]);  clone_980 = None
        mm_977: "f32[32, 8]" = torch.ops.aten.mm.default(view_1964, slice_37)
        view_1965: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_977, [2, 16, 8]);  mm_977 = None
        slice_32250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3907, 1, 7808, 7824)
        slice_32251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32250, 2, 0, 16);  slice_32250 = None
        add_979: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32251, view_1965);  slice_32251 = view_1965 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3907, 1, 7808, 7824)
        slice_scatter_default_3908: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1954, add_979, 2, 0, 16);  slice_tensor_1954 = add_979 = None
        slice_scatter_default_3909: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3907, slice_scatter_default_3908, 1, 7808, 7824);  slice_scatter_default_3907 = slice_scatter_default_3908 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3909, 1, 7808, 7824)
        slice_32256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32255, 2, 0, 16);  slice_32255 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3909, 1, 7808, 7824)
        slice_scatter_default_3910: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1955, slice_32256, 2, 0, 16);  slice_tensor_1955 = slice_32256 = None
        slice_scatter_default_3911: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3909, slice_scatter_default_3910, 1, 7808, 7824);  slice_scatter_default_3909 = slice_scatter_default_3910 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32275: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7824, 7840)
        slice_32276: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32275, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_981: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32276, memory_format = torch.contiguous_format);  slice_32276 = None
        view_1966: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_981, [32, 16]);  clone_981 = None
        mm_978: "f32[32, 8]" = torch.ops.aten.mm.default(view_1966, slice_7)
        view_1967: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_978, [2, 16, 8]);  mm_978 = None
        slice_32283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3911, 1, 7824, 7840)
        slice_32284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32283, 2, 0, 16);  slice_32283 = None
        add_980: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32284, view_1967);  slice_32284 = view_1967 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3911, 1, 7824, 7840)
        slice_scatter_default_3912: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1956, add_980, 2, 0, 16);  slice_tensor_1956 = add_980 = None
        slice_scatter_default_3913: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3911, slice_scatter_default_3912, 1, 7824, 7840);  slice_scatter_default_3911 = slice_scatter_default_3912 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3913, 1, 7824, 7840)
        slice_32289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32288, 2, 0, 16);  slice_32288 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3913, 1, 7824, 7840)
        slice_scatter_default_3914: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1957, slice_32289, 2, 0, 16);  slice_tensor_1957 = slice_32289 = None
        slice_scatter_default_3915: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3913, slice_scatter_default_3914, 1, 7824, 7840);  slice_scatter_default_3913 = slice_scatter_default_3914 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32309: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32275, 2, 16, 32);  slice_32275 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_982: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32309, memory_format = torch.contiguous_format);  slice_32309 = None
        view_1968: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_982, [32, 11]);  clone_982 = None
        mm_979: "f32[32, 8]" = torch.ops.aten.mm.default(view_1968, slice_37)
        view_1969: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_979, [2, 16, 8]);  mm_979 = None
        slice_32316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3915, 1, 7824, 7840)
        slice_32317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32316, 2, 0, 16);  slice_32316 = None
        add_981: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32317, view_1969);  slice_32317 = view_1969 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1958: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3915, 1, 7824, 7840)
        slice_scatter_default_3916: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1958, add_981, 2, 0, 16);  slice_tensor_1958 = add_981 = None
        slice_scatter_default_3917: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3915, slice_scatter_default_3916, 1, 7824, 7840);  slice_scatter_default_3915 = slice_scatter_default_3916 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3917, 1, 7824, 7840)
        slice_32322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32321, 2, 0, 16);  slice_32321 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3917, 1, 7824, 7840)
        slice_scatter_default_3918: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1959, slice_32322, 2, 0, 16);  slice_tensor_1959 = slice_32322 = None
        slice_scatter_default_3919: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3917, slice_scatter_default_3918, 1, 7824, 7840);  slice_scatter_default_3917 = slice_scatter_default_3918 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32341: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7840, 7856)
        slice_32342: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32341, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_983: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32342, memory_format = torch.contiguous_format);  slice_32342 = None
        view_1970: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_983, [32, 16]);  clone_983 = None
        mm_980: "f32[32, 8]" = torch.ops.aten.mm.default(view_1970, slice_7)
        view_1971: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_980, [2, 16, 8]);  mm_980 = None
        slice_32349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3919, 1, 7840, 7856)
        slice_32350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32349, 2, 0, 16);  slice_32349 = None
        add_982: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32350, view_1971);  slice_32350 = view_1971 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3919, 1, 7840, 7856)
        slice_scatter_default_3920: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1960, add_982, 2, 0, 16);  slice_tensor_1960 = add_982 = None
        slice_scatter_default_3921: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3919, slice_scatter_default_3920, 1, 7840, 7856);  slice_scatter_default_3919 = slice_scatter_default_3920 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3921, 1, 7840, 7856)
        slice_32355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32354, 2, 0, 16);  slice_32354 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3921, 1, 7840, 7856)
        slice_scatter_default_3922: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1961, slice_32355, 2, 0, 16);  slice_tensor_1961 = slice_32355 = None
        slice_scatter_default_3923: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3921, slice_scatter_default_3922, 1, 7840, 7856);  slice_scatter_default_3921 = slice_scatter_default_3922 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32375: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32341, 2, 16, 32);  slice_32341 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_984: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32375, memory_format = torch.contiguous_format);  slice_32375 = None
        view_1972: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_984, [32, 11]);  clone_984 = None
        mm_981: "f32[32, 8]" = torch.ops.aten.mm.default(view_1972, slice_37)
        view_1973: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_981, [2, 16, 8]);  mm_981 = None
        slice_32382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3923, 1, 7840, 7856)
        slice_32383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32382, 2, 0, 16);  slice_32382 = None
        add_983: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32383, view_1973);  slice_32383 = view_1973 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3923, 1, 7840, 7856)
        slice_scatter_default_3924: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1962, add_983, 2, 0, 16);  slice_tensor_1962 = add_983 = None
        slice_scatter_default_3925: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3923, slice_scatter_default_3924, 1, 7840, 7856);  slice_scatter_default_3923 = slice_scatter_default_3924 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3925, 1, 7840, 7856)
        slice_32388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32387, 2, 0, 16);  slice_32387 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3925, 1, 7840, 7856)
        slice_scatter_default_3926: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1963, slice_32388, 2, 0, 16);  slice_tensor_1963 = slice_32388 = None
        slice_scatter_default_3927: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3925, slice_scatter_default_3926, 1, 7840, 7856);  slice_scatter_default_3925 = slice_scatter_default_3926 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32407: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7856, 7872)
        slice_32408: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32407, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_985: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32408, memory_format = torch.contiguous_format);  slice_32408 = None
        view_1974: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_985, [32, 16]);  clone_985 = None
        mm_982: "f32[32, 8]" = torch.ops.aten.mm.default(view_1974, slice_7)
        view_1975: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_982, [2, 16, 8]);  mm_982 = None
        slice_32415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3927, 1, 7856, 7872)
        slice_32416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32415, 2, 0, 16);  slice_32415 = None
        add_984: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32416, view_1975);  slice_32416 = view_1975 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3927, 1, 7856, 7872)
        slice_scatter_default_3928: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1964, add_984, 2, 0, 16);  slice_tensor_1964 = add_984 = None
        slice_scatter_default_3929: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3927, slice_scatter_default_3928, 1, 7856, 7872);  slice_scatter_default_3927 = slice_scatter_default_3928 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3929, 1, 7856, 7872)
        slice_32421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32420, 2, 0, 16);  slice_32420 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3929, 1, 7856, 7872)
        slice_scatter_default_3930: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1965, slice_32421, 2, 0, 16);  slice_tensor_1965 = slice_32421 = None
        slice_scatter_default_3931: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3929, slice_scatter_default_3930, 1, 7856, 7872);  slice_scatter_default_3929 = slice_scatter_default_3930 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32441: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32407, 2, 16, 32);  slice_32407 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_986: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32441, memory_format = torch.contiguous_format);  slice_32441 = None
        view_1976: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_986, [32, 11]);  clone_986 = None
        mm_983: "f32[32, 8]" = torch.ops.aten.mm.default(view_1976, slice_37)
        view_1977: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_983, [2, 16, 8]);  mm_983 = None
        slice_32448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3931, 1, 7856, 7872)
        slice_32449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32448, 2, 0, 16);  slice_32448 = None
        add_985: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32449, view_1977);  slice_32449 = view_1977 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3931, 1, 7856, 7872)
        slice_scatter_default_3932: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1966, add_985, 2, 0, 16);  slice_tensor_1966 = add_985 = None
        slice_scatter_default_3933: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3931, slice_scatter_default_3932, 1, 7856, 7872);  slice_scatter_default_3931 = slice_scatter_default_3932 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3933, 1, 7856, 7872)
        slice_32454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32453, 2, 0, 16);  slice_32453 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3933, 1, 7856, 7872)
        slice_scatter_default_3934: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1967, slice_32454, 2, 0, 16);  slice_tensor_1967 = slice_32454 = None
        slice_scatter_default_3935: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3933, slice_scatter_default_3934, 1, 7856, 7872);  slice_scatter_default_3933 = slice_scatter_default_3934 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32473: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7872, 7888)
        slice_32474: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32473, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_987: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32474, memory_format = torch.contiguous_format);  slice_32474 = None
        view_1978: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_987, [32, 16]);  clone_987 = None
        mm_984: "f32[32, 8]" = torch.ops.aten.mm.default(view_1978, slice_7)
        view_1979: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_984, [2, 16, 8]);  mm_984 = None
        slice_32481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3935, 1, 7872, 7888)
        slice_32482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32481, 2, 0, 16);  slice_32481 = None
        add_986: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32482, view_1979);  slice_32482 = view_1979 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3935, 1, 7872, 7888)
        slice_scatter_default_3936: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1968, add_986, 2, 0, 16);  slice_tensor_1968 = add_986 = None
        slice_scatter_default_3937: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3935, slice_scatter_default_3936, 1, 7872, 7888);  slice_scatter_default_3935 = slice_scatter_default_3936 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3937, 1, 7872, 7888)
        slice_32487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32486, 2, 0, 16);  slice_32486 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3937, 1, 7872, 7888)
        slice_scatter_default_3938: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1969, slice_32487, 2, 0, 16);  slice_tensor_1969 = slice_32487 = None
        slice_scatter_default_3939: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3937, slice_scatter_default_3938, 1, 7872, 7888);  slice_scatter_default_3937 = slice_scatter_default_3938 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32507: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32473, 2, 16, 32);  slice_32473 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_988: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32507, memory_format = torch.contiguous_format);  slice_32507 = None
        view_1980: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_988, [32, 11]);  clone_988 = None
        mm_985: "f32[32, 8]" = torch.ops.aten.mm.default(view_1980, slice_37)
        view_1981: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_985, [2, 16, 8]);  mm_985 = None
        slice_32514: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3939, 1, 7872, 7888)
        slice_32515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32514, 2, 0, 16);  slice_32514 = None
        add_987: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32515, view_1981);  slice_32515 = view_1981 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3939, 1, 7872, 7888)
        slice_scatter_default_3940: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1970, add_987, 2, 0, 16);  slice_tensor_1970 = add_987 = None
        slice_scatter_default_3941: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3939, slice_scatter_default_3940, 1, 7872, 7888);  slice_scatter_default_3939 = slice_scatter_default_3940 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32519: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3941, 1, 7872, 7888)
        slice_32520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32519, 2, 0, 16);  slice_32519 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3941, 1, 7872, 7888)
        slice_scatter_default_3942: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1971, slice_32520, 2, 0, 16);  slice_tensor_1971 = slice_32520 = None
        slice_scatter_default_3943: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3941, slice_scatter_default_3942, 1, 7872, 7888);  slice_scatter_default_3941 = slice_scatter_default_3942 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32539: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7888, 7904)
        slice_32540: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32539, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_989: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32540, memory_format = torch.contiguous_format);  slice_32540 = None
        view_1982: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_989, [32, 16]);  clone_989 = None
        mm_986: "f32[32, 8]" = torch.ops.aten.mm.default(view_1982, slice_7)
        view_1983: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_986, [2, 16, 8]);  mm_986 = None
        slice_32547: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3943, 1, 7888, 7904)
        slice_32548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32547, 2, 0, 16);  slice_32547 = None
        add_988: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32548, view_1983);  slice_32548 = view_1983 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3943, 1, 7888, 7904)
        slice_scatter_default_3944: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1972, add_988, 2, 0, 16);  slice_tensor_1972 = add_988 = None
        slice_scatter_default_3945: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3943, slice_scatter_default_3944, 1, 7888, 7904);  slice_scatter_default_3943 = slice_scatter_default_3944 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32552: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3945, 1, 7888, 7904)
        slice_32553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32552, 2, 0, 16);  slice_32552 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3945, 1, 7888, 7904)
        slice_scatter_default_3946: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1973, slice_32553, 2, 0, 16);  slice_tensor_1973 = slice_32553 = None
        slice_scatter_default_3947: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3945, slice_scatter_default_3946, 1, 7888, 7904);  slice_scatter_default_3945 = slice_scatter_default_3946 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32573: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32539, 2, 16, 32);  slice_32539 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_990: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32573, memory_format = torch.contiguous_format);  slice_32573 = None
        view_1984: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_990, [32, 11]);  clone_990 = None
        mm_987: "f32[32, 8]" = torch.ops.aten.mm.default(view_1984, slice_37)
        view_1985: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_987, [2, 16, 8]);  mm_987 = None
        slice_32580: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3947, 1, 7888, 7904)
        slice_32581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32580, 2, 0, 16);  slice_32580 = None
        add_989: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32581, view_1985);  slice_32581 = view_1985 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3947, 1, 7888, 7904)
        slice_scatter_default_3948: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1974, add_989, 2, 0, 16);  slice_tensor_1974 = add_989 = None
        slice_scatter_default_3949: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3947, slice_scatter_default_3948, 1, 7888, 7904);  slice_scatter_default_3947 = slice_scatter_default_3948 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32585: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3949, 1, 7888, 7904)
        slice_32586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32585, 2, 0, 16);  slice_32585 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3949, 1, 7888, 7904)
        slice_scatter_default_3950: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1975, slice_32586, 2, 0, 16);  slice_tensor_1975 = slice_32586 = None
        slice_scatter_default_3951: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3949, slice_scatter_default_3950, 1, 7888, 7904);  slice_scatter_default_3949 = slice_scatter_default_3950 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32605: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7904, 7920)
        slice_32606: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32605, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_991: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32606, memory_format = torch.contiguous_format);  slice_32606 = None
        view_1986: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_991, [32, 16]);  clone_991 = None
        mm_988: "f32[32, 8]" = torch.ops.aten.mm.default(view_1986, slice_7)
        view_1987: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_988, [2, 16, 8]);  mm_988 = None
        slice_32613: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3951, 1, 7904, 7920)
        slice_32614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32613, 2, 0, 16);  slice_32613 = None
        add_990: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32614, view_1987);  slice_32614 = view_1987 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3951, 1, 7904, 7920)
        slice_scatter_default_3952: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1976, add_990, 2, 0, 16);  slice_tensor_1976 = add_990 = None
        slice_scatter_default_3953: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3951, slice_scatter_default_3952, 1, 7904, 7920);  slice_scatter_default_3951 = slice_scatter_default_3952 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32618: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3953, 1, 7904, 7920)
        slice_32619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32618, 2, 0, 16);  slice_32618 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3953, 1, 7904, 7920)
        slice_scatter_default_3954: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1977, slice_32619, 2, 0, 16);  slice_tensor_1977 = slice_32619 = None
        slice_scatter_default_3955: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3953, slice_scatter_default_3954, 1, 7904, 7920);  slice_scatter_default_3953 = slice_scatter_default_3954 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32639: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32605, 2, 16, 32);  slice_32605 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_992: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32639, memory_format = torch.contiguous_format);  slice_32639 = None
        view_1988: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_992, [32, 11]);  clone_992 = None
        mm_989: "f32[32, 8]" = torch.ops.aten.mm.default(view_1988, slice_37)
        view_1989: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_989, [2, 16, 8]);  mm_989 = None
        slice_32646: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3955, 1, 7904, 7920)
        slice_32647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32646, 2, 0, 16);  slice_32646 = None
        add_991: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32647, view_1989);  slice_32647 = view_1989 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3955, 1, 7904, 7920)
        slice_scatter_default_3956: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1978, add_991, 2, 0, 16);  slice_tensor_1978 = add_991 = None
        slice_scatter_default_3957: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3955, slice_scatter_default_3956, 1, 7904, 7920);  slice_scatter_default_3955 = slice_scatter_default_3956 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32651: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3957, 1, 7904, 7920)
        slice_32652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32651, 2, 0, 16);  slice_32651 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3957, 1, 7904, 7920)
        slice_scatter_default_3958: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1979, slice_32652, 2, 0, 16);  slice_tensor_1979 = slice_32652 = None
        slice_scatter_default_3959: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3957, slice_scatter_default_3958, 1, 7904, 7920);  slice_scatter_default_3957 = slice_scatter_default_3958 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32671: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7920, 7936)
        slice_32672: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32671, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_993: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32672, memory_format = torch.contiguous_format);  slice_32672 = None
        view_1990: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_993, [32, 16]);  clone_993 = None
        mm_990: "f32[32, 8]" = torch.ops.aten.mm.default(view_1990, slice_7)
        view_1991: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_990, [2, 16, 8]);  mm_990 = None
        slice_32679: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3959, 1, 7920, 7936)
        slice_32680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32679, 2, 0, 16);  slice_32679 = None
        add_992: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32680, view_1991);  slice_32680 = view_1991 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3959, 1, 7920, 7936)
        slice_scatter_default_3960: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1980, add_992, 2, 0, 16);  slice_tensor_1980 = add_992 = None
        slice_scatter_default_3961: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3959, slice_scatter_default_3960, 1, 7920, 7936);  slice_scatter_default_3959 = slice_scatter_default_3960 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32684: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3961, 1, 7920, 7936)
        slice_32685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32684, 2, 0, 16);  slice_32684 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3961, 1, 7920, 7936)
        slice_scatter_default_3962: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1981, slice_32685, 2, 0, 16);  slice_tensor_1981 = slice_32685 = None
        slice_scatter_default_3963: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3961, slice_scatter_default_3962, 1, 7920, 7936);  slice_scatter_default_3961 = slice_scatter_default_3962 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32705: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32671, 2, 16, 32);  slice_32671 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_994: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32705, memory_format = torch.contiguous_format);  slice_32705 = None
        view_1992: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_994, [32, 11]);  clone_994 = None
        mm_991: "f32[32, 8]" = torch.ops.aten.mm.default(view_1992, slice_37)
        view_1993: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_991, [2, 16, 8]);  mm_991 = None
        slice_32712: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3963, 1, 7920, 7936)
        slice_32713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32712, 2, 0, 16);  slice_32712 = None
        add_993: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32713, view_1993);  slice_32713 = view_1993 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3963, 1, 7920, 7936)
        slice_scatter_default_3964: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1982, add_993, 2, 0, 16);  slice_tensor_1982 = add_993 = None
        slice_scatter_default_3965: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3963, slice_scatter_default_3964, 1, 7920, 7936);  slice_scatter_default_3963 = slice_scatter_default_3964 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32717: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3965, 1, 7920, 7936)
        slice_32718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32717, 2, 0, 16);  slice_32717 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3965, 1, 7920, 7936)
        slice_scatter_default_3966: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1983, slice_32718, 2, 0, 16);  slice_tensor_1983 = slice_32718 = None
        slice_scatter_default_3967: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3965, slice_scatter_default_3966, 1, 7920, 7936);  slice_scatter_default_3965 = slice_scatter_default_3966 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32737: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7936, 7952)
        slice_32738: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32737, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_995: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32738, memory_format = torch.contiguous_format);  slice_32738 = None
        view_1994: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_995, [32, 16]);  clone_995 = None
        mm_992: "f32[32, 8]" = torch.ops.aten.mm.default(view_1994, slice_7)
        view_1995: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_992, [2, 16, 8]);  mm_992 = None
        slice_32745: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3967, 1, 7936, 7952)
        slice_32746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32745, 2, 0, 16);  slice_32745 = None
        add_994: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32746, view_1995);  slice_32746 = view_1995 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3967, 1, 7936, 7952)
        slice_scatter_default_3968: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1984, add_994, 2, 0, 16);  slice_tensor_1984 = add_994 = None
        slice_scatter_default_3969: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3967, slice_scatter_default_3968, 1, 7936, 7952);  slice_scatter_default_3967 = slice_scatter_default_3968 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32750: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3969, 1, 7936, 7952)
        slice_32751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32750, 2, 0, 16);  slice_32750 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3969, 1, 7936, 7952)
        slice_scatter_default_3970: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1985, slice_32751, 2, 0, 16);  slice_tensor_1985 = slice_32751 = None
        slice_scatter_default_3971: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3969, slice_scatter_default_3970, 1, 7936, 7952);  slice_scatter_default_3969 = slice_scatter_default_3970 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32771: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32737, 2, 16, 32);  slice_32737 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_996: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32771, memory_format = torch.contiguous_format);  slice_32771 = None
        view_1996: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_996, [32, 11]);  clone_996 = None
        mm_993: "f32[32, 8]" = torch.ops.aten.mm.default(view_1996, slice_37)
        view_1997: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_993, [2, 16, 8]);  mm_993 = None
        slice_32778: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3971, 1, 7936, 7952)
        slice_32779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32778, 2, 0, 16);  slice_32778 = None
        add_995: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32779, view_1997);  slice_32779 = view_1997 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1986: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3971, 1, 7936, 7952)
        slice_scatter_default_3972: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1986, add_995, 2, 0, 16);  slice_tensor_1986 = add_995 = None
        slice_scatter_default_3973: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3971, slice_scatter_default_3972, 1, 7936, 7952);  slice_scatter_default_3971 = slice_scatter_default_3972 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32783: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3973, 1, 7936, 7952)
        slice_32784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32783, 2, 0, 16);  slice_32783 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3973, 1, 7936, 7952)
        slice_scatter_default_3974: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1987, slice_32784, 2, 0, 16);  slice_tensor_1987 = slice_32784 = None
        slice_scatter_default_3975: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3973, slice_scatter_default_3974, 1, 7936, 7952);  slice_scatter_default_3973 = slice_scatter_default_3974 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32803: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7952, 7968)
        slice_32804: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32803, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_997: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32804, memory_format = torch.contiguous_format);  slice_32804 = None
        view_1998: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_997, [32, 16]);  clone_997 = None
        mm_994: "f32[32, 8]" = torch.ops.aten.mm.default(view_1998, slice_7)
        view_1999: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_994, [2, 16, 8]);  mm_994 = None
        slice_32811: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3975, 1, 7952, 7968)
        slice_32812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32811, 2, 0, 16);  slice_32811 = None
        add_996: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32812, view_1999);  slice_32812 = view_1999 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3975, 1, 7952, 7968)
        slice_scatter_default_3976: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1988, add_996, 2, 0, 16);  slice_tensor_1988 = add_996 = None
        slice_scatter_default_3977: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3975, slice_scatter_default_3976, 1, 7952, 7968);  slice_scatter_default_3975 = slice_scatter_default_3976 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32816: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3977, 1, 7952, 7968)
        slice_32817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32816, 2, 0, 16);  slice_32816 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3977, 1, 7952, 7968)
        slice_scatter_default_3978: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1989, slice_32817, 2, 0, 16);  slice_tensor_1989 = slice_32817 = None
        slice_scatter_default_3979: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3977, slice_scatter_default_3978, 1, 7952, 7968);  slice_scatter_default_3977 = slice_scatter_default_3978 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32837: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32803, 2, 16, 32);  slice_32803 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_998: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32837, memory_format = torch.contiguous_format);  slice_32837 = None
        view_2000: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_998, [32, 11]);  clone_998 = None
        mm_995: "f32[32, 8]" = torch.ops.aten.mm.default(view_2000, slice_37)
        view_2001: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_995, [2, 16, 8]);  mm_995 = None
        slice_32844: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3979, 1, 7952, 7968)
        slice_32845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32844, 2, 0, 16);  slice_32844 = None
        add_997: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32845, view_2001);  slice_32845 = view_2001 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3979, 1, 7952, 7968)
        slice_scatter_default_3980: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1990, add_997, 2, 0, 16);  slice_tensor_1990 = add_997 = None
        slice_scatter_default_3981: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3979, slice_scatter_default_3980, 1, 7952, 7968);  slice_scatter_default_3979 = slice_scatter_default_3980 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32849: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3981, 1, 7952, 7968)
        slice_32850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32849, 2, 0, 16);  slice_32849 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1991: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3981, 1, 7952, 7968)
        slice_scatter_default_3982: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1991, slice_32850, 2, 0, 16);  slice_tensor_1991 = slice_32850 = None
        slice_scatter_default_3983: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3981, slice_scatter_default_3982, 1, 7952, 7968);  slice_scatter_default_3981 = slice_scatter_default_3982 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32869: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7968, 7984)
        slice_32870: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32869, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_999: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32870, memory_format = torch.contiguous_format);  slice_32870 = None
        view_2002: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_999, [32, 16]);  clone_999 = None
        mm_996: "f32[32, 8]" = torch.ops.aten.mm.default(view_2002, slice_7)
        view_2003: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_996, [2, 16, 8]);  mm_996 = None
        slice_32877: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3983, 1, 7968, 7984)
        slice_32878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32877, 2, 0, 16);  slice_32877 = None
        add_998: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32878, view_2003);  slice_32878 = view_2003 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3983, 1, 7968, 7984)
        slice_scatter_default_3984: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1992, add_998, 2, 0, 16);  slice_tensor_1992 = add_998 = None
        slice_scatter_default_3985: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3983, slice_scatter_default_3984, 1, 7968, 7984);  slice_scatter_default_3983 = slice_scatter_default_3984 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32882: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3985, 1, 7968, 7984)
        slice_32883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32882, 2, 0, 16);  slice_32882 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3985, 1, 7968, 7984)
        slice_scatter_default_3986: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1993, slice_32883, 2, 0, 16);  slice_tensor_1993 = slice_32883 = None
        slice_scatter_default_3987: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3985, slice_scatter_default_3986, 1, 7968, 7984);  slice_scatter_default_3985 = slice_scatter_default_3986 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32903: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32869, 2, 16, 32);  slice_32869 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1000: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32903, memory_format = torch.contiguous_format);  slice_32903 = None
        view_2004: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1000, [32, 11]);  clone_1000 = None
        mm_997: "f32[32, 8]" = torch.ops.aten.mm.default(view_2004, slice_37)
        view_2005: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_997, [2, 16, 8]);  mm_997 = None
        slice_32910: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3987, 1, 7968, 7984)
        slice_32911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32910, 2, 0, 16);  slice_32910 = None
        add_999: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32911, view_2005);  slice_32911 = view_2005 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3987, 1, 7968, 7984)
        slice_scatter_default_3988: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1994, add_999, 2, 0, 16);  slice_tensor_1994 = add_999 = None
        slice_scatter_default_3989: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3987, slice_scatter_default_3988, 1, 7968, 7984);  slice_scatter_default_3987 = slice_scatter_default_3988 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32915: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3989, 1, 7968, 7984)
        slice_32916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32915, 2, 0, 16);  slice_32915 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3989, 1, 7968, 7984)
        slice_scatter_default_3990: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1995, slice_32916, 2, 0, 16);  slice_tensor_1995 = slice_32916 = None
        slice_scatter_default_3991: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3989, slice_scatter_default_3990, 1, 7968, 7984);  slice_scatter_default_3989 = slice_scatter_default_3990 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32935: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 7984, 8000)
        slice_32936: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_32935, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1001: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_32936, memory_format = torch.contiguous_format);  slice_32936 = None
        view_2006: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1001, [32, 16]);  clone_1001 = None
        mm_998: "f32[32, 8]" = torch.ops.aten.mm.default(view_2006, slice_7)
        view_2007: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_998, [2, 16, 8]);  mm_998 = None
        slice_32943: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3991, 1, 7984, 8000)
        slice_32944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32943, 2, 0, 16);  slice_32943 = None
        add_1000: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32944, view_2007);  slice_32944 = view_2007 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3991, 1, 7984, 8000)
        slice_scatter_default_3992: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1996, add_1000, 2, 0, 16);  slice_tensor_1996 = add_1000 = None
        slice_scatter_default_3993: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3991, slice_scatter_default_3992, 1, 7984, 8000);  slice_scatter_default_3991 = slice_scatter_default_3992 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32948: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3993, 1, 7984, 8000)
        slice_32949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32948, 2, 0, 16);  slice_32948 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3993, 1, 7984, 8000)
        slice_scatter_default_3994: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1997, slice_32949, 2, 0, 16);  slice_tensor_1997 = slice_32949 = None
        slice_scatter_default_3995: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3993, slice_scatter_default_3994, 1, 7984, 8000);  slice_scatter_default_3993 = slice_scatter_default_3994 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_32969: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_32935, 2, 16, 32);  slice_32935 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1002: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_32969, memory_format = torch.contiguous_format);  slice_32969 = None
        view_2008: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1002, [32, 11]);  clone_1002 = None
        mm_999: "f32[32, 8]" = torch.ops.aten.mm.default(view_2008, slice_37)
        view_2009: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_999, [2, 16, 8]);  mm_999 = None
        slice_32976: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3995, 1, 7984, 8000)
        slice_32977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32976, 2, 0, 16);  slice_32976 = None
        add_1001: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_32977, view_2009);  slice_32977 = view_2009 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3995, 1, 7984, 8000)
        slice_scatter_default_3996: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1998, add_1001, 2, 0, 16);  slice_tensor_1998 = add_1001 = None
        slice_scatter_default_3997: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3995, slice_scatter_default_3996, 1, 7984, 8000);  slice_scatter_default_3995 = slice_scatter_default_3996 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_32981: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3997, 1, 7984, 8000)
        slice_32982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_32981, 2, 0, 16);  slice_32981 = None
        
        # No stacktrace found for following nodes
        slice_tensor_1999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3997, 1, 7984, 8000)
        slice_scatter_default_3998: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_1999, slice_32982, 2, 0, 16);  slice_tensor_1999 = slice_32982 = None
        slice_scatter_default_3999: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3997, slice_scatter_default_3998, 1, 7984, 8000);  slice_scatter_default_3997 = slice_scatter_default_3998 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33001: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8000, 8016)
        slice_33002: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33001, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1003: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33002, memory_format = torch.contiguous_format);  slice_33002 = None
        view_2010: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1003, [32, 16]);  clone_1003 = None
        mm_1000: "f32[32, 8]" = torch.ops.aten.mm.default(view_2010, slice_7)
        view_2011: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1000, [2, 16, 8]);  mm_1000 = None
        slice_33009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3999, 1, 8000, 8016)
        slice_33010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33009, 2, 0, 16);  slice_33009 = None
        add_1002: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33010, view_2011);  slice_33010 = view_2011 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_3999, 1, 8000, 8016)
        slice_scatter_default_4000: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2000, add_1002, 2, 0, 16);  slice_tensor_2000 = add_1002 = None
        slice_scatter_default_4001: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_3999, slice_scatter_default_4000, 1, 8000, 8016);  slice_scatter_default_3999 = slice_scatter_default_4000 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4001, 1, 8000, 8016)
        slice_33015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33014, 2, 0, 16);  slice_33014 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4001, 1, 8000, 8016)
        slice_scatter_default_4002: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2001, slice_33015, 2, 0, 16);  slice_tensor_2001 = slice_33015 = None
        slice_scatter_default_4003: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4001, slice_scatter_default_4002, 1, 8000, 8016);  slice_scatter_default_4001 = slice_scatter_default_4002 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33035: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33001, 2, 16, 32);  slice_33001 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1004: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33035, memory_format = torch.contiguous_format);  slice_33035 = None
        view_2012: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1004, [32, 11]);  clone_1004 = None
        mm_1001: "f32[32, 8]" = torch.ops.aten.mm.default(view_2012, slice_37)
        view_2013: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1001, [2, 16, 8]);  mm_1001 = None
        slice_33042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4003, 1, 8000, 8016)
        slice_33043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33042, 2, 0, 16);  slice_33042 = None
        add_1003: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33043, view_2013);  slice_33043 = view_2013 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4003, 1, 8000, 8016)
        slice_scatter_default_4004: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2002, add_1003, 2, 0, 16);  slice_tensor_2002 = add_1003 = None
        slice_scatter_default_4005: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4003, slice_scatter_default_4004, 1, 8000, 8016);  slice_scatter_default_4003 = slice_scatter_default_4004 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4005, 1, 8000, 8016)
        slice_33048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33047, 2, 0, 16);  slice_33047 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4005, 1, 8000, 8016)
        slice_scatter_default_4006: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2003, slice_33048, 2, 0, 16);  slice_tensor_2003 = slice_33048 = None
        slice_scatter_default_4007: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4005, slice_scatter_default_4006, 1, 8000, 8016);  slice_scatter_default_4005 = slice_scatter_default_4006 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33067: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8016, 8032)
        slice_33068: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33067, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1005: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33068, memory_format = torch.contiguous_format);  slice_33068 = None
        view_2014: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1005, [32, 16]);  clone_1005 = None
        mm_1002: "f32[32, 8]" = torch.ops.aten.mm.default(view_2014, slice_7)
        view_2015: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1002, [2, 16, 8]);  mm_1002 = None
        slice_33075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4007, 1, 8016, 8032)
        slice_33076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33075, 2, 0, 16);  slice_33075 = None
        add_1004: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33076, view_2015);  slice_33076 = view_2015 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4007, 1, 8016, 8032)
        slice_scatter_default_4008: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2004, add_1004, 2, 0, 16);  slice_tensor_2004 = add_1004 = None
        slice_scatter_default_4009: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4007, slice_scatter_default_4008, 1, 8016, 8032);  slice_scatter_default_4007 = slice_scatter_default_4008 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4009, 1, 8016, 8032)
        slice_33081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33080, 2, 0, 16);  slice_33080 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4009, 1, 8016, 8032)
        slice_scatter_default_4010: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2005, slice_33081, 2, 0, 16);  slice_tensor_2005 = slice_33081 = None
        slice_scatter_default_4011: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4009, slice_scatter_default_4010, 1, 8016, 8032);  slice_scatter_default_4009 = slice_scatter_default_4010 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33101: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33067, 2, 16, 32);  slice_33067 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1006: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33101, memory_format = torch.contiguous_format);  slice_33101 = None
        view_2016: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1006, [32, 11]);  clone_1006 = None
        mm_1003: "f32[32, 8]" = torch.ops.aten.mm.default(view_2016, slice_37)
        view_2017: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1003, [2, 16, 8]);  mm_1003 = None
        slice_33108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4011, 1, 8016, 8032)
        slice_33109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33108, 2, 0, 16);  slice_33108 = None
        add_1005: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33109, view_2017);  slice_33109 = view_2017 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4011, 1, 8016, 8032)
        slice_scatter_default_4012: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2006, add_1005, 2, 0, 16);  slice_tensor_2006 = add_1005 = None
        slice_scatter_default_4013: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4011, slice_scatter_default_4012, 1, 8016, 8032);  slice_scatter_default_4011 = slice_scatter_default_4012 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4013, 1, 8016, 8032)
        slice_33114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33113, 2, 0, 16);  slice_33113 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4013, 1, 8016, 8032)
        slice_scatter_default_4014: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2007, slice_33114, 2, 0, 16);  slice_tensor_2007 = slice_33114 = None
        slice_scatter_default_4015: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4013, slice_scatter_default_4014, 1, 8016, 8032);  slice_scatter_default_4013 = slice_scatter_default_4014 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33133: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8032, 8048)
        slice_33134: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33133, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1007: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33134, memory_format = torch.contiguous_format);  slice_33134 = None
        view_2018: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1007, [32, 16]);  clone_1007 = None
        mm_1004: "f32[32, 8]" = torch.ops.aten.mm.default(view_2018, slice_7)
        view_2019: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1004, [2, 16, 8]);  mm_1004 = None
        slice_33141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4015, 1, 8032, 8048)
        slice_33142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33141, 2, 0, 16);  slice_33141 = None
        add_1006: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33142, view_2019);  slice_33142 = view_2019 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4015, 1, 8032, 8048)
        slice_scatter_default_4016: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2008, add_1006, 2, 0, 16);  slice_tensor_2008 = add_1006 = None
        slice_scatter_default_4017: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4015, slice_scatter_default_4016, 1, 8032, 8048);  slice_scatter_default_4015 = slice_scatter_default_4016 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4017, 1, 8032, 8048)
        slice_33147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33146, 2, 0, 16);  slice_33146 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2009: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4017, 1, 8032, 8048)
        slice_scatter_default_4018: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2009, slice_33147, 2, 0, 16);  slice_tensor_2009 = slice_33147 = None
        slice_scatter_default_4019: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4017, slice_scatter_default_4018, 1, 8032, 8048);  slice_scatter_default_4017 = slice_scatter_default_4018 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33167: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33133, 2, 16, 32);  slice_33133 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1008: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33167, memory_format = torch.contiguous_format);  slice_33167 = None
        view_2020: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1008, [32, 11]);  clone_1008 = None
        mm_1005: "f32[32, 8]" = torch.ops.aten.mm.default(view_2020, slice_37)
        view_2021: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1005, [2, 16, 8]);  mm_1005 = None
        slice_33174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4019, 1, 8032, 8048)
        slice_33175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33174, 2, 0, 16);  slice_33174 = None
        add_1007: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33175, view_2021);  slice_33175 = view_2021 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4019, 1, 8032, 8048)
        slice_scatter_default_4020: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2010, add_1007, 2, 0, 16);  slice_tensor_2010 = add_1007 = None
        slice_scatter_default_4021: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4019, slice_scatter_default_4020, 1, 8032, 8048);  slice_scatter_default_4019 = slice_scatter_default_4020 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4021, 1, 8032, 8048)
        slice_33180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33179, 2, 0, 16);  slice_33179 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4021, 1, 8032, 8048)
        slice_scatter_default_4022: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2011, slice_33180, 2, 0, 16);  slice_tensor_2011 = slice_33180 = None
        slice_scatter_default_4023: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4021, slice_scatter_default_4022, 1, 8032, 8048);  slice_scatter_default_4021 = slice_scatter_default_4022 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33199: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8048, 8064)
        slice_33200: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33199, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1009: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33200, memory_format = torch.contiguous_format);  slice_33200 = None
        view_2022: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1009, [32, 16]);  clone_1009 = None
        mm_1006: "f32[32, 8]" = torch.ops.aten.mm.default(view_2022, slice_7)
        view_2023: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1006, [2, 16, 8]);  mm_1006 = None
        slice_33207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4023, 1, 8048, 8064)
        slice_33208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33207, 2, 0, 16);  slice_33207 = None
        add_1008: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33208, view_2023);  slice_33208 = view_2023 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4023, 1, 8048, 8064)
        slice_scatter_default_4024: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2012, add_1008, 2, 0, 16);  slice_tensor_2012 = add_1008 = None
        slice_scatter_default_4025: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4023, slice_scatter_default_4024, 1, 8048, 8064);  slice_scatter_default_4023 = slice_scatter_default_4024 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4025, 1, 8048, 8064)
        slice_33213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33212, 2, 0, 16);  slice_33212 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4025, 1, 8048, 8064)
        slice_scatter_default_4026: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2013, slice_33213, 2, 0, 16);  slice_tensor_2013 = slice_33213 = None
        slice_scatter_default_4027: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4025, slice_scatter_default_4026, 1, 8048, 8064);  slice_scatter_default_4025 = slice_scatter_default_4026 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33233: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33199, 2, 16, 32);  slice_33199 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1010: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33233, memory_format = torch.contiguous_format);  slice_33233 = None
        view_2024: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1010, [32, 11]);  clone_1010 = None
        mm_1007: "f32[32, 8]" = torch.ops.aten.mm.default(view_2024, slice_37)
        view_2025: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1007, [2, 16, 8]);  mm_1007 = None
        slice_33240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4027, 1, 8048, 8064)
        slice_33241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33240, 2, 0, 16);  slice_33240 = None
        add_1009: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33241, view_2025);  slice_33241 = view_2025 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2014: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4027, 1, 8048, 8064)
        slice_scatter_default_4028: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2014, add_1009, 2, 0, 16);  slice_tensor_2014 = add_1009 = None
        slice_scatter_default_4029: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4027, slice_scatter_default_4028, 1, 8048, 8064);  slice_scatter_default_4027 = slice_scatter_default_4028 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4029, 1, 8048, 8064)
        slice_33246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33245, 2, 0, 16);  slice_33245 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4029, 1, 8048, 8064)
        slice_scatter_default_4030: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2015, slice_33246, 2, 0, 16);  slice_tensor_2015 = slice_33246 = None
        slice_scatter_default_4031: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4029, slice_scatter_default_4030, 1, 8048, 8064);  slice_scatter_default_4029 = slice_scatter_default_4030 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33265: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8064, 8080)
        slice_33266: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33265, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1011: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33266, memory_format = torch.contiguous_format);  slice_33266 = None
        view_2026: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1011, [32, 16]);  clone_1011 = None
        mm_1008: "f32[32, 8]" = torch.ops.aten.mm.default(view_2026, slice_7)
        view_2027: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1008, [2, 16, 8]);  mm_1008 = None
        slice_33273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4031, 1, 8064, 8080)
        slice_33274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33273, 2, 0, 16);  slice_33273 = None
        add_1010: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33274, view_2027);  slice_33274 = view_2027 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4031, 1, 8064, 8080)
        slice_scatter_default_4032: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2016, add_1010, 2, 0, 16);  slice_tensor_2016 = add_1010 = None
        slice_scatter_default_4033: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4031, slice_scatter_default_4032, 1, 8064, 8080);  slice_scatter_default_4031 = slice_scatter_default_4032 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4033, 1, 8064, 8080)
        slice_33279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33278, 2, 0, 16);  slice_33278 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4033, 1, 8064, 8080)
        slice_scatter_default_4034: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2017, slice_33279, 2, 0, 16);  slice_tensor_2017 = slice_33279 = None
        slice_scatter_default_4035: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4033, slice_scatter_default_4034, 1, 8064, 8080);  slice_scatter_default_4033 = slice_scatter_default_4034 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33299: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33265, 2, 16, 32);  slice_33265 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1012: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33299, memory_format = torch.contiguous_format);  slice_33299 = None
        view_2028: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1012, [32, 11]);  clone_1012 = None
        mm_1009: "f32[32, 8]" = torch.ops.aten.mm.default(view_2028, slice_37)
        view_2029: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1009, [2, 16, 8]);  mm_1009 = None
        slice_33306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4035, 1, 8064, 8080)
        slice_33307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33306, 2, 0, 16);  slice_33306 = None
        add_1011: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33307, view_2029);  slice_33307 = view_2029 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4035, 1, 8064, 8080)
        slice_scatter_default_4036: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2018, add_1011, 2, 0, 16);  slice_tensor_2018 = add_1011 = None
        slice_scatter_default_4037: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4035, slice_scatter_default_4036, 1, 8064, 8080);  slice_scatter_default_4035 = slice_scatter_default_4036 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4037, 1, 8064, 8080)
        slice_33312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33311, 2, 0, 16);  slice_33311 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2019: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4037, 1, 8064, 8080)
        slice_scatter_default_4038: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2019, slice_33312, 2, 0, 16);  slice_tensor_2019 = slice_33312 = None
        slice_scatter_default_4039: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4037, slice_scatter_default_4038, 1, 8064, 8080);  slice_scatter_default_4037 = slice_scatter_default_4038 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33331: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8080, 8096)
        slice_33332: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33331, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1013: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33332, memory_format = torch.contiguous_format);  slice_33332 = None
        view_2030: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1013, [32, 16]);  clone_1013 = None
        mm_1010: "f32[32, 8]" = torch.ops.aten.mm.default(view_2030, slice_7)
        view_2031: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1010, [2, 16, 8]);  mm_1010 = None
        slice_33339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4039, 1, 8080, 8096)
        slice_33340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33339, 2, 0, 16);  slice_33339 = None
        add_1012: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33340, view_2031);  slice_33340 = view_2031 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4039, 1, 8080, 8096)
        slice_scatter_default_4040: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2020, add_1012, 2, 0, 16);  slice_tensor_2020 = add_1012 = None
        slice_scatter_default_4041: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4039, slice_scatter_default_4040, 1, 8080, 8096);  slice_scatter_default_4039 = slice_scatter_default_4040 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4041, 1, 8080, 8096)
        slice_33345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33344, 2, 0, 16);  slice_33344 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4041, 1, 8080, 8096)
        slice_scatter_default_4042: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2021, slice_33345, 2, 0, 16);  slice_tensor_2021 = slice_33345 = None
        slice_scatter_default_4043: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4041, slice_scatter_default_4042, 1, 8080, 8096);  slice_scatter_default_4041 = slice_scatter_default_4042 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33365: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33331, 2, 16, 32);  slice_33331 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1014: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33365, memory_format = torch.contiguous_format);  slice_33365 = None
        view_2032: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1014, [32, 11]);  clone_1014 = None
        mm_1011: "f32[32, 8]" = torch.ops.aten.mm.default(view_2032, slice_37)
        view_2033: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1011, [2, 16, 8]);  mm_1011 = None
        slice_33372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4043, 1, 8080, 8096)
        slice_33373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33372, 2, 0, 16);  slice_33372 = None
        add_1013: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33373, view_2033);  slice_33373 = view_2033 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4043, 1, 8080, 8096)
        slice_scatter_default_4044: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2022, add_1013, 2, 0, 16);  slice_tensor_2022 = add_1013 = None
        slice_scatter_default_4045: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4043, slice_scatter_default_4044, 1, 8080, 8096);  slice_scatter_default_4043 = slice_scatter_default_4044 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4045, 1, 8080, 8096)
        slice_33378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33377, 2, 0, 16);  slice_33377 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4045, 1, 8080, 8096)
        slice_scatter_default_4046: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2023, slice_33378, 2, 0, 16);  slice_tensor_2023 = slice_33378 = None
        slice_scatter_default_4047: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4045, slice_scatter_default_4046, 1, 8080, 8096);  slice_scatter_default_4045 = slice_scatter_default_4046 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33397: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8096, 8112)
        slice_33398: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33397, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1015: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33398, memory_format = torch.contiguous_format);  slice_33398 = None
        view_2034: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1015, [32, 16]);  clone_1015 = None
        mm_1012: "f32[32, 8]" = torch.ops.aten.mm.default(view_2034, slice_7)
        view_2035: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1012, [2, 16, 8]);  mm_1012 = None
        slice_33405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4047, 1, 8096, 8112)
        slice_33406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33405, 2, 0, 16);  slice_33405 = None
        add_1014: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33406, view_2035);  slice_33406 = view_2035 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2024: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4047, 1, 8096, 8112)
        slice_scatter_default_4048: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2024, add_1014, 2, 0, 16);  slice_tensor_2024 = add_1014 = None
        slice_scatter_default_4049: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4047, slice_scatter_default_4048, 1, 8096, 8112);  slice_scatter_default_4047 = slice_scatter_default_4048 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4049, 1, 8096, 8112)
        slice_33411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33410, 2, 0, 16);  slice_33410 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4049, 1, 8096, 8112)
        slice_scatter_default_4050: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2025, slice_33411, 2, 0, 16);  slice_tensor_2025 = slice_33411 = None
        slice_scatter_default_4051: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4049, slice_scatter_default_4050, 1, 8096, 8112);  slice_scatter_default_4049 = slice_scatter_default_4050 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33431: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33397, 2, 16, 32);  slice_33397 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1016: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33431, memory_format = torch.contiguous_format);  slice_33431 = None
        view_2036: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1016, [32, 11]);  clone_1016 = None
        mm_1013: "f32[32, 8]" = torch.ops.aten.mm.default(view_2036, slice_37)
        view_2037: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1013, [2, 16, 8]);  mm_1013 = None
        slice_33438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4051, 1, 8096, 8112)
        slice_33439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33438, 2, 0, 16);  slice_33438 = None
        add_1015: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33439, view_2037);  slice_33439 = view_2037 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4051, 1, 8096, 8112)
        slice_scatter_default_4052: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2026, add_1015, 2, 0, 16);  slice_tensor_2026 = add_1015 = None
        slice_scatter_default_4053: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4051, slice_scatter_default_4052, 1, 8096, 8112);  slice_scatter_default_4051 = slice_scatter_default_4052 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4053, 1, 8096, 8112)
        slice_33444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33443, 2, 0, 16);  slice_33443 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4053, 1, 8096, 8112)
        slice_scatter_default_4054: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2027, slice_33444, 2, 0, 16);  slice_tensor_2027 = slice_33444 = None
        slice_scatter_default_4055: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4053, slice_scatter_default_4054, 1, 8096, 8112);  slice_scatter_default_4053 = slice_scatter_default_4054 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33463: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8112, 8128)
        slice_33464: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33463, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1017: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33464, memory_format = torch.contiguous_format);  slice_33464 = None
        view_2038: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1017, [32, 16]);  clone_1017 = None
        mm_1014: "f32[32, 8]" = torch.ops.aten.mm.default(view_2038, slice_7)
        view_2039: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1014, [2, 16, 8]);  mm_1014 = None
        slice_33471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4055, 1, 8112, 8128)
        slice_33472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33471, 2, 0, 16);  slice_33471 = None
        add_1016: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33472, view_2039);  slice_33472 = view_2039 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4055, 1, 8112, 8128)
        slice_scatter_default_4056: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2028, add_1016, 2, 0, 16);  slice_tensor_2028 = add_1016 = None
        slice_scatter_default_4057: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4055, slice_scatter_default_4056, 1, 8112, 8128);  slice_scatter_default_4055 = slice_scatter_default_4056 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4057, 1, 8112, 8128)
        slice_33477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33476, 2, 0, 16);  slice_33476 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4057, 1, 8112, 8128)
        slice_scatter_default_4058: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2029, slice_33477, 2, 0, 16);  slice_tensor_2029 = slice_33477 = None
        slice_scatter_default_4059: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4057, slice_scatter_default_4058, 1, 8112, 8128);  slice_scatter_default_4057 = slice_scatter_default_4058 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33497: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33463, 2, 16, 32);  slice_33463 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1018: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33497, memory_format = torch.contiguous_format);  slice_33497 = None
        view_2040: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1018, [32, 11]);  clone_1018 = None
        mm_1015: "f32[32, 8]" = torch.ops.aten.mm.default(view_2040, slice_37)
        view_2041: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1015, [2, 16, 8]);  mm_1015 = None
        slice_33504: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4059, 1, 8112, 8128)
        slice_33505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33504, 2, 0, 16);  slice_33504 = None
        add_1017: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33505, view_2041);  slice_33505 = view_2041 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4059, 1, 8112, 8128)
        slice_scatter_default_4060: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2030, add_1017, 2, 0, 16);  slice_tensor_2030 = add_1017 = None
        slice_scatter_default_4061: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4059, slice_scatter_default_4060, 1, 8112, 8128);  slice_scatter_default_4059 = slice_scatter_default_4060 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33509: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4061, 1, 8112, 8128)
        slice_33510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33509, 2, 0, 16);  slice_33509 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4061, 1, 8112, 8128)
        slice_scatter_default_4062: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2031, slice_33510, 2, 0, 16);  slice_tensor_2031 = slice_33510 = None
        slice_scatter_default_4063: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4061, slice_scatter_default_4062, 1, 8112, 8128);  slice_scatter_default_4061 = slice_scatter_default_4062 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33529: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8128, 8144)
        slice_33530: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33529, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1019: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33530, memory_format = torch.contiguous_format);  slice_33530 = None
        view_2042: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1019, [32, 16]);  clone_1019 = None
        mm_1016: "f32[32, 8]" = torch.ops.aten.mm.default(view_2042, slice_7)
        view_2043: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1016, [2, 16, 8]);  mm_1016 = None
        slice_33537: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4063, 1, 8128, 8144)
        slice_33538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33537, 2, 0, 16);  slice_33537 = None
        add_1018: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33538, view_2043);  slice_33538 = view_2043 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4063, 1, 8128, 8144)
        slice_scatter_default_4064: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2032, add_1018, 2, 0, 16);  slice_tensor_2032 = add_1018 = None
        slice_scatter_default_4065: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4063, slice_scatter_default_4064, 1, 8128, 8144);  slice_scatter_default_4063 = slice_scatter_default_4064 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33542: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4065, 1, 8128, 8144)
        slice_33543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33542, 2, 0, 16);  slice_33542 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4065, 1, 8128, 8144)
        slice_scatter_default_4066: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2033, slice_33543, 2, 0, 16);  slice_tensor_2033 = slice_33543 = None
        slice_scatter_default_4067: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4065, slice_scatter_default_4066, 1, 8128, 8144);  slice_scatter_default_4065 = slice_scatter_default_4066 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33563: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33529, 2, 16, 32);  slice_33529 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1020: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33563, memory_format = torch.contiguous_format);  slice_33563 = None
        view_2044: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1020, [32, 11]);  clone_1020 = None
        mm_1017: "f32[32, 8]" = torch.ops.aten.mm.default(view_2044, slice_37)
        view_2045: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1017, [2, 16, 8]);  mm_1017 = None
        slice_33570: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4067, 1, 8128, 8144)
        slice_33571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33570, 2, 0, 16);  slice_33570 = None
        add_1019: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33571, view_2045);  slice_33571 = view_2045 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4067, 1, 8128, 8144)
        slice_scatter_default_4068: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2034, add_1019, 2, 0, 16);  slice_tensor_2034 = add_1019 = None
        slice_scatter_default_4069: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4067, slice_scatter_default_4068, 1, 8128, 8144);  slice_scatter_default_4067 = slice_scatter_default_4068 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33575: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4069, 1, 8128, 8144)
        slice_33576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33575, 2, 0, 16);  slice_33575 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4069, 1, 8128, 8144)
        slice_scatter_default_4070: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2035, slice_33576, 2, 0, 16);  slice_tensor_2035 = slice_33576 = None
        slice_scatter_default_4071: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4069, slice_scatter_default_4070, 1, 8128, 8144);  slice_scatter_default_4069 = slice_scatter_default_4070 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33595: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8144, 8160)
        slice_33596: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33595, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1021: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33596, memory_format = torch.contiguous_format);  slice_33596 = None
        view_2046: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1021, [32, 16]);  clone_1021 = None
        mm_1018: "f32[32, 8]" = torch.ops.aten.mm.default(view_2046, slice_7)
        view_2047: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1018, [2, 16, 8]);  mm_1018 = None
        slice_33603: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4071, 1, 8144, 8160)
        slice_33604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33603, 2, 0, 16);  slice_33603 = None
        add_1020: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33604, view_2047);  slice_33604 = view_2047 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4071, 1, 8144, 8160)
        slice_scatter_default_4072: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2036, add_1020, 2, 0, 16);  slice_tensor_2036 = add_1020 = None
        slice_scatter_default_4073: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4071, slice_scatter_default_4072, 1, 8144, 8160);  slice_scatter_default_4071 = slice_scatter_default_4072 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33608: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4073, 1, 8144, 8160)
        slice_33609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33608, 2, 0, 16);  slice_33608 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4073, 1, 8144, 8160)
        slice_scatter_default_4074: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2037, slice_33609, 2, 0, 16);  slice_tensor_2037 = slice_33609 = None
        slice_scatter_default_4075: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4073, slice_scatter_default_4074, 1, 8144, 8160);  slice_scatter_default_4073 = slice_scatter_default_4074 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33629: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33595, 2, 16, 32);  slice_33595 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1022: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33629, memory_format = torch.contiguous_format);  slice_33629 = None
        view_2048: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1022, [32, 11]);  clone_1022 = None
        mm_1019: "f32[32, 8]" = torch.ops.aten.mm.default(view_2048, slice_37)
        view_2049: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1019, [2, 16, 8]);  mm_1019 = None
        slice_33636: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4075, 1, 8144, 8160)
        slice_33637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33636, 2, 0, 16);  slice_33636 = None
        add_1021: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33637, view_2049);  slice_33637 = view_2049 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4075, 1, 8144, 8160)
        slice_scatter_default_4076: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2038, add_1021, 2, 0, 16);  slice_tensor_2038 = add_1021 = None
        slice_scatter_default_4077: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4075, slice_scatter_default_4076, 1, 8144, 8160);  slice_scatter_default_4075 = slice_scatter_default_4076 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33641: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4077, 1, 8144, 8160)
        slice_33642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33641, 2, 0, 16);  slice_33641 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4077, 1, 8144, 8160)
        slice_scatter_default_4078: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2039, slice_33642, 2, 0, 16);  slice_tensor_2039 = slice_33642 = None
        slice_scatter_default_4079: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4077, slice_scatter_default_4078, 1, 8144, 8160);  slice_scatter_default_4077 = slice_scatter_default_4078 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33661: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8160, 8176)
        slice_33662: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33661, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1023: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33662, memory_format = torch.contiguous_format);  slice_33662 = None
        view_2050: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1023, [32, 16]);  clone_1023 = None
        mm_1020: "f32[32, 8]" = torch.ops.aten.mm.default(view_2050, slice_7)
        view_2051: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1020, [2, 16, 8]);  mm_1020 = None
        slice_33669: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4079, 1, 8160, 8176)
        slice_33670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33669, 2, 0, 16);  slice_33669 = None
        add_1022: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33670, view_2051);  slice_33670 = view_2051 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4079, 1, 8160, 8176)
        slice_scatter_default_4080: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2040, add_1022, 2, 0, 16);  slice_tensor_2040 = add_1022 = None
        slice_scatter_default_4081: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4079, slice_scatter_default_4080, 1, 8160, 8176);  slice_scatter_default_4079 = slice_scatter_default_4080 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33674: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4081, 1, 8160, 8176)
        slice_33675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33674, 2, 0, 16);  slice_33674 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4081, 1, 8160, 8176)
        slice_scatter_default_4082: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2041, slice_33675, 2, 0, 16);  slice_tensor_2041 = slice_33675 = None
        slice_scatter_default_4083: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4081, slice_scatter_default_4082, 1, 8160, 8176);  slice_scatter_default_4081 = slice_scatter_default_4082 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33695: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33661, 2, 16, 32);  slice_33661 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1024: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33695, memory_format = torch.contiguous_format);  slice_33695 = None
        view_2052: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1024, [32, 11]);  clone_1024 = None
        mm_1021: "f32[32, 8]" = torch.ops.aten.mm.default(view_2052, slice_37)
        view_2053: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1021, [2, 16, 8]);  mm_1021 = None
        slice_33702: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4083, 1, 8160, 8176)
        slice_33703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33702, 2, 0, 16);  slice_33702 = None
        add_1023: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33703, view_2053);  slice_33703 = view_2053 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2042: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4083, 1, 8160, 8176)
        slice_scatter_default_4084: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2042, add_1023, 2, 0, 16);  slice_tensor_2042 = add_1023 = None
        slice_scatter_default_4085: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4083, slice_scatter_default_4084, 1, 8160, 8176);  slice_scatter_default_4083 = slice_scatter_default_4084 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33707: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4085, 1, 8160, 8176)
        slice_33708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33707, 2, 0, 16);  slice_33707 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4085, 1, 8160, 8176)
        slice_scatter_default_4086: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2043, slice_33708, 2, 0, 16);  slice_tensor_2043 = slice_33708 = None
        slice_scatter_default_4087: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4085, slice_scatter_default_4086, 1, 8160, 8176);  slice_scatter_default_4085 = slice_scatter_default_4086 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33727: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8176, 8192)
        slice_33728: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33727, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1025: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33728, memory_format = torch.contiguous_format);  slice_33728 = None
        view_2054: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1025, [32, 16]);  clone_1025 = None
        mm_1022: "f32[32, 8]" = torch.ops.aten.mm.default(view_2054, slice_7)
        view_2055: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1022, [2, 16, 8]);  mm_1022 = None
        slice_33735: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4087, 1, 8176, 8192)
        slice_33736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33735, 2, 0, 16);  slice_33735 = None
        add_1024: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33736, view_2055);  slice_33736 = view_2055 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4087, 1, 8176, 8192)
        slice_scatter_default_4088: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2044, add_1024, 2, 0, 16);  slice_tensor_2044 = add_1024 = None
        slice_scatter_default_4089: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4087, slice_scatter_default_4088, 1, 8176, 8192);  slice_scatter_default_4087 = slice_scatter_default_4088 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33740: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4089, 1, 8176, 8192)
        slice_33741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33740, 2, 0, 16);  slice_33740 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4089, 1, 8176, 8192)
        slice_scatter_default_4090: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2045, slice_33741, 2, 0, 16);  slice_tensor_2045 = slice_33741 = None
        slice_scatter_default_4091: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4089, slice_scatter_default_4090, 1, 8176, 8192);  slice_scatter_default_4089 = slice_scatter_default_4090 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33761: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33727, 2, 16, 32);  slice_33727 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1026: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33761, memory_format = torch.contiguous_format);  slice_33761 = None
        view_2056: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1026, [32, 11]);  clone_1026 = None
        mm_1023: "f32[32, 8]" = torch.ops.aten.mm.default(view_2056, slice_37)
        view_2057: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1023, [2, 16, 8]);  mm_1023 = None
        slice_33768: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4091, 1, 8176, 8192)
        slice_33769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33768, 2, 0, 16);  slice_33768 = None
        add_1025: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33769, view_2057);  slice_33769 = view_2057 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4091, 1, 8176, 8192)
        slice_scatter_default_4092: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2046, add_1025, 2, 0, 16);  slice_tensor_2046 = add_1025 = None
        slice_scatter_default_4093: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4091, slice_scatter_default_4092, 1, 8176, 8192);  slice_scatter_default_4091 = slice_scatter_default_4092 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33773: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4093, 1, 8176, 8192)
        slice_33774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33773, 2, 0, 16);  slice_33773 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2047: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4093, 1, 8176, 8192)
        slice_scatter_default_4094: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2047, slice_33774, 2, 0, 16);  slice_tensor_2047 = slice_33774 = None
        slice_scatter_default_4095: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4093, slice_scatter_default_4094, 1, 8176, 8192);  slice_scatter_default_4093 = slice_scatter_default_4094 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33793: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8192, 8208)
        slice_33794: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33793, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1027: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33794, memory_format = torch.contiguous_format);  slice_33794 = None
        view_2058: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1027, [32, 16]);  clone_1027 = None
        mm_1024: "f32[32, 8]" = torch.ops.aten.mm.default(view_2058, slice_7)
        view_2059: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1024, [2, 16, 8]);  mm_1024 = None
        slice_33801: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4095, 1, 8192, 8208)
        slice_33802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33801, 2, 0, 16);  slice_33801 = None
        add_1026: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33802, view_2059);  slice_33802 = view_2059 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4095, 1, 8192, 8208)
        slice_scatter_default_4096: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2048, add_1026, 2, 0, 16);  slice_tensor_2048 = add_1026 = None
        slice_scatter_default_4097: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4095, slice_scatter_default_4096, 1, 8192, 8208);  slice_scatter_default_4095 = slice_scatter_default_4096 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33806: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4097, 1, 8192, 8208)
        slice_33807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33806, 2, 0, 16);  slice_33806 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4097, 1, 8192, 8208)
        slice_scatter_default_4098: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2049, slice_33807, 2, 0, 16);  slice_tensor_2049 = slice_33807 = None
        slice_scatter_default_4099: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4097, slice_scatter_default_4098, 1, 8192, 8208);  slice_scatter_default_4097 = slice_scatter_default_4098 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33827: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33793, 2, 16, 32);  slice_33793 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1028: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33827, memory_format = torch.contiguous_format);  slice_33827 = None
        view_2060: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1028, [32, 11]);  clone_1028 = None
        mm_1025: "f32[32, 8]" = torch.ops.aten.mm.default(view_2060, slice_37)
        view_2061: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1025, [2, 16, 8]);  mm_1025 = None
        slice_33834: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4099, 1, 8192, 8208)
        slice_33835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33834, 2, 0, 16);  slice_33834 = None
        add_1027: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33835, view_2061);  slice_33835 = view_2061 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4099, 1, 8192, 8208)
        slice_scatter_default_4100: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2050, add_1027, 2, 0, 16);  slice_tensor_2050 = add_1027 = None
        slice_scatter_default_4101: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4099, slice_scatter_default_4100, 1, 8192, 8208);  slice_scatter_default_4099 = slice_scatter_default_4100 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33839: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4101, 1, 8192, 8208)
        slice_33840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33839, 2, 0, 16);  slice_33839 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4101, 1, 8192, 8208)
        slice_scatter_default_4102: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2051, slice_33840, 2, 0, 16);  slice_tensor_2051 = slice_33840 = None
        slice_scatter_default_4103: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4101, slice_scatter_default_4102, 1, 8192, 8208);  slice_scatter_default_4101 = slice_scatter_default_4102 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33859: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8208, 8224)
        slice_33860: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33859, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1029: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33860, memory_format = torch.contiguous_format);  slice_33860 = None
        view_2062: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1029, [32, 16]);  clone_1029 = None
        mm_1026: "f32[32, 8]" = torch.ops.aten.mm.default(view_2062, slice_7)
        view_2063: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1026, [2, 16, 8]);  mm_1026 = None
        slice_33867: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4103, 1, 8208, 8224)
        slice_33868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33867, 2, 0, 16);  slice_33867 = None
        add_1028: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33868, view_2063);  slice_33868 = view_2063 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2052: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4103, 1, 8208, 8224)
        slice_scatter_default_4104: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2052, add_1028, 2, 0, 16);  slice_tensor_2052 = add_1028 = None
        slice_scatter_default_4105: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4103, slice_scatter_default_4104, 1, 8208, 8224);  slice_scatter_default_4103 = slice_scatter_default_4104 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33872: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4105, 1, 8208, 8224)
        slice_33873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33872, 2, 0, 16);  slice_33872 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4105, 1, 8208, 8224)
        slice_scatter_default_4106: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2053, slice_33873, 2, 0, 16);  slice_tensor_2053 = slice_33873 = None
        slice_scatter_default_4107: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4105, slice_scatter_default_4106, 1, 8208, 8224);  slice_scatter_default_4105 = slice_scatter_default_4106 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33893: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33859, 2, 16, 32);  slice_33859 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1030: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33893, memory_format = torch.contiguous_format);  slice_33893 = None
        view_2064: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1030, [32, 11]);  clone_1030 = None
        mm_1027: "f32[32, 8]" = torch.ops.aten.mm.default(view_2064, slice_37)
        view_2065: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1027, [2, 16, 8]);  mm_1027 = None
        slice_33900: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4107, 1, 8208, 8224)
        slice_33901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33900, 2, 0, 16);  slice_33900 = None
        add_1029: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33901, view_2065);  slice_33901 = view_2065 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4107, 1, 8208, 8224)
        slice_scatter_default_4108: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2054, add_1029, 2, 0, 16);  slice_tensor_2054 = add_1029 = None
        slice_scatter_default_4109: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4107, slice_scatter_default_4108, 1, 8208, 8224);  slice_scatter_default_4107 = slice_scatter_default_4108 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33905: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4109, 1, 8208, 8224)
        slice_33906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33905, 2, 0, 16);  slice_33905 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4109, 1, 8208, 8224)
        slice_scatter_default_4110: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2055, slice_33906, 2, 0, 16);  slice_tensor_2055 = slice_33906 = None
        slice_scatter_default_4111: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4109, slice_scatter_default_4110, 1, 8208, 8224);  slice_scatter_default_4109 = slice_scatter_default_4110 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33925: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8224, 8240)
        slice_33926: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33925, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1031: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33926, memory_format = torch.contiguous_format);  slice_33926 = None
        view_2066: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1031, [32, 16]);  clone_1031 = None
        mm_1028: "f32[32, 8]" = torch.ops.aten.mm.default(view_2066, slice_7)
        view_2067: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1028, [2, 16, 8]);  mm_1028 = None
        slice_33933: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4111, 1, 8224, 8240)
        slice_33934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33933, 2, 0, 16);  slice_33933 = None
        add_1030: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33934, view_2067);  slice_33934 = view_2067 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4111, 1, 8224, 8240)
        slice_scatter_default_4112: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2056, add_1030, 2, 0, 16);  slice_tensor_2056 = add_1030 = None
        slice_scatter_default_4113: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4111, slice_scatter_default_4112, 1, 8224, 8240);  slice_scatter_default_4111 = slice_scatter_default_4112 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33938: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4113, 1, 8224, 8240)
        slice_33939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33938, 2, 0, 16);  slice_33938 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2057: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4113, 1, 8224, 8240)
        slice_scatter_default_4114: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2057, slice_33939, 2, 0, 16);  slice_tensor_2057 = slice_33939 = None
        slice_scatter_default_4115: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4113, slice_scatter_default_4114, 1, 8224, 8240);  slice_scatter_default_4113 = slice_scatter_default_4114 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33959: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33925, 2, 16, 32);  slice_33925 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1032: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_33959, memory_format = torch.contiguous_format);  slice_33959 = None
        view_2068: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1032, [32, 11]);  clone_1032 = None
        mm_1029: "f32[32, 8]" = torch.ops.aten.mm.default(view_2068, slice_37)
        view_2069: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1029, [2, 16, 8]);  mm_1029 = None
        slice_33966: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4115, 1, 8224, 8240)
        slice_33967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33966, 2, 0, 16);  slice_33966 = None
        add_1031: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_33967, view_2069);  slice_33967 = view_2069 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4115, 1, 8224, 8240)
        slice_scatter_default_4116: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2058, add_1031, 2, 0, 16);  slice_tensor_2058 = add_1031 = None
        slice_scatter_default_4117: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4115, slice_scatter_default_4116, 1, 8224, 8240);  slice_scatter_default_4115 = slice_scatter_default_4116 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_33971: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4117, 1, 8224, 8240)
        slice_33972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33971, 2, 0, 16);  slice_33971 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4117, 1, 8224, 8240)
        slice_scatter_default_4118: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2059, slice_33972, 2, 0, 16);  slice_tensor_2059 = slice_33972 = None
        slice_scatter_default_4119: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4117, slice_scatter_default_4118, 1, 8224, 8240);  slice_scatter_default_4117 = slice_scatter_default_4118 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_33991: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8240, 8256)
        slice_33992: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_33991, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1033: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_33992, memory_format = torch.contiguous_format);  slice_33992 = None
        view_2070: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1033, [32, 16]);  clone_1033 = None
        mm_1030: "f32[32, 8]" = torch.ops.aten.mm.default(view_2070, slice_7)
        view_2071: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1030, [2, 16, 8]);  mm_1030 = None
        slice_33999: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4119, 1, 8240, 8256)
        slice_34000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_33999, 2, 0, 16);  slice_33999 = None
        add_1032: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34000, view_2071);  slice_34000 = view_2071 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4119, 1, 8240, 8256)
        slice_scatter_default_4120: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2060, add_1032, 2, 0, 16);  slice_tensor_2060 = add_1032 = None
        slice_scatter_default_4121: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4119, slice_scatter_default_4120, 1, 8240, 8256);  slice_scatter_default_4119 = slice_scatter_default_4120 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34004: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4121, 1, 8240, 8256)
        slice_34005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34004, 2, 0, 16);  slice_34004 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4121, 1, 8240, 8256)
        slice_scatter_default_4122: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2061, slice_34005, 2, 0, 16);  slice_tensor_2061 = slice_34005 = None
        slice_scatter_default_4123: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4121, slice_scatter_default_4122, 1, 8240, 8256);  slice_scatter_default_4121 = slice_scatter_default_4122 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34025: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_33991, 2, 16, 32);  slice_33991 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1034: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34025, memory_format = torch.contiguous_format);  slice_34025 = None
        view_2072: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1034, [32, 11]);  clone_1034 = None
        mm_1031: "f32[32, 8]" = torch.ops.aten.mm.default(view_2072, slice_37)
        view_2073: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1031, [2, 16, 8]);  mm_1031 = None
        slice_34032: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4123, 1, 8240, 8256)
        slice_34033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34032, 2, 0, 16);  slice_34032 = None
        add_1033: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34033, view_2073);  slice_34033 = view_2073 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4123, 1, 8240, 8256)
        slice_scatter_default_4124: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2062, add_1033, 2, 0, 16);  slice_tensor_2062 = add_1033 = None
        slice_scatter_default_4125: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4123, slice_scatter_default_4124, 1, 8240, 8256);  slice_scatter_default_4123 = slice_scatter_default_4124 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34037: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4125, 1, 8240, 8256)
        slice_34038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34037, 2, 0, 16);  slice_34037 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4125, 1, 8240, 8256)
        slice_scatter_default_4126: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2063, slice_34038, 2, 0, 16);  slice_tensor_2063 = slice_34038 = None
        slice_scatter_default_4127: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4125, slice_scatter_default_4126, 1, 8240, 8256);  slice_scatter_default_4125 = slice_scatter_default_4126 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34057: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8256, 8272)
        slice_34058: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34057, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1035: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34058, memory_format = torch.contiguous_format);  slice_34058 = None
        view_2074: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1035, [32, 16]);  clone_1035 = None
        mm_1032: "f32[32, 8]" = torch.ops.aten.mm.default(view_2074, slice_7)
        view_2075: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1032, [2, 16, 8]);  mm_1032 = None
        slice_34065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4127, 1, 8256, 8272)
        slice_34066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34065, 2, 0, 16);  slice_34065 = None
        add_1034: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34066, view_2075);  slice_34066 = view_2075 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4127, 1, 8256, 8272)
        slice_scatter_default_4128: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2064, add_1034, 2, 0, 16);  slice_tensor_2064 = add_1034 = None
        slice_scatter_default_4129: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4127, slice_scatter_default_4128, 1, 8256, 8272);  slice_scatter_default_4127 = slice_scatter_default_4128 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4129, 1, 8256, 8272)
        slice_34071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34070, 2, 0, 16);  slice_34070 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2065: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4129, 1, 8256, 8272)
        slice_scatter_default_4130: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2065, slice_34071, 2, 0, 16);  slice_tensor_2065 = slice_34071 = None
        slice_scatter_default_4131: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4129, slice_scatter_default_4130, 1, 8256, 8272);  slice_scatter_default_4129 = slice_scatter_default_4130 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34091: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34057, 2, 16, 32);  slice_34057 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1036: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34091, memory_format = torch.contiguous_format);  slice_34091 = None
        view_2076: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1036, [32, 11]);  clone_1036 = None
        mm_1033: "f32[32, 8]" = torch.ops.aten.mm.default(view_2076, slice_37)
        view_2077: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1033, [2, 16, 8]);  mm_1033 = None
        slice_34098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4131, 1, 8256, 8272)
        slice_34099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34098, 2, 0, 16);  slice_34098 = None
        add_1035: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34099, view_2077);  slice_34099 = view_2077 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4131, 1, 8256, 8272)
        slice_scatter_default_4132: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2066, add_1035, 2, 0, 16);  slice_tensor_2066 = add_1035 = None
        slice_scatter_default_4133: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4131, slice_scatter_default_4132, 1, 8256, 8272);  slice_scatter_default_4131 = slice_scatter_default_4132 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4133, 1, 8256, 8272)
        slice_34104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34103, 2, 0, 16);  slice_34103 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4133, 1, 8256, 8272)
        slice_scatter_default_4134: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2067, slice_34104, 2, 0, 16);  slice_tensor_2067 = slice_34104 = None
        slice_scatter_default_4135: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4133, slice_scatter_default_4134, 1, 8256, 8272);  slice_scatter_default_4133 = slice_scatter_default_4134 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34123: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8272, 8288)
        slice_34124: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34123, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1037: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34124, memory_format = torch.contiguous_format);  slice_34124 = None
        view_2078: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1037, [32, 16]);  clone_1037 = None
        mm_1034: "f32[32, 8]" = torch.ops.aten.mm.default(view_2078, slice_7)
        view_2079: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1034, [2, 16, 8]);  mm_1034 = None
        slice_34131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4135, 1, 8272, 8288)
        slice_34132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34131, 2, 0, 16);  slice_34131 = None
        add_1036: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34132, view_2079);  slice_34132 = view_2079 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4135, 1, 8272, 8288)
        slice_scatter_default_4136: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2068, add_1036, 2, 0, 16);  slice_tensor_2068 = add_1036 = None
        slice_scatter_default_4137: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4135, slice_scatter_default_4136, 1, 8272, 8288);  slice_scatter_default_4135 = slice_scatter_default_4136 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4137, 1, 8272, 8288)
        slice_34137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34136, 2, 0, 16);  slice_34136 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4137, 1, 8272, 8288)
        slice_scatter_default_4138: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2069, slice_34137, 2, 0, 16);  slice_tensor_2069 = slice_34137 = None
        slice_scatter_default_4139: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4137, slice_scatter_default_4138, 1, 8272, 8288);  slice_scatter_default_4137 = slice_scatter_default_4138 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34157: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34123, 2, 16, 32);  slice_34123 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1038: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34157, memory_format = torch.contiguous_format);  slice_34157 = None
        view_2080: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1038, [32, 11]);  clone_1038 = None
        mm_1035: "f32[32, 8]" = torch.ops.aten.mm.default(view_2080, slice_37)
        view_2081: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1035, [2, 16, 8]);  mm_1035 = None
        slice_34164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4139, 1, 8272, 8288)
        slice_34165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34164, 2, 0, 16);  slice_34164 = None
        add_1037: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34165, view_2081);  slice_34165 = view_2081 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2070: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4139, 1, 8272, 8288)
        slice_scatter_default_4140: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2070, add_1037, 2, 0, 16);  slice_tensor_2070 = add_1037 = None
        slice_scatter_default_4141: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4139, slice_scatter_default_4140, 1, 8272, 8288);  slice_scatter_default_4139 = slice_scatter_default_4140 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4141, 1, 8272, 8288)
        slice_34170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34169, 2, 0, 16);  slice_34169 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4141, 1, 8272, 8288)
        slice_scatter_default_4142: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2071, slice_34170, 2, 0, 16);  slice_tensor_2071 = slice_34170 = None
        slice_scatter_default_4143: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4141, slice_scatter_default_4142, 1, 8272, 8288);  slice_scatter_default_4141 = slice_scatter_default_4142 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34189: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8288, 8304)
        slice_34190: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34189, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1039: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34190, memory_format = torch.contiguous_format);  slice_34190 = None
        view_2082: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1039, [32, 16]);  clone_1039 = None
        mm_1036: "f32[32, 8]" = torch.ops.aten.mm.default(view_2082, slice_7)
        view_2083: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1036, [2, 16, 8]);  mm_1036 = None
        slice_34197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4143, 1, 8288, 8304)
        slice_34198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34197, 2, 0, 16);  slice_34197 = None
        add_1038: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34198, view_2083);  slice_34198 = view_2083 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4143, 1, 8288, 8304)
        slice_scatter_default_4144: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2072, add_1038, 2, 0, 16);  slice_tensor_2072 = add_1038 = None
        slice_scatter_default_4145: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4143, slice_scatter_default_4144, 1, 8288, 8304);  slice_scatter_default_4143 = slice_scatter_default_4144 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4145, 1, 8288, 8304)
        slice_34203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34202, 2, 0, 16);  slice_34202 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4145, 1, 8288, 8304)
        slice_scatter_default_4146: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2073, slice_34203, 2, 0, 16);  slice_tensor_2073 = slice_34203 = None
        slice_scatter_default_4147: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4145, slice_scatter_default_4146, 1, 8288, 8304);  slice_scatter_default_4145 = slice_scatter_default_4146 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34223: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34189, 2, 16, 32);  slice_34189 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1040: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34223, memory_format = torch.contiguous_format);  slice_34223 = None
        view_2084: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1040, [32, 11]);  clone_1040 = None
        mm_1037: "f32[32, 8]" = torch.ops.aten.mm.default(view_2084, slice_37)
        view_2085: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1037, [2, 16, 8]);  mm_1037 = None
        slice_34230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4147, 1, 8288, 8304)
        slice_34231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34230, 2, 0, 16);  slice_34230 = None
        add_1039: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34231, view_2085);  slice_34231 = view_2085 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4147, 1, 8288, 8304)
        slice_scatter_default_4148: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2074, add_1039, 2, 0, 16);  slice_tensor_2074 = add_1039 = None
        slice_scatter_default_4149: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4147, slice_scatter_default_4148, 1, 8288, 8304);  slice_scatter_default_4147 = slice_scatter_default_4148 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4149, 1, 8288, 8304)
        slice_34236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34235, 2, 0, 16);  slice_34235 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2075: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4149, 1, 8288, 8304)
        slice_scatter_default_4150: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2075, slice_34236, 2, 0, 16);  slice_tensor_2075 = slice_34236 = None
        slice_scatter_default_4151: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4149, slice_scatter_default_4150, 1, 8288, 8304);  slice_scatter_default_4149 = slice_scatter_default_4150 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34255: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8304, 8320)
        slice_34256: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34255, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1041: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34256, memory_format = torch.contiguous_format);  slice_34256 = None
        view_2086: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1041, [32, 16]);  clone_1041 = None
        mm_1038: "f32[32, 8]" = torch.ops.aten.mm.default(view_2086, slice_7)
        view_2087: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1038, [2, 16, 8]);  mm_1038 = None
        slice_34263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4151, 1, 8304, 8320)
        slice_34264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34263, 2, 0, 16);  slice_34263 = None
        add_1040: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34264, view_2087);  slice_34264 = view_2087 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4151, 1, 8304, 8320)
        slice_scatter_default_4152: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2076, add_1040, 2, 0, 16);  slice_tensor_2076 = add_1040 = None
        slice_scatter_default_4153: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4151, slice_scatter_default_4152, 1, 8304, 8320);  slice_scatter_default_4151 = slice_scatter_default_4152 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4153, 1, 8304, 8320)
        slice_34269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34268, 2, 0, 16);  slice_34268 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4153, 1, 8304, 8320)
        slice_scatter_default_4154: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2077, slice_34269, 2, 0, 16);  slice_tensor_2077 = slice_34269 = None
        slice_scatter_default_4155: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4153, slice_scatter_default_4154, 1, 8304, 8320);  slice_scatter_default_4153 = slice_scatter_default_4154 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34289: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34255, 2, 16, 32);  slice_34255 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1042: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34289, memory_format = torch.contiguous_format);  slice_34289 = None
        view_2088: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1042, [32, 11]);  clone_1042 = None
        mm_1039: "f32[32, 8]" = torch.ops.aten.mm.default(view_2088, slice_37)
        view_2089: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1039, [2, 16, 8]);  mm_1039 = None
        slice_34296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4155, 1, 8304, 8320)
        slice_34297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34296, 2, 0, 16);  slice_34296 = None
        add_1041: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34297, view_2089);  slice_34297 = view_2089 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4155, 1, 8304, 8320)
        slice_scatter_default_4156: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2078, add_1041, 2, 0, 16);  slice_tensor_2078 = add_1041 = None
        slice_scatter_default_4157: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4155, slice_scatter_default_4156, 1, 8304, 8320);  slice_scatter_default_4155 = slice_scatter_default_4156 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4157, 1, 8304, 8320)
        slice_34302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34301, 2, 0, 16);  slice_34301 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4157, 1, 8304, 8320)
        slice_scatter_default_4158: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2079, slice_34302, 2, 0, 16);  slice_tensor_2079 = slice_34302 = None
        slice_scatter_default_4159: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4157, slice_scatter_default_4158, 1, 8304, 8320);  slice_scatter_default_4157 = slice_scatter_default_4158 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34321: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8320, 8336)
        slice_34322: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34321, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1043: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34322, memory_format = torch.contiguous_format);  slice_34322 = None
        view_2090: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1043, [32, 16]);  clone_1043 = None
        mm_1040: "f32[32, 8]" = torch.ops.aten.mm.default(view_2090, slice_7)
        view_2091: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1040, [2, 16, 8]);  mm_1040 = None
        slice_34329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4159, 1, 8320, 8336)
        slice_34330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34329, 2, 0, 16);  slice_34329 = None
        add_1042: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34330, view_2091);  slice_34330 = view_2091 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2080: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4159, 1, 8320, 8336)
        slice_scatter_default_4160: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2080, add_1042, 2, 0, 16);  slice_tensor_2080 = add_1042 = None
        slice_scatter_default_4161: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4159, slice_scatter_default_4160, 1, 8320, 8336);  slice_scatter_default_4159 = slice_scatter_default_4160 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4161, 1, 8320, 8336)
        slice_34335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34334, 2, 0, 16);  slice_34334 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4161, 1, 8320, 8336)
        slice_scatter_default_4162: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2081, slice_34335, 2, 0, 16);  slice_tensor_2081 = slice_34335 = None
        slice_scatter_default_4163: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4161, slice_scatter_default_4162, 1, 8320, 8336);  slice_scatter_default_4161 = slice_scatter_default_4162 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34355: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34321, 2, 16, 32);  slice_34321 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1044: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34355, memory_format = torch.contiguous_format);  slice_34355 = None
        view_2092: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1044, [32, 11]);  clone_1044 = None
        mm_1041: "f32[32, 8]" = torch.ops.aten.mm.default(view_2092, slice_37)
        view_2093: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1041, [2, 16, 8]);  mm_1041 = None
        slice_34362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4163, 1, 8320, 8336)
        slice_34363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34362, 2, 0, 16);  slice_34362 = None
        add_1043: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34363, view_2093);  slice_34363 = view_2093 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4163, 1, 8320, 8336)
        slice_scatter_default_4164: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2082, add_1043, 2, 0, 16);  slice_tensor_2082 = add_1043 = None
        slice_scatter_default_4165: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4163, slice_scatter_default_4164, 1, 8320, 8336);  slice_scatter_default_4163 = slice_scatter_default_4164 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4165, 1, 8320, 8336)
        slice_34368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34367, 2, 0, 16);  slice_34367 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4165, 1, 8320, 8336)
        slice_scatter_default_4166: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2083, slice_34368, 2, 0, 16);  slice_tensor_2083 = slice_34368 = None
        slice_scatter_default_4167: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4165, slice_scatter_default_4166, 1, 8320, 8336);  slice_scatter_default_4165 = slice_scatter_default_4166 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34387: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8336, 8352)
        slice_34388: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34387, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1045: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34388, memory_format = torch.contiguous_format);  slice_34388 = None
        view_2094: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1045, [32, 16]);  clone_1045 = None
        mm_1042: "f32[32, 8]" = torch.ops.aten.mm.default(view_2094, slice_7)
        view_2095: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1042, [2, 16, 8]);  mm_1042 = None
        slice_34395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4167, 1, 8336, 8352)
        slice_34396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34395, 2, 0, 16);  slice_34395 = None
        add_1044: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34396, view_2095);  slice_34396 = view_2095 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4167, 1, 8336, 8352)
        slice_scatter_default_4168: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2084, add_1044, 2, 0, 16);  slice_tensor_2084 = add_1044 = None
        slice_scatter_default_4169: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4167, slice_scatter_default_4168, 1, 8336, 8352);  slice_scatter_default_4167 = slice_scatter_default_4168 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4169, 1, 8336, 8352)
        slice_34401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34400, 2, 0, 16);  slice_34400 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2085: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4169, 1, 8336, 8352)
        slice_scatter_default_4170: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2085, slice_34401, 2, 0, 16);  slice_tensor_2085 = slice_34401 = None
        slice_scatter_default_4171: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4169, slice_scatter_default_4170, 1, 8336, 8352);  slice_scatter_default_4169 = slice_scatter_default_4170 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34421: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34387, 2, 16, 32);  slice_34387 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1046: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34421, memory_format = torch.contiguous_format);  slice_34421 = None
        view_2096: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1046, [32, 11]);  clone_1046 = None
        mm_1043: "f32[32, 8]" = torch.ops.aten.mm.default(view_2096, slice_37)
        view_2097: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1043, [2, 16, 8]);  mm_1043 = None
        slice_34428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4171, 1, 8336, 8352)
        slice_34429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34428, 2, 0, 16);  slice_34428 = None
        add_1045: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34429, view_2097);  slice_34429 = view_2097 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4171, 1, 8336, 8352)
        slice_scatter_default_4172: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2086, add_1045, 2, 0, 16);  slice_tensor_2086 = add_1045 = None
        slice_scatter_default_4173: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4171, slice_scatter_default_4172, 1, 8336, 8352);  slice_scatter_default_4171 = slice_scatter_default_4172 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4173, 1, 8336, 8352)
        slice_34434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34433, 2, 0, 16);  slice_34433 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4173, 1, 8336, 8352)
        slice_scatter_default_4174: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2087, slice_34434, 2, 0, 16);  slice_tensor_2087 = slice_34434 = None
        slice_scatter_default_4175: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4173, slice_scatter_default_4174, 1, 8336, 8352);  slice_scatter_default_4173 = slice_scatter_default_4174 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34453: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8352, 8368)
        slice_34454: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34453, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1047: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34454, memory_format = torch.contiguous_format);  slice_34454 = None
        view_2098: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1047, [32, 16]);  clone_1047 = None
        mm_1044: "f32[32, 8]" = torch.ops.aten.mm.default(view_2098, slice_7)
        view_2099: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1044, [2, 16, 8]);  mm_1044 = None
        slice_34461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4175, 1, 8352, 8368)
        slice_34462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34461, 2, 0, 16);  slice_34461 = None
        add_1046: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34462, view_2099);  slice_34462 = view_2099 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4175, 1, 8352, 8368)
        slice_scatter_default_4176: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2088, add_1046, 2, 0, 16);  slice_tensor_2088 = add_1046 = None
        slice_scatter_default_4177: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4175, slice_scatter_default_4176, 1, 8352, 8368);  slice_scatter_default_4175 = slice_scatter_default_4176 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4177, 1, 8352, 8368)
        slice_34467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34466, 2, 0, 16);  slice_34466 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4177, 1, 8352, 8368)
        slice_scatter_default_4178: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2089, slice_34467, 2, 0, 16);  slice_tensor_2089 = slice_34467 = None
        slice_scatter_default_4179: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4177, slice_scatter_default_4178, 1, 8352, 8368);  slice_scatter_default_4177 = slice_scatter_default_4178 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34487: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34453, 2, 16, 32);  slice_34453 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1048: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34487, memory_format = torch.contiguous_format);  slice_34487 = None
        view_2100: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1048, [32, 11]);  clone_1048 = None
        mm_1045: "f32[32, 8]" = torch.ops.aten.mm.default(view_2100, slice_37)
        view_2101: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1045, [2, 16, 8]);  mm_1045 = None
        slice_34494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4179, 1, 8352, 8368)
        slice_34495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34494, 2, 0, 16);  slice_34494 = None
        add_1047: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34495, view_2101);  slice_34495 = view_2101 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2090: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4179, 1, 8352, 8368)
        slice_scatter_default_4180: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2090, add_1047, 2, 0, 16);  slice_tensor_2090 = add_1047 = None
        slice_scatter_default_4181: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4179, slice_scatter_default_4180, 1, 8352, 8368);  slice_scatter_default_4179 = slice_scatter_default_4180 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4181, 1, 8352, 8368)
        slice_34500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34499, 2, 0, 16);  slice_34499 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4181, 1, 8352, 8368)
        slice_scatter_default_4182: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2091, slice_34500, 2, 0, 16);  slice_tensor_2091 = slice_34500 = None
        slice_scatter_default_4183: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4181, slice_scatter_default_4182, 1, 8352, 8368);  slice_scatter_default_4181 = slice_scatter_default_4182 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34519: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8368, 8384)
        slice_34520: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34519, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1049: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34520, memory_format = torch.contiguous_format);  slice_34520 = None
        view_2102: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1049, [32, 16]);  clone_1049 = None
        mm_1046: "f32[32, 8]" = torch.ops.aten.mm.default(view_2102, slice_7)
        view_2103: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1046, [2, 16, 8]);  mm_1046 = None
        slice_34527: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4183, 1, 8368, 8384)
        slice_34528: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34527, 2, 0, 16);  slice_34527 = None
        add_1048: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34528, view_2103);  slice_34528 = view_2103 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4183, 1, 8368, 8384)
        slice_scatter_default_4184: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2092, add_1048, 2, 0, 16);  slice_tensor_2092 = add_1048 = None
        slice_scatter_default_4185: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4183, slice_scatter_default_4184, 1, 8368, 8384);  slice_scatter_default_4183 = slice_scatter_default_4184 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34532: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4185, 1, 8368, 8384)
        slice_34533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34532, 2, 0, 16);  slice_34532 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4185, 1, 8368, 8384)
        slice_scatter_default_4186: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2093, slice_34533, 2, 0, 16);  slice_tensor_2093 = slice_34533 = None
        slice_scatter_default_4187: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4185, slice_scatter_default_4186, 1, 8368, 8384);  slice_scatter_default_4185 = slice_scatter_default_4186 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34553: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34519, 2, 16, 32);  slice_34519 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1050: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34553, memory_format = torch.contiguous_format);  slice_34553 = None
        view_2104: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1050, [32, 11]);  clone_1050 = None
        mm_1047: "f32[32, 8]" = torch.ops.aten.mm.default(view_2104, slice_37)
        view_2105: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1047, [2, 16, 8]);  mm_1047 = None
        slice_34560: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4187, 1, 8368, 8384)
        slice_34561: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34560, 2, 0, 16);  slice_34560 = None
        add_1049: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34561, view_2105);  slice_34561 = view_2105 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4187, 1, 8368, 8384)
        slice_scatter_default_4188: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2094, add_1049, 2, 0, 16);  slice_tensor_2094 = add_1049 = None
        slice_scatter_default_4189: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4187, slice_scatter_default_4188, 1, 8368, 8384);  slice_scatter_default_4187 = slice_scatter_default_4188 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34565: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4189, 1, 8368, 8384)
        slice_34566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34565, 2, 0, 16);  slice_34565 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4189, 1, 8368, 8384)
        slice_scatter_default_4190: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2095, slice_34566, 2, 0, 16);  slice_tensor_2095 = slice_34566 = None
        slice_scatter_default_4191: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4189, slice_scatter_default_4190, 1, 8368, 8384);  slice_scatter_default_4189 = slice_scatter_default_4190 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34585: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8384, 8400)
        slice_34586: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34585, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1051: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34586, memory_format = torch.contiguous_format);  slice_34586 = None
        view_2106: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1051, [32, 16]);  clone_1051 = None
        mm_1048: "f32[32, 8]" = torch.ops.aten.mm.default(view_2106, slice_7)
        view_2107: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1048, [2, 16, 8]);  mm_1048 = None
        slice_34593: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4191, 1, 8384, 8400)
        slice_34594: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34593, 2, 0, 16);  slice_34593 = None
        add_1050: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34594, view_2107);  slice_34594 = view_2107 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4191, 1, 8384, 8400)
        slice_scatter_default_4192: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2096, add_1050, 2, 0, 16);  slice_tensor_2096 = add_1050 = None
        slice_scatter_default_4193: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4191, slice_scatter_default_4192, 1, 8384, 8400);  slice_scatter_default_4191 = slice_scatter_default_4192 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34598: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4193, 1, 8384, 8400)
        slice_34599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34598, 2, 0, 16);  slice_34598 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4193, 1, 8384, 8400)
        slice_scatter_default_4194: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2097, slice_34599, 2, 0, 16);  slice_tensor_2097 = slice_34599 = None
        slice_scatter_default_4195: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4193, slice_scatter_default_4194, 1, 8384, 8400);  slice_scatter_default_4193 = slice_scatter_default_4194 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34619: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34585, 2, 16, 32);  slice_34585 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1052: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34619, memory_format = torch.contiguous_format);  slice_34619 = None
        view_2108: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1052, [32, 11]);  clone_1052 = None
        mm_1049: "f32[32, 8]" = torch.ops.aten.mm.default(view_2108, slice_37)
        view_2109: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1049, [2, 16, 8]);  mm_1049 = None
        slice_34626: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4195, 1, 8384, 8400)
        slice_34627: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34626, 2, 0, 16);  slice_34626 = None
        add_1051: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34627, view_2109);  slice_34627 = view_2109 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2098: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4195, 1, 8384, 8400)
        slice_scatter_default_4196: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2098, add_1051, 2, 0, 16);  slice_tensor_2098 = add_1051 = None
        slice_scatter_default_4197: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4195, slice_scatter_default_4196, 1, 8384, 8400);  slice_scatter_default_4195 = slice_scatter_default_4196 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34631: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4197, 1, 8384, 8400)
        slice_34632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34631, 2, 0, 16);  slice_34631 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4197, 1, 8384, 8400)
        slice_scatter_default_4198: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2099, slice_34632, 2, 0, 16);  slice_tensor_2099 = slice_34632 = None
        slice_scatter_default_4199: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4197, slice_scatter_default_4198, 1, 8384, 8400);  slice_scatter_default_4197 = slice_scatter_default_4198 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34651: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8400, 8416)
        slice_34652: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34651, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1053: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34652, memory_format = torch.contiguous_format);  slice_34652 = None
        view_2110: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1053, [32, 16]);  clone_1053 = None
        mm_1050: "f32[32, 8]" = torch.ops.aten.mm.default(view_2110, slice_7)
        view_2111: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1050, [2, 16, 8]);  mm_1050 = None
        slice_34659: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4199, 1, 8400, 8416)
        slice_34660: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34659, 2, 0, 16);  slice_34659 = None
        add_1052: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34660, view_2111);  slice_34660 = view_2111 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4199, 1, 8400, 8416)
        slice_scatter_default_4200: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2100, add_1052, 2, 0, 16);  slice_tensor_2100 = add_1052 = None
        slice_scatter_default_4201: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4199, slice_scatter_default_4200, 1, 8400, 8416);  slice_scatter_default_4199 = slice_scatter_default_4200 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34664: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4201, 1, 8400, 8416)
        slice_34665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34664, 2, 0, 16);  slice_34664 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4201, 1, 8400, 8416)
        slice_scatter_default_4202: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2101, slice_34665, 2, 0, 16);  slice_tensor_2101 = slice_34665 = None
        slice_scatter_default_4203: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4201, slice_scatter_default_4202, 1, 8400, 8416);  slice_scatter_default_4201 = slice_scatter_default_4202 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34685: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34651, 2, 16, 32);  slice_34651 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1054: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34685, memory_format = torch.contiguous_format);  slice_34685 = None
        view_2112: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1054, [32, 11]);  clone_1054 = None
        mm_1051: "f32[32, 8]" = torch.ops.aten.mm.default(view_2112, slice_37)
        view_2113: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1051, [2, 16, 8]);  mm_1051 = None
        slice_34692: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4203, 1, 8400, 8416)
        slice_34693: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34692, 2, 0, 16);  slice_34692 = None
        add_1053: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34693, view_2113);  slice_34693 = view_2113 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4203, 1, 8400, 8416)
        slice_scatter_default_4204: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2102, add_1053, 2, 0, 16);  slice_tensor_2102 = add_1053 = None
        slice_scatter_default_4205: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4203, slice_scatter_default_4204, 1, 8400, 8416);  slice_scatter_default_4203 = slice_scatter_default_4204 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34697: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4205, 1, 8400, 8416)
        slice_34698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34697, 2, 0, 16);  slice_34697 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2103: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4205, 1, 8400, 8416)
        slice_scatter_default_4206: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2103, slice_34698, 2, 0, 16);  slice_tensor_2103 = slice_34698 = None
        slice_scatter_default_4207: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4205, slice_scatter_default_4206, 1, 8400, 8416);  slice_scatter_default_4205 = slice_scatter_default_4206 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34717: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8416, 8432)
        slice_34718: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34717, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1055: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34718, memory_format = torch.contiguous_format);  slice_34718 = None
        view_2114: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1055, [32, 16]);  clone_1055 = None
        mm_1052: "f32[32, 8]" = torch.ops.aten.mm.default(view_2114, slice_7)
        view_2115: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1052, [2, 16, 8]);  mm_1052 = None
        slice_34725: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4207, 1, 8416, 8432)
        slice_34726: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34725, 2, 0, 16);  slice_34725 = None
        add_1054: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34726, view_2115);  slice_34726 = view_2115 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4207, 1, 8416, 8432)
        slice_scatter_default_4208: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2104, add_1054, 2, 0, 16);  slice_tensor_2104 = add_1054 = None
        slice_scatter_default_4209: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4207, slice_scatter_default_4208, 1, 8416, 8432);  slice_scatter_default_4207 = slice_scatter_default_4208 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34730: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4209, 1, 8416, 8432)
        slice_34731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34730, 2, 0, 16);  slice_34730 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4209, 1, 8416, 8432)
        slice_scatter_default_4210: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2105, slice_34731, 2, 0, 16);  slice_tensor_2105 = slice_34731 = None
        slice_scatter_default_4211: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4209, slice_scatter_default_4210, 1, 8416, 8432);  slice_scatter_default_4209 = slice_scatter_default_4210 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34751: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34717, 2, 16, 32);  slice_34717 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1056: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34751, memory_format = torch.contiguous_format);  slice_34751 = None
        view_2116: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1056, [32, 11]);  clone_1056 = None
        mm_1053: "f32[32, 8]" = torch.ops.aten.mm.default(view_2116, slice_37)
        view_2117: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1053, [2, 16, 8]);  mm_1053 = None
        slice_34758: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4211, 1, 8416, 8432)
        slice_34759: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34758, 2, 0, 16);  slice_34758 = None
        add_1055: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34759, view_2117);  slice_34759 = view_2117 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4211, 1, 8416, 8432)
        slice_scatter_default_4212: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2106, add_1055, 2, 0, 16);  slice_tensor_2106 = add_1055 = None
        slice_scatter_default_4213: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4211, slice_scatter_default_4212, 1, 8416, 8432);  slice_scatter_default_4211 = slice_scatter_default_4212 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34763: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4213, 1, 8416, 8432)
        slice_34764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34763, 2, 0, 16);  slice_34763 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4213, 1, 8416, 8432)
        slice_scatter_default_4214: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2107, slice_34764, 2, 0, 16);  slice_tensor_2107 = slice_34764 = None
        slice_scatter_default_4215: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4213, slice_scatter_default_4214, 1, 8416, 8432);  slice_scatter_default_4213 = slice_scatter_default_4214 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34783: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8432, 8448)
        slice_34784: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34783, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1057: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34784, memory_format = torch.contiguous_format);  slice_34784 = None
        view_2118: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1057, [32, 16]);  clone_1057 = None
        mm_1054: "f32[32, 8]" = torch.ops.aten.mm.default(view_2118, slice_7)
        view_2119: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1054, [2, 16, 8]);  mm_1054 = None
        slice_34791: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4215, 1, 8432, 8448)
        slice_34792: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34791, 2, 0, 16);  slice_34791 = None
        add_1056: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34792, view_2119);  slice_34792 = view_2119 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2108: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4215, 1, 8432, 8448)
        slice_scatter_default_4216: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2108, add_1056, 2, 0, 16);  slice_tensor_2108 = add_1056 = None
        slice_scatter_default_4217: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4215, slice_scatter_default_4216, 1, 8432, 8448);  slice_scatter_default_4215 = slice_scatter_default_4216 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34796: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4217, 1, 8432, 8448)
        slice_34797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34796, 2, 0, 16);  slice_34796 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4217, 1, 8432, 8448)
        slice_scatter_default_4218: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2109, slice_34797, 2, 0, 16);  slice_tensor_2109 = slice_34797 = None
        slice_scatter_default_4219: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4217, slice_scatter_default_4218, 1, 8432, 8448);  slice_scatter_default_4217 = slice_scatter_default_4218 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34817: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34783, 2, 16, 32);  slice_34783 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1058: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34817, memory_format = torch.contiguous_format);  slice_34817 = None
        view_2120: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1058, [32, 11]);  clone_1058 = None
        mm_1055: "f32[32, 8]" = torch.ops.aten.mm.default(view_2120, slice_37)
        view_2121: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1055, [2, 16, 8]);  mm_1055 = None
        slice_34824: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4219, 1, 8432, 8448)
        slice_34825: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34824, 2, 0, 16);  slice_34824 = None
        add_1057: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34825, view_2121);  slice_34825 = view_2121 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4219, 1, 8432, 8448)
        slice_scatter_default_4220: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2110, add_1057, 2, 0, 16);  slice_tensor_2110 = add_1057 = None
        slice_scatter_default_4221: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4219, slice_scatter_default_4220, 1, 8432, 8448);  slice_scatter_default_4219 = slice_scatter_default_4220 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34829: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4221, 1, 8432, 8448)
        slice_34830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34829, 2, 0, 16);  slice_34829 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4221, 1, 8432, 8448)
        slice_scatter_default_4222: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2111, slice_34830, 2, 0, 16);  slice_tensor_2111 = slice_34830 = None
        slice_scatter_default_4223: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4221, slice_scatter_default_4222, 1, 8432, 8448);  slice_scatter_default_4221 = slice_scatter_default_4222 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34849: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8448, 8464)
        slice_34850: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34849, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1059: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34850, memory_format = torch.contiguous_format);  slice_34850 = None
        view_2122: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1059, [32, 16]);  clone_1059 = None
        mm_1056: "f32[32, 8]" = torch.ops.aten.mm.default(view_2122, slice_7)
        view_2123: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1056, [2, 16, 8]);  mm_1056 = None
        slice_34857: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4223, 1, 8448, 8464)
        slice_34858: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34857, 2, 0, 16);  slice_34857 = None
        add_1058: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34858, view_2123);  slice_34858 = view_2123 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4223, 1, 8448, 8464)
        slice_scatter_default_4224: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2112, add_1058, 2, 0, 16);  slice_tensor_2112 = add_1058 = None
        slice_scatter_default_4225: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4223, slice_scatter_default_4224, 1, 8448, 8464);  slice_scatter_default_4223 = slice_scatter_default_4224 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34862: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4225, 1, 8448, 8464)
        slice_34863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34862, 2, 0, 16);  slice_34862 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2113: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4225, 1, 8448, 8464)
        slice_scatter_default_4226: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2113, slice_34863, 2, 0, 16);  slice_tensor_2113 = slice_34863 = None
        slice_scatter_default_4227: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4225, slice_scatter_default_4226, 1, 8448, 8464);  slice_scatter_default_4225 = slice_scatter_default_4226 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34883: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34849, 2, 16, 32);  slice_34849 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1060: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34883, memory_format = torch.contiguous_format);  slice_34883 = None
        view_2124: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1060, [32, 11]);  clone_1060 = None
        mm_1057: "f32[32, 8]" = torch.ops.aten.mm.default(view_2124, slice_37)
        view_2125: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1057, [2, 16, 8]);  mm_1057 = None
        slice_34890: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4227, 1, 8448, 8464)
        slice_34891: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34890, 2, 0, 16);  slice_34890 = None
        add_1059: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34891, view_2125);  slice_34891 = view_2125 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4227, 1, 8448, 8464)
        slice_scatter_default_4228: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2114, add_1059, 2, 0, 16);  slice_tensor_2114 = add_1059 = None
        slice_scatter_default_4229: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4227, slice_scatter_default_4228, 1, 8448, 8464);  slice_scatter_default_4227 = slice_scatter_default_4228 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34895: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4229, 1, 8448, 8464)
        slice_34896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34895, 2, 0, 16);  slice_34895 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4229, 1, 8448, 8464)
        slice_scatter_default_4230: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2115, slice_34896, 2, 0, 16);  slice_tensor_2115 = slice_34896 = None
        slice_scatter_default_4231: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4229, slice_scatter_default_4230, 1, 8448, 8464);  slice_scatter_default_4229 = slice_scatter_default_4230 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34915: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8464, 8480)
        slice_34916: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34915, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1061: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34916, memory_format = torch.contiguous_format);  slice_34916 = None
        view_2126: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1061, [32, 16]);  clone_1061 = None
        mm_1058: "f32[32, 8]" = torch.ops.aten.mm.default(view_2126, slice_7)
        view_2127: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1058, [2, 16, 8]);  mm_1058 = None
        slice_34923: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4231, 1, 8464, 8480)
        slice_34924: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34923, 2, 0, 16);  slice_34923 = None
        add_1060: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34924, view_2127);  slice_34924 = view_2127 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4231, 1, 8464, 8480)
        slice_scatter_default_4232: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2116, add_1060, 2, 0, 16);  slice_tensor_2116 = add_1060 = None
        slice_scatter_default_4233: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4231, slice_scatter_default_4232, 1, 8464, 8480);  slice_scatter_default_4231 = slice_scatter_default_4232 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34928: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4233, 1, 8464, 8480)
        slice_34929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34928, 2, 0, 16);  slice_34928 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4233, 1, 8464, 8480)
        slice_scatter_default_4234: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2117, slice_34929, 2, 0, 16);  slice_tensor_2117 = slice_34929 = None
        slice_scatter_default_4235: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4233, slice_scatter_default_4234, 1, 8464, 8480);  slice_scatter_default_4233 = slice_scatter_default_4234 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34949: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34915, 2, 16, 32);  slice_34915 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1062: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_34949, memory_format = torch.contiguous_format);  slice_34949 = None
        view_2128: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1062, [32, 11]);  clone_1062 = None
        mm_1059: "f32[32, 8]" = torch.ops.aten.mm.default(view_2128, slice_37)
        view_2129: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1059, [2, 16, 8]);  mm_1059 = None
        slice_34956: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4235, 1, 8464, 8480)
        slice_34957: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34956, 2, 0, 16);  slice_34956 = None
        add_1061: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34957, view_2129);  slice_34957 = view_2129 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2118: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4235, 1, 8464, 8480)
        slice_scatter_default_4236: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2118, add_1061, 2, 0, 16);  slice_tensor_2118 = add_1061 = None
        slice_scatter_default_4237: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4235, slice_scatter_default_4236, 1, 8464, 8480);  slice_scatter_default_4235 = slice_scatter_default_4236 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34961: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4237, 1, 8464, 8480)
        slice_34962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34961, 2, 0, 16);  slice_34961 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4237, 1, 8464, 8480)
        slice_scatter_default_4238: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2119, slice_34962, 2, 0, 16);  slice_tensor_2119 = slice_34962 = None
        slice_scatter_default_4239: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4237, slice_scatter_default_4238, 1, 8464, 8480);  slice_scatter_default_4237 = slice_scatter_default_4238 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_34981: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8480, 8496)
        slice_34982: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_34981, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1063: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_34982, memory_format = torch.contiguous_format);  slice_34982 = None
        view_2130: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1063, [32, 16]);  clone_1063 = None
        mm_1060: "f32[32, 8]" = torch.ops.aten.mm.default(view_2130, slice_7)
        view_2131: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1060, [2, 16, 8]);  mm_1060 = None
        slice_34989: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4239, 1, 8480, 8496)
        slice_34990: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34989, 2, 0, 16);  slice_34989 = None
        add_1062: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_34990, view_2131);  slice_34990 = view_2131 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4239, 1, 8480, 8496)
        slice_scatter_default_4240: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2120, add_1062, 2, 0, 16);  slice_tensor_2120 = add_1062 = None
        slice_scatter_default_4241: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4239, slice_scatter_default_4240, 1, 8480, 8496);  slice_scatter_default_4239 = slice_scatter_default_4240 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_34994: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4241, 1, 8480, 8496)
        slice_34995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_34994, 2, 0, 16);  slice_34994 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4241, 1, 8480, 8496)
        slice_scatter_default_4242: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2121, slice_34995, 2, 0, 16);  slice_tensor_2121 = slice_34995 = None
        slice_scatter_default_4243: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4241, slice_scatter_default_4242, 1, 8480, 8496);  slice_scatter_default_4241 = slice_scatter_default_4242 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35015: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_34981, 2, 16, 32);  slice_34981 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1064: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35015, memory_format = torch.contiguous_format);  slice_35015 = None
        view_2132: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1064, [32, 11]);  clone_1064 = None
        mm_1061: "f32[32, 8]" = torch.ops.aten.mm.default(view_2132, slice_37)
        view_2133: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1061, [2, 16, 8]);  mm_1061 = None
        slice_35022: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4243, 1, 8480, 8496)
        slice_35023: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35022, 2, 0, 16);  slice_35022 = None
        add_1063: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35023, view_2133);  slice_35023 = view_2133 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4243, 1, 8480, 8496)
        slice_scatter_default_4244: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2122, add_1063, 2, 0, 16);  slice_tensor_2122 = add_1063 = None
        slice_scatter_default_4245: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4243, slice_scatter_default_4244, 1, 8480, 8496);  slice_scatter_default_4243 = slice_scatter_default_4244 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35027: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4245, 1, 8480, 8496)
        slice_35028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35027, 2, 0, 16);  slice_35027 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2123: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4245, 1, 8480, 8496)
        slice_scatter_default_4246: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2123, slice_35028, 2, 0, 16);  slice_tensor_2123 = slice_35028 = None
        slice_scatter_default_4247: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4245, slice_scatter_default_4246, 1, 8480, 8496);  slice_scatter_default_4245 = slice_scatter_default_4246 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35047: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8496, 8512)
        slice_35048: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35047, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1065: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35048, memory_format = torch.contiguous_format);  slice_35048 = None
        view_2134: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1065, [32, 16]);  clone_1065 = None
        mm_1062: "f32[32, 8]" = torch.ops.aten.mm.default(view_2134, slice_7)
        view_2135: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1062, [2, 16, 8]);  mm_1062 = None
        slice_35055: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4247, 1, 8496, 8512)
        slice_35056: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35055, 2, 0, 16);  slice_35055 = None
        add_1064: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35056, view_2135);  slice_35056 = view_2135 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4247, 1, 8496, 8512)
        slice_scatter_default_4248: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2124, add_1064, 2, 0, 16);  slice_tensor_2124 = add_1064 = None
        slice_scatter_default_4249: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4247, slice_scatter_default_4248, 1, 8496, 8512);  slice_scatter_default_4247 = slice_scatter_default_4248 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35060: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4249, 1, 8496, 8512)
        slice_35061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35060, 2, 0, 16);  slice_35060 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4249, 1, 8496, 8512)
        slice_scatter_default_4250: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2125, slice_35061, 2, 0, 16);  slice_tensor_2125 = slice_35061 = None
        slice_scatter_default_4251: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4249, slice_scatter_default_4250, 1, 8496, 8512);  slice_scatter_default_4249 = slice_scatter_default_4250 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35081: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35047, 2, 16, 32);  slice_35047 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1066: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35081, memory_format = torch.contiguous_format);  slice_35081 = None
        view_2136: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1066, [32, 11]);  clone_1066 = None
        mm_1063: "f32[32, 8]" = torch.ops.aten.mm.default(view_2136, slice_37)
        view_2137: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1063, [2, 16, 8]);  mm_1063 = None
        slice_35088: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4251, 1, 8496, 8512)
        slice_35089: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35088, 2, 0, 16);  slice_35088 = None
        add_1065: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35089, view_2137);  slice_35089 = view_2137 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4251, 1, 8496, 8512)
        slice_scatter_default_4252: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2126, add_1065, 2, 0, 16);  slice_tensor_2126 = add_1065 = None
        slice_scatter_default_4253: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4251, slice_scatter_default_4252, 1, 8496, 8512);  slice_scatter_default_4251 = slice_scatter_default_4252 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35093: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4253, 1, 8496, 8512)
        slice_35094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35093, 2, 0, 16);  slice_35093 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4253, 1, 8496, 8512)
        slice_scatter_default_4254: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2127, slice_35094, 2, 0, 16);  slice_tensor_2127 = slice_35094 = None
        slice_scatter_default_4255: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4253, slice_scatter_default_4254, 1, 8496, 8512);  slice_scatter_default_4253 = slice_scatter_default_4254 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35113: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8512, 8528)
        slice_35114: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35113, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1067: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35114, memory_format = torch.contiguous_format);  slice_35114 = None
        view_2138: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1067, [32, 16]);  clone_1067 = None
        mm_1064: "f32[32, 8]" = torch.ops.aten.mm.default(view_2138, slice_7)
        view_2139: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1064, [2, 16, 8]);  mm_1064 = None
        slice_35121: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4255, 1, 8512, 8528)
        slice_35122: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35121, 2, 0, 16);  slice_35121 = None
        add_1066: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35122, view_2139);  slice_35122 = view_2139 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4255, 1, 8512, 8528)
        slice_scatter_default_4256: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2128, add_1066, 2, 0, 16);  slice_tensor_2128 = add_1066 = None
        slice_scatter_default_4257: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4255, slice_scatter_default_4256, 1, 8512, 8528);  slice_scatter_default_4255 = slice_scatter_default_4256 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35126: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4257, 1, 8512, 8528)
        slice_35127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35126, 2, 0, 16);  slice_35126 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4257, 1, 8512, 8528)
        slice_scatter_default_4258: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2129, slice_35127, 2, 0, 16);  slice_tensor_2129 = slice_35127 = None
        slice_scatter_default_4259: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4257, slice_scatter_default_4258, 1, 8512, 8528);  slice_scatter_default_4257 = slice_scatter_default_4258 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35147: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35113, 2, 16, 32);  slice_35113 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1068: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35147, memory_format = torch.contiguous_format);  slice_35147 = None
        view_2140: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1068, [32, 11]);  clone_1068 = None
        mm_1065: "f32[32, 8]" = torch.ops.aten.mm.default(view_2140, slice_37)
        view_2141: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1065, [2, 16, 8]);  mm_1065 = None
        slice_35154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4259, 1, 8512, 8528)
        slice_35155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35154, 2, 0, 16);  slice_35154 = None
        add_1067: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35155, view_2141);  slice_35155 = view_2141 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4259, 1, 8512, 8528)
        slice_scatter_default_4260: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2130, add_1067, 2, 0, 16);  slice_tensor_2130 = add_1067 = None
        slice_scatter_default_4261: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4259, slice_scatter_default_4260, 1, 8512, 8528);  slice_scatter_default_4259 = slice_scatter_default_4260 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4261, 1, 8512, 8528)
        slice_35160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35159, 2, 0, 16);  slice_35159 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2131: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4261, 1, 8512, 8528)
        slice_scatter_default_4262: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2131, slice_35160, 2, 0, 16);  slice_tensor_2131 = slice_35160 = None
        slice_scatter_default_4263: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4261, slice_scatter_default_4262, 1, 8512, 8528);  slice_scatter_default_4261 = slice_scatter_default_4262 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35179: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8528, 8544)
        slice_35180: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35179, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1069: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35180, memory_format = torch.contiguous_format);  slice_35180 = None
        view_2142: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1069, [32, 16]);  clone_1069 = None
        mm_1066: "f32[32, 8]" = torch.ops.aten.mm.default(view_2142, slice_7)
        view_2143: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1066, [2, 16, 8]);  mm_1066 = None
        slice_35187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4263, 1, 8528, 8544)
        slice_35188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35187, 2, 0, 16);  slice_35187 = None
        add_1068: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35188, view_2143);  slice_35188 = view_2143 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4263, 1, 8528, 8544)
        slice_scatter_default_4264: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2132, add_1068, 2, 0, 16);  slice_tensor_2132 = add_1068 = None
        slice_scatter_default_4265: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4263, slice_scatter_default_4264, 1, 8528, 8544);  slice_scatter_default_4263 = slice_scatter_default_4264 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4265, 1, 8528, 8544)
        slice_35193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35192, 2, 0, 16);  slice_35192 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4265, 1, 8528, 8544)
        slice_scatter_default_4266: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2133, slice_35193, 2, 0, 16);  slice_tensor_2133 = slice_35193 = None
        slice_scatter_default_4267: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4265, slice_scatter_default_4266, 1, 8528, 8544);  slice_scatter_default_4265 = slice_scatter_default_4266 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35213: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35179, 2, 16, 32);  slice_35179 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1070: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35213, memory_format = torch.contiguous_format);  slice_35213 = None
        view_2144: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1070, [32, 11]);  clone_1070 = None
        mm_1067: "f32[32, 8]" = torch.ops.aten.mm.default(view_2144, slice_37)
        view_2145: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1067, [2, 16, 8]);  mm_1067 = None
        slice_35220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4267, 1, 8528, 8544)
        slice_35221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35220, 2, 0, 16);  slice_35220 = None
        add_1069: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35221, view_2145);  slice_35221 = view_2145 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4267, 1, 8528, 8544)
        slice_scatter_default_4268: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2134, add_1069, 2, 0, 16);  slice_tensor_2134 = add_1069 = None
        slice_scatter_default_4269: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4267, slice_scatter_default_4268, 1, 8528, 8544);  slice_scatter_default_4267 = slice_scatter_default_4268 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4269, 1, 8528, 8544)
        slice_35226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35225, 2, 0, 16);  slice_35225 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4269, 1, 8528, 8544)
        slice_scatter_default_4270: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2135, slice_35226, 2, 0, 16);  slice_tensor_2135 = slice_35226 = None
        slice_scatter_default_4271: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4269, slice_scatter_default_4270, 1, 8528, 8544);  slice_scatter_default_4269 = slice_scatter_default_4270 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35245: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8544, 8560)
        slice_35246: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35245, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1071: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35246, memory_format = torch.contiguous_format);  slice_35246 = None
        view_2146: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1071, [32, 16]);  clone_1071 = None
        mm_1068: "f32[32, 8]" = torch.ops.aten.mm.default(view_2146, slice_7)
        view_2147: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1068, [2, 16, 8]);  mm_1068 = None
        slice_35253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4271, 1, 8544, 8560)
        slice_35254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35253, 2, 0, 16);  slice_35253 = None
        add_1070: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35254, view_2147);  slice_35254 = view_2147 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2136: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4271, 1, 8544, 8560)
        slice_scatter_default_4272: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2136, add_1070, 2, 0, 16);  slice_tensor_2136 = add_1070 = None
        slice_scatter_default_4273: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4271, slice_scatter_default_4272, 1, 8544, 8560);  slice_scatter_default_4271 = slice_scatter_default_4272 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4273, 1, 8544, 8560)
        slice_35259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35258, 2, 0, 16);  slice_35258 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4273, 1, 8544, 8560)
        slice_scatter_default_4274: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2137, slice_35259, 2, 0, 16);  slice_tensor_2137 = slice_35259 = None
        slice_scatter_default_4275: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4273, slice_scatter_default_4274, 1, 8544, 8560);  slice_scatter_default_4273 = slice_scatter_default_4274 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35279: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35245, 2, 16, 32);  slice_35245 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1072: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35279, memory_format = torch.contiguous_format);  slice_35279 = None
        view_2148: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1072, [32, 11]);  clone_1072 = None
        mm_1069: "f32[32, 8]" = torch.ops.aten.mm.default(view_2148, slice_37)
        view_2149: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1069, [2, 16, 8]);  mm_1069 = None
        slice_35286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4275, 1, 8544, 8560)
        slice_35287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35286, 2, 0, 16);  slice_35286 = None
        add_1071: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35287, view_2149);  slice_35287 = view_2149 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4275, 1, 8544, 8560)
        slice_scatter_default_4276: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2138, add_1071, 2, 0, 16);  slice_tensor_2138 = add_1071 = None
        slice_scatter_default_4277: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4275, slice_scatter_default_4276, 1, 8544, 8560);  slice_scatter_default_4275 = slice_scatter_default_4276 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4277, 1, 8544, 8560)
        slice_35292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35291, 2, 0, 16);  slice_35291 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4277, 1, 8544, 8560)
        slice_scatter_default_4278: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2139, slice_35292, 2, 0, 16);  slice_tensor_2139 = slice_35292 = None
        slice_scatter_default_4279: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4277, slice_scatter_default_4278, 1, 8544, 8560);  slice_scatter_default_4277 = slice_scatter_default_4278 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35311: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8560, 8576)
        slice_35312: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35311, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1073: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35312, memory_format = torch.contiguous_format);  slice_35312 = None
        view_2150: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1073, [32, 16]);  clone_1073 = None
        mm_1070: "f32[32, 8]" = torch.ops.aten.mm.default(view_2150, slice_7)
        view_2151: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1070, [2, 16, 8]);  mm_1070 = None
        slice_35319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4279, 1, 8560, 8576)
        slice_35320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35319, 2, 0, 16);  slice_35319 = None
        add_1072: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35320, view_2151);  slice_35320 = view_2151 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4279, 1, 8560, 8576)
        slice_scatter_default_4280: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2140, add_1072, 2, 0, 16);  slice_tensor_2140 = add_1072 = None
        slice_scatter_default_4281: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4279, slice_scatter_default_4280, 1, 8560, 8576);  slice_scatter_default_4279 = slice_scatter_default_4280 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4281, 1, 8560, 8576)
        slice_35325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35324, 2, 0, 16);  slice_35324 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2141: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4281, 1, 8560, 8576)
        slice_scatter_default_4282: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2141, slice_35325, 2, 0, 16);  slice_tensor_2141 = slice_35325 = None
        slice_scatter_default_4283: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4281, slice_scatter_default_4282, 1, 8560, 8576);  slice_scatter_default_4281 = slice_scatter_default_4282 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35345: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35311, 2, 16, 32);  slice_35311 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1074: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35345, memory_format = torch.contiguous_format);  slice_35345 = None
        view_2152: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1074, [32, 11]);  clone_1074 = None
        mm_1071: "f32[32, 8]" = torch.ops.aten.mm.default(view_2152, slice_37)
        view_2153: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1071, [2, 16, 8]);  mm_1071 = None
        slice_35352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4283, 1, 8560, 8576)
        slice_35353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35352, 2, 0, 16);  slice_35352 = None
        add_1073: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35353, view_2153);  slice_35353 = view_2153 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4283, 1, 8560, 8576)
        slice_scatter_default_4284: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2142, add_1073, 2, 0, 16);  slice_tensor_2142 = add_1073 = None
        slice_scatter_default_4285: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4283, slice_scatter_default_4284, 1, 8560, 8576);  slice_scatter_default_4283 = slice_scatter_default_4284 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4285, 1, 8560, 8576)
        slice_35358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35357, 2, 0, 16);  slice_35357 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4285, 1, 8560, 8576)
        slice_scatter_default_4286: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2143, slice_35358, 2, 0, 16);  slice_tensor_2143 = slice_35358 = None
        slice_scatter_default_4287: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4285, slice_scatter_default_4286, 1, 8560, 8576);  slice_scatter_default_4285 = slice_scatter_default_4286 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35377: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8576, 8592)
        slice_35378: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35377, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1075: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35378, memory_format = torch.contiguous_format);  slice_35378 = None
        view_2154: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1075, [32, 16]);  clone_1075 = None
        mm_1072: "f32[32, 8]" = torch.ops.aten.mm.default(view_2154, slice_7)
        view_2155: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1072, [2, 16, 8]);  mm_1072 = None
        slice_35385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4287, 1, 8576, 8592)
        slice_35386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35385, 2, 0, 16);  slice_35385 = None
        add_1074: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35386, view_2155);  slice_35386 = view_2155 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4287, 1, 8576, 8592)
        slice_scatter_default_4288: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2144, add_1074, 2, 0, 16);  slice_tensor_2144 = add_1074 = None
        slice_scatter_default_4289: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4287, slice_scatter_default_4288, 1, 8576, 8592);  slice_scatter_default_4287 = slice_scatter_default_4288 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4289, 1, 8576, 8592)
        slice_35391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35390, 2, 0, 16);  slice_35390 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4289, 1, 8576, 8592)
        slice_scatter_default_4290: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2145, slice_35391, 2, 0, 16);  slice_tensor_2145 = slice_35391 = None
        slice_scatter_default_4291: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4289, slice_scatter_default_4290, 1, 8576, 8592);  slice_scatter_default_4289 = slice_scatter_default_4290 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35411: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35377, 2, 16, 32);  slice_35377 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1076: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35411, memory_format = torch.contiguous_format);  slice_35411 = None
        view_2156: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1076, [32, 11]);  clone_1076 = None
        mm_1073: "f32[32, 8]" = torch.ops.aten.mm.default(view_2156, slice_37)
        view_2157: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1073, [2, 16, 8]);  mm_1073 = None
        slice_35418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4291, 1, 8576, 8592)
        slice_35419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35418, 2, 0, 16);  slice_35418 = None
        add_1075: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35419, view_2157);  slice_35419 = view_2157 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2146: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4291, 1, 8576, 8592)
        slice_scatter_default_4292: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2146, add_1075, 2, 0, 16);  slice_tensor_2146 = add_1075 = None
        slice_scatter_default_4293: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4291, slice_scatter_default_4292, 1, 8576, 8592);  slice_scatter_default_4291 = slice_scatter_default_4292 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4293, 1, 8576, 8592)
        slice_35424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35423, 2, 0, 16);  slice_35423 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4293, 1, 8576, 8592)
        slice_scatter_default_4294: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2147, slice_35424, 2, 0, 16);  slice_tensor_2147 = slice_35424 = None
        slice_scatter_default_4295: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4293, slice_scatter_default_4294, 1, 8576, 8592);  slice_scatter_default_4293 = slice_scatter_default_4294 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35443: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8592, 8608)
        slice_35444: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35443, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1077: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35444, memory_format = torch.contiguous_format);  slice_35444 = None
        view_2158: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1077, [32, 16]);  clone_1077 = None
        mm_1074: "f32[32, 8]" = torch.ops.aten.mm.default(view_2158, slice_7)
        view_2159: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1074, [2, 16, 8]);  mm_1074 = None
        slice_35451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4295, 1, 8592, 8608)
        slice_35452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35451, 2, 0, 16);  slice_35451 = None
        add_1076: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35452, view_2159);  slice_35452 = view_2159 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4295, 1, 8592, 8608)
        slice_scatter_default_4296: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2148, add_1076, 2, 0, 16);  slice_tensor_2148 = add_1076 = None
        slice_scatter_default_4297: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4295, slice_scatter_default_4296, 1, 8592, 8608);  slice_scatter_default_4295 = slice_scatter_default_4296 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4297, 1, 8592, 8608)
        slice_35457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35456, 2, 0, 16);  slice_35456 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4297, 1, 8592, 8608)
        slice_scatter_default_4298: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2149, slice_35457, 2, 0, 16);  slice_tensor_2149 = slice_35457 = None
        slice_scatter_default_4299: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4297, slice_scatter_default_4298, 1, 8592, 8608);  slice_scatter_default_4297 = slice_scatter_default_4298 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35477: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35443, 2, 16, 32);  slice_35443 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1078: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35477, memory_format = torch.contiguous_format);  slice_35477 = None
        view_2160: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1078, [32, 11]);  clone_1078 = None
        mm_1075: "f32[32, 8]" = torch.ops.aten.mm.default(view_2160, slice_37)
        view_2161: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1075, [2, 16, 8]);  mm_1075 = None
        slice_35484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4299, 1, 8592, 8608)
        slice_35485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35484, 2, 0, 16);  slice_35484 = None
        add_1077: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35485, view_2161);  slice_35485 = view_2161 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4299, 1, 8592, 8608)
        slice_scatter_default_4300: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2150, add_1077, 2, 0, 16);  slice_tensor_2150 = add_1077 = None
        slice_scatter_default_4301: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4299, slice_scatter_default_4300, 1, 8592, 8608);  slice_scatter_default_4299 = slice_scatter_default_4300 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4301, 1, 8592, 8608)
        slice_35490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35489, 2, 0, 16);  slice_35489 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2151: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4301, 1, 8592, 8608)
        slice_scatter_default_4302: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2151, slice_35490, 2, 0, 16);  slice_tensor_2151 = slice_35490 = None
        slice_scatter_default_4303: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4301, slice_scatter_default_4302, 1, 8592, 8608);  slice_scatter_default_4301 = slice_scatter_default_4302 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35509: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8608, 8624)
        slice_35510: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35509, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1079: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35510, memory_format = torch.contiguous_format);  slice_35510 = None
        view_2162: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1079, [32, 16]);  clone_1079 = None
        mm_1076: "f32[32, 8]" = torch.ops.aten.mm.default(view_2162, slice_7)
        view_2163: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1076, [2, 16, 8]);  mm_1076 = None
        slice_35517: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4303, 1, 8608, 8624)
        slice_35518: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35517, 2, 0, 16);  slice_35517 = None
        add_1078: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35518, view_2163);  slice_35518 = view_2163 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4303, 1, 8608, 8624)
        slice_scatter_default_4304: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2152, add_1078, 2, 0, 16);  slice_tensor_2152 = add_1078 = None
        slice_scatter_default_4305: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4303, slice_scatter_default_4304, 1, 8608, 8624);  slice_scatter_default_4303 = slice_scatter_default_4304 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35522: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4305, 1, 8608, 8624)
        slice_35523: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35522, 2, 0, 16);  slice_35522 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4305, 1, 8608, 8624)
        slice_scatter_default_4306: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2153, slice_35523, 2, 0, 16);  slice_tensor_2153 = slice_35523 = None
        slice_scatter_default_4307: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4305, slice_scatter_default_4306, 1, 8608, 8624);  slice_scatter_default_4305 = slice_scatter_default_4306 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35543: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35509, 2, 16, 32);  slice_35509 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1080: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35543, memory_format = torch.contiguous_format);  slice_35543 = None
        view_2164: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1080, [32, 11]);  clone_1080 = None
        mm_1077: "f32[32, 8]" = torch.ops.aten.mm.default(view_2164, slice_37)
        view_2165: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1077, [2, 16, 8]);  mm_1077 = None
        slice_35550: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4307, 1, 8608, 8624)
        slice_35551: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35550, 2, 0, 16);  slice_35550 = None
        add_1079: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35551, view_2165);  slice_35551 = view_2165 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2154: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4307, 1, 8608, 8624)
        slice_scatter_default_4308: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2154, add_1079, 2, 0, 16);  slice_tensor_2154 = add_1079 = None
        slice_scatter_default_4309: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4307, slice_scatter_default_4308, 1, 8608, 8624);  slice_scatter_default_4307 = slice_scatter_default_4308 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35555: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4309, 1, 8608, 8624)
        slice_35556: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35555, 2, 0, 16);  slice_35555 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2155: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4309, 1, 8608, 8624)
        slice_scatter_default_4310: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2155, slice_35556, 2, 0, 16);  slice_tensor_2155 = slice_35556 = None
        slice_scatter_default_4311: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4309, slice_scatter_default_4310, 1, 8608, 8624);  slice_scatter_default_4309 = slice_scatter_default_4310 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35575: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8624, 8640)
        slice_35576: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35575, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1081: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35576, memory_format = torch.contiguous_format);  slice_35576 = None
        view_2166: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1081, [32, 16]);  clone_1081 = None
        mm_1078: "f32[32, 8]" = torch.ops.aten.mm.default(view_2166, slice_7)
        view_2167: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1078, [2, 16, 8]);  mm_1078 = None
        slice_35583: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4311, 1, 8624, 8640)
        slice_35584: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35583, 2, 0, 16);  slice_35583 = None
        add_1080: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35584, view_2167);  slice_35584 = view_2167 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2156: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4311, 1, 8624, 8640)
        slice_scatter_default_4312: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2156, add_1080, 2, 0, 16);  slice_tensor_2156 = add_1080 = None
        slice_scatter_default_4313: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4311, slice_scatter_default_4312, 1, 8624, 8640);  slice_scatter_default_4311 = slice_scatter_default_4312 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35588: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4313, 1, 8624, 8640)
        slice_35589: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35588, 2, 0, 16);  slice_35588 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4313, 1, 8624, 8640)
        slice_scatter_default_4314: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2157, slice_35589, 2, 0, 16);  slice_tensor_2157 = slice_35589 = None
        slice_scatter_default_4315: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4313, slice_scatter_default_4314, 1, 8624, 8640);  slice_scatter_default_4313 = slice_scatter_default_4314 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35609: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35575, 2, 16, 32);  slice_35575 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1082: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35609, memory_format = torch.contiguous_format);  slice_35609 = None
        view_2168: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1082, [32, 11]);  clone_1082 = None
        mm_1079: "f32[32, 8]" = torch.ops.aten.mm.default(view_2168, slice_37)
        view_2169: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1079, [2, 16, 8]);  mm_1079 = None
        slice_35616: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4315, 1, 8624, 8640)
        slice_35617: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35616, 2, 0, 16);  slice_35616 = None
        add_1081: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35617, view_2169);  slice_35617 = view_2169 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4315, 1, 8624, 8640)
        slice_scatter_default_4316: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2158, add_1081, 2, 0, 16);  slice_tensor_2158 = add_1081 = None
        slice_scatter_default_4317: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4315, slice_scatter_default_4316, 1, 8624, 8640);  slice_scatter_default_4315 = slice_scatter_default_4316 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35621: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4317, 1, 8624, 8640)
        slice_35622: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35621, 2, 0, 16);  slice_35621 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2159: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4317, 1, 8624, 8640)
        slice_scatter_default_4318: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2159, slice_35622, 2, 0, 16);  slice_tensor_2159 = slice_35622 = None
        slice_scatter_default_4319: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4317, slice_scatter_default_4318, 1, 8624, 8640);  slice_scatter_default_4317 = slice_scatter_default_4318 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35641: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8640, 8656)
        slice_35642: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35641, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1083: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35642, memory_format = torch.contiguous_format);  slice_35642 = None
        view_2170: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1083, [32, 16]);  clone_1083 = None
        mm_1080: "f32[32, 8]" = torch.ops.aten.mm.default(view_2170, slice_7)
        view_2171: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1080, [2, 16, 8]);  mm_1080 = None
        slice_35649: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4319, 1, 8640, 8656)
        slice_35650: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35649, 2, 0, 16);  slice_35649 = None
        add_1082: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35650, view_2171);  slice_35650 = view_2171 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4319, 1, 8640, 8656)
        slice_scatter_default_4320: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2160, add_1082, 2, 0, 16);  slice_tensor_2160 = add_1082 = None
        slice_scatter_default_4321: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4319, slice_scatter_default_4320, 1, 8640, 8656);  slice_scatter_default_4319 = slice_scatter_default_4320 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35654: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4321, 1, 8640, 8656)
        slice_35655: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35654, 2, 0, 16);  slice_35654 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4321, 1, 8640, 8656)
        slice_scatter_default_4322: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2161, slice_35655, 2, 0, 16);  slice_tensor_2161 = slice_35655 = None
        slice_scatter_default_4323: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4321, slice_scatter_default_4322, 1, 8640, 8656);  slice_scatter_default_4321 = slice_scatter_default_4322 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35675: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35641, 2, 16, 32);  slice_35641 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1084: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35675, memory_format = torch.contiguous_format);  slice_35675 = None
        view_2172: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1084, [32, 11]);  clone_1084 = None
        mm_1081: "f32[32, 8]" = torch.ops.aten.mm.default(view_2172, slice_37)
        view_2173: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1081, [2, 16, 8]);  mm_1081 = None
        slice_35682: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4323, 1, 8640, 8656)
        slice_35683: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35682, 2, 0, 16);  slice_35682 = None
        add_1083: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35683, view_2173);  slice_35683 = view_2173 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4323, 1, 8640, 8656)
        slice_scatter_default_4324: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2162, add_1083, 2, 0, 16);  slice_tensor_2162 = add_1083 = None
        slice_scatter_default_4325: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4323, slice_scatter_default_4324, 1, 8640, 8656);  slice_scatter_default_4323 = slice_scatter_default_4324 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35687: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4325, 1, 8640, 8656)
        slice_35688: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35687, 2, 0, 16);  slice_35687 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4325, 1, 8640, 8656)
        slice_scatter_default_4326: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2163, slice_35688, 2, 0, 16);  slice_tensor_2163 = slice_35688 = None
        slice_scatter_default_4327: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4325, slice_scatter_default_4326, 1, 8640, 8656);  slice_scatter_default_4325 = slice_scatter_default_4326 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35707: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8656, 8672)
        slice_35708: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35707, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1085: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35708, memory_format = torch.contiguous_format);  slice_35708 = None
        view_2174: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1085, [32, 16]);  clone_1085 = None
        mm_1082: "f32[32, 8]" = torch.ops.aten.mm.default(view_2174, slice_7)
        view_2175: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1082, [2, 16, 8]);  mm_1082 = None
        slice_35715: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4327, 1, 8656, 8672)
        slice_35716: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35715, 2, 0, 16);  slice_35715 = None
        add_1084: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35716, view_2175);  slice_35716 = view_2175 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2164: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4327, 1, 8656, 8672)
        slice_scatter_default_4328: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2164, add_1084, 2, 0, 16);  slice_tensor_2164 = add_1084 = None
        slice_scatter_default_4329: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4327, slice_scatter_default_4328, 1, 8656, 8672);  slice_scatter_default_4327 = slice_scatter_default_4328 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35720: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4329, 1, 8656, 8672)
        slice_35721: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35720, 2, 0, 16);  slice_35720 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4329, 1, 8656, 8672)
        slice_scatter_default_4330: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2165, slice_35721, 2, 0, 16);  slice_tensor_2165 = slice_35721 = None
        slice_scatter_default_4331: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4329, slice_scatter_default_4330, 1, 8656, 8672);  slice_scatter_default_4329 = slice_scatter_default_4330 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35741: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35707, 2, 16, 32);  slice_35707 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1086: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35741, memory_format = torch.contiguous_format);  slice_35741 = None
        view_2176: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1086, [32, 11]);  clone_1086 = None
        mm_1083: "f32[32, 8]" = torch.ops.aten.mm.default(view_2176, slice_37)
        view_2177: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1083, [2, 16, 8]);  mm_1083 = None
        slice_35748: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4331, 1, 8656, 8672)
        slice_35749: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35748, 2, 0, 16);  slice_35748 = None
        add_1085: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35749, view_2177);  slice_35749 = view_2177 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4331, 1, 8656, 8672)
        slice_scatter_default_4332: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2166, add_1085, 2, 0, 16);  slice_tensor_2166 = add_1085 = None
        slice_scatter_default_4333: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4331, slice_scatter_default_4332, 1, 8656, 8672);  slice_scatter_default_4331 = slice_scatter_default_4332 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35753: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4333, 1, 8656, 8672)
        slice_35754: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35753, 2, 0, 16);  slice_35753 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4333, 1, 8656, 8672)
        slice_scatter_default_4334: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2167, slice_35754, 2, 0, 16);  slice_tensor_2167 = slice_35754 = None
        slice_scatter_default_4335: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4333, slice_scatter_default_4334, 1, 8656, 8672);  slice_scatter_default_4333 = slice_scatter_default_4334 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35773: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8672, 8688)
        slice_35774: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35773, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1087: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35774, memory_format = torch.contiguous_format);  slice_35774 = None
        view_2178: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1087, [32, 16]);  clone_1087 = None
        mm_1084: "f32[32, 8]" = torch.ops.aten.mm.default(view_2178, slice_7)
        view_2179: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1084, [2, 16, 8]);  mm_1084 = None
        slice_35781: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4335, 1, 8672, 8688)
        slice_35782: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35781, 2, 0, 16);  slice_35781 = None
        add_1086: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35782, view_2179);  slice_35782 = view_2179 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4335, 1, 8672, 8688)
        slice_scatter_default_4336: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2168, add_1086, 2, 0, 16);  slice_tensor_2168 = add_1086 = None
        slice_scatter_default_4337: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4335, slice_scatter_default_4336, 1, 8672, 8688);  slice_scatter_default_4335 = slice_scatter_default_4336 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35786: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4337, 1, 8672, 8688)
        slice_35787: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35786, 2, 0, 16);  slice_35786 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2169: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4337, 1, 8672, 8688)
        slice_scatter_default_4338: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2169, slice_35787, 2, 0, 16);  slice_tensor_2169 = slice_35787 = None
        slice_scatter_default_4339: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4337, slice_scatter_default_4338, 1, 8672, 8688);  slice_scatter_default_4337 = slice_scatter_default_4338 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35807: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35773, 2, 16, 32);  slice_35773 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1088: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35807, memory_format = torch.contiguous_format);  slice_35807 = None
        view_2180: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1088, [32, 11]);  clone_1088 = None
        mm_1085: "f32[32, 8]" = torch.ops.aten.mm.default(view_2180, slice_37)
        view_2181: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1085, [2, 16, 8]);  mm_1085 = None
        slice_35814: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4339, 1, 8672, 8688)
        slice_35815: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35814, 2, 0, 16);  slice_35814 = None
        add_1087: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35815, view_2181);  slice_35815 = view_2181 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4339, 1, 8672, 8688)
        slice_scatter_default_4340: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2170, add_1087, 2, 0, 16);  slice_tensor_2170 = add_1087 = None
        slice_scatter_default_4341: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4339, slice_scatter_default_4340, 1, 8672, 8688);  slice_scatter_default_4339 = slice_scatter_default_4340 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35819: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4341, 1, 8672, 8688)
        slice_35820: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35819, 2, 0, 16);  slice_35819 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4341, 1, 8672, 8688)
        slice_scatter_default_4342: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2171, slice_35820, 2, 0, 16);  slice_tensor_2171 = slice_35820 = None
        slice_scatter_default_4343: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4341, slice_scatter_default_4342, 1, 8672, 8688);  slice_scatter_default_4341 = slice_scatter_default_4342 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35839: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8688, 8704)
        slice_35840: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35839, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1089: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35840, memory_format = torch.contiguous_format);  slice_35840 = None
        view_2182: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1089, [32, 16]);  clone_1089 = None
        mm_1086: "f32[32, 8]" = torch.ops.aten.mm.default(view_2182, slice_7)
        view_2183: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1086, [2, 16, 8]);  mm_1086 = None
        slice_35847: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4343, 1, 8688, 8704)
        slice_35848: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35847, 2, 0, 16);  slice_35847 = None
        add_1088: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35848, view_2183);  slice_35848 = view_2183 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4343, 1, 8688, 8704)
        slice_scatter_default_4344: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2172, add_1088, 2, 0, 16);  slice_tensor_2172 = add_1088 = None
        slice_scatter_default_4345: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4343, slice_scatter_default_4344, 1, 8688, 8704);  slice_scatter_default_4343 = slice_scatter_default_4344 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35852: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4345, 1, 8688, 8704)
        slice_35853: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35852, 2, 0, 16);  slice_35852 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4345, 1, 8688, 8704)
        slice_scatter_default_4346: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2173, slice_35853, 2, 0, 16);  slice_tensor_2173 = slice_35853 = None
        slice_scatter_default_4347: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4345, slice_scatter_default_4346, 1, 8688, 8704);  slice_scatter_default_4345 = slice_scatter_default_4346 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35873: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35839, 2, 16, 32);  slice_35839 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1090: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35873, memory_format = torch.contiguous_format);  slice_35873 = None
        view_2184: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1090, [32, 11]);  clone_1090 = None
        mm_1087: "f32[32, 8]" = torch.ops.aten.mm.default(view_2184, slice_37)
        view_2185: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1087, [2, 16, 8]);  mm_1087 = None
        slice_35880: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4347, 1, 8688, 8704)
        slice_35881: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35880, 2, 0, 16);  slice_35880 = None
        add_1089: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35881, view_2185);  slice_35881 = view_2185 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2174: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4347, 1, 8688, 8704)
        slice_scatter_default_4348: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2174, add_1089, 2, 0, 16);  slice_tensor_2174 = add_1089 = None
        slice_scatter_default_4349: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4347, slice_scatter_default_4348, 1, 8688, 8704);  slice_scatter_default_4347 = slice_scatter_default_4348 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35885: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4349, 1, 8688, 8704)
        slice_35886: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35885, 2, 0, 16);  slice_35885 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4349, 1, 8688, 8704)
        slice_scatter_default_4350: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2175, slice_35886, 2, 0, 16);  slice_tensor_2175 = slice_35886 = None
        slice_scatter_default_4351: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4349, slice_scatter_default_4350, 1, 8688, 8704);  slice_scatter_default_4349 = slice_scatter_default_4350 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35905: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8704, 8720)
        slice_35906: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35905, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1091: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35906, memory_format = torch.contiguous_format);  slice_35906 = None
        view_2186: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1091, [32, 16]);  clone_1091 = None
        mm_1088: "f32[32, 8]" = torch.ops.aten.mm.default(view_2186, slice_7)
        view_2187: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1088, [2, 16, 8]);  mm_1088 = None
        slice_35913: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4351, 1, 8704, 8720)
        slice_35914: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35913, 2, 0, 16);  slice_35913 = None
        add_1090: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35914, view_2187);  slice_35914 = view_2187 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4351, 1, 8704, 8720)
        slice_scatter_default_4352: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2176, add_1090, 2, 0, 16);  slice_tensor_2176 = add_1090 = None
        slice_scatter_default_4353: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4351, slice_scatter_default_4352, 1, 8704, 8720);  slice_scatter_default_4351 = slice_scatter_default_4352 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35918: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4353, 1, 8704, 8720)
        slice_35919: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35918, 2, 0, 16);  slice_35918 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4353, 1, 8704, 8720)
        slice_scatter_default_4354: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2177, slice_35919, 2, 0, 16);  slice_tensor_2177 = slice_35919 = None
        slice_scatter_default_4355: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4353, slice_scatter_default_4354, 1, 8704, 8720);  slice_scatter_default_4353 = slice_scatter_default_4354 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35939: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35905, 2, 16, 32);  slice_35905 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1092: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_35939, memory_format = torch.contiguous_format);  slice_35939 = None
        view_2188: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1092, [32, 11]);  clone_1092 = None
        mm_1089: "f32[32, 8]" = torch.ops.aten.mm.default(view_2188, slice_37)
        view_2189: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1089, [2, 16, 8]);  mm_1089 = None
        slice_35946: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4355, 1, 8704, 8720)
        slice_35947: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35946, 2, 0, 16);  slice_35946 = None
        add_1091: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35947, view_2189);  slice_35947 = view_2189 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4355, 1, 8704, 8720)
        slice_scatter_default_4356: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2178, add_1091, 2, 0, 16);  slice_tensor_2178 = add_1091 = None
        slice_scatter_default_4357: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4355, slice_scatter_default_4356, 1, 8704, 8720);  slice_scatter_default_4355 = slice_scatter_default_4356 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35951: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4357, 1, 8704, 8720)
        slice_35952: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35951, 2, 0, 16);  slice_35951 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2179: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4357, 1, 8704, 8720)
        slice_scatter_default_4358: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2179, slice_35952, 2, 0, 16);  slice_tensor_2179 = slice_35952 = None
        slice_scatter_default_4359: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4357, slice_scatter_default_4358, 1, 8704, 8720);  slice_scatter_default_4357 = slice_scatter_default_4358 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_35971: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8720, 8736)
        slice_35972: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_35971, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1093: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_35972, memory_format = torch.contiguous_format);  slice_35972 = None
        view_2190: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1093, [32, 16]);  clone_1093 = None
        mm_1090: "f32[32, 8]" = torch.ops.aten.mm.default(view_2190, slice_7)
        view_2191: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1090, [2, 16, 8]);  mm_1090 = None
        slice_35979: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4359, 1, 8720, 8736)
        slice_35980: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35979, 2, 0, 16);  slice_35979 = None
        add_1092: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_35980, view_2191);  slice_35980 = view_2191 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4359, 1, 8720, 8736)
        slice_scatter_default_4360: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2180, add_1092, 2, 0, 16);  slice_tensor_2180 = add_1092 = None
        slice_scatter_default_4361: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4359, slice_scatter_default_4360, 1, 8720, 8736);  slice_scatter_default_4359 = slice_scatter_default_4360 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_35984: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4361, 1, 8720, 8736)
        slice_35985: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_35984, 2, 0, 16);  slice_35984 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4361, 1, 8720, 8736)
        slice_scatter_default_4362: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2181, slice_35985, 2, 0, 16);  slice_tensor_2181 = slice_35985 = None
        slice_scatter_default_4363: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4361, slice_scatter_default_4362, 1, 8720, 8736);  slice_scatter_default_4361 = slice_scatter_default_4362 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36005: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_35971, 2, 16, 32);  slice_35971 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1094: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36005, memory_format = torch.contiguous_format);  slice_36005 = None
        view_2192: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1094, [32, 11]);  clone_1094 = None
        mm_1091: "f32[32, 8]" = torch.ops.aten.mm.default(view_2192, slice_37)
        view_2193: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1091, [2, 16, 8]);  mm_1091 = None
        slice_36012: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4363, 1, 8720, 8736)
        slice_36013: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36012, 2, 0, 16);  slice_36012 = None
        add_1093: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36013, view_2193);  slice_36013 = view_2193 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4363, 1, 8720, 8736)
        slice_scatter_default_4364: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2182, add_1093, 2, 0, 16);  slice_tensor_2182 = add_1093 = None
        slice_scatter_default_4365: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4363, slice_scatter_default_4364, 1, 8720, 8736);  slice_scatter_default_4363 = slice_scatter_default_4364 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36017: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4365, 1, 8720, 8736)
        slice_36018: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36017, 2, 0, 16);  slice_36017 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4365, 1, 8720, 8736)
        slice_scatter_default_4366: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2183, slice_36018, 2, 0, 16);  slice_tensor_2183 = slice_36018 = None
        slice_scatter_default_4367: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4365, slice_scatter_default_4366, 1, 8720, 8736);  slice_scatter_default_4365 = slice_scatter_default_4366 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36037: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8736, 8752)
        slice_36038: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36037, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1095: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36038, memory_format = torch.contiguous_format);  slice_36038 = None
        view_2194: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1095, [32, 16]);  clone_1095 = None
        mm_1092: "f32[32, 8]" = torch.ops.aten.mm.default(view_2194, slice_7)
        view_2195: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1092, [2, 16, 8]);  mm_1092 = None
        slice_36045: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4367, 1, 8736, 8752)
        slice_36046: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36045, 2, 0, 16);  slice_36045 = None
        add_1094: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36046, view_2195);  slice_36046 = view_2195 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2184: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4367, 1, 8736, 8752)
        slice_scatter_default_4368: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2184, add_1094, 2, 0, 16);  slice_tensor_2184 = add_1094 = None
        slice_scatter_default_4369: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4367, slice_scatter_default_4368, 1, 8736, 8752);  slice_scatter_default_4367 = slice_scatter_default_4368 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36050: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4369, 1, 8736, 8752)
        slice_36051: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36050, 2, 0, 16);  slice_36050 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4369, 1, 8736, 8752)
        slice_scatter_default_4370: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2185, slice_36051, 2, 0, 16);  slice_tensor_2185 = slice_36051 = None
        slice_scatter_default_4371: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4369, slice_scatter_default_4370, 1, 8736, 8752);  slice_scatter_default_4369 = slice_scatter_default_4370 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36071: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36037, 2, 16, 32);  slice_36037 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1096: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36071, memory_format = torch.contiguous_format);  slice_36071 = None
        view_2196: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1096, [32, 11]);  clone_1096 = None
        mm_1093: "f32[32, 8]" = torch.ops.aten.mm.default(view_2196, slice_37)
        view_2197: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1093, [2, 16, 8]);  mm_1093 = None
        slice_36078: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4371, 1, 8736, 8752)
        slice_36079: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36078, 2, 0, 16);  slice_36078 = None
        add_1095: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36079, view_2197);  slice_36079 = view_2197 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4371, 1, 8736, 8752)
        slice_scatter_default_4372: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2186, add_1095, 2, 0, 16);  slice_tensor_2186 = add_1095 = None
        slice_scatter_default_4373: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4371, slice_scatter_default_4372, 1, 8736, 8752);  slice_scatter_default_4371 = slice_scatter_default_4372 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36083: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4373, 1, 8736, 8752)
        slice_36084: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36083, 2, 0, 16);  slice_36083 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2187: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4373, 1, 8736, 8752)
        slice_scatter_default_4374: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2187, slice_36084, 2, 0, 16);  slice_tensor_2187 = slice_36084 = None
        slice_scatter_default_4375: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4373, slice_scatter_default_4374, 1, 8736, 8752);  slice_scatter_default_4373 = slice_scatter_default_4374 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36103: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8752, 8768)
        slice_36104: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36103, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1097: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36104, memory_format = torch.contiguous_format);  slice_36104 = None
        view_2198: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1097, [32, 16]);  clone_1097 = None
        mm_1094: "f32[32, 8]" = torch.ops.aten.mm.default(view_2198, slice_7)
        view_2199: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1094, [2, 16, 8]);  mm_1094 = None
        slice_36111: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4375, 1, 8752, 8768)
        slice_36112: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36111, 2, 0, 16);  slice_36111 = None
        add_1096: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36112, view_2199);  slice_36112 = view_2199 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2188: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4375, 1, 8752, 8768)
        slice_scatter_default_4376: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2188, add_1096, 2, 0, 16);  slice_tensor_2188 = add_1096 = None
        slice_scatter_default_4377: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4375, slice_scatter_default_4376, 1, 8752, 8768);  slice_scatter_default_4375 = slice_scatter_default_4376 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36116: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4377, 1, 8752, 8768)
        slice_36117: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36116, 2, 0, 16);  slice_36116 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2189: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4377, 1, 8752, 8768)
        slice_scatter_default_4378: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2189, slice_36117, 2, 0, 16);  slice_tensor_2189 = slice_36117 = None
        slice_scatter_default_4379: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4377, slice_scatter_default_4378, 1, 8752, 8768);  slice_scatter_default_4377 = slice_scatter_default_4378 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36137: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36103, 2, 16, 32);  slice_36103 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1098: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36137, memory_format = torch.contiguous_format);  slice_36137 = None
        view_2200: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1098, [32, 11]);  clone_1098 = None
        mm_1095: "f32[32, 8]" = torch.ops.aten.mm.default(view_2200, slice_37)
        view_2201: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1095, [2, 16, 8]);  mm_1095 = None
        slice_36144: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4379, 1, 8752, 8768)
        slice_36145: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36144, 2, 0, 16);  slice_36144 = None
        add_1097: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36145, view_2201);  slice_36145 = view_2201 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4379, 1, 8752, 8768)
        slice_scatter_default_4380: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2190, add_1097, 2, 0, 16);  slice_tensor_2190 = add_1097 = None
        slice_scatter_default_4381: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4379, slice_scatter_default_4380, 1, 8752, 8768);  slice_scatter_default_4379 = slice_scatter_default_4380 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36149: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4381, 1, 8752, 8768)
        slice_36150: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36149, 2, 0, 16);  slice_36149 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4381, 1, 8752, 8768)
        slice_scatter_default_4382: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2191, slice_36150, 2, 0, 16);  slice_tensor_2191 = slice_36150 = None
        slice_scatter_default_4383: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4381, slice_scatter_default_4382, 1, 8752, 8768);  slice_scatter_default_4381 = slice_scatter_default_4382 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36169: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8768, 8784)
        slice_36170: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36169, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1099: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36170, memory_format = torch.contiguous_format);  slice_36170 = None
        view_2202: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1099, [32, 16]);  clone_1099 = None
        mm_1096: "f32[32, 8]" = torch.ops.aten.mm.default(view_2202, slice_7)
        view_2203: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1096, [2, 16, 8]);  mm_1096 = None
        slice_36177: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4383, 1, 8768, 8784)
        slice_36178: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36177, 2, 0, 16);  slice_36177 = None
        add_1098: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36178, view_2203);  slice_36178 = view_2203 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2192: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4383, 1, 8768, 8784)
        slice_scatter_default_4384: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2192, add_1098, 2, 0, 16);  slice_tensor_2192 = add_1098 = None
        slice_scatter_default_4385: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4383, slice_scatter_default_4384, 1, 8768, 8784);  slice_scatter_default_4383 = slice_scatter_default_4384 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36182: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4385, 1, 8768, 8784)
        slice_36183: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36182, 2, 0, 16);  slice_36182 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4385, 1, 8768, 8784)
        slice_scatter_default_4386: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2193, slice_36183, 2, 0, 16);  slice_tensor_2193 = slice_36183 = None
        slice_scatter_default_4387: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4385, slice_scatter_default_4386, 1, 8768, 8784);  slice_scatter_default_4385 = slice_scatter_default_4386 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36203: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36169, 2, 16, 32);  slice_36169 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1100: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36203, memory_format = torch.contiguous_format);  slice_36203 = None
        view_2204: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1100, [32, 11]);  clone_1100 = None
        mm_1097: "f32[32, 8]" = torch.ops.aten.mm.default(view_2204, slice_37)
        view_2205: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1097, [2, 16, 8]);  mm_1097 = None
        slice_36210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4387, 1, 8768, 8784)
        slice_36211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36210, 2, 0, 16);  slice_36210 = None
        add_1099: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36211, view_2205);  slice_36211 = view_2205 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4387, 1, 8768, 8784)
        slice_scatter_default_4388: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2194, add_1099, 2, 0, 16);  slice_tensor_2194 = add_1099 = None
        slice_scatter_default_4389: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4387, slice_scatter_default_4388, 1, 8768, 8784);  slice_scatter_default_4387 = slice_scatter_default_4388 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4389, 1, 8768, 8784)
        slice_36216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36215, 2, 0, 16);  slice_36215 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4389, 1, 8768, 8784)
        slice_scatter_default_4390: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2195, slice_36216, 2, 0, 16);  slice_tensor_2195 = slice_36216 = None
        slice_scatter_default_4391: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4389, slice_scatter_default_4390, 1, 8768, 8784);  slice_scatter_default_4389 = slice_scatter_default_4390 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36235: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8784, 8800)
        slice_36236: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36235, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1101: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36236, memory_format = torch.contiguous_format);  slice_36236 = None
        view_2206: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1101, [32, 16]);  clone_1101 = None
        mm_1098: "f32[32, 8]" = torch.ops.aten.mm.default(view_2206, slice_7)
        view_2207: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1098, [2, 16, 8]);  mm_1098 = None
        slice_36243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4391, 1, 8784, 8800)
        slice_36244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36243, 2, 0, 16);  slice_36243 = None
        add_1100: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36244, view_2207);  slice_36244 = view_2207 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4391, 1, 8784, 8800)
        slice_scatter_default_4392: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2196, add_1100, 2, 0, 16);  slice_tensor_2196 = add_1100 = None
        slice_scatter_default_4393: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4391, slice_scatter_default_4392, 1, 8784, 8800);  slice_scatter_default_4391 = slice_scatter_default_4392 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4393, 1, 8784, 8800)
        slice_36249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36248, 2, 0, 16);  slice_36248 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2197: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4393, 1, 8784, 8800)
        slice_scatter_default_4394: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2197, slice_36249, 2, 0, 16);  slice_tensor_2197 = slice_36249 = None
        slice_scatter_default_4395: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4393, slice_scatter_default_4394, 1, 8784, 8800);  slice_scatter_default_4393 = slice_scatter_default_4394 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36269: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36235, 2, 16, 32);  slice_36235 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1102: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36269, memory_format = torch.contiguous_format);  slice_36269 = None
        view_2208: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1102, [32, 11]);  clone_1102 = None
        mm_1099: "f32[32, 8]" = torch.ops.aten.mm.default(view_2208, slice_37)
        view_2209: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1099, [2, 16, 8]);  mm_1099 = None
        slice_36276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4395, 1, 8784, 8800)
        slice_36277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36276, 2, 0, 16);  slice_36276 = None
        add_1101: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36277, view_2209);  slice_36277 = view_2209 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4395, 1, 8784, 8800)
        slice_scatter_default_4396: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2198, add_1101, 2, 0, 16);  slice_tensor_2198 = add_1101 = None
        slice_scatter_default_4397: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4395, slice_scatter_default_4396, 1, 8784, 8800);  slice_scatter_default_4395 = slice_scatter_default_4396 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4397, 1, 8784, 8800)
        slice_36282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36281, 2, 0, 16);  slice_36281 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4397, 1, 8784, 8800)
        slice_scatter_default_4398: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2199, slice_36282, 2, 0, 16);  slice_tensor_2199 = slice_36282 = None
        slice_scatter_default_4399: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4397, slice_scatter_default_4398, 1, 8784, 8800);  slice_scatter_default_4397 = slice_scatter_default_4398 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36301: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8800, 8816)
        slice_36302: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36301, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1103: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36302, memory_format = torch.contiguous_format);  slice_36302 = None
        view_2210: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1103, [32, 16]);  clone_1103 = None
        mm_1100: "f32[32, 8]" = torch.ops.aten.mm.default(view_2210, slice_7)
        view_2211: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1100, [2, 16, 8]);  mm_1100 = None
        slice_36309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4399, 1, 8800, 8816)
        slice_36310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36309, 2, 0, 16);  slice_36309 = None
        add_1102: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36310, view_2211);  slice_36310 = view_2211 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4399, 1, 8800, 8816)
        slice_scatter_default_4400: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2200, add_1102, 2, 0, 16);  slice_tensor_2200 = add_1102 = None
        slice_scatter_default_4401: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4399, slice_scatter_default_4400, 1, 8800, 8816);  slice_scatter_default_4399 = slice_scatter_default_4400 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4401, 1, 8800, 8816)
        slice_36315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36314, 2, 0, 16);  slice_36314 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4401, 1, 8800, 8816)
        slice_scatter_default_4402: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2201, slice_36315, 2, 0, 16);  slice_tensor_2201 = slice_36315 = None
        slice_scatter_default_4403: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4401, slice_scatter_default_4402, 1, 8800, 8816);  slice_scatter_default_4401 = slice_scatter_default_4402 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36335: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36301, 2, 16, 32);  slice_36301 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1104: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36335, memory_format = torch.contiguous_format);  slice_36335 = None
        view_2212: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1104, [32, 11]);  clone_1104 = None
        mm_1101: "f32[32, 8]" = torch.ops.aten.mm.default(view_2212, slice_37)
        view_2213: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1101, [2, 16, 8]);  mm_1101 = None
        slice_36342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4403, 1, 8800, 8816)
        slice_36343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36342, 2, 0, 16);  slice_36342 = None
        add_1103: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36343, view_2213);  slice_36343 = view_2213 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2202: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4403, 1, 8800, 8816)
        slice_scatter_default_4404: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2202, add_1103, 2, 0, 16);  slice_tensor_2202 = add_1103 = None
        slice_scatter_default_4405: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4403, slice_scatter_default_4404, 1, 8800, 8816);  slice_scatter_default_4403 = slice_scatter_default_4404 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4405, 1, 8800, 8816)
        slice_36348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36347, 2, 0, 16);  slice_36347 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4405, 1, 8800, 8816)
        slice_scatter_default_4406: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2203, slice_36348, 2, 0, 16);  slice_tensor_2203 = slice_36348 = None
        slice_scatter_default_4407: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4405, slice_scatter_default_4406, 1, 8800, 8816);  slice_scatter_default_4405 = slice_scatter_default_4406 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36367: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8816, 8832)
        slice_36368: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36367, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1105: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36368, memory_format = torch.contiguous_format);  slice_36368 = None
        view_2214: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1105, [32, 16]);  clone_1105 = None
        mm_1102: "f32[32, 8]" = torch.ops.aten.mm.default(view_2214, slice_7)
        view_2215: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1102, [2, 16, 8]);  mm_1102 = None
        slice_36375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4407, 1, 8816, 8832)
        slice_36376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36375, 2, 0, 16);  slice_36375 = None
        add_1104: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36376, view_2215);  slice_36376 = view_2215 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4407, 1, 8816, 8832)
        slice_scatter_default_4408: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2204, add_1104, 2, 0, 16);  slice_tensor_2204 = add_1104 = None
        slice_scatter_default_4409: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4407, slice_scatter_default_4408, 1, 8816, 8832);  slice_scatter_default_4407 = slice_scatter_default_4408 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4409, 1, 8816, 8832)
        slice_36381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36380, 2, 0, 16);  slice_36380 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4409, 1, 8816, 8832)
        slice_scatter_default_4410: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2205, slice_36381, 2, 0, 16);  slice_tensor_2205 = slice_36381 = None
        slice_scatter_default_4411: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4409, slice_scatter_default_4410, 1, 8816, 8832);  slice_scatter_default_4409 = slice_scatter_default_4410 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36401: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36367, 2, 16, 32);  slice_36367 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1106: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36401, memory_format = torch.contiguous_format);  slice_36401 = None
        view_2216: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1106, [32, 11]);  clone_1106 = None
        mm_1103: "f32[32, 8]" = torch.ops.aten.mm.default(view_2216, slice_37)
        view_2217: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1103, [2, 16, 8]);  mm_1103 = None
        slice_36408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4411, 1, 8816, 8832)
        slice_36409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36408, 2, 0, 16);  slice_36408 = None
        add_1105: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36409, view_2217);  slice_36409 = view_2217 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4411, 1, 8816, 8832)
        slice_scatter_default_4412: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2206, add_1105, 2, 0, 16);  slice_tensor_2206 = add_1105 = None
        slice_scatter_default_4413: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4411, slice_scatter_default_4412, 1, 8816, 8832);  slice_scatter_default_4411 = slice_scatter_default_4412 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4413, 1, 8816, 8832)
        slice_36414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36413, 2, 0, 16);  slice_36413 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2207: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4413, 1, 8816, 8832)
        slice_scatter_default_4414: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2207, slice_36414, 2, 0, 16);  slice_tensor_2207 = slice_36414 = None
        slice_scatter_default_4415: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4413, slice_scatter_default_4414, 1, 8816, 8832);  slice_scatter_default_4413 = slice_scatter_default_4414 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36433: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8832, 8848)
        slice_36434: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36433, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1107: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36434, memory_format = torch.contiguous_format);  slice_36434 = None
        view_2218: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1107, [32, 16]);  clone_1107 = None
        mm_1104: "f32[32, 8]" = torch.ops.aten.mm.default(view_2218, slice_7)
        view_2219: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1104, [2, 16, 8]);  mm_1104 = None
        slice_36441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4415, 1, 8832, 8848)
        slice_36442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36441, 2, 0, 16);  slice_36441 = None
        add_1106: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36442, view_2219);  slice_36442 = view_2219 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4415, 1, 8832, 8848)
        slice_scatter_default_4416: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2208, add_1106, 2, 0, 16);  slice_tensor_2208 = add_1106 = None
        slice_scatter_default_4417: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4415, slice_scatter_default_4416, 1, 8832, 8848);  slice_scatter_default_4415 = slice_scatter_default_4416 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4417, 1, 8832, 8848)
        slice_36447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36446, 2, 0, 16);  slice_36446 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4417, 1, 8832, 8848)
        slice_scatter_default_4418: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2209, slice_36447, 2, 0, 16);  slice_tensor_2209 = slice_36447 = None
        slice_scatter_default_4419: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4417, slice_scatter_default_4418, 1, 8832, 8848);  slice_scatter_default_4417 = slice_scatter_default_4418 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36467: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36433, 2, 16, 32);  slice_36433 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1108: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36467, memory_format = torch.contiguous_format);  slice_36467 = None
        view_2220: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1108, [32, 11]);  clone_1108 = None
        mm_1105: "f32[32, 8]" = torch.ops.aten.mm.default(view_2220, slice_37)
        view_2221: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1105, [2, 16, 8]);  mm_1105 = None
        slice_36474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4419, 1, 8832, 8848)
        slice_36475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36474, 2, 0, 16);  slice_36474 = None
        add_1107: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36475, view_2221);  slice_36475 = view_2221 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2210: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4419, 1, 8832, 8848)
        slice_scatter_default_4420: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2210, add_1107, 2, 0, 16);  slice_tensor_2210 = add_1107 = None
        slice_scatter_default_4421: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4419, slice_scatter_default_4420, 1, 8832, 8848);  slice_scatter_default_4419 = slice_scatter_default_4420 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4421, 1, 8832, 8848)
        slice_36480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36479, 2, 0, 16);  slice_36479 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2211: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4421, 1, 8832, 8848)
        slice_scatter_default_4422: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2211, slice_36480, 2, 0, 16);  slice_tensor_2211 = slice_36480 = None
        slice_scatter_default_4423: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4421, slice_scatter_default_4422, 1, 8832, 8848);  slice_scatter_default_4421 = slice_scatter_default_4422 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36499: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8848, 8864)
        slice_36500: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36499, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1109: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36500, memory_format = torch.contiguous_format);  slice_36500 = None
        view_2222: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1109, [32, 16]);  clone_1109 = None
        mm_1106: "f32[32, 8]" = torch.ops.aten.mm.default(view_2222, slice_7)
        view_2223: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1106, [2, 16, 8]);  mm_1106 = None
        slice_36507: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4423, 1, 8848, 8864)
        slice_36508: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36507, 2, 0, 16);  slice_36507 = None
        add_1108: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36508, view_2223);  slice_36508 = view_2223 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2212: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4423, 1, 8848, 8864)
        slice_scatter_default_4424: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2212, add_1108, 2, 0, 16);  slice_tensor_2212 = add_1108 = None
        slice_scatter_default_4425: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4423, slice_scatter_default_4424, 1, 8848, 8864);  slice_scatter_default_4423 = slice_scatter_default_4424 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36512: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4425, 1, 8848, 8864)
        slice_36513: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36512, 2, 0, 16);  slice_36512 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4425, 1, 8848, 8864)
        slice_scatter_default_4426: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2213, slice_36513, 2, 0, 16);  slice_tensor_2213 = slice_36513 = None
        slice_scatter_default_4427: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4425, slice_scatter_default_4426, 1, 8848, 8864);  slice_scatter_default_4425 = slice_scatter_default_4426 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36533: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36499, 2, 16, 32);  slice_36499 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1110: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36533, memory_format = torch.contiguous_format);  slice_36533 = None
        view_2224: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1110, [32, 11]);  clone_1110 = None
        mm_1107: "f32[32, 8]" = torch.ops.aten.mm.default(view_2224, slice_37)
        view_2225: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1107, [2, 16, 8]);  mm_1107 = None
        slice_36540: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4427, 1, 8848, 8864)
        slice_36541: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36540, 2, 0, 16);  slice_36540 = None
        add_1109: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36541, view_2225);  slice_36541 = view_2225 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4427, 1, 8848, 8864)
        slice_scatter_default_4428: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2214, add_1109, 2, 0, 16);  slice_tensor_2214 = add_1109 = None
        slice_scatter_default_4429: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4427, slice_scatter_default_4428, 1, 8848, 8864);  slice_scatter_default_4427 = slice_scatter_default_4428 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36545: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4429, 1, 8848, 8864)
        slice_36546: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36545, 2, 0, 16);  slice_36545 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2215: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4429, 1, 8848, 8864)
        slice_scatter_default_4430: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2215, slice_36546, 2, 0, 16);  slice_tensor_2215 = slice_36546 = None
        slice_scatter_default_4431: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4429, slice_scatter_default_4430, 1, 8848, 8864);  slice_scatter_default_4429 = slice_scatter_default_4430 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36565: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8864, 8880)
        slice_36566: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36565, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1111: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36566, memory_format = torch.contiguous_format);  slice_36566 = None
        view_2226: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1111, [32, 16]);  clone_1111 = None
        mm_1108: "f32[32, 8]" = torch.ops.aten.mm.default(view_2226, slice_7)
        view_2227: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1108, [2, 16, 8]);  mm_1108 = None
        slice_36573: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4431, 1, 8864, 8880)
        slice_36574: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36573, 2, 0, 16);  slice_36573 = None
        add_1110: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36574, view_2227);  slice_36574 = view_2227 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2216: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4431, 1, 8864, 8880)
        slice_scatter_default_4432: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2216, add_1110, 2, 0, 16);  slice_tensor_2216 = add_1110 = None
        slice_scatter_default_4433: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4431, slice_scatter_default_4432, 1, 8864, 8880);  slice_scatter_default_4431 = slice_scatter_default_4432 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36578: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4433, 1, 8864, 8880)
        slice_36579: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36578, 2, 0, 16);  slice_36578 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2217: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4433, 1, 8864, 8880)
        slice_scatter_default_4434: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2217, slice_36579, 2, 0, 16);  slice_tensor_2217 = slice_36579 = None
        slice_scatter_default_4435: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4433, slice_scatter_default_4434, 1, 8864, 8880);  slice_scatter_default_4433 = slice_scatter_default_4434 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36599: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36565, 2, 16, 32);  slice_36565 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1112: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36599, memory_format = torch.contiguous_format);  slice_36599 = None
        view_2228: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1112, [32, 11]);  clone_1112 = None
        mm_1109: "f32[32, 8]" = torch.ops.aten.mm.default(view_2228, slice_37)
        view_2229: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1109, [2, 16, 8]);  mm_1109 = None
        slice_36606: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4435, 1, 8864, 8880)
        slice_36607: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36606, 2, 0, 16);  slice_36606 = None
        add_1111: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36607, view_2229);  slice_36607 = view_2229 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4435, 1, 8864, 8880)
        slice_scatter_default_4436: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2218, add_1111, 2, 0, 16);  slice_tensor_2218 = add_1111 = None
        slice_scatter_default_4437: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4435, slice_scatter_default_4436, 1, 8864, 8880);  slice_scatter_default_4435 = slice_scatter_default_4436 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36611: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4437, 1, 8864, 8880)
        slice_36612: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36611, 2, 0, 16);  slice_36611 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4437, 1, 8864, 8880)
        slice_scatter_default_4438: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2219, slice_36612, 2, 0, 16);  slice_tensor_2219 = slice_36612 = None
        slice_scatter_default_4439: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4437, slice_scatter_default_4438, 1, 8864, 8880);  slice_scatter_default_4437 = slice_scatter_default_4438 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36631: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8880, 8896)
        slice_36632: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36631, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1113: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36632, memory_format = torch.contiguous_format);  slice_36632 = None
        view_2230: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1113, [32, 16]);  clone_1113 = None
        mm_1110: "f32[32, 8]" = torch.ops.aten.mm.default(view_2230, slice_7)
        view_2231: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1110, [2, 16, 8]);  mm_1110 = None
        slice_36639: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4439, 1, 8880, 8896)
        slice_36640: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36639, 2, 0, 16);  slice_36639 = None
        add_1112: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36640, view_2231);  slice_36640 = view_2231 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2220: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4439, 1, 8880, 8896)
        slice_scatter_default_4440: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2220, add_1112, 2, 0, 16);  slice_tensor_2220 = add_1112 = None
        slice_scatter_default_4441: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4439, slice_scatter_default_4440, 1, 8880, 8896);  slice_scatter_default_4439 = slice_scatter_default_4440 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36644: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4441, 1, 8880, 8896)
        slice_36645: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36644, 2, 0, 16);  slice_36644 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2221: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4441, 1, 8880, 8896)
        slice_scatter_default_4442: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2221, slice_36645, 2, 0, 16);  slice_tensor_2221 = slice_36645 = None
        slice_scatter_default_4443: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4441, slice_scatter_default_4442, 1, 8880, 8896);  slice_scatter_default_4441 = slice_scatter_default_4442 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36665: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36631, 2, 16, 32);  slice_36631 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1114: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36665, memory_format = torch.contiguous_format);  slice_36665 = None
        view_2232: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1114, [32, 11]);  clone_1114 = None
        mm_1111: "f32[32, 8]" = torch.ops.aten.mm.default(view_2232, slice_37)
        view_2233: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1111, [2, 16, 8]);  mm_1111 = None
        slice_36672: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4443, 1, 8880, 8896)
        slice_36673: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36672, 2, 0, 16);  slice_36672 = None
        add_1113: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36673, view_2233);  slice_36673 = view_2233 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2222: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4443, 1, 8880, 8896)
        slice_scatter_default_4444: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2222, add_1113, 2, 0, 16);  slice_tensor_2222 = add_1113 = None
        slice_scatter_default_4445: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4443, slice_scatter_default_4444, 1, 8880, 8896);  slice_scatter_default_4443 = slice_scatter_default_4444 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36677: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4445, 1, 8880, 8896)
        slice_36678: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36677, 2, 0, 16);  slice_36677 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4445, 1, 8880, 8896)
        slice_scatter_default_4446: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2223, slice_36678, 2, 0, 16);  slice_tensor_2223 = slice_36678 = None
        slice_scatter_default_4447: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4445, slice_scatter_default_4446, 1, 8880, 8896);  slice_scatter_default_4445 = slice_scatter_default_4446 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36697: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8896, 8912)
        slice_36698: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36697, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1115: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36698, memory_format = torch.contiguous_format);  slice_36698 = None
        view_2234: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1115, [32, 16]);  clone_1115 = None
        mm_1112: "f32[32, 8]" = torch.ops.aten.mm.default(view_2234, slice_7)
        view_2235: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1112, [2, 16, 8]);  mm_1112 = None
        slice_36705: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4447, 1, 8896, 8912)
        slice_36706: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36705, 2, 0, 16);  slice_36705 = None
        add_1114: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36706, view_2235);  slice_36706 = view_2235 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4447, 1, 8896, 8912)
        slice_scatter_default_4448: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2224, add_1114, 2, 0, 16);  slice_tensor_2224 = add_1114 = None
        slice_scatter_default_4449: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4447, slice_scatter_default_4448, 1, 8896, 8912);  slice_scatter_default_4447 = slice_scatter_default_4448 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36710: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4449, 1, 8896, 8912)
        slice_36711: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36710, 2, 0, 16);  slice_36710 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2225: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4449, 1, 8896, 8912)
        slice_scatter_default_4450: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2225, slice_36711, 2, 0, 16);  slice_tensor_2225 = slice_36711 = None
        slice_scatter_default_4451: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4449, slice_scatter_default_4450, 1, 8896, 8912);  slice_scatter_default_4449 = slice_scatter_default_4450 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36731: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36697, 2, 16, 32);  slice_36697 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1116: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36731, memory_format = torch.contiguous_format);  slice_36731 = None
        view_2236: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1116, [32, 11]);  clone_1116 = None
        mm_1113: "f32[32, 8]" = torch.ops.aten.mm.default(view_2236, slice_37)
        view_2237: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1113, [2, 16, 8]);  mm_1113 = None
        slice_36738: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4451, 1, 8896, 8912)
        slice_36739: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36738, 2, 0, 16);  slice_36738 = None
        add_1115: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36739, view_2237);  slice_36739 = view_2237 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4451, 1, 8896, 8912)
        slice_scatter_default_4452: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2226, add_1115, 2, 0, 16);  slice_tensor_2226 = add_1115 = None
        slice_scatter_default_4453: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4451, slice_scatter_default_4452, 1, 8896, 8912);  slice_scatter_default_4451 = slice_scatter_default_4452 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36743: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4453, 1, 8896, 8912)
        slice_36744: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36743, 2, 0, 16);  slice_36743 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4453, 1, 8896, 8912)
        slice_scatter_default_4454: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2227, slice_36744, 2, 0, 16);  slice_tensor_2227 = slice_36744 = None
        slice_scatter_default_4455: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4453, slice_scatter_default_4454, 1, 8896, 8912);  slice_scatter_default_4453 = slice_scatter_default_4454 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36763: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8912, 8928)
        slice_36764: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36763, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1117: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36764, memory_format = torch.contiguous_format);  slice_36764 = None
        view_2238: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1117, [32, 16]);  clone_1117 = None
        mm_1114: "f32[32, 8]" = torch.ops.aten.mm.default(view_2238, slice_7)
        view_2239: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1114, [2, 16, 8]);  mm_1114 = None
        slice_36771: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4455, 1, 8912, 8928)
        slice_36772: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36771, 2, 0, 16);  slice_36771 = None
        add_1116: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36772, view_2239);  slice_36772 = view_2239 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4455, 1, 8912, 8928)
        slice_scatter_default_4456: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2228, add_1116, 2, 0, 16);  slice_tensor_2228 = add_1116 = None
        slice_scatter_default_4457: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4455, slice_scatter_default_4456, 1, 8912, 8928);  slice_scatter_default_4455 = slice_scatter_default_4456 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36776: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4457, 1, 8912, 8928)
        slice_36777: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36776, 2, 0, 16);  slice_36776 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4457, 1, 8912, 8928)
        slice_scatter_default_4458: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2229, slice_36777, 2, 0, 16);  slice_tensor_2229 = slice_36777 = None
        slice_scatter_default_4459: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4457, slice_scatter_default_4458, 1, 8912, 8928);  slice_scatter_default_4457 = slice_scatter_default_4458 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36797: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36763, 2, 16, 32);  slice_36763 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1118: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36797, memory_format = torch.contiguous_format);  slice_36797 = None
        view_2240: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1118, [32, 11]);  clone_1118 = None
        mm_1115: "f32[32, 8]" = torch.ops.aten.mm.default(view_2240, slice_37)
        view_2241: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1115, [2, 16, 8]);  mm_1115 = None
        slice_36804: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4459, 1, 8912, 8928)
        slice_36805: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36804, 2, 0, 16);  slice_36804 = None
        add_1117: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36805, view_2241);  slice_36805 = view_2241 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2230: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4459, 1, 8912, 8928)
        slice_scatter_default_4460: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2230, add_1117, 2, 0, 16);  slice_tensor_2230 = add_1117 = None
        slice_scatter_default_4461: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4459, slice_scatter_default_4460, 1, 8912, 8928);  slice_scatter_default_4459 = slice_scatter_default_4460 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36809: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4461, 1, 8912, 8928)
        slice_36810: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36809, 2, 0, 16);  slice_36809 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4461, 1, 8912, 8928)
        slice_scatter_default_4462: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2231, slice_36810, 2, 0, 16);  slice_tensor_2231 = slice_36810 = None
        slice_scatter_default_4463: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4461, slice_scatter_default_4462, 1, 8912, 8928);  slice_scatter_default_4461 = slice_scatter_default_4462 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36829: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8928, 8944)
        slice_36830: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36829, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1119: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36830, memory_format = torch.contiguous_format);  slice_36830 = None
        view_2242: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1119, [32, 16]);  clone_1119 = None
        mm_1116: "f32[32, 8]" = torch.ops.aten.mm.default(view_2242, slice_7)
        view_2243: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1116, [2, 16, 8]);  mm_1116 = None
        slice_36837: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4463, 1, 8928, 8944)
        slice_36838: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36837, 2, 0, 16);  slice_36837 = None
        add_1118: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36838, view_2243);  slice_36838 = view_2243 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4463, 1, 8928, 8944)
        slice_scatter_default_4464: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2232, add_1118, 2, 0, 16);  slice_tensor_2232 = add_1118 = None
        slice_scatter_default_4465: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4463, slice_scatter_default_4464, 1, 8928, 8944);  slice_scatter_default_4463 = slice_scatter_default_4464 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36842: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4465, 1, 8928, 8944)
        slice_36843: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36842, 2, 0, 16);  slice_36842 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4465, 1, 8928, 8944)
        slice_scatter_default_4466: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2233, slice_36843, 2, 0, 16);  slice_tensor_2233 = slice_36843 = None
        slice_scatter_default_4467: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4465, slice_scatter_default_4466, 1, 8928, 8944);  slice_scatter_default_4465 = slice_scatter_default_4466 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36863: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36829, 2, 16, 32);  slice_36829 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1120: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36863, memory_format = torch.contiguous_format);  slice_36863 = None
        view_2244: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1120, [32, 11]);  clone_1120 = None
        mm_1117: "f32[32, 8]" = torch.ops.aten.mm.default(view_2244, slice_37)
        view_2245: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1117, [2, 16, 8]);  mm_1117 = None
        slice_36870: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4467, 1, 8928, 8944)
        slice_36871: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36870, 2, 0, 16);  slice_36870 = None
        add_1119: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36871, view_2245);  slice_36871 = view_2245 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4467, 1, 8928, 8944)
        slice_scatter_default_4468: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2234, add_1119, 2, 0, 16);  slice_tensor_2234 = add_1119 = None
        slice_scatter_default_4469: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4467, slice_scatter_default_4468, 1, 8928, 8944);  slice_scatter_default_4467 = slice_scatter_default_4468 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36875: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4469, 1, 8928, 8944)
        slice_36876: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36875, 2, 0, 16);  slice_36875 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2235: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4469, 1, 8928, 8944)
        slice_scatter_default_4470: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2235, slice_36876, 2, 0, 16);  slice_tensor_2235 = slice_36876 = None
        slice_scatter_default_4471: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4469, slice_scatter_default_4470, 1, 8928, 8944);  slice_scatter_default_4469 = slice_scatter_default_4470 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36895: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8944, 8960)
        slice_36896: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36895, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1121: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36896, memory_format = torch.contiguous_format);  slice_36896 = None
        view_2246: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1121, [32, 16]);  clone_1121 = None
        mm_1118: "f32[32, 8]" = torch.ops.aten.mm.default(view_2246, slice_7)
        view_2247: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1118, [2, 16, 8]);  mm_1118 = None
        slice_36903: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4471, 1, 8944, 8960)
        slice_36904: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36903, 2, 0, 16);  slice_36903 = None
        add_1120: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36904, view_2247);  slice_36904 = view_2247 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4471, 1, 8944, 8960)
        slice_scatter_default_4472: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2236, add_1120, 2, 0, 16);  slice_tensor_2236 = add_1120 = None
        slice_scatter_default_4473: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4471, slice_scatter_default_4472, 1, 8944, 8960);  slice_scatter_default_4471 = slice_scatter_default_4472 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36908: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4473, 1, 8944, 8960)
        slice_36909: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36908, 2, 0, 16);  slice_36908 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4473, 1, 8944, 8960)
        slice_scatter_default_4474: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2237, slice_36909, 2, 0, 16);  slice_tensor_2237 = slice_36909 = None
        slice_scatter_default_4475: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4473, slice_scatter_default_4474, 1, 8944, 8960);  slice_scatter_default_4473 = slice_scatter_default_4474 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36929: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36895, 2, 16, 32);  slice_36895 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1122: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36929, memory_format = torch.contiguous_format);  slice_36929 = None
        view_2248: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1122, [32, 11]);  clone_1122 = None
        mm_1119: "f32[32, 8]" = torch.ops.aten.mm.default(view_2248, slice_37)
        view_2249: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1119, [2, 16, 8]);  mm_1119 = None
        slice_36936: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4475, 1, 8944, 8960)
        slice_36937: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36936, 2, 0, 16);  slice_36936 = None
        add_1121: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36937, view_2249);  slice_36937 = view_2249 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4475, 1, 8944, 8960)
        slice_scatter_default_4476: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2238, add_1121, 2, 0, 16);  slice_tensor_2238 = add_1121 = None
        slice_scatter_default_4477: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4475, slice_scatter_default_4476, 1, 8944, 8960);  slice_scatter_default_4475 = slice_scatter_default_4476 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36941: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4477, 1, 8944, 8960)
        slice_36942: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36941, 2, 0, 16);  slice_36941 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4477, 1, 8944, 8960)
        slice_scatter_default_4478: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2239, slice_36942, 2, 0, 16);  slice_tensor_2239 = slice_36942 = None
        slice_scatter_default_4479: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4477, slice_scatter_default_4478, 1, 8944, 8960);  slice_scatter_default_4477 = slice_scatter_default_4478 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36961: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8960, 8976)
        slice_36962: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_36961, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1123: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_36962, memory_format = torch.contiguous_format);  slice_36962 = None
        view_2250: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1123, [32, 16]);  clone_1123 = None
        mm_1120: "f32[32, 8]" = torch.ops.aten.mm.default(view_2250, slice_7)
        view_2251: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1120, [2, 16, 8]);  mm_1120 = None
        slice_36969: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4479, 1, 8960, 8976)
        slice_36970: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36969, 2, 0, 16);  slice_36969 = None
        add_1122: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_36970, view_2251);  slice_36970 = view_2251 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2240: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4479, 1, 8960, 8976)
        slice_scatter_default_4480: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2240, add_1122, 2, 0, 16);  slice_tensor_2240 = add_1122 = None
        slice_scatter_default_4481: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4479, slice_scatter_default_4480, 1, 8960, 8976);  slice_scatter_default_4479 = slice_scatter_default_4480 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_36974: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4481, 1, 8960, 8976)
        slice_36975: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_36974, 2, 0, 16);  slice_36974 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4481, 1, 8960, 8976)
        slice_scatter_default_4482: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2241, slice_36975, 2, 0, 16);  slice_tensor_2241 = slice_36975 = None
        slice_scatter_default_4483: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4481, slice_scatter_default_4482, 1, 8960, 8976);  slice_scatter_default_4481 = slice_scatter_default_4482 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_36995: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_36961, 2, 16, 32);  slice_36961 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1124: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_36995, memory_format = torch.contiguous_format);  slice_36995 = None
        view_2252: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1124, [32, 11]);  clone_1124 = None
        mm_1121: "f32[32, 8]" = torch.ops.aten.mm.default(view_2252, slice_37)
        view_2253: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1121, [2, 16, 8]);  mm_1121 = None
        slice_37002: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4483, 1, 8960, 8976)
        slice_37003: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37002, 2, 0, 16);  slice_37002 = None
        add_1123: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37003, view_2253);  slice_37003 = view_2253 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4483, 1, 8960, 8976)
        slice_scatter_default_4484: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2242, add_1123, 2, 0, 16);  slice_tensor_2242 = add_1123 = None
        slice_scatter_default_4485: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4483, slice_scatter_default_4484, 1, 8960, 8976);  slice_scatter_default_4483 = slice_scatter_default_4484 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37007: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4485, 1, 8960, 8976)
        slice_37008: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37007, 2, 0, 16);  slice_37007 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2243: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4485, 1, 8960, 8976)
        slice_scatter_default_4486: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2243, slice_37008, 2, 0, 16);  slice_tensor_2243 = slice_37008 = None
        slice_scatter_default_4487: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4485, slice_scatter_default_4486, 1, 8960, 8976);  slice_scatter_default_4485 = slice_scatter_default_4486 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37027: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8976, 8992)
        slice_37028: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37027, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1125: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37028, memory_format = torch.contiguous_format);  slice_37028 = None
        view_2254: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1125, [32, 16]);  clone_1125 = None
        mm_1122: "f32[32, 8]" = torch.ops.aten.mm.default(view_2254, slice_7)
        view_2255: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1122, [2, 16, 8]);  mm_1122 = None
        slice_37035: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4487, 1, 8976, 8992)
        slice_37036: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37035, 2, 0, 16);  slice_37035 = None
        add_1124: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37036, view_2255);  slice_37036 = view_2255 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2244: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4487, 1, 8976, 8992)
        slice_scatter_default_4488: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2244, add_1124, 2, 0, 16);  slice_tensor_2244 = add_1124 = None
        slice_scatter_default_4489: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4487, slice_scatter_default_4488, 1, 8976, 8992);  slice_scatter_default_4487 = slice_scatter_default_4488 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37040: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4489, 1, 8976, 8992)
        slice_37041: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37040, 2, 0, 16);  slice_37040 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2245: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4489, 1, 8976, 8992)
        slice_scatter_default_4490: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2245, slice_37041, 2, 0, 16);  slice_tensor_2245 = slice_37041 = None
        slice_scatter_default_4491: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4489, slice_scatter_default_4490, 1, 8976, 8992);  slice_scatter_default_4489 = slice_scatter_default_4490 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37061: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37027, 2, 16, 32);  slice_37027 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1126: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37061, memory_format = torch.contiguous_format);  slice_37061 = None
        view_2256: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1126, [32, 11]);  clone_1126 = None
        mm_1123: "f32[32, 8]" = torch.ops.aten.mm.default(view_2256, slice_37)
        view_2257: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1123, [2, 16, 8]);  mm_1123 = None
        slice_37068: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4491, 1, 8976, 8992)
        slice_37069: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37068, 2, 0, 16);  slice_37068 = None
        add_1125: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37069, view_2257);  slice_37069 = view_2257 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4491, 1, 8976, 8992)
        slice_scatter_default_4492: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2246, add_1125, 2, 0, 16);  slice_tensor_2246 = add_1125 = None
        slice_scatter_default_4493: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4491, slice_scatter_default_4492, 1, 8976, 8992);  slice_scatter_default_4491 = slice_scatter_default_4492 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37073: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4493, 1, 8976, 8992)
        slice_37074: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37073, 2, 0, 16);  slice_37073 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4493, 1, 8976, 8992)
        slice_scatter_default_4494: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2247, slice_37074, 2, 0, 16);  slice_tensor_2247 = slice_37074 = None
        slice_scatter_default_4495: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4493, slice_scatter_default_4494, 1, 8976, 8992);  slice_scatter_default_4493 = slice_scatter_default_4494 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37093: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 8992, 9008)
        slice_37094: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37093, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1127: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37094, memory_format = torch.contiguous_format);  slice_37094 = None
        view_2258: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1127, [32, 16]);  clone_1127 = None
        mm_1124: "f32[32, 8]" = torch.ops.aten.mm.default(view_2258, slice_7)
        view_2259: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1124, [2, 16, 8]);  mm_1124 = None
        slice_37101: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4495, 1, 8992, 9008)
        slice_37102: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37101, 2, 0, 16);  slice_37101 = None
        add_1126: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37102, view_2259);  slice_37102 = view_2259 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2248: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4495, 1, 8992, 9008)
        slice_scatter_default_4496: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2248, add_1126, 2, 0, 16);  slice_tensor_2248 = add_1126 = None
        slice_scatter_default_4497: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4495, slice_scatter_default_4496, 1, 8992, 9008);  slice_scatter_default_4495 = slice_scatter_default_4496 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37106: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4497, 1, 8992, 9008)
        slice_37107: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37106, 2, 0, 16);  slice_37106 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2249: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4497, 1, 8992, 9008)
        slice_scatter_default_4498: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2249, slice_37107, 2, 0, 16);  slice_tensor_2249 = slice_37107 = None
        slice_scatter_default_4499: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4497, slice_scatter_default_4498, 1, 8992, 9008);  slice_scatter_default_4497 = slice_scatter_default_4498 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37127: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37093, 2, 16, 32);  slice_37093 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1128: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37127, memory_format = torch.contiguous_format);  slice_37127 = None
        view_2260: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1128, [32, 11]);  clone_1128 = None
        mm_1125: "f32[32, 8]" = torch.ops.aten.mm.default(view_2260, slice_37)
        view_2261: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1125, [2, 16, 8]);  mm_1125 = None
        slice_37134: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4499, 1, 8992, 9008)
        slice_37135: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37134, 2, 0, 16);  slice_37134 = None
        add_1127: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37135, view_2261);  slice_37135 = view_2261 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2250: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4499, 1, 8992, 9008)
        slice_scatter_default_4500: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2250, add_1127, 2, 0, 16);  slice_tensor_2250 = add_1127 = None
        slice_scatter_default_4501: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4499, slice_scatter_default_4500, 1, 8992, 9008);  slice_scatter_default_4499 = slice_scatter_default_4500 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37139: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4501, 1, 8992, 9008)
        slice_37140: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37139, 2, 0, 16);  slice_37139 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4501, 1, 8992, 9008)
        slice_scatter_default_4502: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2251, slice_37140, 2, 0, 16);  slice_tensor_2251 = slice_37140 = None
        slice_scatter_default_4503: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4501, slice_scatter_default_4502, 1, 8992, 9008);  slice_scatter_default_4501 = slice_scatter_default_4502 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37159: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9008, 9024)
        slice_37160: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37159, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1129: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37160, memory_format = torch.contiguous_format);  slice_37160 = None
        view_2262: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1129, [32, 16]);  clone_1129 = None
        mm_1126: "f32[32, 8]" = torch.ops.aten.mm.default(view_2262, slice_7)
        view_2263: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1126, [2, 16, 8]);  mm_1126 = None
        slice_37167: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4503, 1, 9008, 9024)
        slice_37168: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37167, 2, 0, 16);  slice_37167 = None
        add_1128: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37168, view_2263);  slice_37168 = view_2263 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4503, 1, 9008, 9024)
        slice_scatter_default_4504: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2252, add_1128, 2, 0, 16);  slice_tensor_2252 = add_1128 = None
        slice_scatter_default_4505: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4503, slice_scatter_default_4504, 1, 9008, 9024);  slice_scatter_default_4503 = slice_scatter_default_4504 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37172: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4505, 1, 9008, 9024)
        slice_37173: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37172, 2, 0, 16);  slice_37172 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2253: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4505, 1, 9008, 9024)
        slice_scatter_default_4506: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2253, slice_37173, 2, 0, 16);  slice_tensor_2253 = slice_37173 = None
        slice_scatter_default_4507: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4505, slice_scatter_default_4506, 1, 9008, 9024);  slice_scatter_default_4505 = slice_scatter_default_4506 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37193: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37159, 2, 16, 32);  slice_37159 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1130: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37193, memory_format = torch.contiguous_format);  slice_37193 = None
        view_2264: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1130, [32, 11]);  clone_1130 = None
        mm_1127: "f32[32, 8]" = torch.ops.aten.mm.default(view_2264, slice_37)
        view_2265: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1127, [2, 16, 8]);  mm_1127 = None
        slice_37200: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4507, 1, 9008, 9024)
        slice_37201: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37200, 2, 0, 16);  slice_37200 = None
        add_1129: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37201, view_2265);  slice_37201 = view_2265 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2254: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4507, 1, 9008, 9024)
        slice_scatter_default_4508: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2254, add_1129, 2, 0, 16);  slice_tensor_2254 = add_1129 = None
        slice_scatter_default_4509: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4507, slice_scatter_default_4508, 1, 9008, 9024);  slice_scatter_default_4507 = slice_scatter_default_4508 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37205: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4509, 1, 9008, 9024)
        slice_37206: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37205, 2, 0, 16);  slice_37205 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2255: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4509, 1, 9008, 9024)
        slice_scatter_default_4510: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2255, slice_37206, 2, 0, 16);  slice_tensor_2255 = slice_37206 = None
        slice_scatter_default_4511: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4509, slice_scatter_default_4510, 1, 9008, 9024);  slice_scatter_default_4509 = slice_scatter_default_4510 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37225: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9024, 9040)
        slice_37226: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37225, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1131: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37226, memory_format = torch.contiguous_format);  slice_37226 = None
        view_2266: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1131, [32, 16]);  clone_1131 = None
        mm_1128: "f32[32, 8]" = torch.ops.aten.mm.default(view_2266, slice_7)
        view_2267: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1128, [2, 16, 8]);  mm_1128 = None
        slice_37233: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4511, 1, 9024, 9040)
        slice_37234: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37233, 2, 0, 16);  slice_37233 = None
        add_1130: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37234, view_2267);  slice_37234 = view_2267 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4511, 1, 9024, 9040)
        slice_scatter_default_4512: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2256, add_1130, 2, 0, 16);  slice_tensor_2256 = add_1130 = None
        slice_scatter_default_4513: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4511, slice_scatter_default_4512, 1, 9024, 9040);  slice_scatter_default_4511 = slice_scatter_default_4512 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37238: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4513, 1, 9024, 9040)
        slice_37239: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37238, 2, 0, 16);  slice_37238 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4513, 1, 9024, 9040)
        slice_scatter_default_4514: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2257, slice_37239, 2, 0, 16);  slice_tensor_2257 = slice_37239 = None
        slice_scatter_default_4515: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4513, slice_scatter_default_4514, 1, 9024, 9040);  slice_scatter_default_4513 = slice_scatter_default_4514 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37259: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37225, 2, 16, 32);  slice_37225 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1132: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37259, memory_format = torch.contiguous_format);  slice_37259 = None
        view_2268: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1132, [32, 11]);  clone_1132 = None
        mm_1129: "f32[32, 8]" = torch.ops.aten.mm.default(view_2268, slice_37)
        view_2269: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1129, [2, 16, 8]);  mm_1129 = None
        slice_37266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4515, 1, 9024, 9040)
        slice_37267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37266, 2, 0, 16);  slice_37266 = None
        add_1131: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37267, view_2269);  slice_37267 = view_2269 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2258: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4515, 1, 9024, 9040)
        slice_scatter_default_4516: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2258, add_1131, 2, 0, 16);  slice_tensor_2258 = add_1131 = None
        slice_scatter_default_4517: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4515, slice_scatter_default_4516, 1, 9024, 9040);  slice_scatter_default_4515 = slice_scatter_default_4516 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4517, 1, 9024, 9040)
        slice_37272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37271, 2, 0, 16);  slice_37271 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2259: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4517, 1, 9024, 9040)
        slice_scatter_default_4518: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2259, slice_37272, 2, 0, 16);  slice_tensor_2259 = slice_37272 = None
        slice_scatter_default_4519: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4517, slice_scatter_default_4518, 1, 9024, 9040);  slice_scatter_default_4517 = slice_scatter_default_4518 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37291: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9040, 9056)
        slice_37292: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37291, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1133: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37292, memory_format = torch.contiguous_format);  slice_37292 = None
        view_2270: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1133, [32, 16]);  clone_1133 = None
        mm_1130: "f32[32, 8]" = torch.ops.aten.mm.default(view_2270, slice_7)
        view_2271: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1130, [2, 16, 8]);  mm_1130 = None
        slice_37299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4519, 1, 9040, 9056)
        slice_37300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37299, 2, 0, 16);  slice_37299 = None
        add_1132: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37300, view_2271);  slice_37300 = view_2271 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2260: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4519, 1, 9040, 9056)
        slice_scatter_default_4520: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2260, add_1132, 2, 0, 16);  slice_tensor_2260 = add_1132 = None
        slice_scatter_default_4521: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4519, slice_scatter_default_4520, 1, 9040, 9056);  slice_scatter_default_4519 = slice_scatter_default_4520 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4521, 1, 9040, 9056)
        slice_37305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37304, 2, 0, 16);  slice_37304 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4521, 1, 9040, 9056)
        slice_scatter_default_4522: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2261, slice_37305, 2, 0, 16);  slice_tensor_2261 = slice_37305 = None
        slice_scatter_default_4523: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4521, slice_scatter_default_4522, 1, 9040, 9056);  slice_scatter_default_4521 = slice_scatter_default_4522 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37325: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37291, 2, 16, 32);  slice_37291 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1134: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37325, memory_format = torch.contiguous_format);  slice_37325 = None
        view_2272: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1134, [32, 11]);  clone_1134 = None
        mm_1131: "f32[32, 8]" = torch.ops.aten.mm.default(view_2272, slice_37)
        view_2273: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1131, [2, 16, 8]);  mm_1131 = None
        slice_37332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4523, 1, 9040, 9056)
        slice_37333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37332, 2, 0, 16);  slice_37332 = None
        add_1133: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37333, view_2273);  slice_37333 = view_2273 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4523, 1, 9040, 9056)
        slice_scatter_default_4524: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2262, add_1133, 2, 0, 16);  slice_tensor_2262 = add_1133 = None
        slice_scatter_default_4525: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4523, slice_scatter_default_4524, 1, 9040, 9056);  slice_scatter_default_4523 = slice_scatter_default_4524 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4525, 1, 9040, 9056)
        slice_37338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37337, 2, 0, 16);  slice_37337 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2263: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4525, 1, 9040, 9056)
        slice_scatter_default_4526: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2263, slice_37338, 2, 0, 16);  slice_tensor_2263 = slice_37338 = None
        slice_scatter_default_4527: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4525, slice_scatter_default_4526, 1, 9040, 9056);  slice_scatter_default_4525 = slice_scatter_default_4526 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37357: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9056, 9072)
        slice_37358: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37357, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1135: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37358, memory_format = torch.contiguous_format);  slice_37358 = None
        view_2274: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1135, [32, 16]);  clone_1135 = None
        mm_1132: "f32[32, 8]" = torch.ops.aten.mm.default(view_2274, slice_7)
        view_2275: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1132, [2, 16, 8]);  mm_1132 = None
        slice_37365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4527, 1, 9056, 9072)
        slice_37366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37365, 2, 0, 16);  slice_37365 = None
        add_1134: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37366, view_2275);  slice_37366 = view_2275 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2264: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4527, 1, 9056, 9072)
        slice_scatter_default_4528: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2264, add_1134, 2, 0, 16);  slice_tensor_2264 = add_1134 = None
        slice_scatter_default_4529: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4527, slice_scatter_default_4528, 1, 9056, 9072);  slice_scatter_default_4527 = slice_scatter_default_4528 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4529, 1, 9056, 9072)
        slice_37371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37370, 2, 0, 16);  slice_37370 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2265: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4529, 1, 9056, 9072)
        slice_scatter_default_4530: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2265, slice_37371, 2, 0, 16);  slice_tensor_2265 = slice_37371 = None
        slice_scatter_default_4531: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4529, slice_scatter_default_4530, 1, 9056, 9072);  slice_scatter_default_4529 = slice_scatter_default_4530 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37391: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37357, 2, 16, 32);  slice_37357 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1136: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37391, memory_format = torch.contiguous_format);  slice_37391 = None
        view_2276: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1136, [32, 11]);  clone_1136 = None
        mm_1133: "f32[32, 8]" = torch.ops.aten.mm.default(view_2276, slice_37)
        view_2277: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1133, [2, 16, 8]);  mm_1133 = None
        slice_37398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4531, 1, 9056, 9072)
        slice_37399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37398, 2, 0, 16);  slice_37398 = None
        add_1135: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37399, view_2277);  slice_37399 = view_2277 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2266: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4531, 1, 9056, 9072)
        slice_scatter_default_4532: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2266, add_1135, 2, 0, 16);  slice_tensor_2266 = add_1135 = None
        slice_scatter_default_4533: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4531, slice_scatter_default_4532, 1, 9056, 9072);  slice_scatter_default_4531 = slice_scatter_default_4532 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4533, 1, 9056, 9072)
        slice_37404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37403, 2, 0, 16);  slice_37403 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2267: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4533, 1, 9056, 9072)
        slice_scatter_default_4534: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2267, slice_37404, 2, 0, 16);  slice_tensor_2267 = slice_37404 = None
        slice_scatter_default_4535: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4533, slice_scatter_default_4534, 1, 9056, 9072);  slice_scatter_default_4533 = slice_scatter_default_4534 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37423: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9072, 9088)
        slice_37424: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37423, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1137: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37424, memory_format = torch.contiguous_format);  slice_37424 = None
        view_2278: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1137, [32, 16]);  clone_1137 = None
        mm_1134: "f32[32, 8]" = torch.ops.aten.mm.default(view_2278, slice_7)
        view_2279: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1134, [2, 16, 8]);  mm_1134 = None
        slice_37431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4535, 1, 9072, 9088)
        slice_37432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37431, 2, 0, 16);  slice_37431 = None
        add_1136: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37432, view_2279);  slice_37432 = view_2279 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2268: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4535, 1, 9072, 9088)
        slice_scatter_default_4536: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2268, add_1136, 2, 0, 16);  slice_tensor_2268 = add_1136 = None
        slice_scatter_default_4537: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4535, slice_scatter_default_4536, 1, 9072, 9088);  slice_scatter_default_4535 = slice_scatter_default_4536 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4537, 1, 9072, 9088)
        slice_37437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37436, 2, 0, 16);  slice_37436 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4537, 1, 9072, 9088)
        slice_scatter_default_4538: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2269, slice_37437, 2, 0, 16);  slice_tensor_2269 = slice_37437 = None
        slice_scatter_default_4539: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4537, slice_scatter_default_4538, 1, 9072, 9088);  slice_scatter_default_4537 = slice_scatter_default_4538 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37457: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37423, 2, 16, 32);  slice_37423 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1138: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37457, memory_format = torch.contiguous_format);  slice_37457 = None
        view_2280: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1138, [32, 11]);  clone_1138 = None
        mm_1135: "f32[32, 8]" = torch.ops.aten.mm.default(view_2280, slice_37)
        view_2281: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1135, [2, 16, 8]);  mm_1135 = None
        slice_37464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4539, 1, 9072, 9088)
        slice_37465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37464, 2, 0, 16);  slice_37464 = None
        add_1137: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37465, view_2281);  slice_37465 = view_2281 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4539, 1, 9072, 9088)
        slice_scatter_default_4540: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2270, add_1137, 2, 0, 16);  slice_tensor_2270 = add_1137 = None
        slice_scatter_default_4541: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4539, slice_scatter_default_4540, 1, 9072, 9088);  slice_scatter_default_4539 = slice_scatter_default_4540 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4541, 1, 9072, 9088)
        slice_37470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37469, 2, 0, 16);  slice_37469 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2271: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4541, 1, 9072, 9088)
        slice_scatter_default_4542: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2271, slice_37470, 2, 0, 16);  slice_tensor_2271 = slice_37470 = None
        slice_scatter_default_4543: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4541, slice_scatter_default_4542, 1, 9072, 9088);  slice_scatter_default_4541 = slice_scatter_default_4542 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37489: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9088, 9104)
        slice_37490: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37489, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1139: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37490, memory_format = torch.contiguous_format);  slice_37490 = None
        view_2282: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1139, [32, 16]);  clone_1139 = None
        mm_1136: "f32[32, 8]" = torch.ops.aten.mm.default(view_2282, slice_7)
        view_2283: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1136, [2, 16, 8]);  mm_1136 = None
        slice_37497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4543, 1, 9088, 9104)
        slice_37498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37497, 2, 0, 16);  slice_37497 = None
        add_1138: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37498, view_2283);  slice_37498 = view_2283 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2272: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4543, 1, 9088, 9104)
        slice_scatter_default_4544: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2272, add_1138, 2, 0, 16);  slice_tensor_2272 = add_1138 = None
        slice_scatter_default_4545: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4543, slice_scatter_default_4544, 1, 9088, 9104);  slice_scatter_default_4543 = slice_scatter_default_4544 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37502: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4545, 1, 9088, 9104)
        slice_37503: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37502, 2, 0, 16);  slice_37502 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2273: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4545, 1, 9088, 9104)
        slice_scatter_default_4546: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2273, slice_37503, 2, 0, 16);  slice_tensor_2273 = slice_37503 = None
        slice_scatter_default_4547: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4545, slice_scatter_default_4546, 1, 9088, 9104);  slice_scatter_default_4545 = slice_scatter_default_4546 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37523: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37489, 2, 16, 32);  slice_37489 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1140: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37523, memory_format = torch.contiguous_format);  slice_37523 = None
        view_2284: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1140, [32, 11]);  clone_1140 = None
        mm_1137: "f32[32, 8]" = torch.ops.aten.mm.default(view_2284, slice_37)
        view_2285: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1137, [2, 16, 8]);  mm_1137 = None
        slice_37530: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4547, 1, 9088, 9104)
        slice_37531: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37530, 2, 0, 16);  slice_37530 = None
        add_1139: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37531, view_2285);  slice_37531 = view_2285 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4547, 1, 9088, 9104)
        slice_scatter_default_4548: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2274, add_1139, 2, 0, 16);  slice_tensor_2274 = add_1139 = None
        slice_scatter_default_4549: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4547, slice_scatter_default_4548, 1, 9088, 9104);  slice_scatter_default_4547 = slice_scatter_default_4548 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37535: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4549, 1, 9088, 9104)
        slice_37536: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37535, 2, 0, 16);  slice_37535 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4549, 1, 9088, 9104)
        slice_scatter_default_4550: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2275, slice_37536, 2, 0, 16);  slice_tensor_2275 = slice_37536 = None
        slice_scatter_default_4551: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4549, slice_scatter_default_4550, 1, 9088, 9104);  slice_scatter_default_4549 = slice_scatter_default_4550 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37555: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9104, 9120)
        slice_37556: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37555, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1141: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37556, memory_format = torch.contiguous_format);  slice_37556 = None
        view_2286: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1141, [32, 16]);  clone_1141 = None
        mm_1138: "f32[32, 8]" = torch.ops.aten.mm.default(view_2286, slice_7)
        view_2287: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1138, [2, 16, 8]);  mm_1138 = None
        slice_37563: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4551, 1, 9104, 9120)
        slice_37564: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37563, 2, 0, 16);  slice_37563 = None
        add_1140: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37564, view_2287);  slice_37564 = view_2287 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2276: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4551, 1, 9104, 9120)
        slice_scatter_default_4552: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2276, add_1140, 2, 0, 16);  slice_tensor_2276 = add_1140 = None
        slice_scatter_default_4553: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4551, slice_scatter_default_4552, 1, 9104, 9120);  slice_scatter_default_4551 = slice_scatter_default_4552 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37568: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4553, 1, 9104, 9120)
        slice_37569: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37568, 2, 0, 16);  slice_37568 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2277: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4553, 1, 9104, 9120)
        slice_scatter_default_4554: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2277, slice_37569, 2, 0, 16);  slice_tensor_2277 = slice_37569 = None
        slice_scatter_default_4555: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4553, slice_scatter_default_4554, 1, 9104, 9120);  slice_scatter_default_4553 = slice_scatter_default_4554 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37589: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37555, 2, 16, 32);  slice_37555 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1142: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37589, memory_format = torch.contiguous_format);  slice_37589 = None
        view_2288: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1142, [32, 11]);  clone_1142 = None
        mm_1139: "f32[32, 8]" = torch.ops.aten.mm.default(view_2288, slice_37)
        view_2289: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1139, [2, 16, 8]);  mm_1139 = None
        slice_37596: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4555, 1, 9104, 9120)
        slice_37597: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37596, 2, 0, 16);  slice_37596 = None
        add_1141: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37597, view_2289);  slice_37597 = view_2289 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2278: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4555, 1, 9104, 9120)
        slice_scatter_default_4556: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2278, add_1141, 2, 0, 16);  slice_tensor_2278 = add_1141 = None
        slice_scatter_default_4557: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4555, slice_scatter_default_4556, 1, 9104, 9120);  slice_scatter_default_4555 = slice_scatter_default_4556 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37601: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4557, 1, 9104, 9120)
        slice_37602: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37601, 2, 0, 16);  slice_37601 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4557, 1, 9104, 9120)
        slice_scatter_default_4558: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2279, slice_37602, 2, 0, 16);  slice_tensor_2279 = slice_37602 = None
        slice_scatter_default_4559: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4557, slice_scatter_default_4558, 1, 9104, 9120);  slice_scatter_default_4557 = slice_scatter_default_4558 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37621: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9120, 9136)
        slice_37622: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37621, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1143: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37622, memory_format = torch.contiguous_format);  slice_37622 = None
        view_2290: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1143, [32, 16]);  clone_1143 = None
        mm_1140: "f32[32, 8]" = torch.ops.aten.mm.default(view_2290, slice_7)
        view_2291: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1140, [2, 16, 8]);  mm_1140 = None
        slice_37629: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4559, 1, 9120, 9136)
        slice_37630: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37629, 2, 0, 16);  slice_37629 = None
        add_1142: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37630, view_2291);  slice_37630 = view_2291 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4559, 1, 9120, 9136)
        slice_scatter_default_4560: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2280, add_1142, 2, 0, 16);  slice_tensor_2280 = add_1142 = None
        slice_scatter_default_4561: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4559, slice_scatter_default_4560, 1, 9120, 9136);  slice_scatter_default_4559 = slice_scatter_default_4560 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37634: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4561, 1, 9120, 9136)
        slice_37635: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37634, 2, 0, 16);  slice_37634 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2281: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4561, 1, 9120, 9136)
        slice_scatter_default_4562: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2281, slice_37635, 2, 0, 16);  slice_tensor_2281 = slice_37635 = None
        slice_scatter_default_4563: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4561, slice_scatter_default_4562, 1, 9120, 9136);  slice_scatter_default_4561 = slice_scatter_default_4562 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37655: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37621, 2, 16, 32);  slice_37621 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1144: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37655, memory_format = torch.contiguous_format);  slice_37655 = None
        view_2292: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1144, [32, 11]);  clone_1144 = None
        mm_1141: "f32[32, 8]" = torch.ops.aten.mm.default(view_2292, slice_37)
        view_2293: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1141, [2, 16, 8]);  mm_1141 = None
        slice_37662: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4563, 1, 9120, 9136)
        slice_37663: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37662, 2, 0, 16);  slice_37662 = None
        add_1143: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37663, view_2293);  slice_37663 = view_2293 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2282: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4563, 1, 9120, 9136)
        slice_scatter_default_4564: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2282, add_1143, 2, 0, 16);  slice_tensor_2282 = add_1143 = None
        slice_scatter_default_4565: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4563, slice_scatter_default_4564, 1, 9120, 9136);  slice_scatter_default_4563 = slice_scatter_default_4564 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37667: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4565, 1, 9120, 9136)
        slice_37668: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37667, 2, 0, 16);  slice_37667 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2283: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4565, 1, 9120, 9136)
        slice_scatter_default_4566: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2283, slice_37668, 2, 0, 16);  slice_tensor_2283 = slice_37668 = None
        slice_scatter_default_4567: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4565, slice_scatter_default_4566, 1, 9120, 9136);  slice_scatter_default_4565 = slice_scatter_default_4566 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37687: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9136, 9152)
        slice_37688: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37687, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1145: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37688, memory_format = torch.contiguous_format);  slice_37688 = None
        view_2294: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1145, [32, 16]);  clone_1145 = None
        mm_1142: "f32[32, 8]" = torch.ops.aten.mm.default(view_2294, slice_7)
        view_2295: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1142, [2, 16, 8]);  mm_1142 = None
        slice_37695: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4567, 1, 9136, 9152)
        slice_37696: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37695, 2, 0, 16);  slice_37695 = None
        add_1144: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37696, view_2295);  slice_37696 = view_2295 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4567, 1, 9136, 9152)
        slice_scatter_default_4568: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2284, add_1144, 2, 0, 16);  slice_tensor_2284 = add_1144 = None
        slice_scatter_default_4569: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4567, slice_scatter_default_4568, 1, 9136, 9152);  slice_scatter_default_4567 = slice_scatter_default_4568 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37700: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4569, 1, 9136, 9152)
        slice_37701: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37700, 2, 0, 16);  slice_37700 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4569, 1, 9136, 9152)
        slice_scatter_default_4570: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2285, slice_37701, 2, 0, 16);  slice_tensor_2285 = slice_37701 = None
        slice_scatter_default_4571: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4569, slice_scatter_default_4570, 1, 9136, 9152);  slice_scatter_default_4569 = slice_scatter_default_4570 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37721: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37687, 2, 16, 32);  slice_37687 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1146: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37721, memory_format = torch.contiguous_format);  slice_37721 = None
        view_2296: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1146, [32, 11]);  clone_1146 = None
        mm_1143: "f32[32, 8]" = torch.ops.aten.mm.default(view_2296, slice_37)
        view_2297: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1143, [2, 16, 8]);  mm_1143 = None
        slice_37728: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4571, 1, 9136, 9152)
        slice_37729: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37728, 2, 0, 16);  slice_37728 = None
        add_1145: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37729, view_2297);  slice_37729 = view_2297 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2286: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4571, 1, 9136, 9152)
        slice_scatter_default_4572: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2286, add_1145, 2, 0, 16);  slice_tensor_2286 = add_1145 = None
        slice_scatter_default_4573: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4571, slice_scatter_default_4572, 1, 9136, 9152);  slice_scatter_default_4571 = slice_scatter_default_4572 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37733: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4573, 1, 9136, 9152)
        slice_37734: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37733, 2, 0, 16);  slice_37733 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2287: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4573, 1, 9136, 9152)
        slice_scatter_default_4574: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2287, slice_37734, 2, 0, 16);  slice_tensor_2287 = slice_37734 = None
        slice_scatter_default_4575: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4573, slice_scatter_default_4574, 1, 9136, 9152);  slice_scatter_default_4573 = slice_scatter_default_4574 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37753: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9152, 9168)
        slice_37754: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37753, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1147: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37754, memory_format = torch.contiguous_format);  slice_37754 = None
        view_2298: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1147, [32, 16]);  clone_1147 = None
        mm_1144: "f32[32, 8]" = torch.ops.aten.mm.default(view_2298, slice_7)
        view_2299: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1144, [2, 16, 8]);  mm_1144 = None
        slice_37761: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4575, 1, 9152, 9168)
        slice_37762: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37761, 2, 0, 16);  slice_37761 = None
        add_1146: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37762, view_2299);  slice_37762 = view_2299 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2288: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4575, 1, 9152, 9168)
        slice_scatter_default_4576: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2288, add_1146, 2, 0, 16);  slice_tensor_2288 = add_1146 = None
        slice_scatter_default_4577: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4575, slice_scatter_default_4576, 1, 9152, 9168);  slice_scatter_default_4575 = slice_scatter_default_4576 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37766: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4577, 1, 9152, 9168)
        slice_37767: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37766, 2, 0, 16);  slice_37766 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4577, 1, 9152, 9168)
        slice_scatter_default_4578: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2289, slice_37767, 2, 0, 16);  slice_tensor_2289 = slice_37767 = None
        slice_scatter_default_4579: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4577, slice_scatter_default_4578, 1, 9152, 9168);  slice_scatter_default_4577 = slice_scatter_default_4578 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37787: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37753, 2, 16, 32);  slice_37753 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1148: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37787, memory_format = torch.contiguous_format);  slice_37787 = None
        view_2300: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1148, [32, 11]);  clone_1148 = None
        mm_1145: "f32[32, 8]" = torch.ops.aten.mm.default(view_2300, slice_37)
        view_2301: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1145, [2, 16, 8]);  mm_1145 = None
        slice_37794: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4579, 1, 9152, 9168)
        slice_37795: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37794, 2, 0, 16);  slice_37794 = None
        add_1147: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37795, view_2301);  slice_37795 = view_2301 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4579, 1, 9152, 9168)
        slice_scatter_default_4580: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2290, add_1147, 2, 0, 16);  slice_tensor_2290 = add_1147 = None
        slice_scatter_default_4581: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4579, slice_scatter_default_4580, 1, 9152, 9168);  slice_scatter_default_4579 = slice_scatter_default_4580 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37799: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4581, 1, 9152, 9168)
        slice_37800: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37799, 2, 0, 16);  slice_37799 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2291: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4581, 1, 9152, 9168)
        slice_scatter_default_4582: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2291, slice_37800, 2, 0, 16);  slice_tensor_2291 = slice_37800 = None
        slice_scatter_default_4583: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4581, slice_scatter_default_4582, 1, 9152, 9168);  slice_scatter_default_4581 = slice_scatter_default_4582 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37819: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9168, 9184)
        slice_37820: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37819, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1149: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37820, memory_format = torch.contiguous_format);  slice_37820 = None
        view_2302: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1149, [32, 16]);  clone_1149 = None
        mm_1146: "f32[32, 8]" = torch.ops.aten.mm.default(view_2302, slice_7)
        view_2303: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1146, [2, 16, 8]);  mm_1146 = None
        slice_37827: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4583, 1, 9168, 9184)
        slice_37828: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37827, 2, 0, 16);  slice_37827 = None
        add_1148: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37828, view_2303);  slice_37828 = view_2303 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2292: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4583, 1, 9168, 9184)
        slice_scatter_default_4584: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2292, add_1148, 2, 0, 16);  slice_tensor_2292 = add_1148 = None
        slice_scatter_default_4585: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4583, slice_scatter_default_4584, 1, 9168, 9184);  slice_scatter_default_4583 = slice_scatter_default_4584 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37832: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4585, 1, 9168, 9184)
        slice_37833: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37832, 2, 0, 16);  slice_37832 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2293: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4585, 1, 9168, 9184)
        slice_scatter_default_4586: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2293, slice_37833, 2, 0, 16);  slice_tensor_2293 = slice_37833 = None
        slice_scatter_default_4587: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4585, slice_scatter_default_4586, 1, 9168, 9184);  slice_scatter_default_4585 = slice_scatter_default_4586 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37853: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37819, 2, 16, 32);  slice_37819 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1150: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37853, memory_format = torch.contiguous_format);  slice_37853 = None
        view_2304: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1150, [32, 11]);  clone_1150 = None
        mm_1147: "f32[32, 8]" = torch.ops.aten.mm.default(view_2304, slice_37)
        view_2305: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1147, [2, 16, 8]);  mm_1147 = None
        slice_37860: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4587, 1, 9168, 9184)
        slice_37861: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37860, 2, 0, 16);  slice_37860 = None
        add_1149: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37861, view_2305);  slice_37861 = view_2305 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4587, 1, 9168, 9184)
        slice_scatter_default_4588: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2294, add_1149, 2, 0, 16);  slice_tensor_2294 = add_1149 = None
        slice_scatter_default_4589: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4587, slice_scatter_default_4588, 1, 9168, 9184);  slice_scatter_default_4587 = slice_scatter_default_4588 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37865: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4589, 1, 9168, 9184)
        slice_37866: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37865, 2, 0, 16);  slice_37865 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4589, 1, 9168, 9184)
        slice_scatter_default_4590: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2295, slice_37866, 2, 0, 16);  slice_tensor_2295 = slice_37866 = None
        slice_scatter_default_4591: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4589, slice_scatter_default_4590, 1, 9168, 9184);  slice_scatter_default_4589 = slice_scatter_default_4590 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37885: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9184, 9200)
        slice_37886: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37885, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1151: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37886, memory_format = torch.contiguous_format);  slice_37886 = None
        view_2306: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1151, [32, 16]);  clone_1151 = None
        mm_1148: "f32[32, 8]" = torch.ops.aten.mm.default(view_2306, slice_7)
        view_2307: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1148, [2, 16, 8]);  mm_1148 = None
        slice_37893: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4591, 1, 9184, 9200)
        slice_37894: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37893, 2, 0, 16);  slice_37893 = None
        add_1150: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37894, view_2307);  slice_37894 = view_2307 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2296: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4591, 1, 9184, 9200)
        slice_scatter_default_4592: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2296, add_1150, 2, 0, 16);  slice_tensor_2296 = add_1150 = None
        slice_scatter_default_4593: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4591, slice_scatter_default_4592, 1, 9184, 9200);  slice_scatter_default_4591 = slice_scatter_default_4592 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37898: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4593, 1, 9184, 9200)
        slice_37899: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37898, 2, 0, 16);  slice_37898 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2297: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4593, 1, 9184, 9200)
        slice_scatter_default_4594: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2297, slice_37899, 2, 0, 16);  slice_tensor_2297 = slice_37899 = None
        slice_scatter_default_4595: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4593, slice_scatter_default_4594, 1, 9184, 9200);  slice_scatter_default_4593 = slice_scatter_default_4594 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37919: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37885, 2, 16, 32);  slice_37885 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1152: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37919, memory_format = torch.contiguous_format);  slice_37919 = None
        view_2308: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1152, [32, 11]);  clone_1152 = None
        mm_1149: "f32[32, 8]" = torch.ops.aten.mm.default(view_2308, slice_37)
        view_2309: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1149, [2, 16, 8]);  mm_1149 = None
        slice_37926: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4595, 1, 9184, 9200)
        slice_37927: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37926, 2, 0, 16);  slice_37926 = None
        add_1151: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37927, view_2309);  slice_37927 = view_2309 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2298: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4595, 1, 9184, 9200)
        slice_scatter_default_4596: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2298, add_1151, 2, 0, 16);  slice_tensor_2298 = add_1151 = None
        slice_scatter_default_4597: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4595, slice_scatter_default_4596, 1, 9184, 9200);  slice_scatter_default_4595 = slice_scatter_default_4596 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37931: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4597, 1, 9184, 9200)
        slice_37932: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37931, 2, 0, 16);  slice_37931 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2299: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4597, 1, 9184, 9200)
        slice_scatter_default_4598: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2299, slice_37932, 2, 0, 16);  slice_tensor_2299 = slice_37932 = None
        slice_scatter_default_4599: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4597, slice_scatter_default_4598, 1, 9184, 9200);  slice_scatter_default_4597 = slice_scatter_default_4598 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37951: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9200, 9216)
        slice_37952: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_37951, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1153: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_37952, memory_format = torch.contiguous_format);  slice_37952 = None
        view_2310: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1153, [32, 16]);  clone_1153 = None
        mm_1150: "f32[32, 8]" = torch.ops.aten.mm.default(view_2310, slice_7)
        view_2311: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1150, [2, 16, 8]);  mm_1150 = None
        slice_37959: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4599, 1, 9200, 9216)
        slice_37960: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37959, 2, 0, 16);  slice_37959 = None
        add_1152: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37960, view_2311);  slice_37960 = view_2311 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2300: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4599, 1, 9200, 9216)
        slice_scatter_default_4600: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2300, add_1152, 2, 0, 16);  slice_tensor_2300 = add_1152 = None
        slice_scatter_default_4601: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4599, slice_scatter_default_4600, 1, 9200, 9216);  slice_scatter_default_4599 = slice_scatter_default_4600 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37964: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4601, 1, 9200, 9216)
        slice_37965: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37964, 2, 0, 16);  slice_37964 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2301: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4601, 1, 9200, 9216)
        slice_scatter_default_4602: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2301, slice_37965, 2, 0, 16);  slice_tensor_2301 = slice_37965 = None
        slice_scatter_default_4603: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4601, slice_scatter_default_4602, 1, 9200, 9216);  slice_scatter_default_4601 = slice_scatter_default_4602 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_37985: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_37951, 2, 16, 32);  slice_37951 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1154: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_37985, memory_format = torch.contiguous_format);  slice_37985 = None
        view_2312: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1154, [32, 11]);  clone_1154 = None
        mm_1151: "f32[32, 8]" = torch.ops.aten.mm.default(view_2312, slice_37)
        view_2313: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1151, [2, 16, 8]);  mm_1151 = None
        slice_37992: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4603, 1, 9200, 9216)
        slice_37993: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37992, 2, 0, 16);  slice_37992 = None
        add_1153: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_37993, view_2313);  slice_37993 = view_2313 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4603, 1, 9200, 9216)
        slice_scatter_default_4604: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2302, add_1153, 2, 0, 16);  slice_tensor_2302 = add_1153 = None
        slice_scatter_default_4605: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4603, slice_scatter_default_4604, 1, 9200, 9216);  slice_scatter_default_4603 = slice_scatter_default_4604 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_37997: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4605, 1, 9200, 9216)
        slice_37998: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_37997, 2, 0, 16);  slice_37997 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4605, 1, 9200, 9216)
        slice_scatter_default_4606: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2303, slice_37998, 2, 0, 16);  slice_tensor_2303 = slice_37998 = None
        slice_scatter_default_4607: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4605, slice_scatter_default_4606, 1, 9200, 9216);  slice_scatter_default_4605 = slice_scatter_default_4606 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38017: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9216, 9232)
        slice_38018: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38017, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1155: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38018, memory_format = torch.contiguous_format);  slice_38018 = None
        view_2314: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1155, [32, 16]);  clone_1155 = None
        mm_1152: "f32[32, 8]" = torch.ops.aten.mm.default(view_2314, slice_7)
        view_2315: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1152, [2, 16, 8]);  mm_1152 = None
        slice_38025: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4607, 1, 9216, 9232)
        slice_38026: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38025, 2, 0, 16);  slice_38025 = None
        add_1154: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38026, view_2315);  slice_38026 = view_2315 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2304: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4607, 1, 9216, 9232)
        slice_scatter_default_4608: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2304, add_1154, 2, 0, 16);  slice_tensor_2304 = add_1154 = None
        slice_scatter_default_4609: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4607, slice_scatter_default_4608, 1, 9216, 9232);  slice_scatter_default_4607 = slice_scatter_default_4608 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38030: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4609, 1, 9216, 9232)
        slice_38031: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38030, 2, 0, 16);  slice_38030 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2305: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4609, 1, 9216, 9232)
        slice_scatter_default_4610: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2305, slice_38031, 2, 0, 16);  slice_tensor_2305 = slice_38031 = None
        slice_scatter_default_4611: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4609, slice_scatter_default_4610, 1, 9216, 9232);  slice_scatter_default_4609 = slice_scatter_default_4610 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38051: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38017, 2, 16, 32);  slice_38017 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1156: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38051, memory_format = torch.contiguous_format);  slice_38051 = None
        view_2316: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1156, [32, 11]);  clone_1156 = None
        mm_1153: "f32[32, 8]" = torch.ops.aten.mm.default(view_2316, slice_37)
        view_2317: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1153, [2, 16, 8]);  mm_1153 = None
        slice_38058: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4611, 1, 9216, 9232)
        slice_38059: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38058, 2, 0, 16);  slice_38058 = None
        add_1155: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38059, view_2317);  slice_38059 = view_2317 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2306: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4611, 1, 9216, 9232)
        slice_scatter_default_4612: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2306, add_1155, 2, 0, 16);  slice_tensor_2306 = add_1155 = None
        slice_scatter_default_4613: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4611, slice_scatter_default_4612, 1, 9216, 9232);  slice_scatter_default_4611 = slice_scatter_default_4612 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38063: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4613, 1, 9216, 9232)
        slice_38064: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38063, 2, 0, 16);  slice_38063 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4613, 1, 9216, 9232)
        slice_scatter_default_4614: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2307, slice_38064, 2, 0, 16);  slice_tensor_2307 = slice_38064 = None
        slice_scatter_default_4615: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4613, slice_scatter_default_4614, 1, 9216, 9232);  slice_scatter_default_4613 = slice_scatter_default_4614 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38083: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9232, 9248)
        slice_38084: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38083, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1157: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38084, memory_format = torch.contiguous_format);  slice_38084 = None
        view_2318: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1157, [32, 16]);  clone_1157 = None
        mm_1154: "f32[32, 8]" = torch.ops.aten.mm.default(view_2318, slice_7)
        view_2319: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1154, [2, 16, 8]);  mm_1154 = None
        slice_38091: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4615, 1, 9232, 9248)
        slice_38092: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38091, 2, 0, 16);  slice_38091 = None
        add_1156: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38092, view_2319);  slice_38092 = view_2319 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4615, 1, 9232, 9248)
        slice_scatter_default_4616: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2308, add_1156, 2, 0, 16);  slice_tensor_2308 = add_1156 = None
        slice_scatter_default_4617: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4615, slice_scatter_default_4616, 1, 9232, 9248);  slice_scatter_default_4615 = slice_scatter_default_4616 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38096: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4617, 1, 9232, 9248)
        slice_38097: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38096, 2, 0, 16);  slice_38096 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2309: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4617, 1, 9232, 9248)
        slice_scatter_default_4618: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2309, slice_38097, 2, 0, 16);  slice_tensor_2309 = slice_38097 = None
        slice_scatter_default_4619: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4617, slice_scatter_default_4618, 1, 9232, 9248);  slice_scatter_default_4617 = slice_scatter_default_4618 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38117: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38083, 2, 16, 32);  slice_38083 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1158: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38117, memory_format = torch.contiguous_format);  slice_38117 = None
        view_2320: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1158, [32, 11]);  clone_1158 = None
        mm_1155: "f32[32, 8]" = torch.ops.aten.mm.default(view_2320, slice_37)
        view_2321: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1155, [2, 16, 8]);  mm_1155 = None
        slice_38124: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4619, 1, 9232, 9248)
        slice_38125: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38124, 2, 0, 16);  slice_38124 = None
        add_1157: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38125, view_2321);  slice_38125 = view_2321 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2310: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4619, 1, 9232, 9248)
        slice_scatter_default_4620: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2310, add_1157, 2, 0, 16);  slice_tensor_2310 = add_1157 = None
        slice_scatter_default_4621: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4619, slice_scatter_default_4620, 1, 9232, 9248);  slice_scatter_default_4619 = slice_scatter_default_4620 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38129: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4621, 1, 9232, 9248)
        slice_38130: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38129, 2, 0, 16);  slice_38129 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2311: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4621, 1, 9232, 9248)
        slice_scatter_default_4622: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2311, slice_38130, 2, 0, 16);  slice_tensor_2311 = slice_38130 = None
        slice_scatter_default_4623: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4621, slice_scatter_default_4622, 1, 9232, 9248);  slice_scatter_default_4621 = slice_scatter_default_4622 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38149: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9248, 9264)
        slice_38150: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38149, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1159: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38150, memory_format = torch.contiguous_format);  slice_38150 = None
        view_2322: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1159, [32, 16]);  clone_1159 = None
        mm_1156: "f32[32, 8]" = torch.ops.aten.mm.default(view_2322, slice_7)
        view_2323: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1156, [2, 16, 8]);  mm_1156 = None
        slice_38157: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4623, 1, 9248, 9264)
        slice_38158: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38157, 2, 0, 16);  slice_38157 = None
        add_1158: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38158, view_2323);  slice_38158 = view_2323 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4623, 1, 9248, 9264)
        slice_scatter_default_4624: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2312, add_1158, 2, 0, 16);  slice_tensor_2312 = add_1158 = None
        slice_scatter_default_4625: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4623, slice_scatter_default_4624, 1, 9248, 9264);  slice_scatter_default_4623 = slice_scatter_default_4624 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38162: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4625, 1, 9248, 9264)
        slice_38163: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38162, 2, 0, 16);  slice_38162 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4625, 1, 9248, 9264)
        slice_scatter_default_4626: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2313, slice_38163, 2, 0, 16);  slice_tensor_2313 = slice_38163 = None
        slice_scatter_default_4627: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4625, slice_scatter_default_4626, 1, 9248, 9264);  slice_scatter_default_4625 = slice_scatter_default_4626 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38183: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38149, 2, 16, 32);  slice_38149 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1160: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38183, memory_format = torch.contiguous_format);  slice_38183 = None
        view_2324: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1160, [32, 11]);  clone_1160 = None
        mm_1157: "f32[32, 8]" = torch.ops.aten.mm.default(view_2324, slice_37)
        view_2325: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1157, [2, 16, 8]);  mm_1157 = None
        slice_38190: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4627, 1, 9248, 9264)
        slice_38191: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38190, 2, 0, 16);  slice_38190 = None
        add_1159: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38191, view_2325);  slice_38191 = view_2325 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2314: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4627, 1, 9248, 9264)
        slice_scatter_default_4628: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2314, add_1159, 2, 0, 16);  slice_tensor_2314 = add_1159 = None
        slice_scatter_default_4629: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4627, slice_scatter_default_4628, 1, 9248, 9264);  slice_scatter_default_4627 = slice_scatter_default_4628 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38195: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4629, 1, 9248, 9264)
        slice_38196: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38195, 2, 0, 16);  slice_38195 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2315: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4629, 1, 9248, 9264)
        slice_scatter_default_4630: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2315, slice_38196, 2, 0, 16);  slice_tensor_2315 = slice_38196 = None
        slice_scatter_default_4631: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4629, slice_scatter_default_4630, 1, 9248, 9264);  slice_scatter_default_4629 = slice_scatter_default_4630 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38215: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9264, 9280)
        slice_38216: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38215, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1161: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38216, memory_format = torch.contiguous_format);  slice_38216 = None
        view_2326: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1161, [32, 16]);  clone_1161 = None
        mm_1158: "f32[32, 8]" = torch.ops.aten.mm.default(view_2326, slice_7)
        view_2327: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1158, [2, 16, 8]);  mm_1158 = None
        slice_38223: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4631, 1, 9264, 9280)
        slice_38224: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38223, 2, 0, 16);  slice_38223 = None
        add_1160: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38224, view_2327);  slice_38224 = view_2327 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2316: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4631, 1, 9264, 9280)
        slice_scatter_default_4632: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2316, add_1160, 2, 0, 16);  slice_tensor_2316 = add_1160 = None
        slice_scatter_default_4633: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4631, slice_scatter_default_4632, 1, 9264, 9280);  slice_scatter_default_4631 = slice_scatter_default_4632 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38228: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4633, 1, 9264, 9280)
        slice_38229: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38228, 2, 0, 16);  slice_38228 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4633, 1, 9264, 9280)
        slice_scatter_default_4634: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2317, slice_38229, 2, 0, 16);  slice_tensor_2317 = slice_38229 = None
        slice_scatter_default_4635: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4633, slice_scatter_default_4634, 1, 9264, 9280);  slice_scatter_default_4633 = slice_scatter_default_4634 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38249: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38215, 2, 16, 32);  slice_38215 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1162: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38249, memory_format = torch.contiguous_format);  slice_38249 = None
        view_2328: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1162, [32, 11]);  clone_1162 = None
        mm_1159: "f32[32, 8]" = torch.ops.aten.mm.default(view_2328, slice_37)
        view_2329: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1159, [2, 16, 8]);  mm_1159 = None
        slice_38256: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4635, 1, 9264, 9280)
        slice_38257: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38256, 2, 0, 16);  slice_38256 = None
        add_1161: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38257, view_2329);  slice_38257 = view_2329 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4635, 1, 9264, 9280)
        slice_scatter_default_4636: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2318, add_1161, 2, 0, 16);  slice_tensor_2318 = add_1161 = None
        slice_scatter_default_4637: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4635, slice_scatter_default_4636, 1, 9264, 9280);  slice_scatter_default_4635 = slice_scatter_default_4636 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38261: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4637, 1, 9264, 9280)
        slice_38262: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38261, 2, 0, 16);  slice_38261 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2319: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4637, 1, 9264, 9280)
        slice_scatter_default_4638: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2319, slice_38262, 2, 0, 16);  slice_tensor_2319 = slice_38262 = None
        slice_scatter_default_4639: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4637, slice_scatter_default_4638, 1, 9264, 9280);  slice_scatter_default_4637 = slice_scatter_default_4638 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38281: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9280, 9296)
        slice_38282: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38281, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1163: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38282, memory_format = torch.contiguous_format);  slice_38282 = None
        view_2330: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1163, [32, 16]);  clone_1163 = None
        mm_1160: "f32[32, 8]" = torch.ops.aten.mm.default(view_2330, slice_7)
        view_2331: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1160, [2, 16, 8]);  mm_1160 = None
        slice_38289: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4639, 1, 9280, 9296)
        slice_38290: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38289, 2, 0, 16);  slice_38289 = None
        add_1162: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38290, view_2331);  slice_38290 = view_2331 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2320: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4639, 1, 9280, 9296)
        slice_scatter_default_4640: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2320, add_1162, 2, 0, 16);  slice_tensor_2320 = add_1162 = None
        slice_scatter_default_4641: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4639, slice_scatter_default_4640, 1, 9280, 9296);  slice_scatter_default_4639 = slice_scatter_default_4640 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38294: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4641, 1, 9280, 9296)
        slice_38295: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38294, 2, 0, 16);  slice_38294 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2321: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4641, 1, 9280, 9296)
        slice_scatter_default_4642: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2321, slice_38295, 2, 0, 16);  slice_tensor_2321 = slice_38295 = None
        slice_scatter_default_4643: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4641, slice_scatter_default_4642, 1, 9280, 9296);  slice_scatter_default_4641 = slice_scatter_default_4642 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38315: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38281, 2, 16, 32);  slice_38281 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1164: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38315, memory_format = torch.contiguous_format);  slice_38315 = None
        view_2332: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1164, [32, 11]);  clone_1164 = None
        mm_1161: "f32[32, 8]" = torch.ops.aten.mm.default(view_2332, slice_37)
        view_2333: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1161, [2, 16, 8]);  mm_1161 = None
        slice_38322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4643, 1, 9280, 9296)
        slice_38323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38322, 2, 0, 16);  slice_38322 = None
        add_1163: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38323, view_2333);  slice_38323 = view_2333 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2322: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4643, 1, 9280, 9296)
        slice_scatter_default_4644: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2322, add_1163, 2, 0, 16);  slice_tensor_2322 = add_1163 = None
        slice_scatter_default_4645: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4643, slice_scatter_default_4644, 1, 9280, 9296);  slice_scatter_default_4643 = slice_scatter_default_4644 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4645, 1, 9280, 9296)
        slice_38328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38327, 2, 0, 16);  slice_38327 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2323: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4645, 1, 9280, 9296)
        slice_scatter_default_4646: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2323, slice_38328, 2, 0, 16);  slice_tensor_2323 = slice_38328 = None
        slice_scatter_default_4647: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4645, slice_scatter_default_4646, 1, 9280, 9296);  slice_scatter_default_4645 = slice_scatter_default_4646 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38347: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9296, 9312)
        slice_38348: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38347, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1165: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38348, memory_format = torch.contiguous_format);  slice_38348 = None
        view_2334: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1165, [32, 16]);  clone_1165 = None
        mm_1162: "f32[32, 8]" = torch.ops.aten.mm.default(view_2334, slice_7)
        view_2335: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1162, [2, 16, 8]);  mm_1162 = None
        slice_38355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4647, 1, 9296, 9312)
        slice_38356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38355, 2, 0, 16);  slice_38355 = None
        add_1164: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38356, view_2335);  slice_38356 = view_2335 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2324: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4647, 1, 9296, 9312)
        slice_scatter_default_4648: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2324, add_1164, 2, 0, 16);  slice_tensor_2324 = add_1164 = None
        slice_scatter_default_4649: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4647, slice_scatter_default_4648, 1, 9296, 9312);  slice_scatter_default_4647 = slice_scatter_default_4648 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4649, 1, 9296, 9312)
        slice_38361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38360, 2, 0, 16);  slice_38360 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2325: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4649, 1, 9296, 9312)
        slice_scatter_default_4650: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2325, slice_38361, 2, 0, 16);  slice_tensor_2325 = slice_38361 = None
        slice_scatter_default_4651: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4649, slice_scatter_default_4650, 1, 9296, 9312);  slice_scatter_default_4649 = slice_scatter_default_4650 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38381: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38347, 2, 16, 32);  slice_38347 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1166: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38381, memory_format = torch.contiguous_format);  slice_38381 = None
        view_2336: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1166, [32, 11]);  clone_1166 = None
        mm_1163: "f32[32, 8]" = torch.ops.aten.mm.default(view_2336, slice_37)
        view_2337: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1163, [2, 16, 8]);  mm_1163 = None
        slice_38388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4651, 1, 9296, 9312)
        slice_38389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38388, 2, 0, 16);  slice_38388 = None
        add_1165: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38389, view_2337);  slice_38389 = view_2337 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2326: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4651, 1, 9296, 9312)
        slice_scatter_default_4652: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2326, add_1165, 2, 0, 16);  slice_tensor_2326 = add_1165 = None
        slice_scatter_default_4653: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4651, slice_scatter_default_4652, 1, 9296, 9312);  slice_scatter_default_4651 = slice_scatter_default_4652 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4653, 1, 9296, 9312)
        slice_38394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38393, 2, 0, 16);  slice_38393 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2327: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4653, 1, 9296, 9312)
        slice_scatter_default_4654: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2327, slice_38394, 2, 0, 16);  slice_tensor_2327 = slice_38394 = None
        slice_scatter_default_4655: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4653, slice_scatter_default_4654, 1, 9296, 9312);  slice_scatter_default_4653 = slice_scatter_default_4654 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38413: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9312, 9328)
        slice_38414: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38413, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1167: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38414, memory_format = torch.contiguous_format);  slice_38414 = None
        view_2338: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1167, [32, 16]);  clone_1167 = None
        mm_1164: "f32[32, 8]" = torch.ops.aten.mm.default(view_2338, slice_7)
        view_2339: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1164, [2, 16, 8]);  mm_1164 = None
        slice_38421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4655, 1, 9312, 9328)
        slice_38422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38421, 2, 0, 16);  slice_38421 = None
        add_1166: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38422, view_2339);  slice_38422 = view_2339 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2328: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4655, 1, 9312, 9328)
        slice_scatter_default_4656: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2328, add_1166, 2, 0, 16);  slice_tensor_2328 = add_1166 = None
        slice_scatter_default_4657: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4655, slice_scatter_default_4656, 1, 9312, 9328);  slice_scatter_default_4655 = slice_scatter_default_4656 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4657, 1, 9312, 9328)
        slice_38427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38426, 2, 0, 16);  slice_38426 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2329: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4657, 1, 9312, 9328)
        slice_scatter_default_4658: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2329, slice_38427, 2, 0, 16);  slice_tensor_2329 = slice_38427 = None
        slice_scatter_default_4659: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4657, slice_scatter_default_4658, 1, 9312, 9328);  slice_scatter_default_4657 = slice_scatter_default_4658 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38447: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38413, 2, 16, 32);  slice_38413 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1168: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38447, memory_format = torch.contiguous_format);  slice_38447 = None
        view_2340: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1168, [32, 11]);  clone_1168 = None
        mm_1165: "f32[32, 8]" = torch.ops.aten.mm.default(view_2340, slice_37)
        view_2341: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1165, [2, 16, 8]);  mm_1165 = None
        slice_38454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4659, 1, 9312, 9328)
        slice_38455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38454, 2, 0, 16);  slice_38454 = None
        add_1167: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38455, view_2341);  slice_38455 = view_2341 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2330: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4659, 1, 9312, 9328)
        slice_scatter_default_4660: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2330, add_1167, 2, 0, 16);  slice_tensor_2330 = add_1167 = None
        slice_scatter_default_4661: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4659, slice_scatter_default_4660, 1, 9312, 9328);  slice_scatter_default_4659 = slice_scatter_default_4660 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4661, 1, 9312, 9328)
        slice_38460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38459, 2, 0, 16);  slice_38459 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2331: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4661, 1, 9312, 9328)
        slice_scatter_default_4662: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2331, slice_38460, 2, 0, 16);  slice_tensor_2331 = slice_38460 = None
        slice_scatter_default_4663: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4661, slice_scatter_default_4662, 1, 9312, 9328);  slice_scatter_default_4661 = slice_scatter_default_4662 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38479: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9328, 9344)
        slice_38480: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38479, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1169: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38480, memory_format = torch.contiguous_format);  slice_38480 = None
        view_2342: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1169, [32, 16]);  clone_1169 = None
        mm_1166: "f32[32, 8]" = torch.ops.aten.mm.default(view_2342, slice_7)
        view_2343: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1166, [2, 16, 8]);  mm_1166 = None
        slice_38487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4663, 1, 9328, 9344)
        slice_38488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38487, 2, 0, 16);  slice_38487 = None
        add_1168: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38488, view_2343);  slice_38488 = view_2343 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2332: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4663, 1, 9328, 9344)
        slice_scatter_default_4664: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2332, add_1168, 2, 0, 16);  slice_tensor_2332 = add_1168 = None
        slice_scatter_default_4665: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4663, slice_scatter_default_4664, 1, 9328, 9344);  slice_scatter_default_4663 = slice_scatter_default_4664 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4665, 1, 9328, 9344)
        slice_38493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38492, 2, 0, 16);  slice_38492 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2333: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4665, 1, 9328, 9344)
        slice_scatter_default_4666: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2333, slice_38493, 2, 0, 16);  slice_tensor_2333 = slice_38493 = None
        slice_scatter_default_4667: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4665, slice_scatter_default_4666, 1, 9328, 9344);  slice_scatter_default_4665 = slice_scatter_default_4666 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38513: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38479, 2, 16, 32);  slice_38479 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1170: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38513, memory_format = torch.contiguous_format);  slice_38513 = None
        view_2344: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1170, [32, 11]);  clone_1170 = None
        mm_1167: "f32[32, 8]" = torch.ops.aten.mm.default(view_2344, slice_37)
        view_2345: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1167, [2, 16, 8]);  mm_1167 = None
        slice_38520: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4667, 1, 9328, 9344)
        slice_38521: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38520, 2, 0, 16);  slice_38520 = None
        add_1169: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38521, view_2345);  slice_38521 = view_2345 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2334: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4667, 1, 9328, 9344)
        slice_scatter_default_4668: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2334, add_1169, 2, 0, 16);  slice_tensor_2334 = add_1169 = None
        slice_scatter_default_4669: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4667, slice_scatter_default_4668, 1, 9328, 9344);  slice_scatter_default_4667 = slice_scatter_default_4668 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38525: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4669, 1, 9328, 9344)
        slice_38526: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38525, 2, 0, 16);  slice_38525 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4669, 1, 9328, 9344)
        slice_scatter_default_4670: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2335, slice_38526, 2, 0, 16);  slice_tensor_2335 = slice_38526 = None
        slice_scatter_default_4671: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4669, slice_scatter_default_4670, 1, 9328, 9344);  slice_scatter_default_4669 = slice_scatter_default_4670 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38545: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9344, 9360)
        slice_38546: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38545, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1171: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38546, memory_format = torch.contiguous_format);  slice_38546 = None
        view_2346: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1171, [32, 16]);  clone_1171 = None
        mm_1168: "f32[32, 8]" = torch.ops.aten.mm.default(view_2346, slice_7)
        view_2347: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1168, [2, 16, 8]);  mm_1168 = None
        slice_38553: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4671, 1, 9344, 9360)
        slice_38554: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38553, 2, 0, 16);  slice_38553 = None
        add_1170: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38554, view_2347);  slice_38554 = view_2347 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4671, 1, 9344, 9360)
        slice_scatter_default_4672: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2336, add_1170, 2, 0, 16);  slice_tensor_2336 = add_1170 = None
        slice_scatter_default_4673: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4671, slice_scatter_default_4672, 1, 9344, 9360);  slice_scatter_default_4671 = slice_scatter_default_4672 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38558: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4673, 1, 9344, 9360)
        slice_38559: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38558, 2, 0, 16);  slice_38558 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2337: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4673, 1, 9344, 9360)
        slice_scatter_default_4674: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2337, slice_38559, 2, 0, 16);  slice_tensor_2337 = slice_38559 = None
        slice_scatter_default_4675: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4673, slice_scatter_default_4674, 1, 9344, 9360);  slice_scatter_default_4673 = slice_scatter_default_4674 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38579: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38545, 2, 16, 32);  slice_38545 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1172: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38579, memory_format = torch.contiguous_format);  slice_38579 = None
        view_2348: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1172, [32, 11]);  clone_1172 = None
        mm_1169: "f32[32, 8]" = torch.ops.aten.mm.default(view_2348, slice_37)
        view_2349: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1169, [2, 16, 8]);  mm_1169 = None
        slice_38586: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4675, 1, 9344, 9360)
        slice_38587: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38586, 2, 0, 16);  slice_38586 = None
        add_1171: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38587, view_2349);  slice_38587 = view_2349 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2338: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4675, 1, 9344, 9360)
        slice_scatter_default_4676: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2338, add_1171, 2, 0, 16);  slice_tensor_2338 = add_1171 = None
        slice_scatter_default_4677: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4675, slice_scatter_default_4676, 1, 9344, 9360);  slice_scatter_default_4675 = slice_scatter_default_4676 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38591: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4677, 1, 9344, 9360)
        slice_38592: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38591, 2, 0, 16);  slice_38591 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2339: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4677, 1, 9344, 9360)
        slice_scatter_default_4678: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2339, slice_38592, 2, 0, 16);  slice_tensor_2339 = slice_38592 = None
        slice_scatter_default_4679: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4677, slice_scatter_default_4678, 1, 9344, 9360);  slice_scatter_default_4677 = slice_scatter_default_4678 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38611: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9360, 9376)
        slice_38612: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38611, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1173: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38612, memory_format = torch.contiguous_format);  slice_38612 = None
        view_2350: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1173, [32, 16]);  clone_1173 = None
        mm_1170: "f32[32, 8]" = torch.ops.aten.mm.default(view_2350, slice_7)
        view_2351: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1170, [2, 16, 8]);  mm_1170 = None
        slice_38619: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4679, 1, 9360, 9376)
        slice_38620: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38619, 2, 0, 16);  slice_38619 = None
        add_1172: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38620, view_2351);  slice_38620 = view_2351 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4679, 1, 9360, 9376)
        slice_scatter_default_4680: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2340, add_1172, 2, 0, 16);  slice_tensor_2340 = add_1172 = None
        slice_scatter_default_4681: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4679, slice_scatter_default_4680, 1, 9360, 9376);  slice_scatter_default_4679 = slice_scatter_default_4680 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38624: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4681, 1, 9360, 9376)
        slice_38625: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38624, 2, 0, 16);  slice_38624 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4681, 1, 9360, 9376)
        slice_scatter_default_4682: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2341, slice_38625, 2, 0, 16);  slice_tensor_2341 = slice_38625 = None
        slice_scatter_default_4683: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4681, slice_scatter_default_4682, 1, 9360, 9376);  slice_scatter_default_4681 = slice_scatter_default_4682 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38645: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38611, 2, 16, 32);  slice_38611 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1174: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38645, memory_format = torch.contiguous_format);  slice_38645 = None
        view_2352: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1174, [32, 11]);  clone_1174 = None
        mm_1171: "f32[32, 8]" = torch.ops.aten.mm.default(view_2352, slice_37)
        view_2353: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1171, [2, 16, 8]);  mm_1171 = None
        slice_38652: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4683, 1, 9360, 9376)
        slice_38653: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38652, 2, 0, 16);  slice_38652 = None
        add_1173: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38653, view_2353);  slice_38653 = view_2353 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2342: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4683, 1, 9360, 9376)
        slice_scatter_default_4684: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2342, add_1173, 2, 0, 16);  slice_tensor_2342 = add_1173 = None
        slice_scatter_default_4685: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4683, slice_scatter_default_4684, 1, 9360, 9376);  slice_scatter_default_4683 = slice_scatter_default_4684 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38657: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4685, 1, 9360, 9376)
        slice_38658: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38657, 2, 0, 16);  slice_38657 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2343: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4685, 1, 9360, 9376)
        slice_scatter_default_4686: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2343, slice_38658, 2, 0, 16);  slice_tensor_2343 = slice_38658 = None
        slice_scatter_default_4687: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4685, slice_scatter_default_4686, 1, 9360, 9376);  slice_scatter_default_4685 = slice_scatter_default_4686 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38677: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9376, 9392)
        slice_38678: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38677, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1175: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38678, memory_format = torch.contiguous_format);  slice_38678 = None
        view_2354: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1175, [32, 16]);  clone_1175 = None
        mm_1172: "f32[32, 8]" = torch.ops.aten.mm.default(view_2354, slice_7)
        view_2355: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1172, [2, 16, 8]);  mm_1172 = None
        slice_38685: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4687, 1, 9376, 9392)
        slice_38686: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38685, 2, 0, 16);  slice_38685 = None
        add_1174: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38686, view_2355);  slice_38686 = view_2355 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2344: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4687, 1, 9376, 9392)
        slice_scatter_default_4688: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2344, add_1174, 2, 0, 16);  slice_tensor_2344 = add_1174 = None
        slice_scatter_default_4689: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4687, slice_scatter_default_4688, 1, 9376, 9392);  slice_scatter_default_4687 = slice_scatter_default_4688 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38690: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4689, 1, 9376, 9392)
        slice_38691: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38690, 2, 0, 16);  slice_38690 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4689, 1, 9376, 9392)
        slice_scatter_default_4690: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2345, slice_38691, 2, 0, 16);  slice_tensor_2345 = slice_38691 = None
        slice_scatter_default_4691: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4689, slice_scatter_default_4690, 1, 9376, 9392);  slice_scatter_default_4689 = slice_scatter_default_4690 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38711: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38677, 2, 16, 32);  slice_38677 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1176: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38711, memory_format = torch.contiguous_format);  slice_38711 = None
        view_2356: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1176, [32, 11]);  clone_1176 = None
        mm_1173: "f32[32, 8]" = torch.ops.aten.mm.default(view_2356, slice_37)
        view_2357: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1173, [2, 16, 8]);  mm_1173 = None
        slice_38718: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4691, 1, 9376, 9392)
        slice_38719: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38718, 2, 0, 16);  slice_38718 = None
        add_1175: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38719, view_2357);  slice_38719 = view_2357 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4691, 1, 9376, 9392)
        slice_scatter_default_4692: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2346, add_1175, 2, 0, 16);  slice_tensor_2346 = add_1175 = None
        slice_scatter_default_4693: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4691, slice_scatter_default_4692, 1, 9376, 9392);  slice_scatter_default_4691 = slice_scatter_default_4692 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38723: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4693, 1, 9376, 9392)
        slice_38724: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38723, 2, 0, 16);  slice_38723 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2347: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4693, 1, 9376, 9392)
        slice_scatter_default_4694: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2347, slice_38724, 2, 0, 16);  slice_tensor_2347 = slice_38724 = None
        slice_scatter_default_4695: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4693, slice_scatter_default_4694, 1, 9376, 9392);  slice_scatter_default_4693 = slice_scatter_default_4694 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38743: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9392, 9408)
        slice_38744: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38743, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1177: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38744, memory_format = torch.contiguous_format);  slice_38744 = None
        view_2358: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1177, [32, 16]);  clone_1177 = None
        mm_1174: "f32[32, 8]" = torch.ops.aten.mm.default(view_2358, slice_7)
        view_2359: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1174, [2, 16, 8]);  mm_1174 = None
        slice_38751: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4695, 1, 9392, 9408)
        slice_38752: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38751, 2, 0, 16);  slice_38751 = None
        add_1176: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38752, view_2359);  slice_38752 = view_2359 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2348: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4695, 1, 9392, 9408)
        slice_scatter_default_4696: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2348, add_1176, 2, 0, 16);  slice_tensor_2348 = add_1176 = None
        slice_scatter_default_4697: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4695, slice_scatter_default_4696, 1, 9392, 9408);  slice_scatter_default_4695 = slice_scatter_default_4696 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38756: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4697, 1, 9392, 9408)
        slice_38757: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38756, 2, 0, 16);  slice_38756 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2349: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4697, 1, 9392, 9408)
        slice_scatter_default_4698: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2349, slice_38757, 2, 0, 16);  slice_tensor_2349 = slice_38757 = None
        slice_scatter_default_4699: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4697, slice_scatter_default_4698, 1, 9392, 9408);  slice_scatter_default_4697 = slice_scatter_default_4698 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38777: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38743, 2, 16, 32);  slice_38743 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1178: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38777, memory_format = torch.contiguous_format);  slice_38777 = None
        view_2360: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1178, [32, 11]);  clone_1178 = None
        mm_1175: "f32[32, 8]" = torch.ops.aten.mm.default(view_2360, slice_37)
        view_2361: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1175, [2, 16, 8]);  mm_1175 = None
        slice_38784: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4699, 1, 9392, 9408)
        slice_38785: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38784, 2, 0, 16);  slice_38784 = None
        add_1177: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38785, view_2361);  slice_38785 = view_2361 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4699, 1, 9392, 9408)
        slice_scatter_default_4700: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2350, add_1177, 2, 0, 16);  slice_tensor_2350 = add_1177 = None
        slice_scatter_default_4701: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4699, slice_scatter_default_4700, 1, 9392, 9408);  slice_scatter_default_4699 = slice_scatter_default_4700 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38789: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4701, 1, 9392, 9408)
        slice_38790: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38789, 2, 0, 16);  slice_38789 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4701, 1, 9392, 9408)
        slice_scatter_default_4702: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2351, slice_38790, 2, 0, 16);  slice_tensor_2351 = slice_38790 = None
        slice_scatter_default_4703: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4701, slice_scatter_default_4702, 1, 9392, 9408);  slice_scatter_default_4701 = slice_scatter_default_4702 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38809: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9408, 9424)
        slice_38810: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38809, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1179: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38810, memory_format = torch.contiguous_format);  slice_38810 = None
        view_2362: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1179, [32, 16]);  clone_1179 = None
        mm_1176: "f32[32, 8]" = torch.ops.aten.mm.default(view_2362, slice_7)
        view_2363: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1176, [2, 16, 8]);  mm_1176 = None
        slice_38817: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4703, 1, 9408, 9424)
        slice_38818: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38817, 2, 0, 16);  slice_38817 = None
        add_1178: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38818, view_2363);  slice_38818 = view_2363 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2352: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4703, 1, 9408, 9424)
        slice_scatter_default_4704: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2352, add_1178, 2, 0, 16);  slice_tensor_2352 = add_1178 = None
        slice_scatter_default_4705: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4703, slice_scatter_default_4704, 1, 9408, 9424);  slice_scatter_default_4703 = slice_scatter_default_4704 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38822: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4705, 1, 9408, 9424)
        slice_38823: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38822, 2, 0, 16);  slice_38822 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2353: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4705, 1, 9408, 9424)
        slice_scatter_default_4706: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2353, slice_38823, 2, 0, 16);  slice_tensor_2353 = slice_38823 = None
        slice_scatter_default_4707: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4705, slice_scatter_default_4706, 1, 9408, 9424);  slice_scatter_default_4705 = slice_scatter_default_4706 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38843: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38809, 2, 16, 32);  slice_38809 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1180: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38843, memory_format = torch.contiguous_format);  slice_38843 = None
        view_2364: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1180, [32, 11]);  clone_1180 = None
        mm_1177: "f32[32, 8]" = torch.ops.aten.mm.default(view_2364, slice_37)
        view_2365: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1177, [2, 16, 8]);  mm_1177 = None
        slice_38850: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4707, 1, 9408, 9424)
        slice_38851: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38850, 2, 0, 16);  slice_38850 = None
        add_1179: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38851, view_2365);  slice_38851 = view_2365 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2354: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4707, 1, 9408, 9424)
        slice_scatter_default_4708: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2354, add_1179, 2, 0, 16);  slice_tensor_2354 = add_1179 = None
        slice_scatter_default_4709: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4707, slice_scatter_default_4708, 1, 9408, 9424);  slice_scatter_default_4707 = slice_scatter_default_4708 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38855: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4709, 1, 9408, 9424)
        slice_38856: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38855, 2, 0, 16);  slice_38855 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2355: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4709, 1, 9408, 9424)
        slice_scatter_default_4710: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2355, slice_38856, 2, 0, 16);  slice_tensor_2355 = slice_38856 = None
        slice_scatter_default_4711: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4709, slice_scatter_default_4710, 1, 9408, 9424);  slice_scatter_default_4709 = slice_scatter_default_4710 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38875: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9424, 9440)
        slice_38876: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38875, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1181: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38876, memory_format = torch.contiguous_format);  slice_38876 = None
        view_2366: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1181, [32, 16]);  clone_1181 = None
        mm_1178: "f32[32, 8]" = torch.ops.aten.mm.default(view_2366, slice_7)
        view_2367: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1178, [2, 16, 8]);  mm_1178 = None
        slice_38883: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4711, 1, 9424, 9440)
        slice_38884: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38883, 2, 0, 16);  slice_38883 = None
        add_1180: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38884, view_2367);  slice_38884 = view_2367 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2356: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4711, 1, 9424, 9440)
        slice_scatter_default_4712: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2356, add_1180, 2, 0, 16);  slice_tensor_2356 = add_1180 = None
        slice_scatter_default_4713: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4711, slice_scatter_default_4712, 1, 9424, 9440);  slice_scatter_default_4711 = slice_scatter_default_4712 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38888: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4713, 1, 9424, 9440)
        slice_38889: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38888, 2, 0, 16);  slice_38888 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2357: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4713, 1, 9424, 9440)
        slice_scatter_default_4714: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2357, slice_38889, 2, 0, 16);  slice_tensor_2357 = slice_38889 = None
        slice_scatter_default_4715: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4713, slice_scatter_default_4714, 1, 9424, 9440);  slice_scatter_default_4713 = slice_scatter_default_4714 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38909: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38875, 2, 16, 32);  slice_38875 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1182: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38909, memory_format = torch.contiguous_format);  slice_38909 = None
        view_2368: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1182, [32, 11]);  clone_1182 = None
        mm_1179: "f32[32, 8]" = torch.ops.aten.mm.default(view_2368, slice_37)
        view_2369: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1179, [2, 16, 8]);  mm_1179 = None
        slice_38916: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4715, 1, 9424, 9440)
        slice_38917: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38916, 2, 0, 16);  slice_38916 = None
        add_1181: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38917, view_2369);  slice_38917 = view_2369 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2358: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4715, 1, 9424, 9440)
        slice_scatter_default_4716: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2358, add_1181, 2, 0, 16);  slice_tensor_2358 = add_1181 = None
        slice_scatter_default_4717: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4715, slice_scatter_default_4716, 1, 9424, 9440);  slice_scatter_default_4715 = slice_scatter_default_4716 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38921: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4717, 1, 9424, 9440)
        slice_38922: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38921, 2, 0, 16);  slice_38921 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2359: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4717, 1, 9424, 9440)
        slice_scatter_default_4718: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2359, slice_38922, 2, 0, 16);  slice_tensor_2359 = slice_38922 = None
        slice_scatter_default_4719: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4717, slice_scatter_default_4718, 1, 9424, 9440);  slice_scatter_default_4717 = slice_scatter_default_4718 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38941: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9440, 9456)
        slice_38942: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_38941, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1183: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_38942, memory_format = torch.contiguous_format);  slice_38942 = None
        view_2370: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1183, [32, 16]);  clone_1183 = None
        mm_1180: "f32[32, 8]" = torch.ops.aten.mm.default(view_2370, slice_7)
        view_2371: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1180, [2, 16, 8]);  mm_1180 = None
        slice_38949: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4719, 1, 9440, 9456)
        slice_38950: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38949, 2, 0, 16);  slice_38949 = None
        add_1182: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38950, view_2371);  slice_38950 = view_2371 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2360: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4719, 1, 9440, 9456)
        slice_scatter_default_4720: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2360, add_1182, 2, 0, 16);  slice_tensor_2360 = add_1182 = None
        slice_scatter_default_4721: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4719, slice_scatter_default_4720, 1, 9440, 9456);  slice_scatter_default_4719 = slice_scatter_default_4720 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38954: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4721, 1, 9440, 9456)
        slice_38955: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38954, 2, 0, 16);  slice_38954 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2361: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4721, 1, 9440, 9456)
        slice_scatter_default_4722: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2361, slice_38955, 2, 0, 16);  slice_tensor_2361 = slice_38955 = None
        slice_scatter_default_4723: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4721, slice_scatter_default_4722, 1, 9440, 9456);  slice_scatter_default_4721 = slice_scatter_default_4722 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_38975: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_38941, 2, 16, 32);  slice_38941 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1184: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_38975, memory_format = torch.contiguous_format);  slice_38975 = None
        view_2372: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1184, [32, 11]);  clone_1184 = None
        mm_1181: "f32[32, 8]" = torch.ops.aten.mm.default(view_2372, slice_37)
        view_2373: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1181, [2, 16, 8]);  mm_1181 = None
        slice_38982: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4723, 1, 9440, 9456)
        slice_38983: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38982, 2, 0, 16);  slice_38982 = None
        add_1183: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_38983, view_2373);  slice_38983 = view_2373 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2362: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4723, 1, 9440, 9456)
        slice_scatter_default_4724: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2362, add_1183, 2, 0, 16);  slice_tensor_2362 = add_1183 = None
        slice_scatter_default_4725: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4723, slice_scatter_default_4724, 1, 9440, 9456);  slice_scatter_default_4723 = slice_scatter_default_4724 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_38987: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4725, 1, 9440, 9456)
        slice_38988: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_38987, 2, 0, 16);  slice_38987 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2363: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4725, 1, 9440, 9456)
        slice_scatter_default_4726: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2363, slice_38988, 2, 0, 16);  slice_tensor_2363 = slice_38988 = None
        slice_scatter_default_4727: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4725, slice_scatter_default_4726, 1, 9440, 9456);  slice_scatter_default_4725 = slice_scatter_default_4726 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39007: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9456, 9472)
        slice_39008: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39007, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1185: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39008, memory_format = torch.contiguous_format);  slice_39008 = None
        view_2374: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1185, [32, 16]);  clone_1185 = None
        mm_1182: "f32[32, 8]" = torch.ops.aten.mm.default(view_2374, slice_7)
        view_2375: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1182, [2, 16, 8]);  mm_1182 = None
        slice_39015: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4727, 1, 9456, 9472)
        slice_39016: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39015, 2, 0, 16);  slice_39015 = None
        add_1184: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39016, view_2375);  slice_39016 = view_2375 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2364: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4727, 1, 9456, 9472)
        slice_scatter_default_4728: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2364, add_1184, 2, 0, 16);  slice_tensor_2364 = add_1184 = None
        slice_scatter_default_4729: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4727, slice_scatter_default_4728, 1, 9456, 9472);  slice_scatter_default_4727 = slice_scatter_default_4728 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39020: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4729, 1, 9456, 9472)
        slice_39021: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39020, 2, 0, 16);  slice_39020 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2365: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4729, 1, 9456, 9472)
        slice_scatter_default_4730: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2365, slice_39021, 2, 0, 16);  slice_tensor_2365 = slice_39021 = None
        slice_scatter_default_4731: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4729, slice_scatter_default_4730, 1, 9456, 9472);  slice_scatter_default_4729 = slice_scatter_default_4730 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39041: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39007, 2, 16, 32);  slice_39007 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1186: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39041, memory_format = torch.contiguous_format);  slice_39041 = None
        view_2376: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1186, [32, 11]);  clone_1186 = None
        mm_1183: "f32[32, 8]" = torch.ops.aten.mm.default(view_2376, slice_37)
        view_2377: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1183, [2, 16, 8]);  mm_1183 = None
        slice_39048: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4731, 1, 9456, 9472)
        slice_39049: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39048, 2, 0, 16);  slice_39048 = None
        add_1185: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39049, view_2377);  slice_39049 = view_2377 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2366: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4731, 1, 9456, 9472)
        slice_scatter_default_4732: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2366, add_1185, 2, 0, 16);  slice_tensor_2366 = add_1185 = None
        slice_scatter_default_4733: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4731, slice_scatter_default_4732, 1, 9456, 9472);  slice_scatter_default_4731 = slice_scatter_default_4732 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39053: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4733, 1, 9456, 9472)
        slice_39054: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39053, 2, 0, 16);  slice_39053 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2367: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4733, 1, 9456, 9472)
        slice_scatter_default_4734: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2367, slice_39054, 2, 0, 16);  slice_tensor_2367 = slice_39054 = None
        slice_scatter_default_4735: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4733, slice_scatter_default_4734, 1, 9456, 9472);  slice_scatter_default_4733 = slice_scatter_default_4734 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39073: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9472, 9488)
        slice_39074: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39073, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1187: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39074, memory_format = torch.contiguous_format);  slice_39074 = None
        view_2378: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1187, [32, 16]);  clone_1187 = None
        mm_1184: "f32[32, 8]" = torch.ops.aten.mm.default(view_2378, slice_7)
        view_2379: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1184, [2, 16, 8]);  mm_1184 = None
        slice_39081: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4735, 1, 9472, 9488)
        slice_39082: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39081, 2, 0, 16);  slice_39081 = None
        add_1186: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39082, view_2379);  slice_39082 = view_2379 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4735, 1, 9472, 9488)
        slice_scatter_default_4736: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2368, add_1186, 2, 0, 16);  slice_tensor_2368 = add_1186 = None
        slice_scatter_default_4737: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4735, slice_scatter_default_4736, 1, 9472, 9488);  slice_scatter_default_4735 = slice_scatter_default_4736 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39086: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4737, 1, 9472, 9488)
        slice_39087: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39086, 2, 0, 16);  slice_39086 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4737, 1, 9472, 9488)
        slice_scatter_default_4738: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2369, slice_39087, 2, 0, 16);  slice_tensor_2369 = slice_39087 = None
        slice_scatter_default_4739: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4737, slice_scatter_default_4738, 1, 9472, 9488);  slice_scatter_default_4737 = slice_scatter_default_4738 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39107: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39073, 2, 16, 32);  slice_39073 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1188: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39107, memory_format = torch.contiguous_format);  slice_39107 = None
        view_2380: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1188, [32, 11]);  clone_1188 = None
        mm_1185: "f32[32, 8]" = torch.ops.aten.mm.default(view_2380, slice_37)
        view_2381: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1185, [2, 16, 8]);  mm_1185 = None
        slice_39114: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4739, 1, 9472, 9488)
        slice_39115: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39114, 2, 0, 16);  slice_39114 = None
        add_1187: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39115, view_2381);  slice_39115 = view_2381 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2370: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4739, 1, 9472, 9488)
        slice_scatter_default_4740: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2370, add_1187, 2, 0, 16);  slice_tensor_2370 = add_1187 = None
        slice_scatter_default_4741: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4739, slice_scatter_default_4740, 1, 9472, 9488);  slice_scatter_default_4739 = slice_scatter_default_4740 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39119: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4741, 1, 9472, 9488)
        slice_39120: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39119, 2, 0, 16);  slice_39119 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2371: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4741, 1, 9472, 9488)
        slice_scatter_default_4742: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2371, slice_39120, 2, 0, 16);  slice_tensor_2371 = slice_39120 = None
        slice_scatter_default_4743: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4741, slice_scatter_default_4742, 1, 9472, 9488);  slice_scatter_default_4741 = slice_scatter_default_4742 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39139: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9488, 9504)
        slice_39140: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39139, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1189: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39140, memory_format = torch.contiguous_format);  slice_39140 = None
        view_2382: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1189, [32, 16]);  clone_1189 = None
        mm_1186: "f32[32, 8]" = torch.ops.aten.mm.default(view_2382, slice_7)
        view_2383: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1186, [2, 16, 8]);  mm_1186 = None
        slice_39147: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4743, 1, 9488, 9504)
        slice_39148: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39147, 2, 0, 16);  slice_39147 = None
        add_1188: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39148, view_2383);  slice_39148 = view_2383 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2372: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4743, 1, 9488, 9504)
        slice_scatter_default_4744: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2372, add_1188, 2, 0, 16);  slice_tensor_2372 = add_1188 = None
        slice_scatter_default_4745: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4743, slice_scatter_default_4744, 1, 9488, 9504);  slice_scatter_default_4743 = slice_scatter_default_4744 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39152: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4745, 1, 9488, 9504)
        slice_39153: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39152, 2, 0, 16);  slice_39152 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4745, 1, 9488, 9504)
        slice_scatter_default_4746: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2373, slice_39153, 2, 0, 16);  slice_tensor_2373 = slice_39153 = None
        slice_scatter_default_4747: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4745, slice_scatter_default_4746, 1, 9488, 9504);  slice_scatter_default_4745 = slice_scatter_default_4746 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39173: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39139, 2, 16, 32);  slice_39139 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1190: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39173, memory_format = torch.contiguous_format);  slice_39173 = None
        view_2384: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1190, [32, 11]);  clone_1190 = None
        mm_1187: "f32[32, 8]" = torch.ops.aten.mm.default(view_2384, slice_37)
        view_2385: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1187, [2, 16, 8]);  mm_1187 = None
        slice_39180: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4747, 1, 9488, 9504)
        slice_39181: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39180, 2, 0, 16);  slice_39180 = None
        add_1189: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39181, view_2385);  slice_39181 = view_2385 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4747, 1, 9488, 9504)
        slice_scatter_default_4748: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2374, add_1189, 2, 0, 16);  slice_tensor_2374 = add_1189 = None
        slice_scatter_default_4749: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4747, slice_scatter_default_4748, 1, 9488, 9504);  slice_scatter_default_4747 = slice_scatter_default_4748 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39185: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4749, 1, 9488, 9504)
        slice_39186: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39185, 2, 0, 16);  slice_39185 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2375: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4749, 1, 9488, 9504)
        slice_scatter_default_4750: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2375, slice_39186, 2, 0, 16);  slice_tensor_2375 = slice_39186 = None
        slice_scatter_default_4751: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4749, slice_scatter_default_4750, 1, 9488, 9504);  slice_scatter_default_4749 = slice_scatter_default_4750 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39205: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9504, 9520)
        slice_39206: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39205, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1191: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39206, memory_format = torch.contiguous_format);  slice_39206 = None
        view_2386: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1191, [32, 16]);  clone_1191 = None
        mm_1188: "f32[32, 8]" = torch.ops.aten.mm.default(view_2386, slice_7)
        view_2387: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1188, [2, 16, 8]);  mm_1188 = None
        slice_39213: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4751, 1, 9504, 9520)
        slice_39214: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39213, 2, 0, 16);  slice_39213 = None
        add_1190: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39214, view_2387);  slice_39214 = view_2387 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2376: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4751, 1, 9504, 9520)
        slice_scatter_default_4752: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2376, add_1190, 2, 0, 16);  slice_tensor_2376 = add_1190 = None
        slice_scatter_default_4753: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4751, slice_scatter_default_4752, 1, 9504, 9520);  slice_scatter_default_4751 = slice_scatter_default_4752 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39218: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4753, 1, 9504, 9520)
        slice_39219: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39218, 2, 0, 16);  slice_39218 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2377: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4753, 1, 9504, 9520)
        slice_scatter_default_4754: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2377, slice_39219, 2, 0, 16);  slice_tensor_2377 = slice_39219 = None
        slice_scatter_default_4755: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4753, slice_scatter_default_4754, 1, 9504, 9520);  slice_scatter_default_4753 = slice_scatter_default_4754 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39239: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39205, 2, 16, 32);  slice_39205 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1192: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39239, memory_format = torch.contiguous_format);  slice_39239 = None
        view_2388: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1192, [32, 11]);  clone_1192 = None
        mm_1189: "f32[32, 8]" = torch.ops.aten.mm.default(view_2388, slice_37)
        view_2389: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1189, [2, 16, 8]);  mm_1189 = None
        slice_39246: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4755, 1, 9504, 9520)
        slice_39247: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39246, 2, 0, 16);  slice_39246 = None
        add_1191: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39247, view_2389);  slice_39247 = view_2389 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4755, 1, 9504, 9520)
        slice_scatter_default_4756: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2378, add_1191, 2, 0, 16);  slice_tensor_2378 = add_1191 = None
        slice_scatter_default_4757: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4755, slice_scatter_default_4756, 1, 9504, 9520);  slice_scatter_default_4755 = slice_scatter_default_4756 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39251: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4757, 1, 9504, 9520)
        slice_39252: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39251, 2, 0, 16);  slice_39251 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4757, 1, 9504, 9520)
        slice_scatter_default_4758: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2379, slice_39252, 2, 0, 16);  slice_tensor_2379 = slice_39252 = None
        slice_scatter_default_4759: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4757, slice_scatter_default_4758, 1, 9504, 9520);  slice_scatter_default_4757 = slice_scatter_default_4758 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39271: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9520, 9536)
        slice_39272: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39271, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1193: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39272, memory_format = torch.contiguous_format);  slice_39272 = None
        view_2390: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1193, [32, 16]);  clone_1193 = None
        mm_1190: "f32[32, 8]" = torch.ops.aten.mm.default(view_2390, slice_7)
        view_2391: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1190, [2, 16, 8]);  mm_1190 = None
        slice_39279: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4759, 1, 9520, 9536)
        slice_39280: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39279, 2, 0, 16);  slice_39279 = None
        add_1192: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39280, view_2391);  slice_39280 = view_2391 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2380: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4759, 1, 9520, 9536)
        slice_scatter_default_4760: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2380, add_1192, 2, 0, 16);  slice_tensor_2380 = add_1192 = None
        slice_scatter_default_4761: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4759, slice_scatter_default_4760, 1, 9520, 9536);  slice_scatter_default_4759 = slice_scatter_default_4760 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39284: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4761, 1, 9520, 9536)
        slice_39285: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39284, 2, 0, 16);  slice_39284 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2381: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4761, 1, 9520, 9536)
        slice_scatter_default_4762: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2381, slice_39285, 2, 0, 16);  slice_tensor_2381 = slice_39285 = None
        slice_scatter_default_4763: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4761, slice_scatter_default_4762, 1, 9520, 9536);  slice_scatter_default_4761 = slice_scatter_default_4762 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39305: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39271, 2, 16, 32);  slice_39271 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1194: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39305, memory_format = torch.contiguous_format);  slice_39305 = None
        view_2392: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1194, [32, 11]);  clone_1194 = None
        mm_1191: "f32[32, 8]" = torch.ops.aten.mm.default(view_2392, slice_37)
        view_2393: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1191, [2, 16, 8]);  mm_1191 = None
        slice_39312: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4763, 1, 9520, 9536)
        slice_39313: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39312, 2, 0, 16);  slice_39312 = None
        add_1193: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39313, view_2393);  slice_39313 = view_2393 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2382: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4763, 1, 9520, 9536)
        slice_scatter_default_4764: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2382, add_1193, 2, 0, 16);  slice_tensor_2382 = add_1193 = None
        slice_scatter_default_4765: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4763, slice_scatter_default_4764, 1, 9520, 9536);  slice_scatter_default_4763 = slice_scatter_default_4764 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39317: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4765, 1, 9520, 9536)
        slice_39318: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39317, 2, 0, 16);  slice_39317 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4765, 1, 9520, 9536)
        slice_scatter_default_4766: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2383, slice_39318, 2, 0, 16);  slice_tensor_2383 = slice_39318 = None
        slice_scatter_default_4767: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4765, slice_scatter_default_4766, 1, 9520, 9536);  slice_scatter_default_4765 = slice_scatter_default_4766 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39337: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9536, 9552)
        slice_39338: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39337, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1195: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39338, memory_format = torch.contiguous_format);  slice_39338 = None
        view_2394: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1195, [32, 16]);  clone_1195 = None
        mm_1192: "f32[32, 8]" = torch.ops.aten.mm.default(view_2394, slice_7)
        view_2395: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1192, [2, 16, 8]);  mm_1192 = None
        slice_39345: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4767, 1, 9536, 9552)
        slice_39346: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39345, 2, 0, 16);  slice_39345 = None
        add_1194: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39346, view_2395);  slice_39346 = view_2395 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4767, 1, 9536, 9552)
        slice_scatter_default_4768: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2384, add_1194, 2, 0, 16);  slice_tensor_2384 = add_1194 = None
        slice_scatter_default_4769: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4767, slice_scatter_default_4768, 1, 9536, 9552);  slice_scatter_default_4767 = slice_scatter_default_4768 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39350: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4769, 1, 9536, 9552)
        slice_39351: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39350, 2, 0, 16);  slice_39350 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2385: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4769, 1, 9536, 9552)
        slice_scatter_default_4770: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2385, slice_39351, 2, 0, 16);  slice_tensor_2385 = slice_39351 = None
        slice_scatter_default_4771: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4769, slice_scatter_default_4770, 1, 9536, 9552);  slice_scatter_default_4769 = slice_scatter_default_4770 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39371: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39337, 2, 16, 32);  slice_39337 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1196: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39371, memory_format = torch.contiguous_format);  slice_39371 = None
        view_2396: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1196, [32, 11]);  clone_1196 = None
        mm_1193: "f32[32, 8]" = torch.ops.aten.mm.default(view_2396, slice_37)
        view_2397: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1193, [2, 16, 8]);  mm_1193 = None
        slice_39378: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4771, 1, 9536, 9552)
        slice_39379: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39378, 2, 0, 16);  slice_39378 = None
        add_1195: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39379, view_2397);  slice_39379 = view_2397 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2386: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4771, 1, 9536, 9552)
        slice_scatter_default_4772: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2386, add_1195, 2, 0, 16);  slice_tensor_2386 = add_1195 = None
        slice_scatter_default_4773: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4771, slice_scatter_default_4772, 1, 9536, 9552);  slice_scatter_default_4771 = slice_scatter_default_4772 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39383: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4773, 1, 9536, 9552)
        slice_39384: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39383, 2, 0, 16);  slice_39383 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2387: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4773, 1, 9536, 9552)
        slice_scatter_default_4774: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2387, slice_39384, 2, 0, 16);  slice_tensor_2387 = slice_39384 = None
        slice_scatter_default_4775: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4773, slice_scatter_default_4774, 1, 9536, 9552);  slice_scatter_default_4773 = slice_scatter_default_4774 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39403: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9552, 9568)
        slice_39404: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39403, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1197: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39404, memory_format = torch.contiguous_format);  slice_39404 = None
        view_2398: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1197, [32, 16]);  clone_1197 = None
        mm_1194: "f32[32, 8]" = torch.ops.aten.mm.default(view_2398, slice_7)
        view_2399: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1194, [2, 16, 8]);  mm_1194 = None
        slice_39411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4775, 1, 9552, 9568)
        slice_39412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39411, 2, 0, 16);  slice_39411 = None
        add_1196: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39412, view_2399);  slice_39412 = view_2399 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2388: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4775, 1, 9552, 9568)
        slice_scatter_default_4776: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2388, add_1196, 2, 0, 16);  slice_tensor_2388 = add_1196 = None
        slice_scatter_default_4777: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4775, slice_scatter_default_4776, 1, 9552, 9568);  slice_scatter_default_4775 = slice_scatter_default_4776 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4777, 1, 9552, 9568)
        slice_39417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39416, 2, 0, 16);  slice_39416 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2389: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4777, 1, 9552, 9568)
        slice_scatter_default_4778: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2389, slice_39417, 2, 0, 16);  slice_tensor_2389 = slice_39417 = None
        slice_scatter_default_4779: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4777, slice_scatter_default_4778, 1, 9552, 9568);  slice_scatter_default_4777 = slice_scatter_default_4778 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39437: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39403, 2, 16, 32);  slice_39403 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1198: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39437, memory_format = torch.contiguous_format);  slice_39437 = None
        view_2400: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1198, [32, 11]);  clone_1198 = None
        mm_1195: "f32[32, 8]" = torch.ops.aten.mm.default(view_2400, slice_37)
        view_2401: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1195, [2, 16, 8]);  mm_1195 = None
        slice_39444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4779, 1, 9552, 9568)
        slice_39445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39444, 2, 0, 16);  slice_39444 = None
        add_1197: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39445, view_2401);  slice_39445 = view_2401 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2390: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4779, 1, 9552, 9568)
        slice_scatter_default_4780: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2390, add_1197, 2, 0, 16);  slice_tensor_2390 = add_1197 = None
        slice_scatter_default_4781: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4779, slice_scatter_default_4780, 1, 9552, 9568);  slice_scatter_default_4779 = slice_scatter_default_4780 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4781, 1, 9552, 9568)
        slice_39450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39449, 2, 0, 16);  slice_39449 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2391: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4781, 1, 9552, 9568)
        slice_scatter_default_4782: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2391, slice_39450, 2, 0, 16);  slice_tensor_2391 = slice_39450 = None
        slice_scatter_default_4783: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4781, slice_scatter_default_4782, 1, 9552, 9568);  slice_scatter_default_4781 = slice_scatter_default_4782 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39469: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9568, 9584)
        slice_39470: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39469, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1199: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39470, memory_format = torch.contiguous_format);  slice_39470 = None
        view_2402: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1199, [32, 16]);  clone_1199 = None
        mm_1196: "f32[32, 8]" = torch.ops.aten.mm.default(view_2402, slice_7)
        view_2403: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1196, [2, 16, 8]);  mm_1196 = None
        slice_39477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4783, 1, 9568, 9584)
        slice_39478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39477, 2, 0, 16);  slice_39477 = None
        add_1198: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39478, view_2403);  slice_39478 = view_2403 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2392: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4783, 1, 9568, 9584)
        slice_scatter_default_4784: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2392, add_1198, 2, 0, 16);  slice_tensor_2392 = add_1198 = None
        slice_scatter_default_4785: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4783, slice_scatter_default_4784, 1, 9568, 9584);  slice_scatter_default_4783 = slice_scatter_default_4784 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4785, 1, 9568, 9584)
        slice_39483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39482, 2, 0, 16);  slice_39482 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2393: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4785, 1, 9568, 9584)
        slice_scatter_default_4786: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2393, slice_39483, 2, 0, 16);  slice_tensor_2393 = slice_39483 = None
        slice_scatter_default_4787: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4785, slice_scatter_default_4786, 1, 9568, 9584);  slice_scatter_default_4785 = slice_scatter_default_4786 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39503: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39469, 2, 16, 32);  slice_39469 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1200: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39503, memory_format = torch.contiguous_format);  slice_39503 = None
        view_2404: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1200, [32, 11]);  clone_1200 = None
        mm_1197: "f32[32, 8]" = torch.ops.aten.mm.default(view_2404, slice_37)
        view_2405: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1197, [2, 16, 8]);  mm_1197 = None
        slice_39510: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4787, 1, 9568, 9584)
        slice_39511: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39510, 2, 0, 16);  slice_39510 = None
        add_1199: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39511, view_2405);  slice_39511 = view_2405 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2394: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4787, 1, 9568, 9584)
        slice_scatter_default_4788: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2394, add_1199, 2, 0, 16);  slice_tensor_2394 = add_1199 = None
        slice_scatter_default_4789: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4787, slice_scatter_default_4788, 1, 9568, 9584);  slice_scatter_default_4787 = slice_scatter_default_4788 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39515: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4789, 1, 9568, 9584)
        slice_39516: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39515, 2, 0, 16);  slice_39515 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2395: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4789, 1, 9568, 9584)
        slice_scatter_default_4790: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2395, slice_39516, 2, 0, 16);  slice_tensor_2395 = slice_39516 = None
        slice_scatter_default_4791: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4789, slice_scatter_default_4790, 1, 9568, 9584);  slice_scatter_default_4789 = slice_scatter_default_4790 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39535: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9584, 9600)
        slice_39536: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39535, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1201: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39536, memory_format = torch.contiguous_format);  slice_39536 = None
        view_2406: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1201, [32, 16]);  clone_1201 = None
        mm_1198: "f32[32, 8]" = torch.ops.aten.mm.default(view_2406, slice_7)
        view_2407: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1198, [2, 16, 8]);  mm_1198 = None
        slice_39543: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4791, 1, 9584, 9600)
        slice_39544: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39543, 2, 0, 16);  slice_39543 = None
        add_1200: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39544, view_2407);  slice_39544 = view_2407 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2396: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4791, 1, 9584, 9600)
        slice_scatter_default_4792: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2396, add_1200, 2, 0, 16);  slice_tensor_2396 = add_1200 = None
        slice_scatter_default_4793: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4791, slice_scatter_default_4792, 1, 9584, 9600);  slice_scatter_default_4791 = slice_scatter_default_4792 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39548: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4793, 1, 9584, 9600)
        slice_39549: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39548, 2, 0, 16);  slice_39548 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2397: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4793, 1, 9584, 9600)
        slice_scatter_default_4794: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2397, slice_39549, 2, 0, 16);  slice_tensor_2397 = slice_39549 = None
        slice_scatter_default_4795: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4793, slice_scatter_default_4794, 1, 9584, 9600);  slice_scatter_default_4793 = slice_scatter_default_4794 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39569: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39535, 2, 16, 32);  slice_39535 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1202: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39569, memory_format = torch.contiguous_format);  slice_39569 = None
        view_2408: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1202, [32, 11]);  clone_1202 = None
        mm_1199: "f32[32, 8]" = torch.ops.aten.mm.default(view_2408, slice_37)
        view_2409: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1199, [2, 16, 8]);  mm_1199 = None
        slice_39576: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4795, 1, 9584, 9600)
        slice_39577: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39576, 2, 0, 16);  slice_39576 = None
        add_1201: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39577, view_2409);  slice_39577 = view_2409 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2398: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4795, 1, 9584, 9600)
        slice_scatter_default_4796: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2398, add_1201, 2, 0, 16);  slice_tensor_2398 = add_1201 = None
        slice_scatter_default_4797: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4795, slice_scatter_default_4796, 1, 9584, 9600);  slice_scatter_default_4795 = slice_scatter_default_4796 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39581: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4797, 1, 9584, 9600)
        slice_39582: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39581, 2, 0, 16);  slice_39581 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2399: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4797, 1, 9584, 9600)
        slice_scatter_default_4798: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2399, slice_39582, 2, 0, 16);  slice_tensor_2399 = slice_39582 = None
        slice_scatter_default_4799: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4797, slice_scatter_default_4798, 1, 9584, 9600);  slice_scatter_default_4797 = slice_scatter_default_4798 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39601: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9600, 9616)
        slice_39602: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39601, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1203: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39602, memory_format = torch.contiguous_format);  slice_39602 = None
        view_2410: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1203, [32, 16]);  clone_1203 = None
        mm_1200: "f32[32, 8]" = torch.ops.aten.mm.default(view_2410, slice_7)
        view_2411: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1200, [2, 16, 8]);  mm_1200 = None
        slice_39609: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4799, 1, 9600, 9616)
        slice_39610: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39609, 2, 0, 16);  slice_39609 = None
        add_1202: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39610, view_2411);  slice_39610 = view_2411 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2400: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4799, 1, 9600, 9616)
        slice_scatter_default_4800: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2400, add_1202, 2, 0, 16);  slice_tensor_2400 = add_1202 = None
        slice_scatter_default_4801: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4799, slice_scatter_default_4800, 1, 9600, 9616);  slice_scatter_default_4799 = slice_scatter_default_4800 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39614: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4801, 1, 9600, 9616)
        slice_39615: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39614, 2, 0, 16);  slice_39614 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4801, 1, 9600, 9616)
        slice_scatter_default_4802: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2401, slice_39615, 2, 0, 16);  slice_tensor_2401 = slice_39615 = None
        slice_scatter_default_4803: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4801, slice_scatter_default_4802, 1, 9600, 9616);  slice_scatter_default_4801 = slice_scatter_default_4802 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39635: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39601, 2, 16, 32);  slice_39601 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1204: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39635, memory_format = torch.contiguous_format);  slice_39635 = None
        view_2412: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1204, [32, 11]);  clone_1204 = None
        mm_1201: "f32[32, 8]" = torch.ops.aten.mm.default(view_2412, slice_37)
        view_2413: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1201, [2, 16, 8]);  mm_1201 = None
        slice_39642: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4803, 1, 9600, 9616)
        slice_39643: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39642, 2, 0, 16);  slice_39642 = None
        add_1203: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39643, view_2413);  slice_39643 = view_2413 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4803, 1, 9600, 9616)
        slice_scatter_default_4804: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2402, add_1203, 2, 0, 16);  slice_tensor_2402 = add_1203 = None
        slice_scatter_default_4805: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4803, slice_scatter_default_4804, 1, 9600, 9616);  slice_scatter_default_4803 = slice_scatter_default_4804 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39647: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4805, 1, 9600, 9616)
        slice_39648: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39647, 2, 0, 16);  slice_39647 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2403: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4805, 1, 9600, 9616)
        slice_scatter_default_4806: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2403, slice_39648, 2, 0, 16);  slice_tensor_2403 = slice_39648 = None
        slice_scatter_default_4807: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4805, slice_scatter_default_4806, 1, 9600, 9616);  slice_scatter_default_4805 = slice_scatter_default_4806 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39667: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9616, 9632)
        slice_39668: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39667, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1205: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39668, memory_format = torch.contiguous_format);  slice_39668 = None
        view_2414: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1205, [32, 16]);  clone_1205 = None
        mm_1202: "f32[32, 8]" = torch.ops.aten.mm.default(view_2414, slice_7)
        view_2415: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1202, [2, 16, 8]);  mm_1202 = None
        slice_39675: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4807, 1, 9616, 9632)
        slice_39676: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39675, 2, 0, 16);  slice_39675 = None
        add_1204: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39676, view_2415);  slice_39676 = view_2415 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2404: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4807, 1, 9616, 9632)
        slice_scatter_default_4808: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2404, add_1204, 2, 0, 16);  slice_tensor_2404 = add_1204 = None
        slice_scatter_default_4809: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4807, slice_scatter_default_4808, 1, 9616, 9632);  slice_scatter_default_4807 = slice_scatter_default_4808 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39680: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4809, 1, 9616, 9632)
        slice_39681: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39680, 2, 0, 16);  slice_39680 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2405: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4809, 1, 9616, 9632)
        slice_scatter_default_4810: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2405, slice_39681, 2, 0, 16);  slice_tensor_2405 = slice_39681 = None
        slice_scatter_default_4811: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4809, slice_scatter_default_4810, 1, 9616, 9632);  slice_scatter_default_4809 = slice_scatter_default_4810 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39701: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39667, 2, 16, 32);  slice_39667 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1206: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39701, memory_format = torch.contiguous_format);  slice_39701 = None
        view_2416: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1206, [32, 11]);  clone_1206 = None
        mm_1203: "f32[32, 8]" = torch.ops.aten.mm.default(view_2416, slice_37)
        view_2417: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1203, [2, 16, 8]);  mm_1203 = None
        slice_39708: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4811, 1, 9616, 9632)
        slice_39709: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39708, 2, 0, 16);  slice_39708 = None
        add_1205: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39709, view_2417);  slice_39709 = view_2417 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4811, 1, 9616, 9632)
        slice_scatter_default_4812: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2406, add_1205, 2, 0, 16);  slice_tensor_2406 = add_1205 = None
        slice_scatter_default_4813: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4811, slice_scatter_default_4812, 1, 9616, 9632);  slice_scatter_default_4811 = slice_scatter_default_4812 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39713: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4813, 1, 9616, 9632)
        slice_39714: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39713, 2, 0, 16);  slice_39713 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4813, 1, 9616, 9632)
        slice_scatter_default_4814: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2407, slice_39714, 2, 0, 16);  slice_tensor_2407 = slice_39714 = None
        slice_scatter_default_4815: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4813, slice_scatter_default_4814, 1, 9616, 9632);  slice_scatter_default_4813 = slice_scatter_default_4814 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39733: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9632, 9648)
        slice_39734: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39733, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1207: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39734, memory_format = torch.contiguous_format);  slice_39734 = None
        view_2418: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1207, [32, 16]);  clone_1207 = None
        mm_1204: "f32[32, 8]" = torch.ops.aten.mm.default(view_2418, slice_7)
        view_2419: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1204, [2, 16, 8]);  mm_1204 = None
        slice_39741: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4815, 1, 9632, 9648)
        slice_39742: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39741, 2, 0, 16);  slice_39741 = None
        add_1206: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39742, view_2419);  slice_39742 = view_2419 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2408: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4815, 1, 9632, 9648)
        slice_scatter_default_4816: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2408, add_1206, 2, 0, 16);  slice_tensor_2408 = add_1206 = None
        slice_scatter_default_4817: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4815, slice_scatter_default_4816, 1, 9632, 9648);  slice_scatter_default_4815 = slice_scatter_default_4816 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39746: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4817, 1, 9632, 9648)
        slice_39747: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39746, 2, 0, 16);  slice_39746 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2409: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4817, 1, 9632, 9648)
        slice_scatter_default_4818: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2409, slice_39747, 2, 0, 16);  slice_tensor_2409 = slice_39747 = None
        slice_scatter_default_4819: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4817, slice_scatter_default_4818, 1, 9632, 9648);  slice_scatter_default_4817 = slice_scatter_default_4818 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39767: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39733, 2, 16, 32);  slice_39733 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1208: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39767, memory_format = torch.contiguous_format);  slice_39767 = None
        view_2420: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1208, [32, 11]);  clone_1208 = None
        mm_1205: "f32[32, 8]" = torch.ops.aten.mm.default(view_2420, slice_37)
        view_2421: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1205, [2, 16, 8]);  mm_1205 = None
        slice_39774: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4819, 1, 9632, 9648)
        slice_39775: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39774, 2, 0, 16);  slice_39774 = None
        add_1207: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39775, view_2421);  slice_39775 = view_2421 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2410: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4819, 1, 9632, 9648)
        slice_scatter_default_4820: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2410, add_1207, 2, 0, 16);  slice_tensor_2410 = add_1207 = None
        slice_scatter_default_4821: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4819, slice_scatter_default_4820, 1, 9632, 9648);  slice_scatter_default_4819 = slice_scatter_default_4820 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39779: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4821, 1, 9632, 9648)
        slice_39780: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39779, 2, 0, 16);  slice_39779 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2411: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4821, 1, 9632, 9648)
        slice_scatter_default_4822: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2411, slice_39780, 2, 0, 16);  slice_tensor_2411 = slice_39780 = None
        slice_scatter_default_4823: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4821, slice_scatter_default_4822, 1, 9632, 9648);  slice_scatter_default_4821 = slice_scatter_default_4822 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39799: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9648, 9664)
        slice_39800: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39799, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1209: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39800, memory_format = torch.contiguous_format);  slice_39800 = None
        view_2422: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1209, [32, 16]);  clone_1209 = None
        mm_1206: "f32[32, 8]" = torch.ops.aten.mm.default(view_2422, slice_7)
        view_2423: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1206, [2, 16, 8]);  mm_1206 = None
        slice_39807: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4823, 1, 9648, 9664)
        slice_39808: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39807, 2, 0, 16);  slice_39807 = None
        add_1208: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39808, view_2423);  slice_39808 = view_2423 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2412: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4823, 1, 9648, 9664)
        slice_scatter_default_4824: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2412, add_1208, 2, 0, 16);  slice_tensor_2412 = add_1208 = None
        slice_scatter_default_4825: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4823, slice_scatter_default_4824, 1, 9648, 9664);  slice_scatter_default_4823 = slice_scatter_default_4824 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39812: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4825, 1, 9648, 9664)
        slice_39813: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39812, 2, 0, 16);  slice_39812 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2413: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4825, 1, 9648, 9664)
        slice_scatter_default_4826: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2413, slice_39813, 2, 0, 16);  slice_tensor_2413 = slice_39813 = None
        slice_scatter_default_4827: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4825, slice_scatter_default_4826, 1, 9648, 9664);  slice_scatter_default_4825 = slice_scatter_default_4826 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39833: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39799, 2, 16, 32);  slice_39799 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1210: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39833, memory_format = torch.contiguous_format);  slice_39833 = None
        view_2424: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1210, [32, 11]);  clone_1210 = None
        mm_1207: "f32[32, 8]" = torch.ops.aten.mm.default(view_2424, slice_37)
        view_2425: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1207, [2, 16, 8]);  mm_1207 = None
        slice_39840: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4827, 1, 9648, 9664)
        slice_39841: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39840, 2, 0, 16);  slice_39840 = None
        add_1209: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39841, view_2425);  slice_39841 = view_2425 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2414: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4827, 1, 9648, 9664)
        slice_scatter_default_4828: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2414, add_1209, 2, 0, 16);  slice_tensor_2414 = add_1209 = None
        slice_scatter_default_4829: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4827, slice_scatter_default_4828, 1, 9648, 9664);  slice_scatter_default_4827 = slice_scatter_default_4828 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39845: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4829, 1, 9648, 9664)
        slice_39846: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39845, 2, 0, 16);  slice_39845 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2415: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4829, 1, 9648, 9664)
        slice_scatter_default_4830: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2415, slice_39846, 2, 0, 16);  slice_tensor_2415 = slice_39846 = None
        slice_scatter_default_4831: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4829, slice_scatter_default_4830, 1, 9648, 9664);  slice_scatter_default_4829 = slice_scatter_default_4830 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39865: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9664, 9680)
        slice_39866: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39865, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1211: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39866, memory_format = torch.contiguous_format);  slice_39866 = None
        view_2426: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1211, [32, 16]);  clone_1211 = None
        mm_1208: "f32[32, 8]" = torch.ops.aten.mm.default(view_2426, slice_7)
        view_2427: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1208, [2, 16, 8]);  mm_1208 = None
        slice_39873: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4831, 1, 9664, 9680)
        slice_39874: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39873, 2, 0, 16);  slice_39873 = None
        add_1210: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39874, view_2427);  slice_39874 = view_2427 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2416: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4831, 1, 9664, 9680)
        slice_scatter_default_4832: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2416, add_1210, 2, 0, 16);  slice_tensor_2416 = add_1210 = None
        slice_scatter_default_4833: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4831, slice_scatter_default_4832, 1, 9664, 9680);  slice_scatter_default_4831 = slice_scatter_default_4832 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39878: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4833, 1, 9664, 9680)
        slice_39879: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39878, 2, 0, 16);  slice_39878 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2417: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4833, 1, 9664, 9680)
        slice_scatter_default_4834: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2417, slice_39879, 2, 0, 16);  slice_tensor_2417 = slice_39879 = None
        slice_scatter_default_4835: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4833, slice_scatter_default_4834, 1, 9664, 9680);  slice_scatter_default_4833 = slice_scatter_default_4834 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39899: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39865, 2, 16, 32);  slice_39865 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1212: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39899, memory_format = torch.contiguous_format);  slice_39899 = None
        view_2428: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1212, [32, 11]);  clone_1212 = None
        mm_1209: "f32[32, 8]" = torch.ops.aten.mm.default(view_2428, slice_37)
        view_2429: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1209, [2, 16, 8]);  mm_1209 = None
        slice_39906: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4835, 1, 9664, 9680)
        slice_39907: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39906, 2, 0, 16);  slice_39906 = None
        add_1211: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39907, view_2429);  slice_39907 = view_2429 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2418: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4835, 1, 9664, 9680)
        slice_scatter_default_4836: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2418, add_1211, 2, 0, 16);  slice_tensor_2418 = add_1211 = None
        slice_scatter_default_4837: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4835, slice_scatter_default_4836, 1, 9664, 9680);  slice_scatter_default_4835 = slice_scatter_default_4836 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39911: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4837, 1, 9664, 9680)
        slice_39912: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39911, 2, 0, 16);  slice_39911 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2419: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4837, 1, 9664, 9680)
        slice_scatter_default_4838: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2419, slice_39912, 2, 0, 16);  slice_tensor_2419 = slice_39912 = None
        slice_scatter_default_4839: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4837, slice_scatter_default_4838, 1, 9664, 9680);  slice_scatter_default_4837 = slice_scatter_default_4838 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39931: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9680, 9696)
        slice_39932: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39931, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1213: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39932, memory_format = torch.contiguous_format);  slice_39932 = None
        view_2430: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1213, [32, 16]);  clone_1213 = None
        mm_1210: "f32[32, 8]" = torch.ops.aten.mm.default(view_2430, slice_7)
        view_2431: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1210, [2, 16, 8]);  mm_1210 = None
        slice_39939: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4839, 1, 9680, 9696)
        slice_39940: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39939, 2, 0, 16);  slice_39939 = None
        add_1212: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39940, view_2431);  slice_39940 = view_2431 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2420: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4839, 1, 9680, 9696)
        slice_scatter_default_4840: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2420, add_1212, 2, 0, 16);  slice_tensor_2420 = add_1212 = None
        slice_scatter_default_4841: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4839, slice_scatter_default_4840, 1, 9680, 9696);  slice_scatter_default_4839 = slice_scatter_default_4840 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39944: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4841, 1, 9680, 9696)
        slice_39945: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39944, 2, 0, 16);  slice_39944 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2421: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4841, 1, 9680, 9696)
        slice_scatter_default_4842: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2421, slice_39945, 2, 0, 16);  slice_tensor_2421 = slice_39945 = None
        slice_scatter_default_4843: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4841, slice_scatter_default_4842, 1, 9680, 9696);  slice_scatter_default_4841 = slice_scatter_default_4842 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39965: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39931, 2, 16, 32);  slice_39931 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1214: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_39965, memory_format = torch.contiguous_format);  slice_39965 = None
        view_2432: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1214, [32, 11]);  clone_1214 = None
        mm_1211: "f32[32, 8]" = torch.ops.aten.mm.default(view_2432, slice_37)
        view_2433: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1211, [2, 16, 8]);  mm_1211 = None
        slice_39972: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4843, 1, 9680, 9696)
        slice_39973: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39972, 2, 0, 16);  slice_39972 = None
        add_1213: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_39973, view_2433);  slice_39973 = view_2433 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2422: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4843, 1, 9680, 9696)
        slice_scatter_default_4844: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2422, add_1213, 2, 0, 16);  slice_tensor_2422 = add_1213 = None
        slice_scatter_default_4845: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4843, slice_scatter_default_4844, 1, 9680, 9696);  slice_scatter_default_4843 = slice_scatter_default_4844 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_39977: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4845, 1, 9680, 9696)
        slice_39978: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_39977, 2, 0, 16);  slice_39977 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2423: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4845, 1, 9680, 9696)
        slice_scatter_default_4846: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2423, slice_39978, 2, 0, 16);  slice_tensor_2423 = slice_39978 = None
        slice_scatter_default_4847: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4845, slice_scatter_default_4846, 1, 9680, 9696);  slice_scatter_default_4845 = slice_scatter_default_4846 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_39997: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9696, 9712)
        slice_39998: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_39997, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1215: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_39998, memory_format = torch.contiguous_format);  slice_39998 = None
        view_2434: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1215, [32, 16]);  clone_1215 = None
        mm_1212: "f32[32, 8]" = torch.ops.aten.mm.default(view_2434, slice_7)
        view_2435: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1212, [2, 16, 8]);  mm_1212 = None
        slice_40005: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4847, 1, 9696, 9712)
        slice_40006: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40005, 2, 0, 16);  slice_40005 = None
        add_1214: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40006, view_2435);  slice_40006 = view_2435 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2424: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4847, 1, 9696, 9712)
        slice_scatter_default_4848: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2424, add_1214, 2, 0, 16);  slice_tensor_2424 = add_1214 = None
        slice_scatter_default_4849: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4847, slice_scatter_default_4848, 1, 9696, 9712);  slice_scatter_default_4847 = slice_scatter_default_4848 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40010: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4849, 1, 9696, 9712)
        slice_40011: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40010, 2, 0, 16);  slice_40010 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2425: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4849, 1, 9696, 9712)
        slice_scatter_default_4850: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2425, slice_40011, 2, 0, 16);  slice_tensor_2425 = slice_40011 = None
        slice_scatter_default_4851: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4849, slice_scatter_default_4850, 1, 9696, 9712);  slice_scatter_default_4849 = slice_scatter_default_4850 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40031: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_39997, 2, 16, 32);  slice_39997 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1216: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40031, memory_format = torch.contiguous_format);  slice_40031 = None
        view_2436: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1216, [32, 11]);  clone_1216 = None
        mm_1213: "f32[32, 8]" = torch.ops.aten.mm.default(view_2436, slice_37)
        view_2437: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1213, [2, 16, 8]);  mm_1213 = None
        slice_40038: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4851, 1, 9696, 9712)
        slice_40039: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40038, 2, 0, 16);  slice_40038 = None
        add_1215: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40039, view_2437);  slice_40039 = view_2437 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2426: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4851, 1, 9696, 9712)
        slice_scatter_default_4852: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2426, add_1215, 2, 0, 16);  slice_tensor_2426 = add_1215 = None
        slice_scatter_default_4853: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4851, slice_scatter_default_4852, 1, 9696, 9712);  slice_scatter_default_4851 = slice_scatter_default_4852 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40043: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4853, 1, 9696, 9712)
        slice_40044: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40043, 2, 0, 16);  slice_40043 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2427: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4853, 1, 9696, 9712)
        slice_scatter_default_4854: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2427, slice_40044, 2, 0, 16);  slice_tensor_2427 = slice_40044 = None
        slice_scatter_default_4855: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4853, slice_scatter_default_4854, 1, 9696, 9712);  slice_scatter_default_4853 = slice_scatter_default_4854 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40063: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9712, 9728)
        slice_40064: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40063, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1217: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40064, memory_format = torch.contiguous_format);  slice_40064 = None
        view_2438: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1217, [32, 16]);  clone_1217 = None
        mm_1214: "f32[32, 8]" = torch.ops.aten.mm.default(view_2438, slice_7)
        view_2439: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1214, [2, 16, 8]);  mm_1214 = None
        slice_40071: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4855, 1, 9712, 9728)
        slice_40072: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40071, 2, 0, 16);  slice_40071 = None
        add_1216: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40072, view_2439);  slice_40072 = view_2439 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2428: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4855, 1, 9712, 9728)
        slice_scatter_default_4856: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2428, add_1216, 2, 0, 16);  slice_tensor_2428 = add_1216 = None
        slice_scatter_default_4857: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4855, slice_scatter_default_4856, 1, 9712, 9728);  slice_scatter_default_4855 = slice_scatter_default_4856 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40076: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4857, 1, 9712, 9728)
        slice_40077: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40076, 2, 0, 16);  slice_40076 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2429: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4857, 1, 9712, 9728)
        slice_scatter_default_4858: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2429, slice_40077, 2, 0, 16);  slice_tensor_2429 = slice_40077 = None
        slice_scatter_default_4859: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4857, slice_scatter_default_4858, 1, 9712, 9728);  slice_scatter_default_4857 = slice_scatter_default_4858 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40097: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40063, 2, 16, 32);  slice_40063 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1218: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40097, memory_format = torch.contiguous_format);  slice_40097 = None
        view_2440: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1218, [32, 11]);  clone_1218 = None
        mm_1215: "f32[32, 8]" = torch.ops.aten.mm.default(view_2440, slice_37)
        view_2441: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1215, [2, 16, 8]);  mm_1215 = None
        slice_40104: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4859, 1, 9712, 9728)
        slice_40105: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40104, 2, 0, 16);  slice_40104 = None
        add_1217: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40105, view_2441);  slice_40105 = view_2441 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2430: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4859, 1, 9712, 9728)
        slice_scatter_default_4860: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2430, add_1217, 2, 0, 16);  slice_tensor_2430 = add_1217 = None
        slice_scatter_default_4861: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4859, slice_scatter_default_4860, 1, 9712, 9728);  slice_scatter_default_4859 = slice_scatter_default_4860 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40109: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4861, 1, 9712, 9728)
        slice_40110: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40109, 2, 0, 16);  slice_40109 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2431: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4861, 1, 9712, 9728)
        slice_scatter_default_4862: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2431, slice_40110, 2, 0, 16);  slice_tensor_2431 = slice_40110 = None
        slice_scatter_default_4863: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4861, slice_scatter_default_4862, 1, 9712, 9728);  slice_scatter_default_4861 = slice_scatter_default_4862 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40129: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9728, 9744)
        slice_40130: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40129, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1219: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40130, memory_format = torch.contiguous_format);  slice_40130 = None
        view_2442: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1219, [32, 16]);  clone_1219 = None
        mm_1216: "f32[32, 8]" = torch.ops.aten.mm.default(view_2442, slice_7)
        view_2443: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1216, [2, 16, 8]);  mm_1216 = None
        slice_40137: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4863, 1, 9728, 9744)
        slice_40138: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40137, 2, 0, 16);  slice_40137 = None
        add_1218: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40138, view_2443);  slice_40138 = view_2443 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2432: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4863, 1, 9728, 9744)
        slice_scatter_default_4864: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2432, add_1218, 2, 0, 16);  slice_tensor_2432 = add_1218 = None
        slice_scatter_default_4865: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4863, slice_scatter_default_4864, 1, 9728, 9744);  slice_scatter_default_4863 = slice_scatter_default_4864 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40142: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4865, 1, 9728, 9744)
        slice_40143: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40142, 2, 0, 16);  slice_40142 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2433: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4865, 1, 9728, 9744)
        slice_scatter_default_4866: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2433, slice_40143, 2, 0, 16);  slice_tensor_2433 = slice_40143 = None
        slice_scatter_default_4867: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4865, slice_scatter_default_4866, 1, 9728, 9744);  slice_scatter_default_4865 = slice_scatter_default_4866 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40163: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40129, 2, 16, 32);  slice_40129 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1220: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40163, memory_format = torch.contiguous_format);  slice_40163 = None
        view_2444: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1220, [32, 11]);  clone_1220 = None
        mm_1217: "f32[32, 8]" = torch.ops.aten.mm.default(view_2444, slice_37)
        view_2445: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1217, [2, 16, 8]);  mm_1217 = None
        slice_40170: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4867, 1, 9728, 9744)
        slice_40171: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40170, 2, 0, 16);  slice_40170 = None
        add_1219: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40171, view_2445);  slice_40171 = view_2445 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4867, 1, 9728, 9744)
        slice_scatter_default_4868: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2434, add_1219, 2, 0, 16);  slice_tensor_2434 = add_1219 = None
        slice_scatter_default_4869: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4867, slice_scatter_default_4868, 1, 9728, 9744);  slice_scatter_default_4867 = slice_scatter_default_4868 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40175: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4869, 1, 9728, 9744)
        slice_40176: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40175, 2, 0, 16);  slice_40175 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4869, 1, 9728, 9744)
        slice_scatter_default_4870: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2435, slice_40176, 2, 0, 16);  slice_tensor_2435 = slice_40176 = None
        slice_scatter_default_4871: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4869, slice_scatter_default_4870, 1, 9728, 9744);  slice_scatter_default_4869 = slice_scatter_default_4870 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40195: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9744, 9760)
        slice_40196: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40195, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1221: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40196, memory_format = torch.contiguous_format);  slice_40196 = None
        view_2446: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1221, [32, 16]);  clone_1221 = None
        mm_1218: "f32[32, 8]" = torch.ops.aten.mm.default(view_2446, slice_7)
        view_2447: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1218, [2, 16, 8]);  mm_1218 = None
        slice_40203: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4871, 1, 9744, 9760)
        slice_40204: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40203, 2, 0, 16);  slice_40203 = None
        add_1220: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40204, view_2447);  slice_40204 = view_2447 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2436: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4871, 1, 9744, 9760)
        slice_scatter_default_4872: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2436, add_1220, 2, 0, 16);  slice_tensor_2436 = add_1220 = None
        slice_scatter_default_4873: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4871, slice_scatter_default_4872, 1, 9744, 9760);  slice_scatter_default_4871 = slice_scatter_default_4872 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40208: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4873, 1, 9744, 9760)
        slice_40209: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40208, 2, 0, 16);  slice_40208 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2437: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4873, 1, 9744, 9760)
        slice_scatter_default_4874: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2437, slice_40209, 2, 0, 16);  slice_tensor_2437 = slice_40209 = None
        slice_scatter_default_4875: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4873, slice_scatter_default_4874, 1, 9744, 9760);  slice_scatter_default_4873 = slice_scatter_default_4874 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40229: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40195, 2, 16, 32);  slice_40195 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1222: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40229, memory_format = torch.contiguous_format);  slice_40229 = None
        view_2448: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1222, [32, 11]);  clone_1222 = None
        mm_1219: "f32[32, 8]" = torch.ops.aten.mm.default(view_2448, slice_37)
        view_2449: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1219, [2, 16, 8]);  mm_1219 = None
        slice_40236: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4875, 1, 9744, 9760)
        slice_40237: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40236, 2, 0, 16);  slice_40236 = None
        add_1221: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40237, view_2449);  slice_40237 = view_2449 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2438: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4875, 1, 9744, 9760)
        slice_scatter_default_4876: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2438, add_1221, 2, 0, 16);  slice_tensor_2438 = add_1221 = None
        slice_scatter_default_4877: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4875, slice_scatter_default_4876, 1, 9744, 9760);  slice_scatter_default_4875 = slice_scatter_default_4876 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40241: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4877, 1, 9744, 9760)
        slice_40242: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40241, 2, 0, 16);  slice_40241 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4877, 1, 9744, 9760)
        slice_scatter_default_4878: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2439, slice_40242, 2, 0, 16);  slice_tensor_2439 = slice_40242 = None
        slice_scatter_default_4879: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4877, slice_scatter_default_4878, 1, 9744, 9760);  slice_scatter_default_4877 = slice_scatter_default_4878 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40261: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9760, 9776)
        slice_40262: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40261, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1223: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40262, memory_format = torch.contiguous_format);  slice_40262 = None
        view_2450: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1223, [32, 16]);  clone_1223 = None
        mm_1220: "f32[32, 8]" = torch.ops.aten.mm.default(view_2450, slice_7)
        view_2451: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1220, [2, 16, 8]);  mm_1220 = None
        slice_40269: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4879, 1, 9760, 9776)
        slice_40270: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40269, 2, 0, 16);  slice_40269 = None
        add_1222: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40270, view_2451);  slice_40270 = view_2451 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4879, 1, 9760, 9776)
        slice_scatter_default_4880: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2440, add_1222, 2, 0, 16);  slice_tensor_2440 = add_1222 = None
        slice_scatter_default_4881: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4879, slice_scatter_default_4880, 1, 9760, 9776);  slice_scatter_default_4879 = slice_scatter_default_4880 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40274: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4881, 1, 9760, 9776)
        slice_40275: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40274, 2, 0, 16);  slice_40274 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2441: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4881, 1, 9760, 9776)
        slice_scatter_default_4882: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2441, slice_40275, 2, 0, 16);  slice_tensor_2441 = slice_40275 = None
        slice_scatter_default_4883: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4881, slice_scatter_default_4882, 1, 9760, 9776);  slice_scatter_default_4881 = slice_scatter_default_4882 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40295: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40261, 2, 16, 32);  slice_40261 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1224: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40295, memory_format = torch.contiguous_format);  slice_40295 = None
        view_2452: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1224, [32, 11]);  clone_1224 = None
        mm_1221: "f32[32, 8]" = torch.ops.aten.mm.default(view_2452, slice_37)
        view_2453: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1221, [2, 16, 8]);  mm_1221 = None
        slice_40302: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4883, 1, 9760, 9776)
        slice_40303: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40302, 2, 0, 16);  slice_40302 = None
        add_1223: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40303, view_2453);  slice_40303 = view_2453 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2442: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4883, 1, 9760, 9776)
        slice_scatter_default_4884: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2442, add_1223, 2, 0, 16);  slice_tensor_2442 = add_1223 = None
        slice_scatter_default_4885: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4883, slice_scatter_default_4884, 1, 9760, 9776);  slice_scatter_default_4883 = slice_scatter_default_4884 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40307: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4885, 1, 9760, 9776)
        slice_40308: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40307, 2, 0, 16);  slice_40307 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2443: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4885, 1, 9760, 9776)
        slice_scatter_default_4886: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2443, slice_40308, 2, 0, 16);  slice_tensor_2443 = slice_40308 = None
        slice_scatter_default_4887: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4885, slice_scatter_default_4886, 1, 9760, 9776);  slice_scatter_default_4885 = slice_scatter_default_4886 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40327: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9776, 9792)
        slice_40328: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40327, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1225: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40328, memory_format = torch.contiguous_format);  slice_40328 = None
        view_2454: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1225, [32, 16]);  clone_1225 = None
        mm_1222: "f32[32, 8]" = torch.ops.aten.mm.default(view_2454, slice_7)
        view_2455: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1222, [2, 16, 8]);  mm_1222 = None
        slice_40335: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4887, 1, 9776, 9792)
        slice_40336: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40335, 2, 0, 16);  slice_40335 = None
        add_1224: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40336, view_2455);  slice_40336 = view_2455 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2444: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4887, 1, 9776, 9792)
        slice_scatter_default_4888: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2444, add_1224, 2, 0, 16);  slice_tensor_2444 = add_1224 = None
        slice_scatter_default_4889: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4887, slice_scatter_default_4888, 1, 9776, 9792);  slice_scatter_default_4887 = slice_scatter_default_4888 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40340: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4889, 1, 9776, 9792)
        slice_40341: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40340, 2, 0, 16);  slice_40340 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2445: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4889, 1, 9776, 9792)
        slice_scatter_default_4890: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2445, slice_40341, 2, 0, 16);  slice_tensor_2445 = slice_40341 = None
        slice_scatter_default_4891: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4889, slice_scatter_default_4890, 1, 9776, 9792);  slice_scatter_default_4889 = slice_scatter_default_4890 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40361: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40327, 2, 16, 32);  slice_40327 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1226: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40361, memory_format = torch.contiguous_format);  slice_40361 = None
        view_2456: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1226, [32, 11]);  clone_1226 = None
        mm_1223: "f32[32, 8]" = torch.ops.aten.mm.default(view_2456, slice_37)
        view_2457: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1223, [2, 16, 8]);  mm_1223 = None
        slice_40368: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4891, 1, 9776, 9792)
        slice_40369: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40368, 2, 0, 16);  slice_40368 = None
        add_1225: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40369, view_2457);  slice_40369 = view_2457 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2446: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4891, 1, 9776, 9792)
        slice_scatter_default_4892: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2446, add_1225, 2, 0, 16);  slice_tensor_2446 = add_1225 = None
        slice_scatter_default_4893: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4891, slice_scatter_default_4892, 1, 9776, 9792);  slice_scatter_default_4891 = slice_scatter_default_4892 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40373: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4893, 1, 9776, 9792)
        slice_40374: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40373, 2, 0, 16);  slice_40373 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2447: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4893, 1, 9776, 9792)
        slice_scatter_default_4894: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2447, slice_40374, 2, 0, 16);  slice_tensor_2447 = slice_40374 = None
        slice_scatter_default_4895: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4893, slice_scatter_default_4894, 1, 9776, 9792);  slice_scatter_default_4893 = slice_scatter_default_4894 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40393: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9792, 9808)
        slice_40394: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40393, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1227: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40394, memory_format = torch.contiguous_format);  slice_40394 = None
        view_2458: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1227, [32, 16]);  clone_1227 = None
        mm_1224: "f32[32, 8]" = torch.ops.aten.mm.default(view_2458, slice_7)
        view_2459: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1224, [2, 16, 8]);  mm_1224 = None
        slice_40401: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4895, 1, 9792, 9808)
        slice_40402: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40401, 2, 0, 16);  slice_40401 = None
        add_1226: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40402, view_2459);  slice_40402 = view_2459 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2448: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4895, 1, 9792, 9808)
        slice_scatter_default_4896: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2448, add_1226, 2, 0, 16);  slice_tensor_2448 = add_1226 = None
        slice_scatter_default_4897: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4895, slice_scatter_default_4896, 1, 9792, 9808);  slice_scatter_default_4895 = slice_scatter_default_4896 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40406: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4897, 1, 9792, 9808)
        slice_40407: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40406, 2, 0, 16);  slice_40406 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2449: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4897, 1, 9792, 9808)
        slice_scatter_default_4898: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2449, slice_40407, 2, 0, 16);  slice_tensor_2449 = slice_40407 = None
        slice_scatter_default_4899: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4897, slice_scatter_default_4898, 1, 9792, 9808);  slice_scatter_default_4897 = slice_scatter_default_4898 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40427: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40393, 2, 16, 32);  slice_40393 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1228: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40427, memory_format = torch.contiguous_format);  slice_40427 = None
        view_2460: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1228, [32, 11]);  clone_1228 = None
        mm_1225: "f32[32, 8]" = torch.ops.aten.mm.default(view_2460, slice_37)
        view_2461: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1225, [2, 16, 8]);  mm_1225 = None
        slice_40434: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4899, 1, 9792, 9808)
        slice_40435: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40434, 2, 0, 16);  slice_40434 = None
        add_1227: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40435, view_2461);  slice_40435 = view_2461 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2450: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4899, 1, 9792, 9808)
        slice_scatter_default_4900: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2450, add_1227, 2, 0, 16);  slice_tensor_2450 = add_1227 = None
        slice_scatter_default_4901: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4899, slice_scatter_default_4900, 1, 9792, 9808);  slice_scatter_default_4899 = slice_scatter_default_4900 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40439: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4901, 1, 9792, 9808)
        slice_40440: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40439, 2, 0, 16);  slice_40439 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2451: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4901, 1, 9792, 9808)
        slice_scatter_default_4902: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2451, slice_40440, 2, 0, 16);  slice_tensor_2451 = slice_40440 = None
        slice_scatter_default_4903: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4901, slice_scatter_default_4902, 1, 9792, 9808);  slice_scatter_default_4901 = slice_scatter_default_4902 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40459: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9808, 9824)
        slice_40460: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40459, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1229: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40460, memory_format = torch.contiguous_format);  slice_40460 = None
        view_2462: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1229, [32, 16]);  clone_1229 = None
        mm_1226: "f32[32, 8]" = torch.ops.aten.mm.default(view_2462, slice_7)
        view_2463: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1226, [2, 16, 8]);  mm_1226 = None
        slice_40467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4903, 1, 9808, 9824)
        slice_40468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40467, 2, 0, 16);  slice_40467 = None
        add_1228: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40468, view_2463);  slice_40468 = view_2463 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2452: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4903, 1, 9808, 9824)
        slice_scatter_default_4904: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2452, add_1228, 2, 0, 16);  slice_tensor_2452 = add_1228 = None
        slice_scatter_default_4905: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4903, slice_scatter_default_4904, 1, 9808, 9824);  slice_scatter_default_4903 = slice_scatter_default_4904 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4905, 1, 9808, 9824)
        slice_40473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40472, 2, 0, 16);  slice_40472 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2453: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4905, 1, 9808, 9824)
        slice_scatter_default_4906: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2453, slice_40473, 2, 0, 16);  slice_tensor_2453 = slice_40473 = None
        slice_scatter_default_4907: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4905, slice_scatter_default_4906, 1, 9808, 9824);  slice_scatter_default_4905 = slice_scatter_default_4906 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40493: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40459, 2, 16, 32);  slice_40459 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1230: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40493, memory_format = torch.contiguous_format);  slice_40493 = None
        view_2464: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1230, [32, 11]);  clone_1230 = None
        mm_1227: "f32[32, 8]" = torch.ops.aten.mm.default(view_2464, slice_37)
        view_2465: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1227, [2, 16, 8]);  mm_1227 = None
        slice_40500: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4907, 1, 9808, 9824)
        slice_40501: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40500, 2, 0, 16);  slice_40500 = None
        add_1229: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40501, view_2465);  slice_40501 = view_2465 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2454: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4907, 1, 9808, 9824)
        slice_scatter_default_4908: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2454, add_1229, 2, 0, 16);  slice_tensor_2454 = add_1229 = None
        slice_scatter_default_4909: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4907, slice_scatter_default_4908, 1, 9808, 9824);  slice_scatter_default_4907 = slice_scatter_default_4908 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40505: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4909, 1, 9808, 9824)
        slice_40506: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40505, 2, 0, 16);  slice_40505 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2455: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4909, 1, 9808, 9824)
        slice_scatter_default_4910: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2455, slice_40506, 2, 0, 16);  slice_tensor_2455 = slice_40506 = None
        slice_scatter_default_4911: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4909, slice_scatter_default_4910, 1, 9808, 9824);  slice_scatter_default_4909 = slice_scatter_default_4910 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40525: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9824, 9840)
        slice_40526: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40525, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1231: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40526, memory_format = torch.contiguous_format);  slice_40526 = None
        view_2466: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1231, [32, 16]);  clone_1231 = None
        mm_1228: "f32[32, 8]" = torch.ops.aten.mm.default(view_2466, slice_7)
        view_2467: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1228, [2, 16, 8]);  mm_1228 = None
        slice_40533: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4911, 1, 9824, 9840)
        slice_40534: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40533, 2, 0, 16);  slice_40533 = None
        add_1230: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40534, view_2467);  slice_40534 = view_2467 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2456: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4911, 1, 9824, 9840)
        slice_scatter_default_4912: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2456, add_1230, 2, 0, 16);  slice_tensor_2456 = add_1230 = None
        slice_scatter_default_4913: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4911, slice_scatter_default_4912, 1, 9824, 9840);  slice_scatter_default_4911 = slice_scatter_default_4912 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40538: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4913, 1, 9824, 9840)
        slice_40539: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40538, 2, 0, 16);  slice_40538 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2457: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4913, 1, 9824, 9840)
        slice_scatter_default_4914: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2457, slice_40539, 2, 0, 16);  slice_tensor_2457 = slice_40539 = None
        slice_scatter_default_4915: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4913, slice_scatter_default_4914, 1, 9824, 9840);  slice_scatter_default_4913 = slice_scatter_default_4914 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40559: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40525, 2, 16, 32);  slice_40525 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1232: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40559, memory_format = torch.contiguous_format);  slice_40559 = None
        view_2468: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1232, [32, 11]);  clone_1232 = None
        mm_1229: "f32[32, 8]" = torch.ops.aten.mm.default(view_2468, slice_37)
        view_2469: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1229, [2, 16, 8]);  mm_1229 = None
        slice_40566: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4915, 1, 9824, 9840)
        slice_40567: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40566, 2, 0, 16);  slice_40566 = None
        add_1231: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40567, view_2469);  slice_40567 = view_2469 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2458: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4915, 1, 9824, 9840)
        slice_scatter_default_4916: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2458, add_1231, 2, 0, 16);  slice_tensor_2458 = add_1231 = None
        slice_scatter_default_4917: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4915, slice_scatter_default_4916, 1, 9824, 9840);  slice_scatter_default_4915 = slice_scatter_default_4916 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40571: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4917, 1, 9824, 9840)
        slice_40572: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40571, 2, 0, 16);  slice_40571 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2459: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4917, 1, 9824, 9840)
        slice_scatter_default_4918: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2459, slice_40572, 2, 0, 16);  slice_tensor_2459 = slice_40572 = None
        slice_scatter_default_4919: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4917, slice_scatter_default_4918, 1, 9824, 9840);  slice_scatter_default_4917 = slice_scatter_default_4918 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40591: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9840, 9856)
        slice_40592: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40591, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1233: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40592, memory_format = torch.contiguous_format);  slice_40592 = None
        view_2470: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1233, [32, 16]);  clone_1233 = None
        mm_1230: "f32[32, 8]" = torch.ops.aten.mm.default(view_2470, slice_7)
        view_2471: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1230, [2, 16, 8]);  mm_1230 = None
        slice_40599: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4919, 1, 9840, 9856)
        slice_40600: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40599, 2, 0, 16);  slice_40599 = None
        add_1232: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40600, view_2471);  slice_40600 = view_2471 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2460: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4919, 1, 9840, 9856)
        slice_scatter_default_4920: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2460, add_1232, 2, 0, 16);  slice_tensor_2460 = add_1232 = None
        slice_scatter_default_4921: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4919, slice_scatter_default_4920, 1, 9840, 9856);  slice_scatter_default_4919 = slice_scatter_default_4920 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40604: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4921, 1, 9840, 9856)
        slice_40605: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40604, 2, 0, 16);  slice_40604 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2461: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4921, 1, 9840, 9856)
        slice_scatter_default_4922: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2461, slice_40605, 2, 0, 16);  slice_tensor_2461 = slice_40605 = None
        slice_scatter_default_4923: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4921, slice_scatter_default_4922, 1, 9840, 9856);  slice_scatter_default_4921 = slice_scatter_default_4922 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40625: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40591, 2, 16, 32);  slice_40591 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1234: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40625, memory_format = torch.contiguous_format);  slice_40625 = None
        view_2472: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1234, [32, 11]);  clone_1234 = None
        mm_1231: "f32[32, 8]" = torch.ops.aten.mm.default(view_2472, slice_37)
        view_2473: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1231, [2, 16, 8]);  mm_1231 = None
        slice_40632: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4923, 1, 9840, 9856)
        slice_40633: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40632, 2, 0, 16);  slice_40632 = None
        add_1233: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40633, view_2473);  slice_40633 = view_2473 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2462: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4923, 1, 9840, 9856)
        slice_scatter_default_4924: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2462, add_1233, 2, 0, 16);  slice_tensor_2462 = add_1233 = None
        slice_scatter_default_4925: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4923, slice_scatter_default_4924, 1, 9840, 9856);  slice_scatter_default_4923 = slice_scatter_default_4924 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40637: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4925, 1, 9840, 9856)
        slice_40638: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40637, 2, 0, 16);  slice_40637 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2463: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4925, 1, 9840, 9856)
        slice_scatter_default_4926: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2463, slice_40638, 2, 0, 16);  slice_tensor_2463 = slice_40638 = None
        slice_scatter_default_4927: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4925, slice_scatter_default_4926, 1, 9840, 9856);  slice_scatter_default_4925 = slice_scatter_default_4926 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40657: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9856, 9872)
        slice_40658: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40657, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1235: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40658, memory_format = torch.contiguous_format);  slice_40658 = None
        view_2474: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1235, [32, 16]);  clone_1235 = None
        mm_1232: "f32[32, 8]" = torch.ops.aten.mm.default(view_2474, slice_7)
        view_2475: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1232, [2, 16, 8]);  mm_1232 = None
        slice_40665: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4927, 1, 9856, 9872)
        slice_40666: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40665, 2, 0, 16);  slice_40665 = None
        add_1234: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40666, view_2475);  slice_40666 = view_2475 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2464: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4927, 1, 9856, 9872)
        slice_scatter_default_4928: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2464, add_1234, 2, 0, 16);  slice_tensor_2464 = add_1234 = None
        slice_scatter_default_4929: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4927, slice_scatter_default_4928, 1, 9856, 9872);  slice_scatter_default_4927 = slice_scatter_default_4928 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40670: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4929, 1, 9856, 9872)
        slice_40671: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40670, 2, 0, 16);  slice_40670 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2465: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4929, 1, 9856, 9872)
        slice_scatter_default_4930: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2465, slice_40671, 2, 0, 16);  slice_tensor_2465 = slice_40671 = None
        slice_scatter_default_4931: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4929, slice_scatter_default_4930, 1, 9856, 9872);  slice_scatter_default_4929 = slice_scatter_default_4930 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40691: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40657, 2, 16, 32);  slice_40657 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1236: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40691, memory_format = torch.contiguous_format);  slice_40691 = None
        view_2476: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1236, [32, 11]);  clone_1236 = None
        mm_1233: "f32[32, 8]" = torch.ops.aten.mm.default(view_2476, slice_37)
        view_2477: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1233, [2, 16, 8]);  mm_1233 = None
        slice_40698: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4931, 1, 9856, 9872)
        slice_40699: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40698, 2, 0, 16);  slice_40698 = None
        add_1235: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40699, view_2477);  slice_40699 = view_2477 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2466: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4931, 1, 9856, 9872)
        slice_scatter_default_4932: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2466, add_1235, 2, 0, 16);  slice_tensor_2466 = add_1235 = None
        slice_scatter_default_4933: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4931, slice_scatter_default_4932, 1, 9856, 9872);  slice_scatter_default_4931 = slice_scatter_default_4932 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40703: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4933, 1, 9856, 9872)
        slice_40704: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40703, 2, 0, 16);  slice_40703 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2467: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4933, 1, 9856, 9872)
        slice_scatter_default_4934: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2467, slice_40704, 2, 0, 16);  slice_tensor_2467 = slice_40704 = None
        slice_scatter_default_4935: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4933, slice_scatter_default_4934, 1, 9856, 9872);  slice_scatter_default_4933 = slice_scatter_default_4934 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40723: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9872, 9888)
        slice_40724: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40723, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1237: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40724, memory_format = torch.contiguous_format);  slice_40724 = None
        view_2478: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1237, [32, 16]);  clone_1237 = None
        mm_1234: "f32[32, 8]" = torch.ops.aten.mm.default(view_2478, slice_7)
        view_2479: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1234, [2, 16, 8]);  mm_1234 = None
        slice_40731: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4935, 1, 9872, 9888)
        slice_40732: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40731, 2, 0, 16);  slice_40731 = None
        add_1236: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40732, view_2479);  slice_40732 = view_2479 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2468: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4935, 1, 9872, 9888)
        slice_scatter_default_4936: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2468, add_1236, 2, 0, 16);  slice_tensor_2468 = add_1236 = None
        slice_scatter_default_4937: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4935, slice_scatter_default_4936, 1, 9872, 9888);  slice_scatter_default_4935 = slice_scatter_default_4936 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40736: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4937, 1, 9872, 9888)
        slice_40737: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40736, 2, 0, 16);  slice_40736 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2469: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4937, 1, 9872, 9888)
        slice_scatter_default_4938: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2469, slice_40737, 2, 0, 16);  slice_tensor_2469 = slice_40737 = None
        slice_scatter_default_4939: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4937, slice_scatter_default_4938, 1, 9872, 9888);  slice_scatter_default_4937 = slice_scatter_default_4938 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40757: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40723, 2, 16, 32);  slice_40723 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1238: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40757, memory_format = torch.contiguous_format);  slice_40757 = None
        view_2480: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1238, [32, 11]);  clone_1238 = None
        mm_1235: "f32[32, 8]" = torch.ops.aten.mm.default(view_2480, slice_37)
        view_2481: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1235, [2, 16, 8]);  mm_1235 = None
        slice_40764: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4939, 1, 9872, 9888)
        slice_40765: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40764, 2, 0, 16);  slice_40764 = None
        add_1237: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40765, view_2481);  slice_40765 = view_2481 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2470: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4939, 1, 9872, 9888)
        slice_scatter_default_4940: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2470, add_1237, 2, 0, 16);  slice_tensor_2470 = add_1237 = None
        slice_scatter_default_4941: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4939, slice_scatter_default_4940, 1, 9872, 9888);  slice_scatter_default_4939 = slice_scatter_default_4940 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40769: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4941, 1, 9872, 9888)
        slice_40770: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40769, 2, 0, 16);  slice_40769 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2471: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4941, 1, 9872, 9888)
        slice_scatter_default_4942: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2471, slice_40770, 2, 0, 16);  slice_tensor_2471 = slice_40770 = None
        slice_scatter_default_4943: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4941, slice_scatter_default_4942, 1, 9872, 9888);  slice_scatter_default_4941 = slice_scatter_default_4942 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40789: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9888, 9904)
        slice_40790: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40789, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1239: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40790, memory_format = torch.contiguous_format);  slice_40790 = None
        view_2482: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1239, [32, 16]);  clone_1239 = None
        mm_1236: "f32[32, 8]" = torch.ops.aten.mm.default(view_2482, slice_7)
        view_2483: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1236, [2, 16, 8]);  mm_1236 = None
        slice_40797: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4943, 1, 9888, 9904)
        slice_40798: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40797, 2, 0, 16);  slice_40797 = None
        add_1238: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40798, view_2483);  slice_40798 = view_2483 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2472: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4943, 1, 9888, 9904)
        slice_scatter_default_4944: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2472, add_1238, 2, 0, 16);  slice_tensor_2472 = add_1238 = None
        slice_scatter_default_4945: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4943, slice_scatter_default_4944, 1, 9888, 9904);  slice_scatter_default_4943 = slice_scatter_default_4944 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40802: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4945, 1, 9888, 9904)
        slice_40803: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40802, 2, 0, 16);  slice_40802 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2473: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4945, 1, 9888, 9904)
        slice_scatter_default_4946: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2473, slice_40803, 2, 0, 16);  slice_tensor_2473 = slice_40803 = None
        slice_scatter_default_4947: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4945, slice_scatter_default_4946, 1, 9888, 9904);  slice_scatter_default_4945 = slice_scatter_default_4946 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40823: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40789, 2, 16, 32);  slice_40789 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1240: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40823, memory_format = torch.contiguous_format);  slice_40823 = None
        view_2484: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1240, [32, 11]);  clone_1240 = None
        mm_1237: "f32[32, 8]" = torch.ops.aten.mm.default(view_2484, slice_37)
        view_2485: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1237, [2, 16, 8]);  mm_1237 = None
        slice_40830: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4947, 1, 9888, 9904)
        slice_40831: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40830, 2, 0, 16);  slice_40830 = None
        add_1239: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40831, view_2485);  slice_40831 = view_2485 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2474: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4947, 1, 9888, 9904)
        slice_scatter_default_4948: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2474, add_1239, 2, 0, 16);  slice_tensor_2474 = add_1239 = None
        slice_scatter_default_4949: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4947, slice_scatter_default_4948, 1, 9888, 9904);  slice_scatter_default_4947 = slice_scatter_default_4948 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40835: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4949, 1, 9888, 9904)
        slice_40836: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40835, 2, 0, 16);  slice_40835 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2475: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4949, 1, 9888, 9904)
        slice_scatter_default_4950: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2475, slice_40836, 2, 0, 16);  slice_tensor_2475 = slice_40836 = None
        slice_scatter_default_4951: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4949, slice_scatter_default_4950, 1, 9888, 9904);  slice_scatter_default_4949 = slice_scatter_default_4950 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40855: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9904, 9920)
        slice_40856: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40855, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1241: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40856, memory_format = torch.contiguous_format);  slice_40856 = None
        view_2486: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1241, [32, 16]);  clone_1241 = None
        mm_1238: "f32[32, 8]" = torch.ops.aten.mm.default(view_2486, slice_7)
        view_2487: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1238, [2, 16, 8]);  mm_1238 = None
        slice_40863: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4951, 1, 9904, 9920)
        slice_40864: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40863, 2, 0, 16);  slice_40863 = None
        add_1240: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40864, view_2487);  slice_40864 = view_2487 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2476: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4951, 1, 9904, 9920)
        slice_scatter_default_4952: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2476, add_1240, 2, 0, 16);  slice_tensor_2476 = add_1240 = None
        slice_scatter_default_4953: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4951, slice_scatter_default_4952, 1, 9904, 9920);  slice_scatter_default_4951 = slice_scatter_default_4952 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40868: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4953, 1, 9904, 9920)
        slice_40869: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40868, 2, 0, 16);  slice_40868 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2477: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4953, 1, 9904, 9920)
        slice_scatter_default_4954: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2477, slice_40869, 2, 0, 16);  slice_tensor_2477 = slice_40869 = None
        slice_scatter_default_4955: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4953, slice_scatter_default_4954, 1, 9904, 9920);  slice_scatter_default_4953 = slice_scatter_default_4954 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40889: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40855, 2, 16, 32);  slice_40855 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1242: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40889, memory_format = torch.contiguous_format);  slice_40889 = None
        view_2488: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1242, [32, 11]);  clone_1242 = None
        mm_1239: "f32[32, 8]" = torch.ops.aten.mm.default(view_2488, slice_37)
        view_2489: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1239, [2, 16, 8]);  mm_1239 = None
        slice_40896: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4955, 1, 9904, 9920)
        slice_40897: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40896, 2, 0, 16);  slice_40896 = None
        add_1241: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40897, view_2489);  slice_40897 = view_2489 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2478: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4955, 1, 9904, 9920)
        slice_scatter_default_4956: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2478, add_1241, 2, 0, 16);  slice_tensor_2478 = add_1241 = None
        slice_scatter_default_4957: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4955, slice_scatter_default_4956, 1, 9904, 9920);  slice_scatter_default_4955 = slice_scatter_default_4956 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40901: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4957, 1, 9904, 9920)
        slice_40902: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40901, 2, 0, 16);  slice_40901 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2479: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4957, 1, 9904, 9920)
        slice_scatter_default_4958: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2479, slice_40902, 2, 0, 16);  slice_tensor_2479 = slice_40902 = None
        slice_scatter_default_4959: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4957, slice_scatter_default_4958, 1, 9904, 9920);  slice_scatter_default_4957 = slice_scatter_default_4958 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40921: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9920, 9936)
        slice_40922: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40921, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1243: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40922, memory_format = torch.contiguous_format);  slice_40922 = None
        view_2490: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1243, [32, 16]);  clone_1243 = None
        mm_1240: "f32[32, 8]" = torch.ops.aten.mm.default(view_2490, slice_7)
        view_2491: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1240, [2, 16, 8]);  mm_1240 = None
        slice_40929: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4959, 1, 9920, 9936)
        slice_40930: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40929, 2, 0, 16);  slice_40929 = None
        add_1242: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40930, view_2491);  slice_40930 = view_2491 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2480: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4959, 1, 9920, 9936)
        slice_scatter_default_4960: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2480, add_1242, 2, 0, 16);  slice_tensor_2480 = add_1242 = None
        slice_scatter_default_4961: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4959, slice_scatter_default_4960, 1, 9920, 9936);  slice_scatter_default_4959 = slice_scatter_default_4960 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40934: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4961, 1, 9920, 9936)
        slice_40935: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40934, 2, 0, 16);  slice_40934 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2481: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4961, 1, 9920, 9936)
        slice_scatter_default_4962: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2481, slice_40935, 2, 0, 16);  slice_tensor_2481 = slice_40935 = None
        slice_scatter_default_4963: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4961, slice_scatter_default_4962, 1, 9920, 9936);  slice_scatter_default_4961 = slice_scatter_default_4962 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40955: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40921, 2, 16, 32);  slice_40921 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1244: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_40955, memory_format = torch.contiguous_format);  slice_40955 = None
        view_2492: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1244, [32, 11]);  clone_1244 = None
        mm_1241: "f32[32, 8]" = torch.ops.aten.mm.default(view_2492, slice_37)
        view_2493: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1241, [2, 16, 8]);  mm_1241 = None
        slice_40962: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4963, 1, 9920, 9936)
        slice_40963: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40962, 2, 0, 16);  slice_40962 = None
        add_1243: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40963, view_2493);  slice_40963 = view_2493 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2482: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4963, 1, 9920, 9936)
        slice_scatter_default_4964: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2482, add_1243, 2, 0, 16);  slice_tensor_2482 = add_1243 = None
        slice_scatter_default_4965: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4963, slice_scatter_default_4964, 1, 9920, 9936);  slice_scatter_default_4963 = slice_scatter_default_4964 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_40967: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4965, 1, 9920, 9936)
        slice_40968: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40967, 2, 0, 16);  slice_40967 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2483: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4965, 1, 9920, 9936)
        slice_scatter_default_4966: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2483, slice_40968, 2, 0, 16);  slice_tensor_2483 = slice_40968 = None
        slice_scatter_default_4967: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4965, slice_scatter_default_4966, 1, 9920, 9936);  slice_scatter_default_4965 = slice_scatter_default_4966 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_40987: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9936, 9952)
        slice_40988: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_40987, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1245: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_40988, memory_format = torch.contiguous_format);  slice_40988 = None
        view_2494: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1245, [32, 16]);  clone_1245 = None
        mm_1242: "f32[32, 8]" = torch.ops.aten.mm.default(view_2494, slice_7)
        view_2495: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1242, [2, 16, 8]);  mm_1242 = None
        slice_40995: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4967, 1, 9936, 9952)
        slice_40996: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_40995, 2, 0, 16);  slice_40995 = None
        add_1244: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_40996, view_2495);  slice_40996 = view_2495 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2484: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4967, 1, 9936, 9952)
        slice_scatter_default_4968: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2484, add_1244, 2, 0, 16);  slice_tensor_2484 = add_1244 = None
        slice_scatter_default_4969: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4967, slice_scatter_default_4968, 1, 9936, 9952);  slice_scatter_default_4967 = slice_scatter_default_4968 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41000: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4969, 1, 9936, 9952)
        slice_41001: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41000, 2, 0, 16);  slice_41000 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2485: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4969, 1, 9936, 9952)
        slice_scatter_default_4970: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2485, slice_41001, 2, 0, 16);  slice_tensor_2485 = slice_41001 = None
        slice_scatter_default_4971: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4969, slice_scatter_default_4970, 1, 9936, 9952);  slice_scatter_default_4969 = slice_scatter_default_4970 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41021: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_40987, 2, 16, 32);  slice_40987 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1246: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_41021, memory_format = torch.contiguous_format);  slice_41021 = None
        view_2496: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1246, [32, 11]);  clone_1246 = None
        mm_1243: "f32[32, 8]" = torch.ops.aten.mm.default(view_2496, slice_37)
        view_2497: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1243, [2, 16, 8]);  mm_1243 = None
        slice_41028: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4971, 1, 9936, 9952)
        slice_41029: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41028, 2, 0, 16);  slice_41028 = None
        add_1245: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41029, view_2497);  slice_41029 = view_2497 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2486: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4971, 1, 9936, 9952)
        slice_scatter_default_4972: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2486, add_1245, 2, 0, 16);  slice_tensor_2486 = add_1245 = None
        slice_scatter_default_4973: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4971, slice_scatter_default_4972, 1, 9936, 9952);  slice_scatter_default_4971 = slice_scatter_default_4972 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41033: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4973, 1, 9936, 9952)
        slice_41034: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41033, 2, 0, 16);  slice_41033 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2487: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4973, 1, 9936, 9952)
        slice_scatter_default_4974: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2487, slice_41034, 2, 0, 16);  slice_tensor_2487 = slice_41034 = None
        slice_scatter_default_4975: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4973, slice_scatter_default_4974, 1, 9936, 9952);  slice_scatter_default_4973 = slice_scatter_default_4974 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41053: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9952, 9968)
        slice_41054: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_41053, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1247: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_41054, memory_format = torch.contiguous_format);  slice_41054 = None
        view_2498: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1247, [32, 16]);  clone_1247 = None
        mm_1244: "f32[32, 8]" = torch.ops.aten.mm.default(view_2498, slice_7)
        view_2499: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1244, [2, 16, 8]);  mm_1244 = None
        slice_41061: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4975, 1, 9952, 9968)
        slice_41062: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41061, 2, 0, 16);  slice_41061 = None
        add_1246: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41062, view_2499);  slice_41062 = view_2499 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2488: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4975, 1, 9952, 9968)
        slice_scatter_default_4976: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2488, add_1246, 2, 0, 16);  slice_tensor_2488 = add_1246 = None
        slice_scatter_default_4977: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4975, slice_scatter_default_4976, 1, 9952, 9968);  slice_scatter_default_4975 = slice_scatter_default_4976 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41066: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4977, 1, 9952, 9968)
        slice_41067: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41066, 2, 0, 16);  slice_41066 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2489: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4977, 1, 9952, 9968)
        slice_scatter_default_4978: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2489, slice_41067, 2, 0, 16);  slice_tensor_2489 = slice_41067 = None
        slice_scatter_default_4979: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4977, slice_scatter_default_4978, 1, 9952, 9968);  slice_scatter_default_4977 = slice_scatter_default_4978 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41087: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_41053, 2, 16, 32);  slice_41053 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1248: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_41087, memory_format = torch.contiguous_format);  slice_41087 = None
        view_2500: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1248, [32, 11]);  clone_1248 = None
        mm_1245: "f32[32, 8]" = torch.ops.aten.mm.default(view_2500, slice_37)
        view_2501: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1245, [2, 16, 8]);  mm_1245 = None
        slice_41094: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4979, 1, 9952, 9968)
        slice_41095: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41094, 2, 0, 16);  slice_41094 = None
        add_1247: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41095, view_2501);  slice_41095 = view_2501 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2490: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4979, 1, 9952, 9968)
        slice_scatter_default_4980: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2490, add_1247, 2, 0, 16);  slice_tensor_2490 = add_1247 = None
        slice_scatter_default_4981: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4979, slice_scatter_default_4980, 1, 9952, 9968);  slice_scatter_default_4979 = slice_scatter_default_4980 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41099: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4981, 1, 9952, 9968)
        slice_41100: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41099, 2, 0, 16);  slice_41099 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2491: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4981, 1, 9952, 9968)
        slice_scatter_default_4982: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2491, slice_41100, 2, 0, 16);  slice_tensor_2491 = slice_41100 = None
        slice_scatter_default_4983: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4981, slice_scatter_default_4982, 1, 9952, 9968);  slice_scatter_default_4981 = slice_scatter_default_4982 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41119: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9968, 9984)
        slice_41120: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_41119, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1249: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_41120, memory_format = torch.contiguous_format);  slice_41120 = None
        view_2502: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1249, [32, 16]);  clone_1249 = None
        mm_1246: "f32[32, 8]" = torch.ops.aten.mm.default(view_2502, slice_7)
        view_2503: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1246, [2, 16, 8]);  mm_1246 = None
        slice_41127: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4983, 1, 9968, 9984)
        slice_41128: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41127, 2, 0, 16);  slice_41127 = None
        add_1248: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41128, view_2503);  slice_41128 = view_2503 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2492: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4983, 1, 9968, 9984)
        slice_scatter_default_4984: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2492, add_1248, 2, 0, 16);  slice_tensor_2492 = add_1248 = None
        slice_scatter_default_4985: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4983, slice_scatter_default_4984, 1, 9968, 9984);  slice_scatter_default_4983 = slice_scatter_default_4984 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41132: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4985, 1, 9968, 9984)
        slice_41133: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41132, 2, 0, 16);  slice_41132 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2493: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4985, 1, 9968, 9984)
        slice_scatter_default_4986: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2493, slice_41133, 2, 0, 16);  slice_tensor_2493 = slice_41133 = None
        slice_scatter_default_4987: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4985, slice_scatter_default_4986, 1, 9968, 9984);  slice_scatter_default_4985 = slice_scatter_default_4986 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41153: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_41119, 2, 16, 32);  slice_41119 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1250: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_41153, memory_format = torch.contiguous_format);  slice_41153 = None
        view_2504: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1250, [32, 11]);  clone_1250 = None
        mm_1247: "f32[32, 8]" = torch.ops.aten.mm.default(view_2504, slice_37)
        view_2505: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1247, [2, 16, 8]);  mm_1247 = None
        slice_41160: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4987, 1, 9968, 9984)
        slice_41161: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41160, 2, 0, 16);  slice_41160 = None
        add_1249: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41161, view_2505);  slice_41161 = view_2505 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2494: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4987, 1, 9968, 9984)
        slice_scatter_default_4988: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2494, add_1249, 2, 0, 16);  slice_tensor_2494 = add_1249 = None
        slice_scatter_default_4989: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4987, slice_scatter_default_4988, 1, 9968, 9984);  slice_scatter_default_4987 = slice_scatter_default_4988 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41165: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4989, 1, 9968, 9984)
        slice_41166: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41165, 2, 0, 16);  slice_41165 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2495: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4989, 1, 9968, 9984)
        slice_scatter_default_4990: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2495, slice_41166, 2, 0, 16);  slice_tensor_2495 = slice_41166 = None
        slice_scatter_default_4991: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4989, slice_scatter_default_4990, 1, 9968, 9984);  slice_scatter_default_4989 = slice_scatter_default_4990 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41185: "f32[2, 16, 27]" = torch.ops.aten.slice.Tensor(view_8, 1, 9984, 10000);  view_8 = None
        slice_41186: "f32[2, 16, 16]" = torch.ops.aten.slice.Tensor(slice_41185, 2, 0, 16)
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1251: "f32[2, 16, 16]" = torch.ops.aten.clone.default(slice_41186, memory_format = torch.contiguous_format);  slice_41186 = None
        view_2506: "f32[32, 16]" = torch.ops.aten.reshape.default(clone_1251, [32, 16]);  clone_1251 = None
        mm_1248: "f32[32, 8]" = torch.ops.aten.mm.default(view_2506, slice_7);  slice_7 = None
        view_2507: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1248, [2, 16, 8]);  mm_1248 = None
        slice_41193: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4991, 1, 9984, 10000)
        slice_41194: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41193, 2, 0, 16);  slice_41193 = None
        add_1250: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41194, view_2507);  slice_41194 = view_2507 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2496: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4991, 1, 9984, 10000)
        slice_scatter_default_4992: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2496, add_1250, 2, 0, 16);  slice_tensor_2496 = add_1250 = None
        slice_scatter_default_4993: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4991, slice_scatter_default_4992, 1, 9984, 10000);  slice_scatter_default_4991 = slice_scatter_default_4992 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41198: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4993, 1, 9984, 10000)
        slice_41199: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41198, 2, 0, 16);  slice_41198 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2497: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4993, 1, 9984, 10000)
        slice_scatter_default_4994: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2497, slice_41199, 2, 0, 16);  slice_tensor_2497 = slice_41199 = None
        slice_scatter_default_4995: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4993, slice_scatter_default_4994, 1, 9984, 10000);  slice_scatter_default_4993 = slice_scatter_default_4994 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:77 in conv2d_manual, code: cols_tile = cols[:, i:i+TILE_SIZE, k:k+TILE_SIZE]  # (N, TILE_SIZE, TILE_SIZE)
        slice_41219: "f32[2, 16, 11]" = torch.ops.aten.slice.Tensor(slice_41185, 2, 16, 32);  slice_41185 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        clone_1252: "f32[2, 16, 11]" = torch.ops.aten.clone.default(slice_41219, memory_format = torch.contiguous_format);  slice_41219 = None
        view_2508: "f32[32, 11]" = torch.ops.aten.reshape.default(clone_1252, [32, 11]);  clone_1252 = None
        mm_1249: "f32[32, 8]" = torch.ops.aten.mm.default(view_2508, slice_37);  slice_37 = None
        view_2509: "f32[2, 16, 8]" = torch.ops.aten.reshape.default(mm_1249, [2, 16, 8]);  mm_1249 = None
        slice_41226: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4995, 1, 9984, 10000)
        slice_41227: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41226, 2, 0, 16);  slice_41226 = None
        add_1251: "f32[2, 16, 8]" = torch.ops.aten.add.Tensor(slice_41227, view_2509);  slice_41227 = view_2509 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2498: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4995, 1, 9984, 10000)
        slice_scatter_default_4996: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2498, add_1251, 2, 0, 16);  slice_tensor_2498 = add_1251 = None
        slice_scatter_default_4997: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4995, slice_scatter_default_4996, 1, 9984, 10000);  slice_scatter_default_4995 = slice_scatter_default_4996 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        slice_41231: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4997, 1, 9984, 10000)
        slice_41232: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_41231, 2, 0, 16);  slice_41231 = None
        
        # No stacktrace found for following nodes
        slice_tensor_2499: "f32[2, 16, 8]" = torch.ops.aten.slice.Tensor(slice_scatter_default_4997, 1, 9984, 10000)
        slice_scatter_default_4998: "f32[2, 16, 8]" = torch.ops.aten.slice_scatter.default(slice_tensor_2499, slice_41232, 2, 0, 16);  slice_tensor_2499 = slice_41232 = None
        slice_scatter_default_4999: "f32[2, 10000, 8]" = torch.ops.aten.slice_scatter.default(slice_scatter_default_4997, slice_scatter_default_4998, 1, 9984, 10000);  slice_scatter_default_4997 = slice_scatter_default_4998 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:81 in conv2d_manual, code: out = out + self.bias # (N, out_h*out_w, C_out) + (C_out,) > (N, out_h*out_w, C_out)
        add_1252: "f32[2, 10000, 8]" = torch.ops.aten.add.Tensor(slice_scatter_default_4999, primals_3);  slice_scatter_default_4999 = primals_3 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:83 in conv2d_manual, code: out = out.permute(0, 2, 1).contiguous().view(N, C_out, int(self.out_h), int(self.out_w)) # (N, C_out, out_h, out_w)
        permute_2: "f32[2, 8, 10000]" = torch.ops.aten.permute.default(add_1252, [0, 2, 1]);  add_1252 = None
        clone_1253: "f32[2, 8, 10000]" = torch.ops.aten.clone.default(permute_2, memory_format = torch.contiguous_format);  permute_2 = None
        view_2510: "f32[2, 8, 100, 100]" = torch.ops.aten.reshape.default(clone_1253, [2, 8, 100, 100]);  clone_1253 = None
        
         # File: /home/ec2-user/ML_compilers/mp2/gpu/myconv.py:79 in conv2d_manual, code: out[:, i:i+TILE_SIZE, j:j+TILE_SIZE] += torch.matmul(cols_tile, weight_tile) # (N, TILE_SIZE, TILE_SIZE)
        permute_4: "f32[11, 32]" = torch.ops.aten.permute.default(view_2508, [1, 0]);  view_2508 = None
        permute_5: "f32[16, 32]" = torch.ops.aten.permute.default(view_2506, [1, 0]);  view_2506 = None
        permute_6: "f32[11, 32]" = torch.ops.aten.permute.default(view_2504, [1, 0]);  view_2504 = None
        permute_7: "f32[16, 32]" = torch.ops.aten.permute.default(view_2502, [1, 0]);  view_2502 = None
        permute_8: "f32[11, 32]" = torch.ops.aten.permute.default(view_2500, [1, 0]);  view_2500 = None
        permute_9: "f32[16, 32]" = torch.ops.aten.permute.default(view_2498, [1, 0]);  view_2498 = None
        permute_10: "f32[11, 32]" = torch.ops.aten.permute.default(view_2496, [1, 0]);  view_2496 = None
        permute_11: "f32[16, 32]" = torch.ops.aten.permute.default(view_2494, [1, 0]);  view_2494 = None
        permute_12: "f32[11, 32]" = torch.ops.aten.permute.default(view_2492, [1, 0]);  view_2492 = None
        permute_13: "f32[16, 32]" = torch.ops.aten.permute.default(view_2490, [1, 0]);  view_2490 = None
        permute_14: "f32[11, 32]" = torch.ops.aten.permute.default(view_2488, [1, 0]);  view_2488 = None
        permute_15: "f32[16, 32]" = torch.ops.aten.permute.default(view_2486, [1, 0]);  view_2486 = None
        permute_16: "f32[11, 32]" = torch.ops.aten.permute.default(view_2484, [1, 0]);  view_2484 = None
        permute_17: "f32[16, 32]" = torch.ops.aten.permute.default(view_2482, [1, 0]);  view_2482 = None
        permute_18: "f32[11, 32]" = torch.ops.aten.permute.default(view_2480, [1, 0]);  view_2480 = None
        permute_19: "f32[16, 32]" = torch.ops.aten.permute.default(view_2478, [1, 0]);  view_2478 = None
        permute_20: "f32[11, 32]" = torch.ops.aten.permute.default(view_2476, [1, 0]);  view_2476 = None
        permute_21: "f32[16, 32]" = torch.ops.aten.permute.default(view_2474, [1, 0]);  view_2474 = None
        permute_22: "f32[11, 32]" = torch.ops.aten.permute.default(view_2472, [1, 0]);  view_2472 = None
        permute_23: "f32[16, 32]" = torch.ops.aten.permute.default(view_2470, [1, 0]);  view_2470 = None
        permute_24: "f32[11, 32]" = torch.ops.aten.permute.default(view_2468, [1, 0]);  view_2468 = None
        permute_25: "f32[16, 32]" = torch.ops.aten.permute.default(view_2466, [1, 0]);  view_2466 = None
        permute_26: "f32[11, 32]" = torch.ops.aten.permute.default(view_2464, [1, 0]);  view_2464 = None
        permute_27: "f32[16, 32]" = torch.ops.aten.permute.default(view_2462, [1, 0]);  view_2462 = None
        permute_28: "f32[11, 32]" = torch.ops.aten.permute.default(view_2460, [1, 0]);  view_2460 = None
        permute_29: "f32[16, 32]" = torch.ops.aten.permute.default(view_2458, [1, 0]);  view_2458 = None
        permute_30: "f32[11, 32]" = torch.ops.aten.permute.default(view_2456, [1, 0]);  view_2456 = None
        permute_31: "f32[16, 32]" = torch.ops.aten.permute.default(view_2454, [1, 0]);  view_2454 = None
        permute_32: "f32[11, 32]" = torch.ops.aten.permute.default(view_2452, [1, 0]);  view_2452 = None
        permute_33: "f32[16, 32]" = torch.ops.aten.permute.default(view_2450, [1, 0]);  view_2450 = None
        permute_34: "f32[11, 32]" = torch.ops.aten.permute.default(view_2448, [1, 0]);  view_2448 = None
        permute_35: "f32[16, 32]" = torch.ops.aten.permute.default(view_2446, [1, 0]);  view_2446 = None
        permute_36: "f32[11, 32]" = torch.ops.aten.permute.default(view_2444, [1, 0]);  view_2444 = None
        permute_37: "f32[16, 32]" = torch.ops.aten.permute.default(view_2442, [1, 0]);  view_2442 = None
        permute_38: "f32[11, 32]" = torch.ops.aten.permute.default(view_2440, [1, 0]);  view_2440 = None
        permute_39: "f32[16, 32]" = torch.ops.aten.permute.default(view_2438, [1, 0]);  view_2438 = None
        permute_40: "f32[11, 32]" = torch.ops.aten.permute.default(view_2436, [1, 0]);  view_2436 = None
        permute_41: "f32[16, 32]" = torch.ops.aten.permute.default(view_2434, [1, 0]);  view_2434 = None
        permute_42: "f32[11, 32]" = torch.ops.aten.permute.default(view_2432, [1, 0]);  view_2432 = None
        permute_43: "f32[16, 32]" = torch.ops.aten.permute.default(view_2430, [1, 0]);  view_2430 = None
        permute_44: "f32[11, 32]" = torch.ops.aten.permute.default(view_2428, [1, 0]);  view_2428 = None
        permute_45: "f32[16, 32]" = torch.ops.aten.permute.default(view_2426, [1, 0]);  view_2426 = None
        permute_46: "f32[11, 32]" = torch.ops.aten.permute.default(view_2424, [1, 0]);  view_2424 = None
        permute_47: "f32[16, 32]" = torch.ops.aten.permute.default(view_2422, [1, 0]);  view_2422 = None
        permute_48: "f32[11, 32]" = torch.ops.aten.permute.default(view_2420, [1, 0]);  view_2420 = None
        permute_49: "f32[16, 32]" = torch.ops.aten.permute.default(view_2418, [1, 0]);  view_2418 = None
        permute_50: "f32[11, 32]" = torch.ops.aten.permute.default(view_2416, [1, 0]);  view_2416 = None
        permute_51: "f32[16, 32]" = torch.ops.aten.permute.default(view_2414, [1, 0]);  view_2414 = None
        permute_52: "f32[11, 32]" = torch.ops.aten.permute.default(view_2412, [1, 0]);  view_2412 = None
        permute_53: "f32[16, 32]" = torch.ops.aten.permute.default(view_2410, [1, 0]);  view_2410 = None
        permute_54: "f32[11, 32]" = torch.ops.aten.permute.default(view_2408, [1, 0]);  view_2408 = None
        permute_55: "f32[16, 32]" = torch.ops.aten.permute.default(view_2406, [1, 0]);  view_2406 = None
        permute_56: "f32[11, 32]" = torch.ops.aten.permute.default(view_2404, [1, 0]);  view_2404 = None
        permute_57: "f32[16, 32]" = torch.ops.aten.permute.default(view_2402, [1, 0]);  view_2402 = None
        permute_58: "f32[11, 32]" = torch.ops.aten.permute.default(view_2400, [1, 0]);  view_2400 = None
        permute_59: "f32[16, 32]" = torch.ops.aten.permute.default(view_2398, [1, 0]);  view_2398 = None
        permute_60: "f32[11, 32]" = torch.ops.aten.permute.default(view_2396, [1, 0]);  view_2396 = None
        permute_61: "f32[16, 32]" = torch.ops.aten.permute.default(view_2394, [1, 0]);  view_2394 = None
        permute_62: "f32[11, 32]" = torch.ops.aten.permute.default(view_2392, [1, 0]);  view_2392 = None
        permute_63: "f32[16, 32]" = torch.ops.aten.permute.default(view_2390, [1, 0]);  view_2390 = None
        permute_64: "f32[11, 32]" = torch.ops.aten.permute.default(view_2388, [1, 0]);  view_2388 = None
        permute_65: "f32[16, 32]" = torch.ops.aten.permute.default(view_2386, [1, 0]);  view_2386 = None
        permute_66: "f32[11, 32]" = torch.ops.aten.permute.default(view_2384, [1, 0]);  view_2384 = None
        permute_67: "f32[16, 32]" = torch.ops.aten.permute.default(view_2382, [1, 0]);  view_2382 = None
        permute_68: "f32[11, 32]" = torch.ops.aten.permute.default(view_2380, [1, 0]);  view_2380 = None
        permute_69: "f32[16, 32]" = torch.ops.aten.permute.default(view_2378, [1, 0]);  view_2378 = None
        permute_70: "f32[11, 32]" = torch.ops.aten.permute.default(view_2376, [1, 0]);  view_2376 = None
        permute_71: "f32[16, 32]" = torch.ops.aten.permute.default(view_2374, [1, 0]);  view_2374 = None
        permute_72: "f32[11, 32]" = torch.ops.aten.permute.default(view_2372, [1, 0]);  view_2372 = None
        permute_73: "f32[16, 32]" = torch.ops.aten.permute.default(view_2370, [1, 0]);  view_2370 = None
        permute_74: "f32[11, 32]" = torch.ops.aten.permute.default(view_2368, [1, 0]);  view_2368 = None
        permute_75: "f32[16, 32]" = torch.ops.aten.permute.default(view_2366, [1, 0]);  view_2366 = None
        permute_76: "f32[11, 32]" = torch.ops.aten.permute.default(view_2364, [1, 0]);  view_2364 = None
        permute_77: "f32[16, 32]" = torch.ops.aten.permute.default(view_2362, [1, 0]);  view_2362 = None
        permute_78: "f32[11, 32]" = torch.ops.aten.permute.default(view_2360, [1, 0]);  view_2360 = None
        permute_79: "f32[16, 32]" = torch.ops.aten.permute.default(view_2358, [1, 0]);  view_2358 = None
        permute_80: "f32[11, 32]" = torch.ops.aten.permute.default(view_2356, [1, 0]);  view_2356 = None
        permute_81: "f32[16, 32]" = torch.ops.aten.permute.default(view_2354, [1, 0]);  view_2354 = None
        permute_82: "f32[11, 32]" = torch.ops.aten.permute.default(view_2352, [1, 0]);  view_2352 = None
        permute_83: "f32[16, 32]" = torch.ops.aten.permute.default(view_2350, [1, 0]);  view_2350 = None
        permute_84: "f32[11, 32]" = torch.ops.aten.permute.default(view_2348, [1, 0]);  view_2348 = None
        permute_85: "f32[16, 32]" = torch.ops.aten.permute.default(view_2346, [1, 0]);  view_2346 = None
        permute_86: "f32[11, 32]" = torch.ops.aten.permute.default(view_2344, [1, 0]);  view_2344 = None
        permute_87: "f32[16, 32]" = torch.ops.aten.permute.default(view_2342, [1, 0]);  view_2342 = None
        permute_88: "f32[11, 32]" = torch.ops.aten.permute.default(view_2340, [1, 0]);  view_2340 = None
        permute_89: "f32[16, 32]" = torch.ops.aten.permute.default(view_2338, [1, 0]);  view_2338 = None
        permute_90: "f32[11, 32]" = torch.ops.aten.permute.default(view_2336, [1, 0]);  view_2336 = None
        permute_91: "f32[16, 32]" = torch.ops.aten.permute.default(view_2334, [1, 0]);  view_2334 = None
        permute_92: "f32[11, 32]" = torch.ops.aten.permute.default(view_2332, [1, 0]);  view_2332 = None
        permute_93: "f32[16, 32]" = torch.ops.aten.permute.default(view_2330, [1, 0]);  view_2330 = None
        permute_94: "f32[11, 32]" = torch.ops.aten.permute.default(view_2328, [1, 0]);  view_2328 = None
        permute_95: "f32[16, 32]" = torch.ops.aten.permute.default(view_2326, [1, 0]);  view_2326 = None
        permute_96: "f32[11, 32]" = torch.ops.aten.permute.default(view_2324, [1, 0]);  view_2324 = None
        permute_97: "f32[16, 32]" = torch.ops.aten.permute.default(view_2322, [1, 0]);  view_2322 = None
        permute_98: "f32[11, 32]" = torch.ops.aten.permute.default(view_2320, [1, 0]);  view_2320 = None
        permute_99: "f32[16, 32]" = torch.ops.aten.permute.default(view_2318, [1, 0]);  view_2318 = None
        permute_100: "f32[11, 32]" = torch.ops.aten.permute.default(view_2316, [1, 0]);  view_2316 = None
        permute_101: "f32[16, 32]" = torch.ops.aten.permute.default(view_2314, [1, 0]);  view_2314 = None
        permute_102: "f32[11, 32]" = torch.ops.aten.permute.default(view_2312, [1, 0]);  view_2312 = None
        permute_103: "f32[16, 32]" = torch.ops.aten.permute.default(view_2310, [1, 0]);  view_2310 = None
        permute_104: "f32[11, 32]" = torch.ops.aten.permute.default(view_2308, [1, 0]);  view_2308 = None
        permute_105: "f32[16, 32]" = torch.ops.aten.permute.default(view_2306, [1, 0]);  view_2306 = None
        permute_106: "f32[11, 32]" = torch.ops.aten.permute.default(view_2304, [1, 0]);  view_2304 = None
        permute_107: "f32[16, 32]" = torch.ops.aten.permute.default(view_2302, [1, 0]);  view_2302 = None
        permute_108: "f32[11, 32]" = torch.ops.aten.permute.default(view_2300, [1, 0]);  view_2300 = None
        permute_109: "f32[16, 32]" = torch.ops.aten.permute.default(view_2298, [1, 0]);  view_2298 = None
        permute_110: "f32[11, 32]" = torch.ops.aten.permute.default(view_2296, [1, 0]);  view_2296 = None
        permute_111: "f32[16, 32]" = torch.ops.aten.permute.default(view_2294, [1, 0]);  view_2294 = None
        permute_112: "f32[11, 32]" = torch.ops.aten.permute.default(view_2292, [1, 0]);  view_2292 = None
        permute_113: "f32[16, 32]" = torch.ops.aten.permute.default(view_2290, [1, 0]);  view_2290 = None
        permute_114: "f32[11, 32]" = torch.ops.aten.permute.default(view_2288, [1, 0]);  view_2288 = None
        permute_115: "f32[16, 32]" = torch.ops.aten.permute.default(view_2286, [1, 0]);  view_2286 = None
        permute_116: "f32[11, 32]" = torch.ops.aten.permute.default(view_2284, [1, 0]);  view_2284 = None
        permute_117: "f32[16, 32]" = torch.ops.aten.permute.default(view_2282, [1, 0]);  view_2282 = None
        permute_118: "f32[11, 32]" = torch.ops.aten.permute.default(view_2280, [1, 0]);  view_2280 = None
        permute_119: "f32[16, 32]" = torch.ops.aten.permute.default(view_2278, [1, 0]);  view_2278 = None
        permute_120: "f32[11, 32]" = torch.ops.aten.permute.default(view_2276, [1, 0]);  view_2276 = None
        permute_121: "f32[16, 32]" = torch.ops.aten.permute.default(view_2274, [1, 0]);  view_2274 = None
        permute_122: "f32[11, 32]" = torch.ops.aten.permute.default(view_2272, [1, 0]);  view_2272 = None
        permute_123: "f32[16, 32]" = torch.ops.aten.permute.default(view_2270, [1, 0]);  view_2270 = None
        permute_124: "f32[11, 32]" = torch.ops.aten.permute.default(view_2268, [1, 0]);  view_2268 = None
        permute_125: "f32[16, 32]" = torch.ops.aten.permute.default(view_2266, [1, 0]);  view_2266 = None
        permute_126: "f32[11, 32]" = torch.ops.aten.permute.default(view_2264, [1, 0]);  view_2264 = None
        permute_127: "f32[16, 32]" = torch.ops.aten.permute.default(view_2262, [1, 0]);  view_2262 = None
        permute_128: "f32[11, 32]" = torch.ops.aten.permute.default(view_2260, [1, 0]);  view_2260 = None
        permute_129: "f32[16, 32]" = torch.ops.aten.permute.default(view_2258, [1, 0]);  view_2258 = None
        permute_130: "f32[11, 32]" = torch.ops.aten.permute.default(view_2256, [1, 0]);  view_2256 = None
        permute_131: "f32[16, 32]" = torch.ops.aten.permute.default(view_2254, [1, 0]);  view_2254 = None
        permute_132: "f32[11, 32]" = torch.ops.aten.permute.default(view_2252, [1, 0]);  view_2252 = None
        permute_133: "f32[16, 32]" = torch.ops.aten.permute.default(view_2250, [1, 0]);  view_2250 = None
        permute_134: "f32[11, 32]" = torch.ops.aten.permute.default(view_2248, [1, 0]);  view_2248 = None
        permute_135: "f32[16, 32]" = torch.ops.aten.permute.default(view_2246, [1, 0]);  view_2246 = None
        permute_136: "f32[11, 32]" = torch.ops.aten.permute.default(view_2244, [1, 0]);  view_2244 = None
        permute_137: "f32[16, 32]" = torch.ops.aten.permute.default(view_2242, [1, 0]);  view_2242 = None
        permute_138: "f32[11, 32]" = torch.ops.aten.permute.default(view_2240, [1, 0]);  view_2240 = None
        permute_139: "f32[16, 32]" = torch.ops.aten.permute.default(view_2238, [1, 0]);  view_2238 = None
        permute_140: "f32[11, 32]" = torch.ops.aten.permute.default(view_2236, [1, 0]);  view_2236 = None
        permute_141: "f32[16, 32]" = torch.ops.aten.permute.default(view_2234, [1, 0]);  view_2234 = None
        permute_142: "f32[11, 32]" = torch.ops.aten.permute.default(view_2232, [1, 0]);  view_2232 = None
        permute_143: "f32[16, 32]" = torch.ops.aten.permute.default(view_2230, [1, 0]);  view_2230 = None
        permute_144: "f32[11, 32]" = torch.ops.aten.permute.default(view_2228, [1, 0]);  view_2228 = None
        permute_145: "f32[16, 32]" = torch.ops.aten.permute.default(view_2226, [1, 0]);  view_2226 = None
        permute_146: "f32[11, 32]" = torch.ops.aten.permute.default(view_2224, [1, 0]);  view_2224 = None
        permute_147: "f32[16, 32]" = torch.ops.aten.permute.default(view_2222, [1, 0]);  view_2222 = None
        permute_148: "f32[11, 32]" = torch.ops.aten.permute.default(view_2220, [1, 0]);  view_2220 = None
        permute_149: "f32[16, 32]" = torch.ops.aten.permute.default(view_2218, [1, 0]);  view_2218 = None
        permute_150: "f32[11, 32]" = torch.ops.aten.permute.default(view_2216, [1, 0]);  view_2216 = None
        permute_151: "f32[16, 32]" = torch.ops.aten.permute.default(view_2214, [1, 0]);  view_2214 = None
        permute_152: "f32[11, 32]" = torch.ops.aten.permute.default(view_2212, [1, 0]);  view_2212 = None
        permute_153: "f32[16, 32]" = torch.ops.aten.permute.default(view_2210, [1, 0]);  view_2210 = None
        permute_154: "f32[11, 32]" = torch.ops.aten.permute.default(view_2208, [1, 0]);  view_2208 = None
        permute_155: "f32[16, 32]" = torch.ops.aten.permute.default(view_2206, [1, 0]);  view_2206 = None
        permute_156: "f32[11, 32]" = torch.ops.aten.permute.default(view_2204, [1, 0]);  view_2204 = None
        permute_157: "f32[16, 32]" = torch.ops.aten.permute.default(view_2202, [1, 0]);  view_2202 = None
        permute_158: "f32[11, 32]" = torch.ops.aten.permute.default(view_2200, [1, 0]);  view_2200 = None
        permute_159: "f32[16, 32]" = torch.ops.aten.permute.default(view_2198, [1, 0]);  view_2198 = None
        permute_160: "f32[11, 32]" = torch.ops.aten.permute.default(view_2196, [1, 0]);  view_2196 = None
        permute_161: "f32[16, 32]" = torch.ops.aten.permute.default(view_2194, [1, 0]);  view_2194 = None
        permute_162: "f32[11, 32]" = torch.ops.aten.permute.default(view_2192, [1, 0]);  view_2192 = None
        permute_163: "f32[16, 32]" = torch.ops.aten.permute.default(view_2190, [1, 0]);  view_2190 = None
        permute_164: "f32[11, 32]" = torch.ops.aten.permute.default(view_2188, [1, 0]);  view_2188 = None
        permute_165: "f32[16, 32]" = torch.ops.aten.permute.default(view_2186, [1, 0]);  view_2186 = None
        permute_166: "f32[11, 32]" = torch.ops.aten.permute.default(view_2184, [1, 0]);  view_2184 = None
        permute_167: "f32[16, 32]" = torch.ops.aten.permute.default(view_2182, [1, 0]);  view_2182 = None
        permute_168: "f32[11, 32]" = torch.ops.aten.permute.default(view_2180, [1, 0]);  view_2180 = None
        permute_169: "f32[16, 32]" = torch.ops.aten.permute.default(view_2178, [1, 0]);  view_2178 = None
        permute_170: "f32[11, 32]" = torch.ops.aten.permute.default(view_2176, [1, 0]);  view_2176 = None
        permute_171: "f32[16, 32]" = torch.ops.aten.permute.default(view_2174, [1, 0]);  view_2174 = None
        permute_172: "f32[11, 32]" = torch.ops.aten.permute.default(view_2172, [1, 0]);  view_2172 = None
        permute_173: "f32[16, 32]" = torch.ops.aten.permute.default(view_2170, [1, 0]);  view_2170 = None
        permute_174: "f32[11, 32]" = torch.ops.aten.permute.default(view_2168, [1, 0]);  view_2168 = None
        permute_175: "f32[16, 32]" = torch.ops.aten.permute.default(view_2166, [1, 0]);  view_2166 = None
        permute_176: "f32[11, 32]" = torch.ops.aten.permute.default(view_2164, [1, 0]);  view_2164 = None
        permute_177: "f32[16, 32]" = torch.ops.aten.permute.default(view_2162, [1, 0]);  view_2162 = None
        permute_178: "f32[11, 32]" = torch.ops.aten.permute.default(view_2160, [1, 0]);  view_2160 = None
        permute_179: "f32[16, 32]" = torch.ops.aten.permute.default(view_2158, [1, 0]);  view_2158 = None
        permute_180: "f32[11, 32]" = torch.ops.aten.permute.default(view_2156, [1, 0]);  view_2156 = None
        permute_181: "f32[16, 32]" = torch.ops.aten.permute.default(view_2154, [1, 0]);  view_2154 = None
        permute_182: "f32[11, 32]" = torch.ops.aten.permute.default(view_2152, [1, 0]);  view_2152 = None
        permute_183: "f32[16, 32]" = torch.ops.aten.permute.default(view_2150, [1, 0]);  view_2150 = None
        permute_184: "f32[11, 32]" = torch.ops.aten.permute.default(view_2148, [1, 0]);  view_2148 = None
        permute_185: "f32[16, 32]" = torch.ops.aten.permute.default(view_2146, [1, 0]);  view_2146 = None
        permute_186: "f32[11, 32]" = torch.ops.aten.permute.default(view_2144, [1, 0]);  view_2144 = None
        permute_187: "f32[16, 32]" = torch.ops.aten.permute.default(view_2142, [1, 0]);  view_2142 = None
        permute_188: "f32[11, 32]" = torch.ops.aten.permute.default(view_2140, [1, 0]);  view_2140 = None
        permute_189: "f32[16, 32]" = torch.ops.aten.permute.default(view_2138, [1, 0]);  view_2138 = None
        permute_190: "f32[11, 32]" = torch.ops.aten.permute.default(view_2136, [1, 0]);  view_2136 = None
        permute_191: "f32[16, 32]" = torch.ops.aten.permute.default(view_2134, [1, 0]);  view_2134 = None
        permute_192: "f32[11, 32]" = torch.ops.aten.permute.default(view_2132, [1, 0]);  view_2132 = None
        permute_193: "f32[16, 32]" = torch.ops.aten.permute.default(view_2130, [1, 0]);  view_2130 = None
        permute_194: "f32[11, 32]" = torch.ops.aten.permute.default(view_2128, [1, 0]);  view_2128 = None
        permute_195: "f32[16, 32]" = torch.ops.aten.permute.default(view_2126, [1, 0]);  view_2126 = None
        permute_196: "f32[11, 32]" = torch.ops.aten.permute.default(view_2124, [1, 0]);  view_2124 = None
        permute_197: "f32[16, 32]" = torch.ops.aten.permute.default(view_2122, [1, 0]);  view_2122 = None
        permute_198: "f32[11, 32]" = torch.ops.aten.permute.default(view_2120, [1, 0]);  view_2120 = None
        permute_199: "f32[16, 32]" = torch.ops.aten.permute.default(view_2118, [1, 0]);  view_2118 = None
        permute_200: "f32[11, 32]" = torch.ops.aten.permute.default(view_2116, [1, 0]);  view_2116 = None
        permute_201: "f32[16, 32]" = torch.ops.aten.permute.default(view_2114, [1, 0]);  view_2114 = None
        permute_202: "f32[11, 32]" = torch.ops.aten.permute.default(view_2112, [1, 0]);  view_2112 = None
        permute_203: "f32[16, 32]" = torch.ops.aten.permute.default(view_2110, [1, 0]);  view_2110 = None
        permute_204: "f32[11, 32]" = torch.ops.aten.permute.default(view_2108, [1, 0]);  view_2108 = None
        permute_205: "f32[16, 32]" = torch.ops.aten.permute.default(view_2106, [1, 0]);  view_2106 = None
        permute_206: "f32[11, 32]" = torch.ops.aten.permute.default(view_2104, [1, 0]);  view_2104 = None
        permute_207: "f32[16, 32]" = torch.ops.aten.permute.default(view_2102, [1, 0]);  view_2102 = None
        permute_208: "f32[11, 32]" = torch.ops.aten.permute.default(view_2100, [1, 0]);  view_2100 = None
        permute_209: "f32[16, 32]" = torch.ops.aten.permute.default(view_2098, [1, 0]);  view_2098 = None
        permute_210: "f32[11, 32]" = torch.ops.aten.permute.default(view_2096, [1, 0]);  view_2096 = None
        permute_211: "f32[16, 32]" = torch.ops.aten.permute.default(view_2094, [1, 0]);  view_2094 = None
        permute_212: "f32[11, 32]" = torch.ops.aten.permute.default(view_2092, [1, 0]);  view_2092 = None
        permute_213: "f32[16, 32]" = torch.ops.aten.permute.default(view_2090, [1, 0]);  view_2090 = None
        permute_214: "f32[11, 32]" = torch.ops.aten.permute.default(view_2088, [1, 0]);  view_2088 = None
        permute_215: "f32[16, 32]" = torch.ops.aten.permute.default(view_2086, [1, 0]);  view_2086 = None
        permute_216: "f32[11, 32]" = torch.ops.aten.permute.default(view_2084, [1, 0]);  view_2084 = None
        permute_217: "f32[16, 32]" = torch.ops.aten.permute.default(view_2082, [1, 0]);  view_2082 = None
        permute_218: "f32[11, 32]" = torch.ops.aten.permute.default(view_2080, [1, 0]);  view_2080 = None
        permute_219: "f32[16, 32]" = torch.ops.aten.permute.default(view_2078, [1, 0]);  view_2078 = None
        permute_220: "f32[11, 32]" = torch.ops.aten.permute.default(view_2076, [1, 0]);  view_2076 = None
        permute_221: "f32[16, 32]" = torch.ops.aten.permute.default(view_2074, [1, 0]);  view_2074 = None
        permute_222: "f32[11, 32]" = torch.ops.aten.permute.default(view_2072, [1, 0]);  view_2072 = None
        permute_223: "f32[16, 32]" = torch.ops.aten.permute.default(view_2070, [1, 0]);  view_2070 = None
        permute_224: "f32[11, 32]" = torch.ops.aten.permute.default(view_2068, [1, 0]);  view_2068 = None
        permute_225: "f32[16, 32]" = torch.ops.aten.permute.default(view_2066, [1, 0]);  view_2066 = None
        permute_226: "f32[11, 32]" = torch.ops.aten.permute.default(view_2064, [1, 0]);  view_2064 = None
        permute_227: "f32[16, 32]" = torch.ops.aten.permute.default(view_2062, [1, 0]);  view_2062 = None
        permute_228: "f32[11, 32]" = torch.ops.aten.permute.default(view_2060, [1, 0]);  view_2060 = None
        permute_229: "f32[16, 32]" = torch.ops.aten.permute.default(view_2058, [1, 0]);  view_2058 = None
        permute_230: "f32[11, 32]" = torch.ops.aten.permute.default(view_2056, [1, 0]);  view_2056 = None
        permute_231: "f32[16, 32]" = torch.ops.aten.permute.default(view_2054, [1, 0]);  view_2054 = None
        permute_232: "f32[11, 32]" = torch.ops.aten.permute.default(view_2052, [1, 0]);  view_2052 = None
        permute_233: "f32[16, 32]" = torch.ops.aten.permute.default(view_2050, [1, 0]);  view_2050 = None
        permute_234: "f32[11, 32]" = torch.ops.aten.permute.default(view_2048, [1, 0]);  view_2048 = None
        permute_235: "f32[16, 32]" = torch.ops.aten.permute.default(view_2046, [1, 0]);  view_2046 = None
        permute_236: "f32[11, 32]" = torch.ops.aten.permute.default(view_2044, [1, 0]);  view_2044 = None
        permute_237: "f32[16, 32]" = torch.ops.aten.permute.default(view_2042, [1, 0]);  view_2042 = None
        permute_238: "f32[11, 32]" = torch.ops.aten.permute.default(view_2040, [1, 0]);  view_2040 = None
        permute_239: "f32[16, 32]" = torch.ops.aten.permute.default(view_2038, [1, 0]);  view_2038 = None
        permute_240: "f32[11, 32]" = torch.ops.aten.permute.default(view_2036, [1, 0]);  view_2036 = None
        permute_241: "f32[16, 32]" = torch.ops.aten.permute.default(view_2034, [1, 0]);  view_2034 = None
        permute_242: "f32[11, 32]" = torch.ops.aten.permute.default(view_2032, [1, 0]);  view_2032 = None
        permute_243: "f32[16, 32]" = torch.ops.aten.permute.default(view_2030, [1, 0]);  view_2030 = None
        permute_244: "f32[11, 32]" = torch.ops.aten.permute.default(view_2028, [1, 0]);  view_2028 = None
        permute_245: "f32[16, 32]" = torch.ops.aten.permute.default(view_2026, [1, 0]);  view_2026 = None
        permute_246: "f32[11, 32]" = torch.ops.aten.permute.default(view_2024, [1, 0]);  view_2024 = None
        permute_247: "f32[16, 32]" = torch.ops.aten.permute.default(view_2022, [1, 0]);  view_2022 = None
        permute_248: "f32[11, 32]" = torch.ops.aten.permute.default(view_2020, [1, 0]);  view_2020 = None
        permute_249: "f32[16, 32]" = torch.ops.aten.permute.default(view_2018, [1, 0]);  view_2018 = None
        permute_250: "f32[11, 32]" = torch.ops.aten.permute.default(view_2016, [1, 0]);  view_2016 = None
        permute_251: "f32[16, 32]" = torch.ops.aten.permute.default(view_2014, [1, 0]);  view_2014 = None
        permute_252: "f32[11, 32]" = torch.ops.aten.permute.default(view_2012, [1, 0]);  view_2012 = None
        permute_253: "f32[16, 32]" = torch.ops.aten.permute.default(view_2010, [1, 0]);  view_2010 = None
        permute_254: "f32[11, 32]" = torch.ops.aten.permute.default(view_2008, [1, 0]);  view_2008 = None
        permute_255: "f32[16, 32]" = torch.ops.aten.permute.default(view_2006, [1, 0]);  view_2006 = None
        permute_256: "f32[11, 32]" = torch.ops.aten.permute.default(view_2004, [1, 0]);  view_2004 = None
        permute_257: "f32[16, 32]" = torch.ops.aten.permute.default(view_2002, [1, 0]);  view_2002 = None
        permute_258: "f32[11, 32]" = torch.ops.aten.permute.default(view_2000, [1, 0]);  view_2000 = None
        permute_259: "f32[16, 32]" = torch.ops.aten.permute.default(view_1998, [1, 0]);  view_1998 = None
        permute_260: "f32[11, 32]" = torch.ops.aten.permute.default(view_1996, [1, 0]);  view_1996 = None
        permute_261: "f32[16, 32]" = torch.ops.aten.permute.default(view_1994, [1, 0]);  view_1994 = None
        permute_262: "f32[11, 32]" = torch.ops.aten.permute.default(view_1992, [1, 0]);  view_1992 = None
        permute_263: "f32[16, 32]" = torch.ops.aten.permute.default(view_1990, [1, 0]);  view_1990 = None
        permute_264: "f32[11, 32]" = torch.ops.aten.permute.default(view_1988, [1, 0]);  view_1988 = None
        permute_265: "f32[16, 32]" = torch.ops.aten.permute.default(view_1986, [1, 0]);  view_1986 = None
        permute_266: "f32[11, 32]" = torch.ops.aten.permute.default(view_1984, [1, 0]);  view_1984 = None
        permute_267: "f32[16, 32]" = torch.ops.aten.permute.default(view_1982, [1, 0]);  view_1982 = None
        permute_268: "f32[11, 32]" = torch.ops.aten.permute.default(view_1980, [1, 0]);  view_1980 = None
        permute_269: "f32[16, 32]" = torch.ops.aten.permute.default(view_1978, [1, 0]);  view_1978 = None
        permute_270: "f32[11, 32]" = torch.ops.aten.permute.default(view_1976, [1, 0]);  view_1976 = None
        permute_271: "f32[16, 32]" = torch.ops.aten.permute.default(view_1974, [1, 0]);  view_1974 = None
        permute_272: "f32[11, 32]" = torch.ops.aten.permute.default(view_1972, [1, 0]);  view_1972 = None
        permute_273: "f32[16, 32]" = torch.ops.aten.permute.default(view_1970, [1, 0]);  view_1970 = None
        permute_274: "f32[11, 32]" = torch.ops.aten.permute.default(view_1968, [1, 0]);  view_1968 = None
        permute_275: "f32[16, 32]" = torch.ops.aten.permute.default(view_1966, [1, 0]);  view_1966 = None
        permute_276: "f32[11, 32]" = torch.ops.aten.permute.default(view_1964, [1, 0]);  view_1964 = None
        permute_277: "f32[16, 32]" = torch.ops.aten.permute.default(view_1962, [1, 0]);  view_1962 = None
        permute_278: "f32[11, 32]" = torch.ops.aten.permute.default(view_1960, [1, 0]);  view_1960 = None
        permute_279: "f32[16, 32]" = torch.ops.aten.permute.default(view_1958, [1, 0]);  view_1958 = None
        permute_280: "f32[11, 32]" = torch.ops.aten.permute.default(view_1956, [1, 0]);  view_1956 = None
        permute_281: "f32[16, 32]" = torch.ops.aten.permute.default(view_1954, [1, 0]);  view_1954 = None
        permute_282: "f32[11, 32]" = torch.ops.aten.permute.default(view_1952, [1, 0]);  view_1952 = None
        permute_283: "f32[16, 32]" = torch.ops.aten.permute.default(view_1950, [1, 0]);  view_1950 = None
        permute_284: "f32[11, 32]" = torch.ops.aten.permute.default(view_1948, [1, 0]);  view_1948 = None
        permute_285: "f32[16, 32]" = torch.ops.aten.permute.default(view_1946, [1, 0]);  view_1946 = None
        permute_286: "f32[11, 32]" = torch.ops.aten.permute.default(view_1944, [1, 0]);  view_1944 = None
        permute_287: "f32[16, 32]" = torch.ops.aten.permute.default(view_1942, [1, 0]);  view_1942 = None
        permute_288: "f32[11, 32]" = torch.ops.aten.permute.default(view_1940, [1, 0]);  view_1940 = None
        permute_289: "f32[16, 32]" = torch.ops.aten.permute.default(view_1938, [1, 0]);  view_1938 = None
        permute_290: "f32[11, 32]" = torch.ops.aten.permute.default(view_1936, [1, 0]);  view_1936 = None
        permute_291: "f32[16, 32]" = torch.ops.aten.permute.default(view_1934, [1, 0]);  view_1934 = None
        permute_292: "f32[11, 32]" = torch.ops.aten.permute.default(view_1932, [1, 0]);  view_1932 = None
        permute_293: "f32[16, 32]" = torch.ops.aten.permute.default(view_1930, [1, 0]);  view_1930 = None
        permute_294: "f32[11, 32]" = torch.ops.aten.permute.default(view_1928, [1, 0]);  view_1928 = None
        permute_295: "f32[16, 32]" = torch.ops.aten.permute.default(view_1926, [1, 0]);  view_1926 = None
        permute_296: "f32[11, 32]" = torch.ops.aten.permute.default(view_1924, [1, 0]);  view_1924 = None
        permute_297: "f32[16, 32]" = torch.ops.aten.permute.default(view_1922, [1, 0]);  view_1922 = None
        permute_298: "f32[11, 32]" = torch.ops.aten.permute.default(view_1920, [1, 0]);  view_1920 = None
        permute_299: "f32[16, 32]" = torch.ops.aten.permute.default(view_1918, [1, 0]);  view_1918 = None
        permute_300: "f32[11, 32]" = torch.ops.aten.permute.default(view_1916, [1, 0]);  view_1916 = None
        permute_301: "f32[16, 32]" = torch.ops.aten.permute.default(view_1914, [1, 0]);  view_1914 = None
        permute_302: "f32[11, 32]" = torch.ops.aten.permute.default(view_1912, [1, 0]);  view_1912 = None
        permute_303: "f32[16, 32]" = torch.ops.aten.permute.default(view_1910, [1, 0]);  view_1910 = None
        permute_304: "f32[11, 32]" = torch.ops.aten.permute.default(view_1908, [1, 0]);  view_1908 = None
        permute_305: "f32[16, 32]" = torch.ops.aten.permute.default(view_1906, [1, 0]);  view_1906 = None
        permute_306: "f32[11, 32]" = torch.ops.aten.permute.default(view_1904, [1, 0]);  view_1904 = None
        permute_307: "f32[16, 32]" = torch.ops.aten.permute.default(view_1902, [1, 0]);  view_1902 = None
        permute_308: "f32[11, 32]" = torch.ops.aten.permute.default(view_1900, [1, 0]);  view_1900 = None
        permute_309: "f32[16, 32]" = torch.ops.aten.permute.default(view_1898, [1, 0]);  view_1898 = None
        permute_310: "f32[11, 32]" = torch.ops.aten.permute.default(view_1896, [1, 0]);  view_1896 = None
        permute_311: "f32[16, 32]" = torch.ops.aten.permute.default(view_1894, [1, 0]);  view_1894 = None
        permute_312: "f32[11, 32]" = torch.ops.aten.permute.default(view_1892, [1, 0]);  view_1892 = None
        permute_313: "f32[16, 32]" = torch.ops.aten.permute.default(view_1890, [1, 0]);  view_1890 = None
        permute_314: "f32[11, 32]" = torch.ops.aten.permute.default(view_1888, [1, 0]);  view_1888 = None
        permute_315: "f32[16, 32]" = torch.ops.aten.permute.default(view_1886, [1, 0]);  view_1886 = None
        permute_316: "f32[11, 32]" = torch.ops.aten.permute.default(view_1884, [1, 0]);  view_1884 = None
        permute_317: "f32[16, 32]" = torch.ops.aten.permute.default(view_1882, [1, 0]);  view_1882 = None
        permute_318: "f32[11, 32]" = torch.ops.aten.permute.default(view_1880, [1, 0]);  view_1880 = None
        permute_319: "f32[16, 32]" = torch.ops.aten.permute.default(view_1878, [1, 0]);  view_1878 = None
        permute_320: "f32[11, 32]" = torch.ops.aten.permute.default(view_1876, [1, 0]);  view_1876 = None
        permute_321: "f32[16, 32]" = torch.ops.aten.permute.default(view_1874, [1, 0]);  view_1874 = None
        permute_322: "f32[11, 32]" = torch.ops.aten.permute.default(view_1872, [1, 0]);  view_1872 = None
        permute_323: "f32[16, 32]" = torch.ops.aten.permute.default(view_1870, [1, 0]);  view_1870 = None
        permute_324: "f32[11, 32]" = torch.ops.aten.permute.default(view_1868, [1, 0]);  view_1868 = None
        permute_325: "f32[16, 32]" = torch.ops.aten.permute.default(view_1866, [1, 0]);  view_1866 = None
        permute_326: "f32[11, 32]" = torch.ops.aten.permute.default(view_1864, [1, 0]);  view_1864 = None
        permute_327: "f32[16, 32]" = torch.ops.aten.permute.default(view_1862, [1, 0]);  view_1862 = None
        permute_328: "f32[11, 32]" = torch.ops.aten.permute.default(view_1860, [1, 0]);  view_1860 = None
        permute_329: "f32[16, 32]" = torch.ops.aten.permute.default(view_1858, [1, 0]);  view_1858 = None
        permute_330: "f32[11, 32]" = torch.ops.aten.permute.default(view_1856, [1, 0]);  view_1856 = None
        permute_331: "f32[16, 32]" = torch.ops.aten.permute.default(view_1854, [1, 0]);  view_1854 = None
        permute_332: "f32[11, 32]" = torch.ops.aten.permute.default(view_1852, [1, 0]);  view_1852 = None
        permute_333: "f32[16, 32]" = torch.ops.aten.permute.default(view_1850, [1, 0]);  view_1850 = None
        permute_334: "f32[11, 32]" = torch.ops.aten.permute.default(view_1848, [1, 0]);  view_1848 = None
        permute_335: "f32[16, 32]" = torch.ops.aten.permute.default(view_1846, [1, 0]);  view_1846 = None
        permute_336: "f32[11, 32]" = torch.ops.aten.permute.default(view_1844, [1, 0]);  view_1844 = None
        permute_337: "f32[16, 32]" = torch.ops.aten.permute.default(view_1842, [1, 0]);  view_1842 = None
        permute_338: "f32[11, 32]" = torch.ops.aten.permute.default(view_1840, [1, 0]);  view_1840 = None
        permute_339: "f32[16, 32]" = torch.ops.aten.permute.default(view_1838, [1, 0]);  view_1838 = None
        permute_340: "f32[11, 32]" = torch.ops.aten.permute.default(view_1836, [1, 0]);  view_1836 = None
        permute_341: "f32[16, 32]" = torch.ops.aten.permute.default(view_1834, [1, 0]);  view_1834 = None
        permute_342: "f32[11, 32]" = torch.ops.aten.permute.default(view_1832, [1, 0]);  view_1832 = None
        permute_343: "f32[16, 32]" = torch.ops.aten.permute.default(view_1830, [1, 0]);  view_1830 = None
        permute_344: "f32[11, 32]" = torch.ops.aten.permute.default(view_1828, [1, 0]);  view_1828 = None
        permute_345: "f32[16, 32]" = torch.ops.aten.permute.default(view_1826, [1, 0]);  view_1826 = None
        permute_346: "f32[11, 32]" = torch.ops.aten.permute.default(view_1824, [1, 0]);  view_1824 = None
        permute_347: "f32[16, 32]" = torch.ops.aten.permute.default(view_1822, [1, 0]);  view_1822 = None
        permute_348: "f32[11, 32]" = torch.ops.aten.permute.default(view_1820, [1, 0]);  view_1820 = None
        permute_349: "f32[16, 32]" = torch.ops.aten.permute.default(view_1818, [1, 0]);  view_1818 = None
        permute_350: "f32[11, 32]" = torch.ops.aten.permute.default(view_1816, [1, 0]);  view_1816 = None
        permute_351: "f32[16, 32]" = torch.ops.aten.permute.default(view_1814, [1, 0]);  view_1814 = None
        permute_352: "f32[11, 32]" = torch.ops.aten.permute.default(view_1812, [1, 0]);  view_1812 = None
        permute_353: "f32[16, 32]" = torch.ops.aten.permute.default(view_1810, [1, 0]);  view_1810 = None
        permute_354: "f32[11, 32]" = torch.ops.aten.permute.default(view_1808, [1, 0]);  view_1808 = None
        permute_355: "f32[16, 32]" = torch.ops.aten.permute.default(view_1806, [1, 0]);  view_1806 = None
        permute_356: "f32[11, 32]" = torch.ops.aten.permute.default(view_1804, [1, 0]);  view_1804 = None
        permute_357: "f32[16, 32]" = torch.ops.aten.permute.default(view_1802, [1, 0]);  view_1802 = None
        permute_358: "f32[11, 32]" = torch.ops.aten.permute.default(view_1800, [1, 0]);  view_1800 = None
        permute_359: "f32[16, 32]" = torch.ops.aten.permute.default(view_1798, [1, 0]);  view_1798 = None
        permute_360: "f32[11, 32]" = torch.ops.aten.permute.default(view_1796, [1, 0]);  view_1796 = None
        permute_361: "f32[16, 32]" = torch.ops.aten.permute.default(view_1794, [1, 0]);  view_1794 = None
        permute_362: "f32[11, 32]" = torch.ops.aten.permute.default(view_1792, [1, 0]);  view_1792 = None
        permute_363: "f32[16, 32]" = torch.ops.aten.permute.default(view_1790, [1, 0]);  view_1790 = None
        permute_364: "f32[11, 32]" = torch.ops.aten.permute.default(view_1788, [1, 0]);  view_1788 = None
        permute_365: "f32[16, 32]" = torch.ops.aten.permute.default(view_1786, [1, 0]);  view_1786 = None
        permute_366: "f32[11, 32]" = torch.ops.aten.permute.default(view_1784, [1, 0]);  view_1784 = None
        permute_367: "f32[16, 32]" = torch.ops.aten.permute.default(view_1782, [1, 0]);  view_1782 = None
        permute_368: "f32[11, 32]" = torch.ops.aten.permute.default(view_1780, [1, 0]);  view_1780 = None
        permute_369: "f32[16, 32]" = torch.ops.aten.permute.default(view_1778, [1, 0]);  view_1778 = None
        permute_370: "f32[11, 32]" = torch.ops.aten.permute.default(view_1776, [1, 0]);  view_1776 = None
        permute_371: "f32[16, 32]" = torch.ops.aten.permute.default(view_1774, [1, 0]);  view_1774 = None
        permute_372: "f32[11, 32]" = torch.ops.aten.permute.default(view_1772, [1, 0]);  view_1772 = None
        permute_373: "f32[16, 32]" = torch.ops.aten.permute.default(view_1770, [1, 0]);  view_1770 = None
        permute_374: "f32[11, 32]" = torch.ops.aten.permute.default(view_1768, [1, 0]);  view_1768 = None
        permute_375: "f32[16, 32]" = torch.ops.aten.permute.default(view_1766, [1, 0]);  view_1766 = None
        permute_376: "f32[11, 32]" = torch.ops.aten.permute.default(view_1764, [1, 0]);  view_1764 = None
        permute_377: "f32[16, 32]" = torch.ops.aten.permute.default(view_1762, [1, 0]);  view_1762 = None
        permute_378: "f32[11, 32]" = torch.ops.aten.permute.default(view_1760, [1, 0]);  view_1760 = None
        permute_379: "f32[16, 32]" = torch.ops.aten.permute.default(view_1758, [1, 0]);  view_1758 = None
        permute_380: "f32[11, 32]" = torch.ops.aten.permute.default(view_1756, [1, 0]);  view_1756 = None
        permute_381: "f32[16, 32]" = torch.ops.aten.permute.default(view_1754, [1, 0]);  view_1754 = None
        permute_382: "f32[11, 32]" = torch.ops.aten.permute.default(view_1752, [1, 0]);  view_1752 = None
        permute_383: "f32[16, 32]" = torch.ops.aten.permute.default(view_1750, [1, 0]);  view_1750 = None
        permute_384: "f32[11, 32]" = torch.ops.aten.permute.default(view_1748, [1, 0]);  view_1748 = None
        permute_385: "f32[16, 32]" = torch.ops.aten.permute.default(view_1746, [1, 0]);  view_1746 = None
        permute_386: "f32[11, 32]" = torch.ops.aten.permute.default(view_1744, [1, 0]);  view_1744 = None
        permute_387: "f32[16, 32]" = torch.ops.aten.permute.default(view_1742, [1, 0]);  view_1742 = None
        permute_388: "f32[11, 32]" = torch.ops.aten.permute.default(view_1740, [1, 0]);  view_1740 = None
        permute_389: "f32[16, 32]" = torch.ops.aten.permute.default(view_1738, [1, 0]);  view_1738 = None
        permute_390: "f32[11, 32]" = torch.ops.aten.permute.default(view_1736, [1, 0]);  view_1736 = None
        permute_391: "f32[16, 32]" = torch.ops.aten.permute.default(view_1734, [1, 0]);  view_1734 = None
        permute_392: "f32[11, 32]" = torch.ops.aten.permute.default(view_1732, [1, 0]);  view_1732 = None
        permute_393: "f32[16, 32]" = torch.ops.aten.permute.default(view_1730, [1, 0]);  view_1730 = None
        permute_394: "f32[11, 32]" = torch.ops.aten.permute.default(view_1728, [1, 0]);  view_1728 = None
        permute_395: "f32[16, 32]" = torch.ops.aten.permute.default(view_1726, [1, 0]);  view_1726 = None
        permute_396: "f32[11, 32]" = torch.ops.aten.permute.default(view_1724, [1, 0]);  view_1724 = None
        permute_397: "f32[16, 32]" = torch.ops.aten.permute.default(view_1722, [1, 0]);  view_1722 = None
        permute_398: "f32[11, 32]" = torch.ops.aten.permute.default(view_1720, [1, 0]);  view_1720 = None
        permute_399: "f32[16, 32]" = torch.ops.aten.permute.default(view_1718, [1, 0]);  view_1718 = None
        permute_400: "f32[11, 32]" = torch.ops.aten.permute.default(view_1716, [1, 0]);  view_1716 = None
        permute_401: "f32[16, 32]" = torch.ops.aten.permute.default(view_1714, [1, 0]);  view_1714 = None
        permute_402: "f32[11, 32]" = torch.ops.aten.permute.default(view_1712, [1, 0]);  view_1712 = None
        permute_403: "f32[16, 32]" = torch.ops.aten.permute.default(view_1710, [1, 0]);  view_1710 = None
        permute_404: "f32[11, 32]" = torch.ops.aten.permute.default(view_1708, [1, 0]);  view_1708 = None
        permute_405: "f32[16, 32]" = torch.ops.aten.permute.default(view_1706, [1, 0]);  view_1706 = None
        permute_406: "f32[11, 32]" = torch.ops.aten.permute.default(view_1704, [1, 0]);  view_1704 = None
        permute_407: "f32[16, 32]" = torch.ops.aten.permute.default(view_1702, [1, 0]);  view_1702 = None
        permute_408: "f32[11, 32]" = torch.ops.aten.permute.default(view_1700, [1, 0]);  view_1700 = None
        permute_409: "f32[16, 32]" = torch.ops.aten.permute.default(view_1698, [1, 0]);  view_1698 = None
        permute_410: "f32[11, 32]" = torch.ops.aten.permute.default(view_1696, [1, 0]);  view_1696 = None
        permute_411: "f32[16, 32]" = torch.ops.aten.permute.default(view_1694, [1, 0]);  view_1694 = None
        permute_412: "f32[11, 32]" = torch.ops.aten.permute.default(view_1692, [1, 0]);  view_1692 = None
        permute_413: "f32[16, 32]" = torch.ops.aten.permute.default(view_1690, [1, 0]);  view_1690 = None
        permute_414: "f32[11, 32]" = torch.ops.aten.permute.default(view_1688, [1, 0]);  view_1688 = None
        permute_415: "f32[16, 32]" = torch.ops.aten.permute.default(view_1686, [1, 0]);  view_1686 = None
        permute_416: "f32[11, 32]" = torch.ops.aten.permute.default(view_1684, [1, 0]);  view_1684 = None
        permute_417: "f32[16, 32]" = torch.ops.aten.permute.default(view_1682, [1, 0]);  view_1682 = None
        permute_418: "f32[11, 32]" = torch.ops.aten.permute.default(view_1680, [1, 0]);  view_1680 = None
        permute_419: "f32[16, 32]" = torch.ops.aten.permute.default(view_1678, [1, 0]);  view_1678 = None
        permute_420: "f32[11, 32]" = torch.ops.aten.permute.default(view_1676, [1, 0]);  view_1676 = None
        permute_421: "f32[16, 32]" = torch.ops.aten.permute.default(view_1674, [1, 0]);  view_1674 = None
        permute_422: "f32[11, 32]" = torch.ops.aten.permute.default(view_1672, [1, 0]);  view_1672 = None
        permute_423: "f32[16, 32]" = torch.ops.aten.permute.default(view_1670, [1, 0]);  view_1670 = None
        permute_424: "f32[11, 32]" = torch.ops.aten.permute.default(view_1668, [1, 0]);  view_1668 = None
        permute_425: "f32[16, 32]" = torch.ops.aten.permute.default(view_1666, [1, 0]);  view_1666 = None
        permute_426: "f32[11, 32]" = torch.ops.aten.permute.default(view_1664, [1, 0]);  view_1664 = None
        permute_427: "f32[16, 32]" = torch.ops.aten.permute.default(view_1662, [1, 0]);  view_1662 = None
        permute_428: "f32[11, 32]" = torch.ops.aten.permute.default(view_1660, [1, 0]);  view_1660 = None
        permute_429: "f32[16, 32]" = torch.ops.aten.permute.default(view_1658, [1, 0]);  view_1658 = None
        permute_430: "f32[11, 32]" = torch.ops.aten.permute.default(view_1656, [1, 0]);  view_1656 = None
        permute_431: "f32[16, 32]" = torch.ops.aten.permute.default(view_1654, [1, 0]);  view_1654 = None
        permute_432: "f32[11, 32]" = torch.ops.aten.permute.default(view_1652, [1, 0]);  view_1652 = None
        permute_433: "f32[16, 32]" = torch.ops.aten.permute.default(view_1650, [1, 0]);  view_1650 = None
        permute_434: "f32[11, 32]" = torch.ops.aten.permute.default(view_1648, [1, 0]);  view_1648 = None
        permute_435: "f32[16, 32]" = torch.ops.aten.permute.default(view_1646, [1, 0]);  view_1646 = None
        permute_436: "f32[11, 32]" = torch.ops.aten.permute.default(view_1644, [1, 0]);  view_1644 = None
        permute_437: "f32[16, 32]" = torch.ops.aten.permute.default(view_1642, [1, 0]);  view_1642 = None
        permute_438: "f32[11, 32]" = torch.ops.aten.permute.default(view_1640, [1, 0]);  view_1640 = None
        permute_439: "f32[16, 32]" = torch.ops.aten.permute.default(view_1638, [1, 0]);  view_1638 = None
        permute_440: "f32[11, 32]" = torch.ops.aten.permute.default(view_1636, [1, 0]);  view_1636 = None
        permute_441: "f32[16, 32]" = torch.ops.aten.permute.default(view_1634, [1, 0]);  view_1634 = None
        permute_442: "f32[11, 32]" = torch.ops.aten.permute.default(view_1632, [1, 0]);  view_1632 = None
        permute_443: "f32[16, 32]" = torch.ops.aten.permute.default(view_1630, [1, 0]);  view_1630 = None
        permute_444: "f32[11, 32]" = torch.ops.aten.permute.default(view_1628, [1, 0]);  view_1628 = None
        permute_445: "f32[16, 32]" = torch.ops.aten.permute.default(view_1626, [1, 0]);  view_1626 = None
        permute_446: "f32[11, 32]" = torch.ops.aten.permute.default(view_1624, [1, 0]);  view_1624 = None
        permute_447: "f32[16, 32]" = torch.ops.aten.permute.default(view_1622, [1, 0]);  view_1622 = None
        permute_448: "f32[11, 32]" = torch.ops.aten.permute.default(view_1620, [1, 0]);  view_1620 = None
        permute_449: "f32[16, 32]" = torch.ops.aten.permute.default(view_1618, [1, 0]);  view_1618 = None
        permute_450: "f32[11, 32]" = torch.ops.aten.permute.default(view_1616, [1, 0]);  view_1616 = None
        permute_451: "f32[16, 32]" = torch.ops.aten.permute.default(view_1614, [1, 0]);  view_1614 = None
        permute_452: "f32[11, 32]" = torch.ops.aten.permute.default(view_1612, [1, 0]);  view_1612 = None
        permute_453: "f32[16, 32]" = torch.ops.aten.permute.default(view_1610, [1, 0]);  view_1610 = None
        permute_454: "f32[11, 32]" = torch.ops.aten.permute.default(view_1608, [1, 0]);  view_1608 = None
        permute_455: "f32[16, 32]" = torch.ops.aten.permute.default(view_1606, [1, 0]);  view_1606 = None
        permute_456: "f32[11, 32]" = torch.ops.aten.permute.default(view_1604, [1, 0]);  view_1604 = None
        permute_457: "f32[16, 32]" = torch.ops.aten.permute.default(view_1602, [1, 0]);  view_1602 = None
        permute_458: "f32[11, 32]" = torch.ops.aten.permute.default(view_1600, [1, 0]);  view_1600 = None
        permute_459: "f32[16, 32]" = torch.ops.aten.permute.default(view_1598, [1, 0]);  view_1598 = None
        permute_460: "f32[11, 32]" = torch.ops.aten.permute.default(view_1596, [1, 0]);  view_1596 = None
        permute_461: "f32[16, 32]" = torch.ops.aten.permute.default(view_1594, [1, 0]);  view_1594 = None
        permute_462: "f32[11, 32]" = torch.ops.aten.permute.default(view_1592, [1, 0]);  view_1592 = None
        permute_463: "f32[16, 32]" = torch.ops.aten.permute.default(view_1590, [1, 0]);  view_1590 = None
        permute_464: "f32[11, 32]" = torch.ops.aten.permute.default(view_1588, [1, 0]);  view_1588 = None
        permute_465: "f32[16, 32]" = torch.ops.aten.permute.default(view_1586, [1, 0]);  view_1586 = None
        permute_466: "f32[11, 32]" = torch.ops.aten.permute.default(view_1584, [1, 0]);  view_1584 = None
        permute_467: "f32[16, 32]" = torch.ops.aten.permute.default(view_1582, [1, 0]);  view_1582 = None
        permute_468: "f32[11, 32]" = torch.ops.aten.permute.default(view_1580, [1, 0]);  view_1580 = None
        permute_469: "f32[16, 32]" = torch.ops.aten.permute.default(view_1578, [1, 0]);  view_1578 = None
        permute_470: "f32[11, 32]" = torch.ops.aten.permute.default(view_1576, [1, 0]);  view_1576 = None
        permute_471: "f32[16, 32]" = torch.ops.aten.permute.default(view_1574, [1, 0]);  view_1574 = None
        permute_472: "f32[11, 32]" = torch.ops.aten.permute.default(view_1572, [1, 0]);  view_1572 = None
        permute_473: "f32[16, 32]" = torch.ops.aten.permute.default(view_1570, [1, 0]);  view_1570 = None
        permute_474: "f32[11, 32]" = torch.ops.aten.permute.default(view_1568, [1, 0]);  view_1568 = None
        permute_475: "f32[16, 32]" = torch.ops.aten.permute.default(view_1566, [1, 0]);  view_1566 = None
        permute_476: "f32[11, 32]" = torch.ops.aten.permute.default(view_1564, [1, 0]);  view_1564 = None
        permute_477: "f32[16, 32]" = torch.ops.aten.permute.default(view_1562, [1, 0]);  view_1562 = None
        permute_478: "f32[11, 32]" = torch.ops.aten.permute.default(view_1560, [1, 0]);  view_1560 = None
        permute_479: "f32[16, 32]" = torch.ops.aten.permute.default(view_1558, [1, 0]);  view_1558 = None
        permute_480: "f32[11, 32]" = torch.ops.aten.permute.default(view_1556, [1, 0]);  view_1556 = None
        permute_481: "f32[16, 32]" = torch.ops.aten.permute.default(view_1554, [1, 0]);  view_1554 = None
        permute_482: "f32[11, 32]" = torch.ops.aten.permute.default(view_1552, [1, 0]);  view_1552 = None
        permute_483: "f32[16, 32]" = torch.ops.aten.permute.default(view_1550, [1, 0]);  view_1550 = None
        permute_484: "f32[11, 32]" = torch.ops.aten.permute.default(view_1548, [1, 0]);  view_1548 = None
        permute_485: "f32[16, 32]" = torch.ops.aten.permute.default(view_1546, [1, 0]);  view_1546 = None
        permute_486: "f32[11, 32]" = torch.ops.aten.permute.default(view_1544, [1, 0]);  view_1544 = None
        permute_487: "f32[16, 32]" = torch.ops.aten.permute.default(view_1542, [1, 0]);  view_1542 = None
        permute_488: "f32[11, 32]" = torch.ops.aten.permute.default(view_1540, [1, 0]);  view_1540 = None
        permute_489: "f32[16, 32]" = torch.ops.aten.permute.default(view_1538, [1, 0]);  view_1538 = None
        permute_490: "f32[11, 32]" = torch.ops.aten.permute.default(view_1536, [1, 0]);  view_1536 = None
        permute_491: "f32[16, 32]" = torch.ops.aten.permute.default(view_1534, [1, 0]);  view_1534 = None
        permute_492: "f32[11, 32]" = torch.ops.aten.permute.default(view_1532, [1, 0]);  view_1532 = None
        permute_493: "f32[16, 32]" = torch.ops.aten.permute.default(view_1530, [1, 0]);  view_1530 = None
        permute_494: "f32[11, 32]" = torch.ops.aten.permute.default(view_1528, [1, 0]);  view_1528 = None
        permute_495: "f32[16, 32]" = torch.ops.aten.permute.default(view_1526, [1, 0]);  view_1526 = None
        permute_496: "f32[11, 32]" = torch.ops.aten.permute.default(view_1524, [1, 0]);  view_1524 = None
        permute_497: "f32[16, 32]" = torch.ops.aten.permute.default(view_1522, [1, 0]);  view_1522 = None
        permute_498: "f32[11, 32]" = torch.ops.aten.permute.default(view_1520, [1, 0]);  view_1520 = None
        permute_499: "f32[16, 32]" = torch.ops.aten.permute.default(view_1518, [1, 0]);  view_1518 = None
        permute_500: "f32[11, 32]" = torch.ops.aten.permute.default(view_1516, [1, 0]);  view_1516 = None
        permute_501: "f32[16, 32]" = torch.ops.aten.permute.default(view_1514, [1, 0]);  view_1514 = None
        permute_502: "f32[11, 32]" = torch.ops.aten.permute.default(view_1512, [1, 0]);  view_1512 = None
        permute_503: "f32[16, 32]" = torch.ops.aten.permute.default(view_1510, [1, 0]);  view_1510 = None
        permute_504: "f32[11, 32]" = torch.ops.aten.permute.default(view_1508, [1, 0]);  view_1508 = None
        permute_505: "f32[16, 32]" = torch.ops.aten.permute.default(view_1506, [1, 0]);  view_1506 = None
        permute_506: "f32[11, 32]" = torch.ops.aten.permute.default(view_1504, [1, 0]);  view_1504 = None
        permute_507: "f32[16, 32]" = torch.ops.aten.permute.default(view_1502, [1, 0]);  view_1502 = None
        permute_508: "f32[11, 32]" = torch.ops.aten.permute.default(view_1500, [1, 0]);  view_1500 = None
        permute_509: "f32[16, 32]" = torch.ops.aten.permute.default(view_1498, [1, 0]);  view_1498 = None
        permute_510: "f32[11, 32]" = torch.ops.aten.permute.default(view_1496, [1, 0]);  view_1496 = None
        permute_511: "f32[16, 32]" = torch.ops.aten.permute.default(view_1494, [1, 0]);  view_1494 = None
        permute_512: "f32[11, 32]" = torch.ops.aten.permute.default(view_1492, [1, 0]);  view_1492 = None
        permute_513: "f32[16, 32]" = torch.ops.aten.permute.default(view_1490, [1, 0]);  view_1490 = None
        permute_514: "f32[11, 32]" = torch.ops.aten.permute.default(view_1488, [1, 0]);  view_1488 = None
        permute_515: "f32[16, 32]" = torch.ops.aten.permute.default(view_1486, [1, 0]);  view_1486 = None
        permute_516: "f32[11, 32]" = torch.ops.aten.permute.default(view_1484, [1, 0]);  view_1484 = None
        permute_517: "f32[16, 32]" = torch.ops.aten.permute.default(view_1482, [1, 0]);  view_1482 = None
        permute_518: "f32[11, 32]" = torch.ops.aten.permute.default(view_1480, [1, 0]);  view_1480 = None
        permute_519: "f32[16, 32]" = torch.ops.aten.permute.default(view_1478, [1, 0]);  view_1478 = None
        permute_520: "f32[11, 32]" = torch.ops.aten.permute.default(view_1476, [1, 0]);  view_1476 = None
        permute_521: "f32[16, 32]" = torch.ops.aten.permute.default(view_1474, [1, 0]);  view_1474 = None
        permute_522: "f32[11, 32]" = torch.ops.aten.permute.default(view_1472, [1, 0]);  view_1472 = None
        permute_523: "f32[16, 32]" = torch.ops.aten.permute.default(view_1470, [1, 0]);  view_1470 = None
        permute_524: "f32[11, 32]" = torch.ops.aten.permute.default(view_1468, [1, 0]);  view_1468 = None
        permute_525: "f32[16, 32]" = torch.ops.aten.permute.default(view_1466, [1, 0]);  view_1466 = None
        permute_526: "f32[11, 32]" = torch.ops.aten.permute.default(view_1464, [1, 0]);  view_1464 = None
        permute_527: "f32[16, 32]" = torch.ops.aten.permute.default(view_1462, [1, 0]);  view_1462 = None
        permute_528: "f32[11, 32]" = torch.ops.aten.permute.default(view_1460, [1, 0]);  view_1460 = None
        permute_529: "f32[16, 32]" = torch.ops.aten.permute.default(view_1458, [1, 0]);  view_1458 = None
        permute_530: "f32[11, 32]" = torch.ops.aten.permute.default(view_1456, [1, 0]);  view_1456 = None
        permute_531: "f32[16, 32]" = torch.ops.aten.permute.default(view_1454, [1, 0]);  view_1454 = None
        permute_532: "f32[11, 32]" = torch.ops.aten.permute.default(view_1452, [1, 0]);  view_1452 = None
        permute_533: "f32[16, 32]" = torch.ops.aten.permute.default(view_1450, [1, 0]);  view_1450 = None
        permute_534: "f32[11, 32]" = torch.ops.aten.permute.default(view_1448, [1, 0]);  view_1448 = None
        permute_535: "f32[16, 32]" = torch.ops.aten.permute.default(view_1446, [1, 0]);  view_1446 = None
        permute_536: "f32[11, 32]" = torch.ops.aten.permute.default(view_1444, [1, 0]);  view_1444 = None
        permute_537: "f32[16, 32]" = torch.ops.aten.permute.default(view_1442, [1, 0]);  view_1442 = None
        permute_538: "f32[11, 32]" = torch.ops.aten.permute.default(view_1440, [1, 0]);  view_1440 = None
        permute_539: "f32[16, 32]" = torch.ops.aten.permute.default(view_1438, [1, 0]);  view_1438 = None
        permute_540: "f32[11, 32]" = torch.ops.aten.permute.default(view_1436, [1, 0]);  view_1436 = None
        permute_541: "f32[16, 32]" = torch.ops.aten.permute.default(view_1434, [1, 0]);  view_1434 = None
        permute_542: "f32[11, 32]" = torch.ops.aten.permute.default(view_1432, [1, 0]);  view_1432 = None
        permute_543: "f32[16, 32]" = torch.ops.aten.permute.default(view_1430, [1, 0]);  view_1430 = None
        permute_544: "f32[11, 32]" = torch.ops.aten.permute.default(view_1428, [1, 0]);  view_1428 = None
        permute_545: "f32[16, 32]" = torch.ops.aten.permute.default(view_1426, [1, 0]);  view_1426 = None
        permute_546: "f32[11, 32]" = torch.ops.aten.permute.default(view_1424, [1, 0]);  view_1424 = None
        permute_547: "f32[16, 32]" = torch.ops.aten.permute.default(view_1422, [1, 0]);  view_1422 = None
        permute_548: "f32[11, 32]" = torch.ops.aten.permute.default(view_1420, [1, 0]);  view_1420 = None
        permute_549: "f32[16, 32]" = torch.ops.aten.permute.default(view_1418, [1, 0]);  view_1418 = None
        permute_550: "f32[11, 32]" = torch.ops.aten.permute.default(view_1416, [1, 0]);  view_1416 = None
        permute_551: "f32[16, 32]" = torch.ops.aten.permute.default(view_1414, [1, 0]);  view_1414 = None
        permute_552: "f32[11, 32]" = torch.ops.aten.permute.default(view_1412, [1, 0]);  view_1412 = None
        permute_553: "f32[16, 32]" = torch.ops.aten.permute.default(view_1410, [1, 0]);  view_1410 = None
        permute_554: "f32[11, 32]" = torch.ops.aten.permute.default(view_1408, [1, 0]);  view_1408 = None
        permute_555: "f32[16, 32]" = torch.ops.aten.permute.default(view_1406, [1, 0]);  view_1406 = None
        permute_556: "f32[11, 32]" = torch.ops.aten.permute.default(view_1404, [1, 0]);  view_1404 = None
        permute_557: "f32[16, 32]" = torch.ops.aten.permute.default(view_1402, [1, 0]);  view_1402 = None
        permute_558: "f32[11, 32]" = torch.ops.aten.permute.default(view_1400, [1, 0]);  view_1400 = None
        permute_559: "f32[16, 32]" = torch.ops.aten.permute.default(view_1398, [1, 0]);  view_1398 = None
        permute_560: "f32[11, 32]" = torch.ops.aten.permute.default(view_1396, [1, 0]);  view_1396 = None
        permute_561: "f32[16, 32]" = torch.ops.aten.permute.default(view_1394, [1, 0]);  view_1394 = None
        permute_562: "f32[11, 32]" = torch.ops.aten.permute.default(view_1392, [1, 0]);  view_1392 = None
        permute_563: "f32[16, 32]" = torch.ops.aten.permute.default(view_1390, [1, 0]);  view_1390 = None
        permute_564: "f32[11, 32]" = torch.ops.aten.permute.default(view_1388, [1, 0]);  view_1388 = None
        permute_565: "f32[16, 32]" = torch.ops.aten.permute.default(view_1386, [1, 0]);  view_1386 = None
        permute_566: "f32[11, 32]" = torch.ops.aten.permute.default(view_1384, [1, 0]);  view_1384 = None
        permute_567: "f32[16, 32]" = torch.ops.aten.permute.default(view_1382, [1, 0]);  view_1382 = None
        permute_568: "f32[11, 32]" = torch.ops.aten.permute.default(view_1380, [1, 0]);  view_1380 = None
        permute_569: "f32[16, 32]" = torch.ops.aten.permute.default(view_1378, [1, 0]);  view_1378 = None
        permute_570: "f32[11, 32]" = torch.ops.aten.permute.default(view_1376, [1, 0]);  view_1376 = None
        permute_571: "f32[16, 32]" = torch.ops.aten.permute.default(view_1374, [1, 0]);  view_1374 = None
        permute_572: "f32[11, 32]" = torch.ops.aten.permute.default(view_1372, [1, 0]);  view_1372 = None
        permute_573: "f32[16, 32]" = torch.ops.aten.permute.default(view_1370, [1, 0]);  view_1370 = None
        permute_574: "f32[11, 32]" = torch.ops.aten.permute.default(view_1368, [1, 0]);  view_1368 = None
        permute_575: "f32[16, 32]" = torch.ops.aten.permute.default(view_1366, [1, 0]);  view_1366 = None
        permute_576: "f32[11, 32]" = torch.ops.aten.permute.default(view_1364, [1, 0]);  view_1364 = None
        permute_577: "f32[16, 32]" = torch.ops.aten.permute.default(view_1362, [1, 0]);  view_1362 = None
        permute_578: "f32[11, 32]" = torch.ops.aten.permute.default(view_1360, [1, 0]);  view_1360 = None
        permute_579: "f32[16, 32]" = torch.ops.aten.permute.default(view_1358, [1, 0]);  view_1358 = None
        permute_580: "f32[11, 32]" = torch.ops.aten.permute.default(view_1356, [1, 0]);  view_1356 = None
        permute_581: "f32[16, 32]" = torch.ops.aten.permute.default(view_1354, [1, 0]);  view_1354 = None
        permute_582: "f32[11, 32]" = torch.ops.aten.permute.default(view_1352, [1, 0]);  view_1352 = None
        permute_583: "f32[16, 32]" = torch.ops.aten.permute.default(view_1350, [1, 0]);  view_1350 = None
        permute_584: "f32[11, 32]" = torch.ops.aten.permute.default(view_1348, [1, 0]);  view_1348 = None
        permute_585: "f32[16, 32]" = torch.ops.aten.permute.default(view_1346, [1, 0]);  view_1346 = None
        permute_586: "f32[11, 32]" = torch.ops.aten.permute.default(view_1344, [1, 0]);  view_1344 = None
        permute_587: "f32[16, 32]" = torch.ops.aten.permute.default(view_1342, [1, 0]);  view_1342 = None
        permute_588: "f32[11, 32]" = torch.ops.aten.permute.default(view_1340, [1, 0]);  view_1340 = None
        permute_589: "f32[16, 32]" = torch.ops.aten.permute.default(view_1338, [1, 0]);  view_1338 = None
        permute_590: "f32[11, 32]" = torch.ops.aten.permute.default(view_1336, [1, 0]);  view_1336 = None
        permute_591: "f32[16, 32]" = torch.ops.aten.permute.default(view_1334, [1, 0]);  view_1334 = None
        permute_592: "f32[11, 32]" = torch.ops.aten.permute.default(view_1332, [1, 0]);  view_1332 = None
        permute_593: "f32[16, 32]" = torch.ops.aten.permute.default(view_1330, [1, 0]);  view_1330 = None
        permute_594: "f32[11, 32]" = torch.ops.aten.permute.default(view_1328, [1, 0]);  view_1328 = None
        permute_595: "f32[16, 32]" = torch.ops.aten.permute.default(view_1326, [1, 0]);  view_1326 = None
        permute_596: "f32[11, 32]" = torch.ops.aten.permute.default(view_1324, [1, 0]);  view_1324 = None
        permute_597: "f32[16, 32]" = torch.ops.aten.permute.default(view_1322, [1, 0]);  view_1322 = None
        permute_598: "f32[11, 32]" = torch.ops.aten.permute.default(view_1320, [1, 0]);  view_1320 = None
        permute_599: "f32[16, 32]" = torch.ops.aten.permute.default(view_1318, [1, 0]);  view_1318 = None
        permute_600: "f32[11, 32]" = torch.ops.aten.permute.default(view_1316, [1, 0]);  view_1316 = None
        permute_601: "f32[16, 32]" = torch.ops.aten.permute.default(view_1314, [1, 0]);  view_1314 = None
        permute_602: "f32[11, 32]" = torch.ops.aten.permute.default(view_1312, [1, 0]);  view_1312 = None
        permute_603: "f32[16, 32]" = torch.ops.aten.permute.default(view_1310, [1, 0]);  view_1310 = None
        permute_604: "f32[11, 32]" = torch.ops.aten.permute.default(view_1308, [1, 0]);  view_1308 = None
        permute_605: "f32[16, 32]" = torch.ops.aten.permute.default(view_1306, [1, 0]);  view_1306 = None
        permute_606: "f32[11, 32]" = torch.ops.aten.permute.default(view_1304, [1, 0]);  view_1304 = None
        permute_607: "f32[16, 32]" = torch.ops.aten.permute.default(view_1302, [1, 0]);  view_1302 = None
        permute_608: "f32[11, 32]" = torch.ops.aten.permute.default(view_1300, [1, 0]);  view_1300 = None
        permute_609: "f32[16, 32]" = torch.ops.aten.permute.default(view_1298, [1, 0]);  view_1298 = None
        permute_610: "f32[11, 32]" = torch.ops.aten.permute.default(view_1296, [1, 0]);  view_1296 = None
        permute_611: "f32[16, 32]" = torch.ops.aten.permute.default(view_1294, [1, 0]);  view_1294 = None
        permute_612: "f32[11, 32]" = torch.ops.aten.permute.default(view_1292, [1, 0]);  view_1292 = None
        permute_613: "f32[16, 32]" = torch.ops.aten.permute.default(view_1290, [1, 0]);  view_1290 = None
        permute_614: "f32[11, 32]" = torch.ops.aten.permute.default(view_1288, [1, 0]);  view_1288 = None
        permute_615: "f32[16, 32]" = torch.ops.aten.permute.default(view_1286, [1, 0]);  view_1286 = None
        permute_616: "f32[11, 32]" = torch.ops.aten.permute.default(view_1284, [1, 0]);  view_1284 = None
        permute_617: "f32[16, 32]" = torch.ops.aten.permute.default(view_1282, [1, 0]);  view_1282 = None
        permute_618: "f32[11, 32]" = torch.ops.aten.permute.default(view_1280, [1, 0]);  view_1280 = None
        permute_619: "f32[16, 32]" = torch.ops.aten.permute.default(view_1278, [1, 0]);  view_1278 = None
        permute_620: "f32[11, 32]" = torch.ops.aten.permute.default(view_1276, [1, 0]);  view_1276 = None
        permute_621: "f32[16, 32]" = torch.ops.aten.permute.default(view_1274, [1, 0]);  view_1274 = None
        permute_622: "f32[11, 32]" = torch.ops.aten.permute.default(view_1272, [1, 0]);  view_1272 = None
        permute_623: "f32[16, 32]" = torch.ops.aten.permute.default(view_1270, [1, 0]);  view_1270 = None
        permute_624: "f32[11, 32]" = torch.ops.aten.permute.default(view_1268, [1, 0]);  view_1268 = None
        permute_625: "f32[16, 32]" = torch.ops.aten.permute.default(view_1266, [1, 0]);  view_1266 = None
        permute_626: "f32[11, 32]" = torch.ops.aten.permute.default(view_1264, [1, 0]);  view_1264 = None
        permute_627: "f32[16, 32]" = torch.ops.aten.permute.default(view_1262, [1, 0]);  view_1262 = None
        permute_628: "f32[11, 32]" = torch.ops.aten.permute.default(view_1260, [1, 0]);  view_1260 = None
        permute_629: "f32[16, 32]" = torch.ops.aten.permute.default(view_1258, [1, 0]);  view_1258 = None
        permute_630: "f32[11, 32]" = torch.ops.aten.permute.default(view_1256, [1, 0]);  view_1256 = None
        permute_631: "f32[16, 32]" = torch.ops.aten.permute.default(view_1254, [1, 0]);  view_1254 = None
        permute_632: "f32[11, 32]" = torch.ops.aten.permute.default(view_1252, [1, 0]);  view_1252 = None
        permute_633: "f32[16, 32]" = torch.ops.aten.permute.default(view_1250, [1, 0]);  view_1250 = None
        permute_634: "f32[11, 32]" = torch.ops.aten.permute.default(view_1248, [1, 0]);  view_1248 = None
        permute_635: "f32[16, 32]" = torch.ops.aten.permute.default(view_1246, [1, 0]);  view_1246 = None
        permute_636: "f32[11, 32]" = torch.ops.aten.permute.default(view_1244, [1, 0]);  view_1244 = None
        permute_637: "f32[16, 32]" = torch.ops.aten.permute.default(view_1242, [1, 0]);  view_1242 = None
        permute_638: "f32[11, 32]" = torch.ops.aten.permute.default(view_1240, [1, 0]);  view_1240 = None
        permute_639: "f32[16, 32]" = torch.ops.aten.permute.default(view_1238, [1, 0]);  view_1238 = None
        permute_640: "f32[11, 32]" = torch.ops.aten.permute.default(view_1236, [1, 0]);  view_1236 = None
        permute_641: "f32[16, 32]" = torch.ops.aten.permute.default(view_1234, [1, 0]);  view_1234 = None
        permute_642: "f32[11, 32]" = torch.ops.aten.permute.default(view_1232, [1, 0]);  view_1232 = None
        permute_643: "f32[16, 32]" = torch.ops.aten.permute.default(view_1230, [1, 0]);  view_1230 = None
        permute_644: "f32[11, 32]" = torch.ops.aten.permute.default(view_1228, [1, 0]);  view_1228 = None
        permute_645: "f32[16, 32]" = torch.ops.aten.permute.default(view_1226, [1, 0]);  view_1226 = None
        permute_646: "f32[11, 32]" = torch.ops.aten.permute.default(view_1224, [1, 0]);  view_1224 = None
        permute_647: "f32[16, 32]" = torch.ops.aten.permute.default(view_1222, [1, 0]);  view_1222 = None
        permute_648: "f32[11, 32]" = torch.ops.aten.permute.default(view_1220, [1, 0]);  view_1220 = None
        permute_649: "f32[16, 32]" = torch.ops.aten.permute.default(view_1218, [1, 0]);  view_1218 = None
        permute_650: "f32[11, 32]" = torch.ops.aten.permute.default(view_1216, [1, 0]);  view_1216 = None
        permute_651: "f32[16, 32]" = torch.ops.aten.permute.default(view_1214, [1, 0]);  view_1214 = None
        permute_652: "f32[11, 32]" = torch.ops.aten.permute.default(view_1212, [1, 0]);  view_1212 = None
        permute_653: "f32[16, 32]" = torch.ops.aten.permute.default(view_1210, [1, 0]);  view_1210 = None
        permute_654: "f32[11, 32]" = torch.ops.aten.permute.default(view_1208, [1, 0]);  view_1208 = None
        permute_655: "f32[16, 32]" = torch.ops.aten.permute.default(view_1206, [1, 0]);  view_1206 = None
        permute_656: "f32[11, 32]" = torch.ops.aten.permute.default(view_1204, [1, 0]);  view_1204 = None
        permute_657: "f32[16, 32]" = torch.ops.aten.permute.default(view_1202, [1, 0]);  view_1202 = None
        permute_658: "f32[11, 32]" = torch.ops.aten.permute.default(view_1200, [1, 0]);  view_1200 = None
        permute_659: "f32[16, 32]" = torch.ops.aten.permute.default(view_1198, [1, 0]);  view_1198 = None
        permute_660: "f32[11, 32]" = torch.ops.aten.permute.default(view_1196, [1, 0]);  view_1196 = None
        permute_661: "f32[16, 32]" = torch.ops.aten.permute.default(view_1194, [1, 0]);  view_1194 = None
        permute_662: "f32[11, 32]" = torch.ops.aten.permute.default(view_1192, [1, 0]);  view_1192 = None
        permute_663: "f32[16, 32]" = torch.ops.aten.permute.default(view_1190, [1, 0]);  view_1190 = None
        permute_664: "f32[11, 32]" = torch.ops.aten.permute.default(view_1188, [1, 0]);  view_1188 = None
        permute_665: "f32[16, 32]" = torch.ops.aten.permute.default(view_1186, [1, 0]);  view_1186 = None
        permute_666: "f32[11, 32]" = torch.ops.aten.permute.default(view_1184, [1, 0]);  view_1184 = None
        permute_667: "f32[16, 32]" = torch.ops.aten.permute.default(view_1182, [1, 0]);  view_1182 = None
        permute_668: "f32[11, 32]" = torch.ops.aten.permute.default(view_1180, [1, 0]);  view_1180 = None
        permute_669: "f32[16, 32]" = torch.ops.aten.permute.default(view_1178, [1, 0]);  view_1178 = None
        permute_670: "f32[11, 32]" = torch.ops.aten.permute.default(view_1176, [1, 0]);  view_1176 = None
        permute_671: "f32[16, 32]" = torch.ops.aten.permute.default(view_1174, [1, 0]);  view_1174 = None
        permute_672: "f32[11, 32]" = torch.ops.aten.permute.default(view_1172, [1, 0]);  view_1172 = None
        permute_673: "f32[16, 32]" = torch.ops.aten.permute.default(view_1170, [1, 0]);  view_1170 = None
        permute_674: "f32[11, 32]" = torch.ops.aten.permute.default(view_1168, [1, 0]);  view_1168 = None
        permute_675: "f32[16, 32]" = torch.ops.aten.permute.default(view_1166, [1, 0]);  view_1166 = None
        permute_676: "f32[11, 32]" = torch.ops.aten.permute.default(view_1164, [1, 0]);  view_1164 = None
        permute_677: "f32[16, 32]" = torch.ops.aten.permute.default(view_1162, [1, 0]);  view_1162 = None
        permute_678: "f32[11, 32]" = torch.ops.aten.permute.default(view_1160, [1, 0]);  view_1160 = None
        permute_679: "f32[16, 32]" = torch.ops.aten.permute.default(view_1158, [1, 0]);  view_1158 = None
        permute_680: "f32[11, 32]" = torch.ops.aten.permute.default(view_1156, [1, 0]);  view_1156 = None
        permute_681: "f32[16, 32]" = torch.ops.aten.permute.default(view_1154, [1, 0]);  view_1154 = None
        permute_682: "f32[11, 32]" = torch.ops.aten.permute.default(view_1152, [1, 0]);  view_1152 = None
        permute_683: "f32[16, 32]" = torch.ops.aten.permute.default(view_1150, [1, 0]);  view_1150 = None
        permute_684: "f32[11, 32]" = torch.ops.aten.permute.default(view_1148, [1, 0]);  view_1148 = None
        permute_685: "f32[16, 32]" = torch.ops.aten.permute.default(view_1146, [1, 0]);  view_1146 = None
        permute_686: "f32[11, 32]" = torch.ops.aten.permute.default(view_1144, [1, 0]);  view_1144 = None
        permute_687: "f32[16, 32]" = torch.ops.aten.permute.default(view_1142, [1, 0]);  view_1142 = None
        permute_688: "f32[11, 32]" = torch.ops.aten.permute.default(view_1140, [1, 0]);  view_1140 = None
        permute_689: "f32[16, 32]" = torch.ops.aten.permute.default(view_1138, [1, 0]);  view_1138 = None
        permute_690: "f32[11, 32]" = torch.ops.aten.permute.default(view_1136, [1, 0]);  view_1136 = None
        permute_691: "f32[16, 32]" = torch.ops.aten.permute.default(view_1134, [1, 0]);  view_1134 = None
        permute_692: "f32[11, 32]" = torch.ops.aten.permute.default(view_1132, [1, 0]);  view_1132 = None
        permute_693: "f32[16, 32]" = torch.ops.aten.permute.default(view_1130, [1, 0]);  view_1130 = None
        permute_694: "f32[11, 32]" = torch.ops.aten.permute.default(view_1128, [1, 0]);  view_1128 = None
        permute_695: "f32[16, 32]" = torch.ops.aten.permute.default(view_1126, [1, 0]);  view_1126 = None
        permute_696: "f32[11, 32]" = torch.ops.aten.permute.default(view_1124, [1, 0]);  view_1124 = None
        permute_697: "f32[16, 32]" = torch.ops.aten.permute.default(view_1122, [1, 0]);  view_1122 = None
        permute_698: "f32[11, 32]" = torch.ops.aten.permute.default(view_1120, [1, 0]);  view_1120 = None
        permute_699: "f32[16, 32]" = torch.ops.aten.permute.default(view_1118, [1, 0]);  view_1118 = None
        permute_700: "f32[11, 32]" = torch.ops.aten.permute.default(view_1116, [1, 0]);  view_1116 = None
        permute_701: "f32[16, 32]" = torch.ops.aten.permute.default(view_1114, [1, 0]);  view_1114 = None
        permute_702: "f32[11, 32]" = torch.ops.aten.permute.default(view_1112, [1, 0]);  view_1112 = None
        permute_703: "f32[16, 32]" = torch.ops.aten.permute.default(view_1110, [1, 0]);  view_1110 = None
        permute_704: "f32[11, 32]" = torch.ops.aten.permute.default(view_1108, [1, 0]);  view_1108 = None
        permute_705: "f32[16, 32]" = torch.ops.aten.permute.default(view_1106, [1, 0]);  view_1106 = None
        permute_706: "f32[11, 32]" = torch.ops.aten.permute.default(view_1104, [1, 0]);  view_1104 = None
        permute_707: "f32[16, 32]" = torch.ops.aten.permute.default(view_1102, [1, 0]);  view_1102 = None
        permute_708: "f32[11, 32]" = torch.ops.aten.permute.default(view_1100, [1, 0]);  view_1100 = None
        permute_709: "f32[16, 32]" = torch.ops.aten.permute.default(view_1098, [1, 0]);  view_1098 = None
        permute_710: "f32[11, 32]" = torch.ops.aten.permute.default(view_1096, [1, 0]);  view_1096 = None
        permute_711: "f32[16, 32]" = torch.ops.aten.permute.default(view_1094, [1, 0]);  view_1094 = None
        permute_712: "f32[11, 32]" = torch.ops.aten.permute.default(view_1092, [1, 0]);  view_1092 = None
        permute_713: "f32[16, 32]" = torch.ops.aten.permute.default(view_1090, [1, 0]);  view_1090 = None
        permute_714: "f32[11, 32]" = torch.ops.aten.permute.default(view_1088, [1, 0]);  view_1088 = None
        permute_715: "f32[16, 32]" = torch.ops.aten.permute.default(view_1086, [1, 0]);  view_1086 = None
        permute_716: "f32[11, 32]" = torch.ops.aten.permute.default(view_1084, [1, 0]);  view_1084 = None
        permute_717: "f32[16, 32]" = torch.ops.aten.permute.default(view_1082, [1, 0]);  view_1082 = None
        permute_718: "f32[11, 32]" = torch.ops.aten.permute.default(view_1080, [1, 0]);  view_1080 = None
        permute_719: "f32[16, 32]" = torch.ops.aten.permute.default(view_1078, [1, 0]);  view_1078 = None
        permute_720: "f32[11, 32]" = torch.ops.aten.permute.default(view_1076, [1, 0]);  view_1076 = None
        permute_721: "f32[16, 32]" = torch.ops.aten.permute.default(view_1074, [1, 0]);  view_1074 = None
        permute_722: "f32[11, 32]" = torch.ops.aten.permute.default(view_1072, [1, 0]);  view_1072 = None
        permute_723: "f32[16, 32]" = torch.ops.aten.permute.default(view_1070, [1, 0]);  view_1070 = None
        permute_724: "f32[11, 32]" = torch.ops.aten.permute.default(view_1068, [1, 0]);  view_1068 = None
        permute_725: "f32[16, 32]" = torch.ops.aten.permute.default(view_1066, [1, 0]);  view_1066 = None
        permute_726: "f32[11, 32]" = torch.ops.aten.permute.default(view_1064, [1, 0]);  view_1064 = None
        permute_727: "f32[16, 32]" = torch.ops.aten.permute.default(view_1062, [1, 0]);  view_1062 = None
        permute_728: "f32[11, 32]" = torch.ops.aten.permute.default(view_1060, [1, 0]);  view_1060 = None
        permute_729: "f32[16, 32]" = torch.ops.aten.permute.default(view_1058, [1, 0]);  view_1058 = None
        permute_730: "f32[11, 32]" = torch.ops.aten.permute.default(view_1056, [1, 0]);  view_1056 = None
        permute_731: "f32[16, 32]" = torch.ops.aten.permute.default(view_1054, [1, 0]);  view_1054 = None
        permute_732: "f32[11, 32]" = torch.ops.aten.permute.default(view_1052, [1, 0]);  view_1052 = None
        permute_733: "f32[16, 32]" = torch.ops.aten.permute.default(view_1050, [1, 0]);  view_1050 = None
        permute_734: "f32[11, 32]" = torch.ops.aten.permute.default(view_1048, [1, 0]);  view_1048 = None
        permute_735: "f32[16, 32]" = torch.ops.aten.permute.default(view_1046, [1, 0]);  view_1046 = None
        permute_736: "f32[11, 32]" = torch.ops.aten.permute.default(view_1044, [1, 0]);  view_1044 = None
        permute_737: "f32[16, 32]" = torch.ops.aten.permute.default(view_1042, [1, 0]);  view_1042 = None
        permute_738: "f32[11, 32]" = torch.ops.aten.permute.default(view_1040, [1, 0]);  view_1040 = None
        permute_739: "f32[16, 32]" = torch.ops.aten.permute.default(view_1038, [1, 0]);  view_1038 = None
        permute_740: "f32[11, 32]" = torch.ops.aten.permute.default(view_1036, [1, 0]);  view_1036 = None
        permute_741: "f32[16, 32]" = torch.ops.aten.permute.default(view_1034, [1, 0]);  view_1034 = None
        permute_742: "f32[11, 32]" = torch.ops.aten.permute.default(view_1032, [1, 0]);  view_1032 = None
        permute_743: "f32[16, 32]" = torch.ops.aten.permute.default(view_1030, [1, 0]);  view_1030 = None
        permute_744: "f32[11, 32]" = torch.ops.aten.permute.default(view_1028, [1, 0]);  view_1028 = None
        permute_745: "f32[16, 32]" = torch.ops.aten.permute.default(view_1026, [1, 0]);  view_1026 = None
        permute_746: "f32[11, 32]" = torch.ops.aten.permute.default(view_1024, [1, 0]);  view_1024 = None
        permute_747: "f32[16, 32]" = torch.ops.aten.permute.default(view_1022, [1, 0]);  view_1022 = None
        permute_748: "f32[11, 32]" = torch.ops.aten.permute.default(view_1020, [1, 0]);  view_1020 = None
        permute_749: "f32[16, 32]" = torch.ops.aten.permute.default(view_1018, [1, 0]);  view_1018 = None
        permute_750: "f32[11, 32]" = torch.ops.aten.permute.default(view_1016, [1, 0]);  view_1016 = None
        permute_751: "f32[16, 32]" = torch.ops.aten.permute.default(view_1014, [1, 0]);  view_1014 = None
        permute_752: "f32[11, 32]" = torch.ops.aten.permute.default(view_1012, [1, 0]);  view_1012 = None
        permute_753: "f32[16, 32]" = torch.ops.aten.permute.default(view_1010, [1, 0]);  view_1010 = None
        permute_754: "f32[11, 32]" = torch.ops.aten.permute.default(view_1008, [1, 0]);  view_1008 = None
        permute_755: "f32[16, 32]" = torch.ops.aten.permute.default(view_1006, [1, 0]);  view_1006 = None
        permute_756: "f32[11, 32]" = torch.ops.aten.permute.default(view_1004, [1, 0]);  view_1004 = None
        permute_757: "f32[16, 32]" = torch.ops.aten.permute.default(view_1002, [1, 0]);  view_1002 = None
        permute_758: "f32[11, 32]" = torch.ops.aten.permute.default(view_1000, [1, 0]);  view_1000 = None
        permute_759: "f32[16, 32]" = torch.ops.aten.permute.default(view_998, [1, 0]);  view_998 = None
        permute_760: "f32[11, 32]" = torch.ops.aten.permute.default(view_996, [1, 0]);  view_996 = None
        permute_761: "f32[16, 32]" = torch.ops.aten.permute.default(view_994, [1, 0]);  view_994 = None
        permute_762: "f32[11, 32]" = torch.ops.aten.permute.default(view_992, [1, 0]);  view_992 = None
        permute_763: "f32[16, 32]" = torch.ops.aten.permute.default(view_990, [1, 0]);  view_990 = None
        permute_764: "f32[11, 32]" = torch.ops.aten.permute.default(view_988, [1, 0]);  view_988 = None
        permute_765: "f32[16, 32]" = torch.ops.aten.permute.default(view_986, [1, 0]);  view_986 = None
        permute_766: "f32[11, 32]" = torch.ops.aten.permute.default(view_984, [1, 0]);  view_984 = None
        permute_767: "f32[16, 32]" = torch.ops.aten.permute.default(view_982, [1, 0]);  view_982 = None
        permute_768: "f32[11, 32]" = torch.ops.aten.permute.default(view_980, [1, 0]);  view_980 = None
        permute_769: "f32[16, 32]" = torch.ops.aten.permute.default(view_978, [1, 0]);  view_978 = None
        permute_770: "f32[11, 32]" = torch.ops.aten.permute.default(view_976, [1, 0]);  view_976 = None
        permute_771: "f32[16, 32]" = torch.ops.aten.permute.default(view_974, [1, 0]);  view_974 = None
        permute_772: "f32[11, 32]" = torch.ops.aten.permute.default(view_972, [1, 0]);  view_972 = None
        permute_773: "f32[16, 32]" = torch.ops.aten.permute.default(view_970, [1, 0]);  view_970 = None
        permute_774: "f32[11, 32]" = torch.ops.aten.permute.default(view_968, [1, 0]);  view_968 = None
        permute_775: "f32[16, 32]" = torch.ops.aten.permute.default(view_966, [1, 0]);  view_966 = None
        permute_776: "f32[11, 32]" = torch.ops.aten.permute.default(view_964, [1, 0]);  view_964 = None
        permute_777: "f32[16, 32]" = torch.ops.aten.permute.default(view_962, [1, 0]);  view_962 = None
        permute_778: "f32[11, 32]" = torch.ops.aten.permute.default(view_960, [1, 0]);  view_960 = None
        permute_779: "f32[16, 32]" = torch.ops.aten.permute.default(view_958, [1, 0]);  view_958 = None
        permute_780: "f32[11, 32]" = torch.ops.aten.permute.default(view_956, [1, 0]);  view_956 = None
        permute_781: "f32[16, 32]" = torch.ops.aten.permute.default(view_954, [1, 0]);  view_954 = None
        permute_782: "f32[11, 32]" = torch.ops.aten.permute.default(view_952, [1, 0]);  view_952 = None
        permute_783: "f32[16, 32]" = torch.ops.aten.permute.default(view_950, [1, 0]);  view_950 = None
        permute_784: "f32[11, 32]" = torch.ops.aten.permute.default(view_948, [1, 0]);  view_948 = None
        permute_785: "f32[16, 32]" = torch.ops.aten.permute.default(view_946, [1, 0]);  view_946 = None
        permute_786: "f32[11, 32]" = torch.ops.aten.permute.default(view_944, [1, 0]);  view_944 = None
        permute_787: "f32[16, 32]" = torch.ops.aten.permute.default(view_942, [1, 0]);  view_942 = None
        permute_788: "f32[11, 32]" = torch.ops.aten.permute.default(view_940, [1, 0]);  view_940 = None
        permute_789: "f32[16, 32]" = torch.ops.aten.permute.default(view_938, [1, 0]);  view_938 = None
        permute_790: "f32[11, 32]" = torch.ops.aten.permute.default(view_936, [1, 0]);  view_936 = None
        permute_791: "f32[16, 32]" = torch.ops.aten.permute.default(view_934, [1, 0]);  view_934 = None
        permute_792: "f32[11, 32]" = torch.ops.aten.permute.default(view_932, [1, 0]);  view_932 = None
        permute_793: "f32[16, 32]" = torch.ops.aten.permute.default(view_930, [1, 0]);  view_930 = None
        permute_794: "f32[11, 32]" = torch.ops.aten.permute.default(view_928, [1, 0]);  view_928 = None
        permute_795: "f32[16, 32]" = torch.ops.aten.permute.default(view_926, [1, 0]);  view_926 = None
        permute_796: "f32[11, 32]" = torch.ops.aten.permute.default(view_924, [1, 0]);  view_924 = None
        permute_797: "f32[16, 32]" = torch.ops.aten.permute.default(view_922, [1, 0]);  view_922 = None
        permute_798: "f32[11, 32]" = torch.ops.aten.permute.default(view_920, [1, 0]);  view_920 = None
        permute_799: "f32[16, 32]" = torch.ops.aten.permute.default(view_918, [1, 0]);  view_918 = None
        permute_800: "f32[11, 32]" = torch.ops.aten.permute.default(view_916, [1, 0]);  view_916 = None
        permute_801: "f32[16, 32]" = torch.ops.aten.permute.default(view_914, [1, 0]);  view_914 = None
        permute_802: "f32[11, 32]" = torch.ops.aten.permute.default(view_912, [1, 0]);  view_912 = None
        permute_803: "f32[16, 32]" = torch.ops.aten.permute.default(view_910, [1, 0]);  view_910 = None
        permute_804: "f32[11, 32]" = torch.ops.aten.permute.default(view_908, [1, 0]);  view_908 = None
        permute_805: "f32[16, 32]" = torch.ops.aten.permute.default(view_906, [1, 0]);  view_906 = None
        permute_806: "f32[11, 32]" = torch.ops.aten.permute.default(view_904, [1, 0]);  view_904 = None
        permute_807: "f32[16, 32]" = torch.ops.aten.permute.default(view_902, [1, 0]);  view_902 = None
        permute_808: "f32[11, 32]" = torch.ops.aten.permute.default(view_900, [1, 0]);  view_900 = None
        permute_809: "f32[16, 32]" = torch.ops.aten.permute.default(view_898, [1, 0]);  view_898 = None
        permute_810: "f32[11, 32]" = torch.ops.aten.permute.default(view_896, [1, 0]);  view_896 = None
        permute_811: "f32[16, 32]" = torch.ops.aten.permute.default(view_894, [1, 0]);  view_894 = None
        permute_812: "f32[11, 32]" = torch.ops.aten.permute.default(view_892, [1, 0]);  view_892 = None
        permute_813: "f32[16, 32]" = torch.ops.aten.permute.default(view_890, [1, 0]);  view_890 = None
        permute_814: "f32[11, 32]" = torch.ops.aten.permute.default(view_888, [1, 0]);  view_888 = None
        permute_815: "f32[16, 32]" = torch.ops.aten.permute.default(view_886, [1, 0]);  view_886 = None
        permute_816: "f32[11, 32]" = torch.ops.aten.permute.default(view_884, [1, 0]);  view_884 = None
        permute_817: "f32[16, 32]" = torch.ops.aten.permute.default(view_882, [1, 0]);  view_882 = None
        permute_818: "f32[11, 32]" = torch.ops.aten.permute.default(view_880, [1, 0]);  view_880 = None
        permute_819: "f32[16, 32]" = torch.ops.aten.permute.default(view_878, [1, 0]);  view_878 = None
        permute_820: "f32[11, 32]" = torch.ops.aten.permute.default(view_876, [1, 0]);  view_876 = None
        permute_821: "f32[16, 32]" = torch.ops.aten.permute.default(view_874, [1, 0]);  view_874 = None
        permute_822: "f32[11, 32]" = torch.ops.aten.permute.default(view_872, [1, 0]);  view_872 = None
        permute_823: "f32[16, 32]" = torch.ops.aten.permute.default(view_870, [1, 0]);  view_870 = None
        permute_824: "f32[11, 32]" = torch.ops.aten.permute.default(view_868, [1, 0]);  view_868 = None
        permute_825: "f32[16, 32]" = torch.ops.aten.permute.default(view_866, [1, 0]);  view_866 = None
        permute_826: "f32[11, 32]" = torch.ops.aten.permute.default(view_864, [1, 0]);  view_864 = None
        permute_827: "f32[16, 32]" = torch.ops.aten.permute.default(view_862, [1, 0]);  view_862 = None
        permute_828: "f32[11, 32]" = torch.ops.aten.permute.default(view_860, [1, 0]);  view_860 = None
        permute_829: "f32[16, 32]" = torch.ops.aten.permute.default(view_858, [1, 0]);  view_858 = None
        permute_830: "f32[11, 32]" = torch.ops.aten.permute.default(view_856, [1, 0]);  view_856 = None
        permute_831: "f32[16, 32]" = torch.ops.aten.permute.default(view_854, [1, 0]);  view_854 = None
        permute_832: "f32[11, 32]" = torch.ops.aten.permute.default(view_852, [1, 0]);  view_852 = None
        permute_833: "f32[16, 32]" = torch.ops.aten.permute.default(view_850, [1, 0]);  view_850 = None
        permute_834: "f32[11, 32]" = torch.ops.aten.permute.default(view_848, [1, 0]);  view_848 = None
        permute_835: "f32[16, 32]" = torch.ops.aten.permute.default(view_846, [1, 0]);  view_846 = None
        permute_836: "f32[11, 32]" = torch.ops.aten.permute.default(view_844, [1, 0]);  view_844 = None
        permute_837: "f32[16, 32]" = torch.ops.aten.permute.default(view_842, [1, 0]);  view_842 = None
        permute_838: "f32[11, 32]" = torch.ops.aten.permute.default(view_840, [1, 0]);  view_840 = None
        permute_839: "f32[16, 32]" = torch.ops.aten.permute.default(view_838, [1, 0]);  view_838 = None
        permute_840: "f32[11, 32]" = torch.ops.aten.permute.default(view_836, [1, 0]);  view_836 = None
        permute_841: "f32[16, 32]" = torch.ops.aten.permute.default(view_834, [1, 0]);  view_834 = None
        permute_842: "f32[11, 32]" = torch.ops.aten.permute.default(view_832, [1, 0]);  view_832 = None
        permute_843: "f32[16, 32]" = torch.ops.aten.permute.default(view_830, [1, 0]);  view_830 = None
        permute_844: "f32[11, 32]" = torch.ops.aten.permute.default(view_828, [1, 0]);  view_828 = None
        permute_845: "f32[16, 32]" = torch.ops.aten.permute.default(view_826, [1, 0]);  view_826 = None
        permute_846: "f32[11, 32]" = torch.ops.aten.permute.default(view_824, [1, 0]);  view_824 = None
        permute_847: "f32[16, 32]" = torch.ops.aten.permute.default(view_822, [1, 0]);  view_822 = None
        permute_848: "f32[11, 32]" = torch.ops.aten.permute.default(view_820, [1, 0]);  view_820 = None
        permute_849: "f32[16, 32]" = torch.ops.aten.permute.default(view_818, [1, 0]);  view_818 = None
        permute_850: "f32[11, 32]" = torch.ops.aten.permute.default(view_816, [1, 0]);  view_816 = None
        permute_851: "f32[16, 32]" = torch.ops.aten.permute.default(view_814, [1, 0]);  view_814 = None
        permute_852: "f32[11, 32]" = torch.ops.aten.permute.default(view_812, [1, 0]);  view_812 = None
        permute_853: "f32[16, 32]" = torch.ops.aten.permute.default(view_810, [1, 0]);  view_810 = None
        permute_854: "f32[11, 32]" = torch.ops.aten.permute.default(view_808, [1, 0]);  view_808 = None
        permute_855: "f32[16, 32]" = torch.ops.aten.permute.default(view_806, [1, 0]);  view_806 = None
        permute_856: "f32[11, 32]" = torch.ops.aten.permute.default(view_804, [1, 0]);  view_804 = None
        permute_857: "f32[16, 32]" = torch.ops.aten.permute.default(view_802, [1, 0]);  view_802 = None
        permute_858: "f32[11, 32]" = torch.ops.aten.permute.default(view_800, [1, 0]);  view_800 = None
        permute_859: "f32[16, 32]" = torch.ops.aten.permute.default(view_798, [1, 0]);  view_798 = None
        permute_860: "f32[11, 32]" = torch.ops.aten.permute.default(view_796, [1, 0]);  view_796 = None
        permute_861: "f32[16, 32]" = torch.ops.aten.permute.default(view_794, [1, 0]);  view_794 = None
        permute_862: "f32[11, 32]" = torch.ops.aten.permute.default(view_792, [1, 0]);  view_792 = None
        permute_863: "f32[16, 32]" = torch.ops.aten.permute.default(view_790, [1, 0]);  view_790 = None
        permute_864: "f32[11, 32]" = torch.ops.aten.permute.default(view_788, [1, 0]);  view_788 = None
        permute_865: "f32[16, 32]" = torch.ops.aten.permute.default(view_786, [1, 0]);  view_786 = None
        permute_866: "f32[11, 32]" = torch.ops.aten.permute.default(view_784, [1, 0]);  view_784 = None
        permute_867: "f32[16, 32]" = torch.ops.aten.permute.default(view_782, [1, 0]);  view_782 = None
        permute_868: "f32[11, 32]" = torch.ops.aten.permute.default(view_780, [1, 0]);  view_780 = None
        permute_869: "f32[16, 32]" = torch.ops.aten.permute.default(view_778, [1, 0]);  view_778 = None
        permute_870: "f32[11, 32]" = torch.ops.aten.permute.default(view_776, [1, 0]);  view_776 = None
        permute_871: "f32[16, 32]" = torch.ops.aten.permute.default(view_774, [1, 0]);  view_774 = None
        permute_872: "f32[11, 32]" = torch.ops.aten.permute.default(view_772, [1, 0]);  view_772 = None
        permute_873: "f32[16, 32]" = torch.ops.aten.permute.default(view_770, [1, 0]);  view_770 = None
        permute_874: "f32[11, 32]" = torch.ops.aten.permute.default(view_768, [1, 0]);  view_768 = None
        permute_875: "f32[16, 32]" = torch.ops.aten.permute.default(view_766, [1, 0]);  view_766 = None
        permute_876: "f32[11, 32]" = torch.ops.aten.permute.default(view_764, [1, 0]);  view_764 = None
        permute_877: "f32[16, 32]" = torch.ops.aten.permute.default(view_762, [1, 0]);  view_762 = None
        permute_878: "f32[11, 32]" = torch.ops.aten.permute.default(view_760, [1, 0]);  view_760 = None
        permute_879: "f32[16, 32]" = torch.ops.aten.permute.default(view_758, [1, 0]);  view_758 = None
        permute_880: "f32[11, 32]" = torch.ops.aten.permute.default(view_756, [1, 0]);  view_756 = None
        permute_881: "f32[16, 32]" = torch.ops.aten.permute.default(view_754, [1, 0]);  view_754 = None
        permute_882: "f32[11, 32]" = torch.ops.aten.permute.default(view_752, [1, 0]);  view_752 = None
        permute_883: "f32[16, 32]" = torch.ops.aten.permute.default(view_750, [1, 0]);  view_750 = None
        permute_884: "f32[11, 32]" = torch.ops.aten.permute.default(view_748, [1, 0]);  view_748 = None
        permute_885: "f32[16, 32]" = torch.ops.aten.permute.default(view_746, [1, 0]);  view_746 = None
        permute_886: "f32[11, 32]" = torch.ops.aten.permute.default(view_744, [1, 0]);  view_744 = None
        permute_887: "f32[16, 32]" = torch.ops.aten.permute.default(view_742, [1, 0]);  view_742 = None
        permute_888: "f32[11, 32]" = torch.ops.aten.permute.default(view_740, [1, 0]);  view_740 = None
        permute_889: "f32[16, 32]" = torch.ops.aten.permute.default(view_738, [1, 0]);  view_738 = None
        permute_890: "f32[11, 32]" = torch.ops.aten.permute.default(view_736, [1, 0]);  view_736 = None
        permute_891: "f32[16, 32]" = torch.ops.aten.permute.default(view_734, [1, 0]);  view_734 = None
        permute_892: "f32[11, 32]" = torch.ops.aten.permute.default(view_732, [1, 0]);  view_732 = None
        permute_893: "f32[16, 32]" = torch.ops.aten.permute.default(view_730, [1, 0]);  view_730 = None
        permute_894: "f32[11, 32]" = torch.ops.aten.permute.default(view_728, [1, 0]);  view_728 = None
        permute_895: "f32[16, 32]" = torch.ops.aten.permute.default(view_726, [1, 0]);  view_726 = None
        permute_896: "f32[11, 32]" = torch.ops.aten.permute.default(view_724, [1, 0]);  view_724 = None
        permute_897: "f32[16, 32]" = torch.ops.aten.permute.default(view_722, [1, 0]);  view_722 = None
        permute_898: "f32[11, 32]" = torch.ops.aten.permute.default(view_720, [1, 0]);  view_720 = None
        permute_899: "f32[16, 32]" = torch.ops.aten.permute.default(view_718, [1, 0]);  view_718 = None
        permute_900: "f32[11, 32]" = torch.ops.aten.permute.default(view_716, [1, 0]);  view_716 = None
        permute_901: "f32[16, 32]" = torch.ops.aten.permute.default(view_714, [1, 0]);  view_714 = None
        permute_902: "f32[11, 32]" = torch.ops.aten.permute.default(view_712, [1, 0]);  view_712 = None
        permute_903: "f32[16, 32]" = torch.ops.aten.permute.default(view_710, [1, 0]);  view_710 = None
        permute_904: "f32[11, 32]" = torch.ops.aten.permute.default(view_708, [1, 0]);  view_708 = None
        permute_905: "f32[16, 32]" = torch.ops.aten.permute.default(view_706, [1, 0]);  view_706 = None
        permute_906: "f32[11, 32]" = torch.ops.aten.permute.default(view_704, [1, 0]);  view_704 = None
        permute_907: "f32[16, 32]" = torch.ops.aten.permute.default(view_702, [1, 0]);  view_702 = None
        permute_908: "f32[11, 32]" = torch.ops.aten.permute.default(view_700, [1, 0]);  view_700 = None
        permute_909: "f32[16, 32]" = torch.ops.aten.permute.default(view_698, [1, 0]);  view_698 = None
        permute_910: "f32[11, 32]" = torch.ops.aten.permute.default(view_696, [1, 0]);  view_696 = None
        permute_911: "f32[16, 32]" = torch.ops.aten.permute.default(view_694, [1, 0]);  view_694 = None
        permute_912: "f32[11, 32]" = torch.ops.aten.permute.default(view_692, [1, 0]);  view_692 = None
        permute_913: "f32[16, 32]" = torch.ops.aten.permute.default(view_690, [1, 0]);  view_690 = None
        permute_914: "f32[11, 32]" = torch.ops.aten.permute.default(view_688, [1, 0]);  view_688 = None
        permute_915: "f32[16, 32]" = torch.ops.aten.permute.default(view_686, [1, 0]);  view_686 = None
        permute_916: "f32[11, 32]" = torch.ops.aten.permute.default(view_684, [1, 0]);  view_684 = None
        permute_917: "f32[16, 32]" = torch.ops.aten.permute.default(view_682, [1, 0]);  view_682 = None
        permute_918: "f32[11, 32]" = torch.ops.aten.permute.default(view_680, [1, 0]);  view_680 = None
        permute_919: "f32[16, 32]" = torch.ops.aten.permute.default(view_678, [1, 0]);  view_678 = None
        permute_920: "f32[11, 32]" = torch.ops.aten.permute.default(view_676, [1, 0]);  view_676 = None
        permute_921: "f32[16, 32]" = torch.ops.aten.permute.default(view_674, [1, 0]);  view_674 = None
        permute_922: "f32[11, 32]" = torch.ops.aten.permute.default(view_672, [1, 0]);  view_672 = None
        permute_923: "f32[16, 32]" = torch.ops.aten.permute.default(view_670, [1, 0]);  view_670 = None
        permute_924: "f32[11, 32]" = torch.ops.aten.permute.default(view_668, [1, 0]);  view_668 = None
        permute_925: "f32[16, 32]" = torch.ops.aten.permute.default(view_666, [1, 0]);  view_666 = None
        permute_926: "f32[11, 32]" = torch.ops.aten.permute.default(view_664, [1, 0]);  view_664 = None
        permute_927: "f32[16, 32]" = torch.ops.aten.permute.default(view_662, [1, 0]);  view_662 = None
        permute_928: "f32[11, 32]" = torch.ops.aten.permute.default(view_660, [1, 0]);  view_660 = None
        permute_929: "f32[16, 32]" = torch.ops.aten.permute.default(view_658, [1, 0]);  view_658 = None
        permute_930: "f32[11, 32]" = torch.ops.aten.permute.default(view_656, [1, 0]);  view_656 = None
        permute_931: "f32[16, 32]" = torch.ops.aten.permute.default(view_654, [1, 0]);  view_654 = None
        permute_932: "f32[11, 32]" = torch.ops.aten.permute.default(view_652, [1, 0]);  view_652 = None
        permute_933: "f32[16, 32]" = torch.ops.aten.permute.default(view_650, [1, 0]);  view_650 = None
        permute_934: "f32[11, 32]" = torch.ops.aten.permute.default(view_648, [1, 0]);  view_648 = None
        permute_935: "f32[16, 32]" = torch.ops.aten.permute.default(view_646, [1, 0]);  view_646 = None
        permute_936: "f32[11, 32]" = torch.ops.aten.permute.default(view_644, [1, 0]);  view_644 = None
        permute_937: "f32[16, 32]" = torch.ops.aten.permute.default(view_642, [1, 0]);  view_642 = None
        permute_938: "f32[11, 32]" = torch.ops.aten.permute.default(view_640, [1, 0]);  view_640 = None
        permute_939: "f32[16, 32]" = torch.ops.aten.permute.default(view_638, [1, 0]);  view_638 = None
        permute_940: "f32[11, 32]" = torch.ops.aten.permute.default(view_636, [1, 0]);  view_636 = None
        permute_941: "f32[16, 32]" = torch.ops.aten.permute.default(view_634, [1, 0]);  view_634 = None
        permute_942: "f32[11, 32]" = torch.ops.aten.permute.default(view_632, [1, 0]);  view_632 = None
        permute_943: "f32[16, 32]" = torch.ops.aten.permute.default(view_630, [1, 0]);  view_630 = None
        permute_944: "f32[11, 32]" = torch.ops.aten.permute.default(view_628, [1, 0]);  view_628 = None
        permute_945: "f32[16, 32]" = torch.ops.aten.permute.default(view_626, [1, 0]);  view_626 = None
        permute_946: "f32[11, 32]" = torch.ops.aten.permute.default(view_624, [1, 0]);  view_624 = None
        permute_947: "f32[16, 32]" = torch.ops.aten.permute.default(view_622, [1, 0]);  view_622 = None
        permute_948: "f32[11, 32]" = torch.ops.aten.permute.default(view_620, [1, 0]);  view_620 = None
        permute_949: "f32[16, 32]" = torch.ops.aten.permute.default(view_618, [1, 0]);  view_618 = None
        permute_950: "f32[11, 32]" = torch.ops.aten.permute.default(view_616, [1, 0]);  view_616 = None
        permute_951: "f32[16, 32]" = torch.ops.aten.permute.default(view_614, [1, 0]);  view_614 = None
        permute_952: "f32[11, 32]" = torch.ops.aten.permute.default(view_612, [1, 0]);  view_612 = None
        permute_953: "f32[16, 32]" = torch.ops.aten.permute.default(view_610, [1, 0]);  view_610 = None
        permute_954: "f32[11, 32]" = torch.ops.aten.permute.default(view_608, [1, 0]);  view_608 = None
        permute_955: "f32[16, 32]" = torch.ops.aten.permute.default(view_606, [1, 0]);  view_606 = None
        permute_956: "f32[11, 32]" = torch.ops.aten.permute.default(view_604, [1, 0]);  view_604 = None
        permute_957: "f32[16, 32]" = torch.ops.aten.permute.default(view_602, [1, 0]);  view_602 = None
        permute_958: "f32[11, 32]" = torch.ops.aten.permute.default(view_600, [1, 0]);  view_600 = None
        permute_959: "f32[16, 32]" = torch.ops.aten.permute.default(view_598, [1, 0]);  view_598 = None
        permute_960: "f32[11, 32]" = torch.ops.aten.permute.default(view_596, [1, 0]);  view_596 = None
        permute_961: "f32[16, 32]" = torch.ops.aten.permute.default(view_594, [1, 0]);  view_594 = None
        permute_962: "f32[11, 32]" = torch.ops.aten.permute.default(view_592, [1, 0]);  view_592 = None
        permute_963: "f32[16, 32]" = torch.ops.aten.permute.default(view_590, [1, 0]);  view_590 = None
        permute_964: "f32[11, 32]" = torch.ops.aten.permute.default(view_588, [1, 0]);  view_588 = None
        permute_965: "f32[16, 32]" = torch.ops.aten.permute.default(view_586, [1, 0]);  view_586 = None
        permute_966: "f32[11, 32]" = torch.ops.aten.permute.default(view_584, [1, 0]);  view_584 = None
        permute_967: "f32[16, 32]" = torch.ops.aten.permute.default(view_582, [1, 0]);  view_582 = None
        permute_968: "f32[11, 32]" = torch.ops.aten.permute.default(view_580, [1, 0]);  view_580 = None
        permute_969: "f32[16, 32]" = torch.ops.aten.permute.default(view_578, [1, 0]);  view_578 = None
        permute_970: "f32[11, 32]" = torch.ops.aten.permute.default(view_576, [1, 0]);  view_576 = None
        permute_971: "f32[16, 32]" = torch.ops.aten.permute.default(view_574, [1, 0]);  view_574 = None
        permute_972: "f32[11, 32]" = torch.ops.aten.permute.default(view_572, [1, 0]);  view_572 = None
        permute_973: "f32[16, 32]" = torch.ops.aten.permute.default(view_570, [1, 0]);  view_570 = None
        permute_974: "f32[11, 32]" = torch.ops.aten.permute.default(view_568, [1, 0]);  view_568 = None
        permute_975: "f32[16, 32]" = torch.ops.aten.permute.default(view_566, [1, 0]);  view_566 = None
        permute_976: "f32[11, 32]" = torch.ops.aten.permute.default(view_564, [1, 0]);  view_564 = None
        permute_977: "f32[16, 32]" = torch.ops.aten.permute.default(view_562, [1, 0]);  view_562 = None
        permute_978: "f32[11, 32]" = torch.ops.aten.permute.default(view_560, [1, 0]);  view_560 = None
        permute_979: "f32[16, 32]" = torch.ops.aten.permute.default(view_558, [1, 0]);  view_558 = None
        permute_980: "f32[11, 32]" = torch.ops.aten.permute.default(view_556, [1, 0]);  view_556 = None
        permute_981: "f32[16, 32]" = torch.ops.aten.permute.default(view_554, [1, 0]);  view_554 = None
        permute_982: "f32[11, 32]" = torch.ops.aten.permute.default(view_552, [1, 0]);  view_552 = None
        permute_983: "f32[16, 32]" = torch.ops.aten.permute.default(view_550, [1, 0]);  view_550 = None
        permute_984: "f32[11, 32]" = torch.ops.aten.permute.default(view_548, [1, 0]);  view_548 = None
        permute_985: "f32[16, 32]" = torch.ops.aten.permute.default(view_546, [1, 0]);  view_546 = None
        permute_986: "f32[11, 32]" = torch.ops.aten.permute.default(view_544, [1, 0]);  view_544 = None
        permute_987: "f32[16, 32]" = torch.ops.aten.permute.default(view_542, [1, 0]);  view_542 = None
        permute_988: "f32[11, 32]" = torch.ops.aten.permute.default(view_540, [1, 0]);  view_540 = None
        permute_989: "f32[16, 32]" = torch.ops.aten.permute.default(view_538, [1, 0]);  view_538 = None
        permute_990: "f32[11, 32]" = torch.ops.aten.permute.default(view_536, [1, 0]);  view_536 = None
        permute_991: "f32[16, 32]" = torch.ops.aten.permute.default(view_534, [1, 0]);  view_534 = None
        permute_992: "f32[11, 32]" = torch.ops.aten.permute.default(view_532, [1, 0]);  view_532 = None
        permute_993: "f32[16, 32]" = torch.ops.aten.permute.default(view_530, [1, 0]);  view_530 = None
        permute_994: "f32[11, 32]" = torch.ops.aten.permute.default(view_528, [1, 0]);  view_528 = None
        permute_995: "f32[16, 32]" = torch.ops.aten.permute.default(view_526, [1, 0]);  view_526 = None
        permute_996: "f32[11, 32]" = torch.ops.aten.permute.default(view_524, [1, 0]);  view_524 = None
        permute_997: "f32[16, 32]" = torch.ops.aten.permute.default(view_522, [1, 0]);  view_522 = None
        permute_998: "f32[11, 32]" = torch.ops.aten.permute.default(view_520, [1, 0]);  view_520 = None
        permute_999: "f32[16, 32]" = torch.ops.aten.permute.default(view_518, [1, 0]);  view_518 = None
        permute_1000: "f32[11, 32]" = torch.ops.aten.permute.default(view_516, [1, 0]);  view_516 = None
        permute_1001: "f32[16, 32]" = torch.ops.aten.permute.default(view_514, [1, 0]);  view_514 = None
        permute_1002: "f32[11, 32]" = torch.ops.aten.permute.default(view_512, [1, 0]);  view_512 = None
        permute_1003: "f32[16, 32]" = torch.ops.aten.permute.default(view_510, [1, 0]);  view_510 = None
        permute_1004: "f32[11, 32]" = torch.ops.aten.permute.default(view_508, [1, 0]);  view_508 = None
        permute_1005: "f32[16, 32]" = torch.ops.aten.permute.default(view_506, [1, 0]);  view_506 = None
        permute_1006: "f32[11, 32]" = torch.ops.aten.permute.default(view_504, [1, 0]);  view_504 = None
        permute_1007: "f32[16, 32]" = torch.ops.aten.permute.default(view_502, [1, 0]);  view_502 = None
        permute_1008: "f32[11, 32]" = torch.ops.aten.permute.default(view_500, [1, 0]);  view_500 = None
        permute_1009: "f32[16, 32]" = torch.ops.aten.permute.default(view_498, [1, 0]);  view_498 = None
        permute_1010: "f32[11, 32]" = torch.ops.aten.permute.default(view_496, [1, 0]);  view_496 = None
        permute_1011: "f32[16, 32]" = torch.ops.aten.permute.default(view_494, [1, 0]);  view_494 = None
        permute_1012: "f32[11, 32]" = torch.ops.aten.permute.default(view_492, [1, 0]);  view_492 = None
        permute_1013: "f32[16, 32]" = torch.ops.aten.permute.default(view_490, [1, 0]);  view_490 = None
        permute_1014: "f32[11, 32]" = torch.ops.aten.permute.default(view_488, [1, 0]);  view_488 = None
        permute_1015: "f32[16, 32]" = torch.ops.aten.permute.default(view_486, [1, 0]);  view_486 = None
        permute_1016: "f32[11, 32]" = torch.ops.aten.permute.default(view_484, [1, 0]);  view_484 = None
        permute_1017: "f32[16, 32]" = torch.ops.aten.permute.default(view_482, [1, 0]);  view_482 = None
        permute_1018: "f32[11, 32]" = torch.ops.aten.permute.default(view_480, [1, 0]);  view_480 = None
        permute_1019: "f32[16, 32]" = torch.ops.aten.permute.default(view_478, [1, 0]);  view_478 = None
        permute_1020: "f32[11, 32]" = torch.ops.aten.permute.default(view_476, [1, 0]);  view_476 = None
        permute_1021: "f32[16, 32]" = torch.ops.aten.permute.default(view_474, [1, 0]);  view_474 = None
        permute_1022: "f32[11, 32]" = torch.ops.aten.permute.default(view_472, [1, 0]);  view_472 = None
        permute_1023: "f32[16, 32]" = torch.ops.aten.permute.default(view_470, [1, 0]);  view_470 = None
        permute_1024: "f32[11, 32]" = torch.ops.aten.permute.default(view_468, [1, 0]);  view_468 = None
        permute_1025: "f32[16, 32]" = torch.ops.aten.permute.default(view_466, [1, 0]);  view_466 = None
        permute_1026: "f32[11, 32]" = torch.ops.aten.permute.default(view_464, [1, 0]);  view_464 = None
        permute_1027: "f32[16, 32]" = torch.ops.aten.permute.default(view_462, [1, 0]);  view_462 = None
        permute_1028: "f32[11, 32]" = torch.ops.aten.permute.default(view_460, [1, 0]);  view_460 = None
        permute_1029: "f32[16, 32]" = torch.ops.aten.permute.default(view_458, [1, 0]);  view_458 = None
        permute_1030: "f32[11, 32]" = torch.ops.aten.permute.default(view_456, [1, 0]);  view_456 = None
        permute_1031: "f32[16, 32]" = torch.ops.aten.permute.default(view_454, [1, 0]);  view_454 = None
        permute_1032: "f32[11, 32]" = torch.ops.aten.permute.default(view_452, [1, 0]);  view_452 = None
        permute_1033: "f32[16, 32]" = torch.ops.aten.permute.default(view_450, [1, 0]);  view_450 = None
        permute_1034: "f32[11, 32]" = torch.ops.aten.permute.default(view_448, [1, 0]);  view_448 = None
        permute_1035: "f32[16, 32]" = torch.ops.aten.permute.default(view_446, [1, 0]);  view_446 = None
        permute_1036: "f32[11, 32]" = torch.ops.aten.permute.default(view_444, [1, 0]);  view_444 = None
        permute_1037: "f32[16, 32]" = torch.ops.aten.permute.default(view_442, [1, 0]);  view_442 = None
        permute_1038: "f32[11, 32]" = torch.ops.aten.permute.default(view_440, [1, 0]);  view_440 = None
        permute_1039: "f32[16, 32]" = torch.ops.aten.permute.default(view_438, [1, 0]);  view_438 = None
        permute_1040: "f32[11, 32]" = torch.ops.aten.permute.default(view_436, [1, 0]);  view_436 = None
        permute_1041: "f32[16, 32]" = torch.ops.aten.permute.default(view_434, [1, 0]);  view_434 = None
        permute_1042: "f32[11, 32]" = torch.ops.aten.permute.default(view_432, [1, 0]);  view_432 = None
        permute_1043: "f32[16, 32]" = torch.ops.aten.permute.default(view_430, [1, 0]);  view_430 = None
        permute_1044: "f32[11, 32]" = torch.ops.aten.permute.default(view_428, [1, 0]);  view_428 = None
        permute_1045: "f32[16, 32]" = torch.ops.aten.permute.default(view_426, [1, 0]);  view_426 = None
        permute_1046: "f32[11, 32]" = torch.ops.aten.permute.default(view_424, [1, 0]);  view_424 = None
        permute_1047: "f32[16, 32]" = torch.ops.aten.permute.default(view_422, [1, 0]);  view_422 = None
        permute_1048: "f32[11, 32]" = torch.ops.aten.permute.default(view_420, [1, 0]);  view_420 = None
        permute_1049: "f32[16, 32]" = torch.ops.aten.permute.default(view_418, [1, 0]);  view_418 = None
        permute_1050: "f32[11, 32]" = torch.ops.aten.permute.default(view_416, [1, 0]);  view_416 = None
        permute_1051: "f32[16, 32]" = torch.ops.aten.permute.default(view_414, [1, 0]);  view_414 = None
        permute_1052: "f32[11, 32]" = torch.ops.aten.permute.default(view_412, [1, 0]);  view_412 = None
        permute_1053: "f32[16, 32]" = torch.ops.aten.permute.default(view_410, [1, 0]);  view_410 = None
        permute_1054: "f32[11, 32]" = torch.ops.aten.permute.default(view_408, [1, 0]);  view_408 = None
        permute_1055: "f32[16, 32]" = torch.ops.aten.permute.default(view_406, [1, 0]);  view_406 = None
        permute_1056: "f32[11, 32]" = torch.ops.aten.permute.default(view_404, [1, 0]);  view_404 = None
        permute_1057: "f32[16, 32]" = torch.ops.aten.permute.default(view_402, [1, 0]);  view_402 = None
        permute_1058: "f32[11, 32]" = torch.ops.aten.permute.default(view_400, [1, 0]);  view_400 = None
        permute_1059: "f32[16, 32]" = torch.ops.aten.permute.default(view_398, [1, 0]);  view_398 = None
        permute_1060: "f32[11, 32]" = torch.ops.aten.permute.default(view_396, [1, 0]);  view_396 = None
        permute_1061: "f32[16, 32]" = torch.ops.aten.permute.default(view_394, [1, 0]);  view_394 = None
        permute_1062: "f32[11, 32]" = torch.ops.aten.permute.default(view_392, [1, 0]);  view_392 = None
        permute_1063: "f32[16, 32]" = torch.ops.aten.permute.default(view_390, [1, 0]);  view_390 = None
        permute_1064: "f32[11, 32]" = torch.ops.aten.permute.default(view_388, [1, 0]);  view_388 = None
        permute_1065: "f32[16, 32]" = torch.ops.aten.permute.default(view_386, [1, 0]);  view_386 = None
        permute_1066: "f32[11, 32]" = torch.ops.aten.permute.default(view_384, [1, 0]);  view_384 = None
        permute_1067: "f32[16, 32]" = torch.ops.aten.permute.default(view_382, [1, 0]);  view_382 = None
        permute_1068: "f32[11, 32]" = torch.ops.aten.permute.default(view_380, [1, 0]);  view_380 = None
        permute_1069: "f32[16, 32]" = torch.ops.aten.permute.default(view_378, [1, 0]);  view_378 = None
        permute_1070: "f32[11, 32]" = torch.ops.aten.permute.default(view_376, [1, 0]);  view_376 = None
        permute_1071: "f32[16, 32]" = torch.ops.aten.permute.default(view_374, [1, 0]);  view_374 = None
        permute_1072: "f32[11, 32]" = torch.ops.aten.permute.default(view_372, [1, 0]);  view_372 = None
        permute_1073: "f32[16, 32]" = torch.ops.aten.permute.default(view_370, [1, 0]);  view_370 = None
        permute_1074: "f32[11, 32]" = torch.ops.aten.permute.default(view_368, [1, 0]);  view_368 = None
        permute_1075: "f32[16, 32]" = torch.ops.aten.permute.default(view_366, [1, 0]);  view_366 = None
        permute_1076: "f32[11, 32]" = torch.ops.aten.permute.default(view_364, [1, 0]);  view_364 = None
        permute_1077: "f32[16, 32]" = torch.ops.aten.permute.default(view_362, [1, 0]);  view_362 = None
        permute_1078: "f32[11, 32]" = torch.ops.aten.permute.default(view_360, [1, 0]);  view_360 = None
        permute_1079: "f32[16, 32]" = torch.ops.aten.permute.default(view_358, [1, 0]);  view_358 = None
        permute_1080: "f32[11, 32]" = torch.ops.aten.permute.default(view_356, [1, 0]);  view_356 = None
        permute_1081: "f32[16, 32]" = torch.ops.aten.permute.default(view_354, [1, 0]);  view_354 = None
        permute_1082: "f32[11, 32]" = torch.ops.aten.permute.default(view_352, [1, 0]);  view_352 = None
        permute_1083: "f32[16, 32]" = torch.ops.aten.permute.default(view_350, [1, 0]);  view_350 = None
        permute_1084: "f32[11, 32]" = torch.ops.aten.permute.default(view_348, [1, 0]);  view_348 = None
        permute_1085: "f32[16, 32]" = torch.ops.aten.permute.default(view_346, [1, 0]);  view_346 = None
        permute_1086: "f32[11, 32]" = torch.ops.aten.permute.default(view_344, [1, 0]);  view_344 = None
        permute_1087: "f32[16, 32]" = torch.ops.aten.permute.default(view_342, [1, 0]);  view_342 = None
        permute_1088: "f32[11, 32]" = torch.ops.aten.permute.default(view_340, [1, 0]);  view_340 = None
        permute_1089: "f32[16, 32]" = torch.ops.aten.permute.default(view_338, [1, 0]);  view_338 = None
        permute_1090: "f32[11, 32]" = torch.ops.aten.permute.default(view_336, [1, 0]);  view_336 = None
        permute_1091: "f32[16, 32]" = torch.ops.aten.permute.default(view_334, [1, 0]);  view_334 = None
        permute_1092: "f32[11, 32]" = torch.ops.aten.permute.default(view_332, [1, 0]);  view_332 = None
        permute_1093: "f32[16, 32]" = torch.ops.aten.permute.default(view_330, [1, 0]);  view_330 = None
        permute_1094: "f32[11, 32]" = torch.ops.aten.permute.default(view_328, [1, 0]);  view_328 = None
        permute_1095: "f32[16, 32]" = torch.ops.aten.permute.default(view_326, [1, 0]);  view_326 = None
        permute_1096: "f32[11, 32]" = torch.ops.aten.permute.default(view_324, [1, 0]);  view_324 = None
        permute_1097: "f32[16, 32]" = torch.ops.aten.permute.default(view_322, [1, 0]);  view_322 = None
        permute_1098: "f32[11, 32]" = torch.ops.aten.permute.default(view_320, [1, 0]);  view_320 = None
        permute_1099: "f32[16, 32]" = torch.ops.aten.permute.default(view_318, [1, 0]);  view_318 = None
        permute_1100: "f32[11, 32]" = torch.ops.aten.permute.default(view_316, [1, 0]);  view_316 = None
        permute_1101: "f32[16, 32]" = torch.ops.aten.permute.default(view_314, [1, 0]);  view_314 = None
        permute_1102: "f32[11, 32]" = torch.ops.aten.permute.default(view_312, [1, 0]);  view_312 = None
        permute_1103: "f32[16, 32]" = torch.ops.aten.permute.default(view_310, [1, 0]);  view_310 = None
        permute_1104: "f32[11, 32]" = torch.ops.aten.permute.default(view_308, [1, 0]);  view_308 = None
        permute_1105: "f32[16, 32]" = torch.ops.aten.permute.default(view_306, [1, 0]);  view_306 = None
        permute_1106: "f32[11, 32]" = torch.ops.aten.permute.default(view_304, [1, 0]);  view_304 = None
        permute_1107: "f32[16, 32]" = torch.ops.aten.permute.default(view_302, [1, 0]);  view_302 = None
        permute_1108: "f32[11, 32]" = torch.ops.aten.permute.default(view_300, [1, 0]);  view_300 = None
        permute_1109: "f32[16, 32]" = torch.ops.aten.permute.default(view_298, [1, 0]);  view_298 = None
        permute_1110: "f32[11, 32]" = torch.ops.aten.permute.default(view_296, [1, 0]);  view_296 = None
        permute_1111: "f32[16, 32]" = torch.ops.aten.permute.default(view_294, [1, 0]);  view_294 = None
        permute_1112: "f32[11, 32]" = torch.ops.aten.permute.default(view_292, [1, 0]);  view_292 = None
        permute_1113: "f32[16, 32]" = torch.ops.aten.permute.default(view_290, [1, 0]);  view_290 = None
        permute_1114: "f32[11, 32]" = torch.ops.aten.permute.default(view_288, [1, 0]);  view_288 = None
        permute_1115: "f32[16, 32]" = torch.ops.aten.permute.default(view_286, [1, 0]);  view_286 = None
        permute_1116: "f32[11, 32]" = torch.ops.aten.permute.default(view_284, [1, 0]);  view_284 = None
        permute_1117: "f32[16, 32]" = torch.ops.aten.permute.default(view_282, [1, 0]);  view_282 = None
        permute_1118: "f32[11, 32]" = torch.ops.aten.permute.default(view_280, [1, 0]);  view_280 = None
        permute_1119: "f32[16, 32]" = torch.ops.aten.permute.default(view_278, [1, 0]);  view_278 = None
        permute_1120: "f32[11, 32]" = torch.ops.aten.permute.default(view_276, [1, 0]);  view_276 = None
        permute_1121: "f32[16, 32]" = torch.ops.aten.permute.default(view_274, [1, 0]);  view_274 = None
        permute_1122: "f32[11, 32]" = torch.ops.aten.permute.default(view_272, [1, 0]);  view_272 = None
        permute_1123: "f32[16, 32]" = torch.ops.aten.permute.default(view_270, [1, 0]);  view_270 = None
        permute_1124: "f32[11, 32]" = torch.ops.aten.permute.default(view_268, [1, 0]);  view_268 = None
        permute_1125: "f32[16, 32]" = torch.ops.aten.permute.default(view_266, [1, 0]);  view_266 = None
        permute_1126: "f32[11, 32]" = torch.ops.aten.permute.default(view_264, [1, 0]);  view_264 = None
        permute_1127: "f32[16, 32]" = torch.ops.aten.permute.default(view_262, [1, 0]);  view_262 = None
        permute_1128: "f32[11, 32]" = torch.ops.aten.permute.default(view_260, [1, 0]);  view_260 = None
        permute_1129: "f32[16, 32]" = torch.ops.aten.permute.default(view_258, [1, 0]);  view_258 = None
        permute_1130: "f32[11, 32]" = torch.ops.aten.permute.default(view_256, [1, 0]);  view_256 = None
        permute_1131: "f32[16, 32]" = torch.ops.aten.permute.default(view_254, [1, 0]);  view_254 = None
        permute_1132: "f32[11, 32]" = torch.ops.aten.permute.default(view_252, [1, 0]);  view_252 = None
        permute_1133: "f32[16, 32]" = torch.ops.aten.permute.default(view_250, [1, 0]);  view_250 = None
        permute_1134: "f32[11, 32]" = torch.ops.aten.permute.default(view_248, [1, 0]);  view_248 = None
        permute_1135: "f32[16, 32]" = torch.ops.aten.permute.default(view_246, [1, 0]);  view_246 = None
        permute_1136: "f32[11, 32]" = torch.ops.aten.permute.default(view_244, [1, 0]);  view_244 = None
        permute_1137: "f32[16, 32]" = torch.ops.aten.permute.default(view_242, [1, 0]);  view_242 = None
        permute_1138: "f32[11, 32]" = torch.ops.aten.permute.default(view_240, [1, 0]);  view_240 = None
        permute_1139: "f32[16, 32]" = torch.ops.aten.permute.default(view_238, [1, 0]);  view_238 = None
        permute_1140: "f32[11, 32]" = torch.ops.aten.permute.default(view_236, [1, 0]);  view_236 = None
        permute_1141: "f32[16, 32]" = torch.ops.aten.permute.default(view_234, [1, 0]);  view_234 = None
        permute_1142: "f32[11, 32]" = torch.ops.aten.permute.default(view_232, [1, 0]);  view_232 = None
        permute_1143: "f32[16, 32]" = torch.ops.aten.permute.default(view_230, [1, 0]);  view_230 = None
        permute_1144: "f32[11, 32]" = torch.ops.aten.permute.default(view_228, [1, 0]);  view_228 = None
        permute_1145: "f32[16, 32]" = torch.ops.aten.permute.default(view_226, [1, 0]);  view_226 = None
        permute_1146: "f32[11, 32]" = torch.ops.aten.permute.default(view_224, [1, 0]);  view_224 = None
        permute_1147: "f32[16, 32]" = torch.ops.aten.permute.default(view_222, [1, 0]);  view_222 = None
        permute_1148: "f32[11, 32]" = torch.ops.aten.permute.default(view_220, [1, 0]);  view_220 = None
        permute_1149: "f32[16, 32]" = torch.ops.aten.permute.default(view_218, [1, 0]);  view_218 = None
        permute_1150: "f32[11, 32]" = torch.ops.aten.permute.default(view_216, [1, 0]);  view_216 = None
        permute_1151: "f32[16, 32]" = torch.ops.aten.permute.default(view_214, [1, 0]);  view_214 = None
        permute_1152: "f32[11, 32]" = torch.ops.aten.permute.default(view_212, [1, 0]);  view_212 = None
        permute_1153: "f32[16, 32]" = torch.ops.aten.permute.default(view_210, [1, 0]);  view_210 = None
        permute_1154: "f32[11, 32]" = torch.ops.aten.permute.default(view_208, [1, 0]);  view_208 = None
        permute_1155: "f32[16, 32]" = torch.ops.aten.permute.default(view_206, [1, 0]);  view_206 = None
        permute_1156: "f32[11, 32]" = torch.ops.aten.permute.default(view_204, [1, 0]);  view_204 = None
        permute_1157: "f32[16, 32]" = torch.ops.aten.permute.default(view_202, [1, 0]);  view_202 = None
        permute_1158: "f32[11, 32]" = torch.ops.aten.permute.default(view_200, [1, 0]);  view_200 = None
        permute_1159: "f32[16, 32]" = torch.ops.aten.permute.default(view_198, [1, 0]);  view_198 = None
        permute_1160: "f32[11, 32]" = torch.ops.aten.permute.default(view_196, [1, 0]);  view_196 = None
        permute_1161: "f32[16, 32]" = torch.ops.aten.permute.default(view_194, [1, 0]);  view_194 = None
        permute_1162: "f32[11, 32]" = torch.ops.aten.permute.default(view_192, [1, 0]);  view_192 = None
        permute_1163: "f32[16, 32]" = torch.ops.aten.permute.default(view_190, [1, 0]);  view_190 = None
        permute_1164: "f32[11, 32]" = torch.ops.aten.permute.default(view_188, [1, 0]);  view_188 = None
        permute_1165: "f32[16, 32]" = torch.ops.aten.permute.default(view_186, [1, 0]);  view_186 = None
        permute_1166: "f32[11, 32]" = torch.ops.aten.permute.default(view_184, [1, 0]);  view_184 = None
        permute_1167: "f32[16, 32]" = torch.ops.aten.permute.default(view_182, [1, 0]);  view_182 = None
        permute_1168: "f32[11, 32]" = torch.ops.aten.permute.default(view_180, [1, 0]);  view_180 = None
        permute_1169: "f32[16, 32]" = torch.ops.aten.permute.default(view_178, [1, 0]);  view_178 = None
        permute_1170: "f32[11, 32]" = torch.ops.aten.permute.default(view_176, [1, 0]);  view_176 = None
        permute_1171: "f32[16, 32]" = torch.ops.aten.permute.default(view_174, [1, 0]);  view_174 = None
        permute_1172: "f32[11, 32]" = torch.ops.aten.permute.default(view_172, [1, 0]);  view_172 = None
        permute_1173: "f32[16, 32]" = torch.ops.aten.permute.default(view_170, [1, 0]);  view_170 = None
        permute_1174: "f32[11, 32]" = torch.ops.aten.permute.default(view_168, [1, 0]);  view_168 = None
        permute_1175: "f32[16, 32]" = torch.ops.aten.permute.default(view_166, [1, 0]);  view_166 = None
        permute_1176: "f32[11, 32]" = torch.ops.aten.permute.default(view_164, [1, 0]);  view_164 = None
        permute_1177: "f32[16, 32]" = torch.ops.aten.permute.default(view_162, [1, 0]);  view_162 = None
        permute_1178: "f32[11, 32]" = torch.ops.aten.permute.default(view_160, [1, 0]);  view_160 = None
        permute_1179: "f32[16, 32]" = torch.ops.aten.permute.default(view_158, [1, 0]);  view_158 = None
        permute_1180: "f32[11, 32]" = torch.ops.aten.permute.default(view_156, [1, 0]);  view_156 = None
        permute_1181: "f32[16, 32]" = torch.ops.aten.permute.default(view_154, [1, 0]);  view_154 = None
        permute_1182: "f32[11, 32]" = torch.ops.aten.permute.default(view_152, [1, 0]);  view_152 = None
        permute_1183: "f32[16, 32]" = torch.ops.aten.permute.default(view_150, [1, 0]);  view_150 = None
        permute_1184: "f32[11, 32]" = torch.ops.aten.permute.default(view_148, [1, 0]);  view_148 = None
        permute_1185: "f32[16, 32]" = torch.ops.aten.permute.default(view_146, [1, 0]);  view_146 = None
        permute_1186: "f32[11, 32]" = torch.ops.aten.permute.default(view_144, [1, 0]);  view_144 = None
        permute_1187: "f32[16, 32]" = torch.ops.aten.permute.default(view_142, [1, 0]);  view_142 = None
        permute_1188: "f32[11, 32]" = torch.ops.aten.permute.default(view_140, [1, 0]);  view_140 = None
        permute_1189: "f32[16, 32]" = torch.ops.aten.permute.default(view_138, [1, 0]);  view_138 = None
        permute_1190: "f32[11, 32]" = torch.ops.aten.permute.default(view_136, [1, 0]);  view_136 = None
        permute_1191: "f32[16, 32]" = torch.ops.aten.permute.default(view_134, [1, 0]);  view_134 = None
        permute_1192: "f32[11, 32]" = torch.ops.aten.permute.default(view_132, [1, 0]);  view_132 = None
        permute_1193: "f32[16, 32]" = torch.ops.aten.permute.default(view_130, [1, 0]);  view_130 = None
        permute_1194: "f32[11, 32]" = torch.ops.aten.permute.default(view_128, [1, 0]);  view_128 = None
        permute_1195: "f32[16, 32]" = torch.ops.aten.permute.default(view_126, [1, 0]);  view_126 = None
        permute_1196: "f32[11, 32]" = torch.ops.aten.permute.default(view_124, [1, 0]);  view_124 = None
        permute_1197: "f32[16, 32]" = torch.ops.aten.permute.default(view_122, [1, 0]);  view_122 = None
        permute_1198: "f32[11, 32]" = torch.ops.aten.permute.default(view_120, [1, 0]);  view_120 = None
        permute_1199: "f32[16, 32]" = torch.ops.aten.permute.default(view_118, [1, 0]);  view_118 = None
        permute_1200: "f32[11, 32]" = torch.ops.aten.permute.default(view_116, [1, 0]);  view_116 = None
        permute_1201: "f32[16, 32]" = torch.ops.aten.permute.default(view_114, [1, 0]);  view_114 = None
        permute_1202: "f32[11, 32]" = torch.ops.aten.permute.default(view_112, [1, 0]);  view_112 = None
        permute_1203: "f32[16, 32]" = torch.ops.aten.permute.default(view_110, [1, 0]);  view_110 = None
        permute_1204: "f32[11, 32]" = torch.ops.aten.permute.default(view_108, [1, 0]);  view_108 = None
        permute_1205: "f32[16, 32]" = torch.ops.aten.permute.default(view_106, [1, 0]);  view_106 = None
        permute_1206: "f32[11, 32]" = torch.ops.aten.permute.default(view_104, [1, 0]);  view_104 = None
        permute_1207: "f32[16, 32]" = torch.ops.aten.permute.default(view_102, [1, 0]);  view_102 = None
        permute_1208: "f32[11, 32]" = torch.ops.aten.permute.default(view_100, [1, 0]);  view_100 = None
        permute_1209: "f32[16, 32]" = torch.ops.aten.permute.default(view_98, [1, 0]);  view_98 = None
        permute_1210: "f32[11, 32]" = torch.ops.aten.permute.default(view_96, [1, 0]);  view_96 = None
        permute_1211: "f32[16, 32]" = torch.ops.aten.permute.default(view_94, [1, 0]);  view_94 = None
        permute_1212: "f32[11, 32]" = torch.ops.aten.permute.default(view_92, [1, 0]);  view_92 = None
        permute_1213: "f32[16, 32]" = torch.ops.aten.permute.default(view_90, [1, 0]);  view_90 = None
        permute_1214: "f32[11, 32]" = torch.ops.aten.permute.default(view_88, [1, 0]);  view_88 = None
        permute_1215: "f32[16, 32]" = torch.ops.aten.permute.default(view_86, [1, 0]);  view_86 = None
        permute_1216: "f32[11, 32]" = torch.ops.aten.permute.default(view_84, [1, 0]);  view_84 = None
        permute_1217: "f32[16, 32]" = torch.ops.aten.permute.default(view_82, [1, 0]);  view_82 = None
        permute_1218: "f32[11, 32]" = torch.ops.aten.permute.default(view_80, [1, 0]);  view_80 = None
        permute_1219: "f32[16, 32]" = torch.ops.aten.permute.default(view_78, [1, 0]);  view_78 = None
        permute_1220: "f32[11, 32]" = torch.ops.aten.permute.default(view_76, [1, 0]);  view_76 = None
        permute_1221: "f32[16, 32]" = torch.ops.aten.permute.default(view_74, [1, 0]);  view_74 = None
        permute_1222: "f32[11, 32]" = torch.ops.aten.permute.default(view_72, [1, 0]);  view_72 = None
        permute_1223: "f32[16, 32]" = torch.ops.aten.permute.default(view_70, [1, 0]);  view_70 = None
        permute_1224: "f32[11, 32]" = torch.ops.aten.permute.default(view_68, [1, 0]);  view_68 = None
        permute_1225: "f32[16, 32]" = torch.ops.aten.permute.default(view_66, [1, 0]);  view_66 = None
        permute_1226: "f32[11, 32]" = torch.ops.aten.permute.default(view_64, [1, 0]);  view_64 = None
        permute_1227: "f32[16, 32]" = torch.ops.aten.permute.default(view_62, [1, 0]);  view_62 = None
        permute_1228: "f32[11, 32]" = torch.ops.aten.permute.default(view_60, [1, 0]);  view_60 = None
        permute_1229: "f32[16, 32]" = torch.ops.aten.permute.default(view_58, [1, 0]);  view_58 = None
        permute_1230: "f32[11, 32]" = torch.ops.aten.permute.default(view_56, [1, 0]);  view_56 = None
        permute_1231: "f32[16, 32]" = torch.ops.aten.permute.default(view_54, [1, 0]);  view_54 = None
        permute_1232: "f32[11, 32]" = torch.ops.aten.permute.default(view_52, [1, 0]);  view_52 = None
        permute_1233: "f32[16, 32]" = torch.ops.aten.permute.default(view_50, [1, 0]);  view_50 = None
        permute_1234: "f32[11, 32]" = torch.ops.aten.permute.default(view_48, [1, 0]);  view_48 = None
        permute_1235: "f32[16, 32]" = torch.ops.aten.permute.default(view_46, [1, 0]);  view_46 = None
        permute_1236: "f32[11, 32]" = torch.ops.aten.permute.default(view_44, [1, 0]);  view_44 = None
        permute_1237: "f32[16, 32]" = torch.ops.aten.permute.default(view_42, [1, 0]);  view_42 = None
        permute_1238: "f32[11, 32]" = torch.ops.aten.permute.default(view_40, [1, 0]);  view_40 = None
        permute_1239: "f32[16, 32]" = torch.ops.aten.permute.default(view_38, [1, 0]);  view_38 = None
        permute_1240: "f32[11, 32]" = torch.ops.aten.permute.default(view_36, [1, 0]);  view_36 = None
        permute_1241: "f32[16, 32]" = torch.ops.aten.permute.default(view_34, [1, 0]);  view_34 = None
        permute_1242: "f32[11, 32]" = torch.ops.aten.permute.default(view_32, [1, 0]);  view_32 = None
        permute_1243: "f32[16, 32]" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
        permute_1244: "f32[11, 32]" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
        permute_1245: "f32[16, 32]" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
        permute_1246: "f32[11, 32]" = torch.ops.aten.permute.default(view_24, [1, 0]);  view_24 = None
        permute_1247: "f32[16, 32]" = torch.ops.aten.permute.default(view_22, [1, 0]);  view_22 = None
        permute_1248: "f32[11, 32]" = torch.ops.aten.permute.default(view_20, [1, 0]);  view_20 = None
        permute_1249: "f32[16, 32]" = torch.ops.aten.permute.default(view_18, [1, 0]);  view_18 = None
        permute_1250: "f32[11, 32]" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
        permute_1251: "f32[16, 32]" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
        permute_1252: "f32[11, 32]" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
        permute_1253: "f32[16, 32]" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
        return (view_2510, full, permute_4, permute_5, permute_6, permute_7, permute_8, permute_9, permute_10, permute_11, permute_12, permute_13, permute_14, permute_15, permute_16, permute_17, permute_18, permute_19, permute_20, permute_21, permute_22, permute_23, permute_24, permute_25, permute_26, permute_27, permute_28, permute_29, permute_30, permute_31, permute_32, permute_33, permute_34, permute_35, permute_36, permute_37, permute_38, permute_39, permute_40, permute_41, permute_42, permute_43, permute_44, permute_45, permute_46, permute_47, permute_48, permute_49, permute_50, permute_51, permute_52, permute_53, permute_54, permute_55, permute_56, permute_57, permute_58, permute_59, permute_60, permute_61, permute_62, permute_63, permute_64, permute_65, permute_66, permute_67, permute_68, permute_69, permute_70, permute_71, permute_72, permute_73, permute_74, permute_75, permute_76, permute_77, permute_78, permute_79, permute_80, permute_81, permute_82, permute_83, permute_84, permute_85, permute_86, permute_87, permute_88, permute_89, permute_90, permute_91, permute_92, permute_93, permute_94, permute_95, permute_96, permute_97, permute_98, permute_99, permute_100, permute_101, permute_102, permute_103, permute_104, permute_105, permute_106, permute_107, permute_108, permute_109, permute_110, permute_111, permute_112, permute_113, permute_114, permute_115, permute_116, permute_117, permute_118, permute_119, permute_120, permute_121, permute_122, permute_123, permute_124, permute_125, permute_126, permute_127, permute_128, permute_129, permute_130, permute_131, permute_132, permute_133, permute_134, permute_135, permute_136, permute_137, permute_138, permute_139, permute_140, permute_141, permute_142, permute_143, permute_144, permute_145, permute_146, permute_147, permute_148, permute_149, permute_150, permute_151, permute_152, permute_153, permute_154, permute_155, permute_156, permute_157, permute_158, permute_159, permute_160, permute_161, permute_162, permute_163, permute_164, permute_165, permute_166, permute_167, permute_168, permute_169, permute_170, permute_171, permute_172, permute_173, permute_174, permute_175, permute_176, permute_177, permute_178, permute_179, permute_180, permute_181, permute_182, permute_183, permute_184, permute_185, permute_186, permute_187, permute_188, permute_189, permute_190, permute_191, permute_192, permute_193, permute_194, permute_195, permute_196, permute_197, permute_198, permute_199, permute_200, permute_201, permute_202, permute_203, permute_204, permute_205, permute_206, permute_207, permute_208, permute_209, permute_210, permute_211, permute_212, permute_213, permute_214, permute_215, permute_216, permute_217, permute_218, permute_219, permute_220, permute_221, permute_222, permute_223, permute_224, permute_225, permute_226, permute_227, permute_228, permute_229, permute_230, permute_231, permute_232, permute_233, permute_234, permute_235, permute_236, permute_237, permute_238, permute_239, permute_240, permute_241, permute_242, permute_243, permute_244, permute_245, permute_246, permute_247, permute_248, permute_249, permute_250, permute_251, permute_252, permute_253, permute_254, permute_255, permute_256, permute_257, permute_258, permute_259, permute_260, permute_261, permute_262, permute_263, permute_264, permute_265, permute_266, permute_267, permute_268, permute_269, permute_270, permute_271, permute_272, permute_273, permute_274, permute_275, permute_276, permute_277, permute_278, permute_279, permute_280, permute_281, permute_282, permute_283, permute_284, permute_285, permute_286, permute_287, permute_288, permute_289, permute_290, permute_291, permute_292, permute_293, permute_294, permute_295, permute_296, permute_297, permute_298, permute_299, permute_300, permute_301, permute_302, permute_303, permute_304, permute_305, permute_306, permute_307, permute_308, permute_309, permute_310, permute_311, permute_312, permute_313, permute_314, permute_315, permute_316, permute_317, permute_318, permute_319, permute_320, permute_321, permute_322, permute_323, permute_324, permute_325, permute_326, permute_327, permute_328, permute_329, permute_330, permute_331, permute_332, permute_333, permute_334, permute_335, permute_336, permute_337, permute_338, permute_339, permute_340, permute_341, permute_342, permute_343, permute_344, permute_345, permute_346, permute_347, permute_348, permute_349, permute_350, permute_351, permute_352, permute_353, permute_354, permute_355, permute_356, permute_357, permute_358, permute_359, permute_360, permute_361, permute_362, permute_363, permute_364, permute_365, permute_366, permute_367, permute_368, permute_369, permute_370, permute_371, permute_372, permute_373, permute_374, permute_375, permute_376, permute_377, permute_378, permute_379, permute_380, permute_381, permute_382, permute_383, permute_384, permute_385, permute_386, permute_387, permute_388, permute_389, permute_390, permute_391, permute_392, permute_393, permute_394, permute_395, permute_396, permute_397, permute_398, permute_399, permute_400, permute_401, permute_402, permute_403, permute_404, permute_405, permute_406, permute_407, permute_408, permute_409, permute_410, permute_411, permute_412, permute_413, permute_414, permute_415, permute_416, permute_417, permute_418, permute_419, permute_420, permute_421, permute_422, permute_423, permute_424, permute_425, permute_426, permute_427, permute_428, permute_429, permute_430, permute_431, permute_432, permute_433, permute_434, permute_435, permute_436, permute_437, permute_438, permute_439, permute_440, permute_441, permute_442, permute_443, permute_444, permute_445, permute_446, permute_447, permute_448, permute_449, permute_450, permute_451, permute_452, permute_453, permute_454, permute_455, permute_456, permute_457, permute_458, permute_459, permute_460, permute_461, permute_462, permute_463, permute_464, permute_465, permute_466, permute_467, permute_468, permute_469, permute_470, permute_471, permute_472, permute_473, permute_474, permute_475, permute_476, permute_477, permute_478, permute_479, permute_480, permute_481, permute_482, permute_483, permute_484, permute_485, permute_486, permute_487, permute_488, permute_489, permute_490, permute_491, permute_492, permute_493, permute_494, permute_495, permute_496, permute_497, permute_498, permute_499, permute_500, permute_501, permute_502, permute_503, permute_504, permute_505, permute_506, permute_507, permute_508, permute_509, permute_510, permute_511, permute_512, permute_513, permute_514, permute_515, permute_516, permute_517, permute_518, permute_519, permute_520, permute_521, permute_522, permute_523, permute_524, permute_525, permute_526, permute_527, permute_528, permute_529, permute_530, permute_531, permute_532, permute_533, permute_534, permute_535, permute_536, permute_537, permute_538, permute_539, permute_540, permute_541, permute_542, permute_543, permute_544, permute_545, permute_546, permute_547, permute_548, permute_549, permute_550, permute_551, permute_552, permute_553, permute_554, permute_555, permute_556, permute_557, permute_558, permute_559, permute_560, permute_561, permute_562, permute_563, permute_564, permute_565, permute_566, permute_567, permute_568, permute_569, permute_570, permute_571, permute_572, permute_573, permute_574, permute_575, permute_576, permute_577, permute_578, permute_579, permute_580, permute_581, permute_582, permute_583, permute_584, permute_585, permute_586, permute_587, permute_588, permute_589, permute_590, permute_591, permute_592, permute_593, permute_594, permute_595, permute_596, permute_597, permute_598, permute_599, permute_600, permute_601, permute_602, permute_603, permute_604, permute_605, permute_606, permute_607, permute_608, permute_609, permute_610, permute_611, permute_612, permute_613, permute_614, permute_615, permute_616, permute_617, permute_618, permute_619, permute_620, permute_621, permute_622, permute_623, permute_624, permute_625, permute_626, permute_627, permute_628, permute_629, permute_630, permute_631, permute_632, permute_633, permute_634, permute_635, permute_636, permute_637, permute_638, permute_639, permute_640, permute_641, permute_642, permute_643, permute_644, permute_645, permute_646, permute_647, permute_648, permute_649, permute_650, permute_651, permute_652, permute_653, permute_654, permute_655, permute_656, permute_657, permute_658, permute_659, permute_660, permute_661, permute_662, permute_663, permute_664, permute_665, permute_666, permute_667, permute_668, permute_669, permute_670, permute_671, permute_672, permute_673, permute_674, permute_675, permute_676, permute_677, permute_678, permute_679, permute_680, permute_681, permute_682, permute_683, permute_684, permute_685, permute_686, permute_687, permute_688, permute_689, permute_690, permute_691, permute_692, permute_693, permute_694, permute_695, permute_696, permute_697, permute_698, permute_699, permute_700, permute_701, permute_702, permute_703, permute_704, permute_705, permute_706, permute_707, permute_708, permute_709, permute_710, permute_711, permute_712, permute_713, permute_714, permute_715, permute_716, permute_717, permute_718, permute_719, permute_720, permute_721, permute_722, permute_723, permute_724, permute_725, permute_726, permute_727, permute_728, permute_729, permute_730, permute_731, permute_732, permute_733, permute_734, permute_735, permute_736, permute_737, permute_738, permute_739, permute_740, permute_741, permute_742, permute_743, permute_744, permute_745, permute_746, permute_747, permute_748, permute_749, permute_750, permute_751, permute_752, permute_753, permute_754, permute_755, permute_756, permute_757, permute_758, permute_759, permute_760, permute_761, permute_762, permute_763, permute_764, permute_765, permute_766, permute_767, permute_768, permute_769, permute_770, permute_771, permute_772, permute_773, permute_774, permute_775, permute_776, permute_777, permute_778, permute_779, permute_780, permute_781, permute_782, permute_783, permute_784, permute_785, permute_786, permute_787, permute_788, permute_789, permute_790, permute_791, permute_792, permute_793, permute_794, permute_795, permute_796, permute_797, permute_798, permute_799, permute_800, permute_801, permute_802, permute_803, permute_804, permute_805, permute_806, permute_807, permute_808, permute_809, permute_810, permute_811, permute_812, permute_813, permute_814, permute_815, permute_816, permute_817, permute_818, permute_819, permute_820, permute_821, permute_822, permute_823, permute_824, permute_825, permute_826, permute_827, permute_828, permute_829, permute_830, permute_831, permute_832, permute_833, permute_834, permute_835, permute_836, permute_837, permute_838, permute_839, permute_840, permute_841, permute_842, permute_843, permute_844, permute_845, permute_846, permute_847, permute_848, permute_849, permute_850, permute_851, permute_852, permute_853, permute_854, permute_855, permute_856, permute_857, permute_858, permute_859, permute_860, permute_861, permute_862, permute_863, permute_864, permute_865, permute_866, permute_867, permute_868, permute_869, permute_870, permute_871, permute_872, permute_873, permute_874, permute_875, permute_876, permute_877, permute_878, permute_879, permute_880, permute_881, permute_882, permute_883, permute_884, permute_885, permute_886, permute_887, permute_888, permute_889, permute_890, permute_891, permute_892, permute_893, permute_894, permute_895, permute_896, permute_897, permute_898, permute_899, permute_900, permute_901, permute_902, permute_903, permute_904, permute_905, permute_906, permute_907, permute_908, permute_909, permute_910, permute_911, permute_912, permute_913, permute_914, permute_915, permute_916, permute_917, permute_918, permute_919, permute_920, permute_921, permute_922, permute_923, permute_924, permute_925, permute_926, permute_927, permute_928, permute_929, permute_930, permute_931, permute_932, permute_933, permute_934, permute_935, permute_936, permute_937, permute_938, permute_939, permute_940, permute_941, permute_942, permute_943, permute_944, permute_945, permute_946, permute_947, permute_948, permute_949, permute_950, permute_951, permute_952, permute_953, permute_954, permute_955, permute_956, permute_957, permute_958, permute_959, permute_960, permute_961, permute_962, permute_963, permute_964, permute_965, permute_966, permute_967, permute_968, permute_969, permute_970, permute_971, permute_972, permute_973, permute_974, permute_975, permute_976, permute_977, permute_978, permute_979, permute_980, permute_981, permute_982, permute_983, permute_984, permute_985, permute_986, permute_987, permute_988, permute_989, permute_990, permute_991, permute_992, permute_993, permute_994, permute_995, permute_996, permute_997, permute_998, permute_999, permute_1000, permute_1001, permute_1002, permute_1003, permute_1004, permute_1005, permute_1006, permute_1007, permute_1008, permute_1009, permute_1010, permute_1011, permute_1012, permute_1013, permute_1014, permute_1015, permute_1016, permute_1017, permute_1018, permute_1019, permute_1020, permute_1021, permute_1022, permute_1023, permute_1024, permute_1025, permute_1026, permute_1027, permute_1028, permute_1029, permute_1030, permute_1031, permute_1032, permute_1033, permute_1034, permute_1035, permute_1036, permute_1037, permute_1038, permute_1039, permute_1040, permute_1041, permute_1042, permute_1043, permute_1044, permute_1045, permute_1046, permute_1047, permute_1048, permute_1049, permute_1050, permute_1051, permute_1052, permute_1053, permute_1054, permute_1055, permute_1056, permute_1057, permute_1058, permute_1059, permute_1060, permute_1061, permute_1062, permute_1063, permute_1064, permute_1065, permute_1066, permute_1067, permute_1068, permute_1069, permute_1070, permute_1071, permute_1072, permute_1073, permute_1074, permute_1075, permute_1076, permute_1077, permute_1078, permute_1079, permute_1080, permute_1081, permute_1082, permute_1083, permute_1084, permute_1085, permute_1086, permute_1087, permute_1088, permute_1089, permute_1090, permute_1091, permute_1092, permute_1093, permute_1094, permute_1095, permute_1096, permute_1097, permute_1098, permute_1099, permute_1100, permute_1101, permute_1102, permute_1103, permute_1104, permute_1105, permute_1106, permute_1107, permute_1108, permute_1109, permute_1110, permute_1111, permute_1112, permute_1113, permute_1114, permute_1115, permute_1116, permute_1117, permute_1118, permute_1119, permute_1120, permute_1121, permute_1122, permute_1123, permute_1124, permute_1125, permute_1126, permute_1127, permute_1128, permute_1129, permute_1130, permute_1131, permute_1132, permute_1133, permute_1134, permute_1135, permute_1136, permute_1137, permute_1138, permute_1139, permute_1140, permute_1141, permute_1142, permute_1143, permute_1144, permute_1145, permute_1146, permute_1147, permute_1148, permute_1149, permute_1150, permute_1151, permute_1152, permute_1153, permute_1154, permute_1155, permute_1156, permute_1157, permute_1158, permute_1159, permute_1160, permute_1161, permute_1162, permute_1163, permute_1164, permute_1165, permute_1166, permute_1167, permute_1168, permute_1169, permute_1170, permute_1171, permute_1172, permute_1173, permute_1174, permute_1175, permute_1176, permute_1177, permute_1178, permute_1179, permute_1180, permute_1181, permute_1182, permute_1183, permute_1184, permute_1185, permute_1186, permute_1187, permute_1188, permute_1189, permute_1190, permute_1191, permute_1192, permute_1193, permute_1194, permute_1195, permute_1196, permute_1197, permute_1198, permute_1199, permute_1200, permute_1201, permute_1202, permute_1203, permute_1204, permute_1205, permute_1206, permute_1207, permute_1208, permute_1209, permute_1210, permute_1211, permute_1212, permute_1213, permute_1214, permute_1215, permute_1216, permute_1217, permute_1218, permute_1219, permute_1220, permute_1221, permute_1222, permute_1223, permute_1224, permute_1225, permute_1226, permute_1227, permute_1228, permute_1229, permute_1230, permute_1231, permute_1232, permute_1233, permute_1234, permute_1235, permute_1236, permute_1237, permute_1238, permute_1239, permute_1240, permute_1241, permute_1242, permute_1243, permute_1244, permute_1245, permute_1246, permute_1247, permute_1248, permute_1249, permute_1250, permute_1251, permute_1252, permute_1253)
        